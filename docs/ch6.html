<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Complex Systems in Psychology - 6&nbsp; Psychological Network Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./ch5.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ch6.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Psychological Network Models</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Complex Systems in Psychology</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/tasospsy/complexity_book" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Complex-Systems-in-Psychology.pdf">
              <i class="bi bi-bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Complex-Systems-in-Psychology.epub">
              <i class="bi bi-bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foreword</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Chaos and unpredictability</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Transitions in complex systems</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Self-organization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Building dynamic system models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch6.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Psychological Network Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">6.1</span> Introduction</a></li>
  <li><a href="#network-theory" id="toc-network-theory" class="nav-link" data-scroll-target="#network-theory"><span class="header-section-number">6.2</span> Network theory</a>
  <ul>
  <li><a href="#network-concepts" id="toc-network-concepts" class="nav-link" data-scroll-target="#network-concepts"><span class="header-section-number">6.2.1</span> Network concepts</a></li>
  <li><a href="#network-types" id="toc-network-types" class="nav-link" data-scroll-target="#network-types"><span class="header-section-number">6.2.2</span> Network types</a></li>
  </ul></li>
  <li><a href="#psychological-network-models" id="toc-psychological-network-models" class="nav-link" data-scroll-target="#psychological-network-models"><span class="header-section-number">6.3</span> Psychological network models</a>
  <ul>
  <li><a href="#mutualism-model-the-case-of-general-intelligence" id="toc-mutualism-model-the-case-of-general-intelligence" class="nav-link" data-scroll-target="#mutualism-model-the-case-of-general-intelligence"><span class="header-section-number">6.3.1</span> Mutualism model: the case of general intelligence</a>
  <ul class="collapse">
  <li><a href="#the-g-factor" id="toc-the-g-factor" class="nav-link" data-scroll-target="#the-g-factor"><span class="header-section-number">6.3.1.1</span> The g factor</a></li>
  <li><a href="#mutualism-model" id="toc-mutualism-model" class="nav-link" data-scroll-target="#mutualism-model"><span class="header-section-number">6.3.1.2</span> Mutualism model</a></li>
  <li><a href="#abnormal-development" id="toc-abnormal-development" class="nav-link" data-scroll-target="#abnormal-development"><span class="header-section-number">6.3.1.3</span> Abnormal development</a></li>
  <li><a href="#the-wiring-of-intelligence" id="toc-the-wiring-of-intelligence" class="nav-link" data-scroll-target="#the-wiring-of-intelligence"><span class="header-section-number">6.3.1.4</span> The wiring of intelligence</a></li>
  </ul></li>
  <li><a href="#symptom-networks" id="toc-symptom-networks" class="nav-link" data-scroll-target="#symptom-networks"><span class="header-section-number">6.3.2</span> Symptom networks</a></li>
  <li><a href="#ising-attitude-model" id="toc-ising-attitude-model" class="nav-link" data-scroll-target="#ising-attitude-model"><span class="header-section-number">6.3.3</span> Ising attitude model</a>
  <ul class="collapse">
  <li><a href="#model-setup" id="toc-model-setup" class="nav-link" data-scroll-target="#model-setup"><span class="header-section-number">6.3.3.1</span> Model setup</a></li>
  <li><a href="#simulation" id="toc-simulation" class="nav-link" data-scroll-target="#simulation"><span class="header-section-number">6.3.3.2</span> Simulation</a></li>
  <li><a href="#learning" id="toc-learning" class="nav-link" data-scroll-target="#learning"><span class="header-section-number">6.3.3.3</span> Learning</a></li>
  <li><a href="#the-stability-of-attitudes-and-entropy-measures" id="toc-the-stability-of-attitudes-and-entropy-measures" class="nav-link" data-scroll-target="#the-stability-of-attitudes-and-entropy-measures"><span class="header-section-number">6.3.3.4</span> The stability of attitudes and entropy measures</a></li>
  <li><a href="#tricriticality" id="toc-tricriticality" class="nav-link" data-scroll-target="#tricriticality"><span class="header-section-number">6.3.3.5</span> Tricriticality</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#psychometric-network-techniques" id="toc-psychometric-network-techniques" class="nav-link" data-scroll-target="#psychometric-network-techniques"><span class="header-section-number">6.4</span> Psychometric network techniques</a>
  <ul>
  <li><a href="#main-techniques" id="toc-main-techniques" class="nav-link" data-scroll-target="#main-techniques"><span class="header-section-number">6.4.1</span> Main techniques</a></li>
  <li><a href="#fitting-the-mutualism-model" id="toc-fitting-the-mutualism-model" class="nav-link" data-scroll-target="#fitting-the-mutualism-model"><span class="header-section-number">6.4.2</span> Fitting the mutualism model</a></li>
  <li><a href="#fitting-ising-models" id="toc-fitting-ising-models" class="nav-link" data-scroll-target="#fitting-ising-models"><span class="header-section-number">6.4.3</span> Fitting Ising models</a></li>
  </ul></li>
  <li><a href="#challenges" id="toc-challenges" class="nav-link" data-scroll-target="#challenges"><span class="header-section-number">6.5</span> Challenges</a>
  <ul>
  <li><a href="#psychological-network-modelling" id="toc-psychological-network-modelling" class="nav-link" data-scroll-target="#psychological-network-modelling"><span class="header-section-number">6.5.1</span> Psychological network modelling</a></li>
  <li><a href="#psychometric-network-analysis" id="toc-psychometric-network-analysis" class="nav-link" data-scroll-target="#psychometric-network-analysis"><span class="header-section-number">6.5.2</span> Psychometric network analysis</a></li>
  </ul></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">6.6</span> Exercises</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Psychological Network Models</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="introduction" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">6.1</span> Introduction</h2>
<p>The functioning (and dysfunctioning) of the human mind is best understood as a complex interplay of various psychological elements such as cognitive functions, mental states, symptoms, and behaviors. This interplay can be modeled using networks, psychological networks.</p>
<p>Psychological networks are perhaps the most thriving area of complex systems research in psychology today. This chapter is about this new line of research. The paper on the mutualism model of general intelligence <span class="citation" data-cites="vandermaasDynamicalModelGeneral2006">(<a href="references.html#ref-vandermaasDynamicalModelGeneral2006" role="doc-biblioref">Van Der Maas et al. 2006</a>)</span> can be seen as the root of this approach, but it really took off, as shown in <a href="#fig-ch6-img1-old-70">Figure&nbsp;<span>6.1</span></a>, when it was applied to clinical psychology <span class="citation" data-cites="borsboomNetworkTheoryMental2017 borsboomPsychometricPerspectivesDiagnostic2008 cramerComorbidityNetworkPerspective2010">(<a href="references.html#ref-borsboomNetworkTheoryMental2017" role="doc-biblioref">Borsboom 2017</a>, <a href="references.html#ref-borsboomPsychometricPerspectivesDiagnostic2008" role="doc-biblioref">2008</a>; <a href="references.html#ref-cramerComorbidityNetworkPerspective2010" role="doc-biblioref">Cramer et al. 2010</a>)</span>, especially when the theoretical work was backed up with psychometric tools <span class="citation" data-cites="epskampEstimatingPsychologicalNetworks2018 epskampQgraphNetworkVisualizations2012 marsmanGuestEditorsIntroduction2022">(<a href="references.html#ref-epskampEstimatingPsychologicalNetworks2018" role="doc-biblioref">Epskamp, Borsboom, and Fried 2018</a>; <a href="references.html#ref-epskampQgraphNetworkVisualizations2012" role="doc-biblioref">Epskamp et al. 2012</a>; <a href="references.html#ref-marsmanGuestEditorsIntroduction2022" role="doc-biblioref">Marsman and Rhemtulla 2022</a>)</span>.</p>
<div id="fig-ch6-img1-old-70" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image1.jpg" class="img-fluid figure-img" style="width:2.7509in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.1: The number of papers on the combination of symptoms and “network analysis” grows exponentially.</figcaption>
</figure>
</div>
<p>In this chapter I will present and discuss the theoretical and psychometric lines of research, accompanied by practical examples. However, I will begin with an introduction to network theory.</p>
</section>
<section id="network-theory" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="network-theory"><span class="header-section-number">6.2</span> Network theory</h2>
<p>It is hard to imagine a discipline in which networks are not a central theme. Networks are the key to understanding systems ranging from particle physics to social networks, from ecosystems to the Internet, and from railways to the brain. The mathematics of network theory is not so easy to grasp, but fortunately the basic concepts and ideas are. I will give a brief introduction.</p>
<section id="network-concepts" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1" class="anchored" data-anchor-id="network-concepts"><span class="header-section-number">6.2.1</span> Network concepts</h3>
<p>A network, a special type of graph, consists of nodes (often called vertices) and links (or connections or edges). I will explain some basic concepts here and illustrate each of them with R-code below.</p>
<p>The size of a network is equal to the number of nodes. Nodes can be anything, particles, neurons, words, people, train stations, etc. Nodes are connected by links. Links can be directed or undirected. For example, causal links are directed. Occasionally you see links from the node to itself. In causal networks this may represents self-excitation or if the weight is negative, self-inhibition. In some cases, links are simply present or absent, in other cases links are weighted, as in most neural networks. The list of all non-zero links is called the adjacency or edge list. The matrix of all weights, indicating the strengths of the connections between nodes, is called the adjacency or edge matrix. For an undirected network, the adjacency matrix is symmetric. For a network without self-loops, the diagonal of the adjacency matrix is zero.</p>
<p>A connected network is a network in which every node is connected to every other node, possibly through intermediate nodes. In a fully connected network, or complete graph, every node is directly connected to every other node. Such a network has a density of one (i.e., the proportion of edges that is present).</p>
<p>Nodes can be in the center of a network or in the periphery. This should not be taken literally as psychological networks have no spatial dimension. Centrality measures quantifiy the relative influence, control, or connectivity of a node compared to other nodes in the network. There are many kinds of centrality measures, such as closeness centrality and degree centrality. The degree of a node is equivalent to the number of links it has. The average degree of a network is the average of this number over all nodes. The degree distribution can take several forms. A random graph, where nodes are connected randomly, has a binomial degree distribution. Most real-world networks have a skewed degree distribution. Sometimes nodes are organized into clusters or communities, where the density is higher than between clusters. The average shortest path length (ASPL) is the average number of edges that must be traversed to get from one node to another using the shortest paths (i.e., the fewest intermediate nodes).</p>
<p>There are many methods available in R for creating and visualizing networks and for computing properties of networks. The igraph and qgraph libraries are very useful. It is a good idea to do a bit of experimentation with this R code below by varying the parameter values.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(igraph);<span class="fu">library</span>(qgraph)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>g1 <span class="ot">&lt;-</span> <span class="fu">graph</span>( <span class="at">edges=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>, <span class="dv">2</span>,<span class="dv">3</span>, <span class="dv">3</span>,<span class="dv">1</span>), <span class="at">n=</span><span class="dv">3</span>, <span class="at">directed=</span>F ) </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(g1) <span class="co"># an undirected network with 3 nodes</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>g2 <span class="ot">&lt;-</span> <span class="fu">graph</span>( <span class="at">edges=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>, <span class="dv">2</span>,<span class="dv">3</span>, <span class="dv">3</span>,<span class="dv">1</span>, <span class="dv">1</span>,<span class="dv">3</span>, <span class="dv">3</span>,<span class="dv">3</span>), <span class="at">n=</span><span class="dv">3</span>, <span class="at">directed=</span>T ) </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(g2) <span class="co"># an directed network with self-excitation on node 3</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">get.adjacency</span>(g2) <span class="co"># weight matrix</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>fcn <span class="ot">&lt;-</span> <span class="fu">make_full_graph</span>(<span class="dv">10</span>) <span class="co"># a fully connected network</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fcn, <span class="at">vertex.size=</span><span class="dv">10</span>, <span class="at">vertex.label=</span><span class="cn">NA</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">layout</span>(<span class="dv">1</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>adj <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">100</span>,<span class="dv">0</span>,.<span class="dv">2</span>),<span class="dv">10</span>,<span class="dv">10</span>) <span class="co"># a weighted adjacency matrix</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>adj <span class="ot">&lt;-</span> adj<span class="sc">*</span><span class="fu">sample</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>,<span class="dv">100</span>,<span class="at">replace=</span>T,<span class="at">prob=</span><span class="fu">c</span>(.<span class="dv">8</span>,.<span class="dv">2</span>)) <span class="co"># set 80% to 0</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="fu">qgraph</span>(adj) <span class="co"># plot in qgraph</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="fu">edge_density</span>(fcn) <span class="co"># indeed 1</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="fu">edge_density</span>(<span class="fu">graph_from_adjacency_matrix</span>(adj,<span class="at">weighted=</span><span class="cn">TRUE</span>)) <span class="co"># indeed .2</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="fu">centralityPlot</span>(<span class="fu">qgraph</span>(adj)) <span class="co"># note centrality() gives more indices</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-ch6-img2-old-71" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image2.jpg" class="img-fluid figure-img" style="width:5.99934in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.2: A weighted directed network with self-loops. Red arrows indicate negative effects. OutStrength and InStrength represent two types of centrality measures in directed networks.</figcaption>
</figure>
</div>
</section>
<section id="network-types" class="level3" data-number="6.2.2">
<h3 data-number="6.2.2" class="anchored" data-anchor-id="network-types"><span class="header-section-number">6.2.2</span> Network types</h3>
<p>Simple networks do not have cycles. An example of an undirected acyclic graph is one with nodes on a line (but not a circle). Connected undirected acyclic graph are trees; if they are partially un-connected, they are forests. Directed acyclic graphs, such as family trees and citation networks, are called DAGs. Most current neutral networks are feedforward networks without cycles, but so-called recurrent networks have cycles.</p>
<p>Igraph has an amazing number of functions for creating specific networks. Some examples are shown in <a href="#fig-ch6-img3-old-72">Figure&nbsp;<span>6.3</span></a>.</p>
<div id="fig-ch6-img3-old-72" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image3.jpg" class="img-fluid figure-img" style="width:5.37769in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.3: Different network types generated with Igraph</figcaption>
</figure>
</div>
<p>The last case in the figure, preferential attachment, is of particular interest because it is created dynamically. It starts with a node and then new nodes are added that prefer links to nodes that already have many links. In the NetLogo model ‘Preferential Attachment simple’ you can see this growth process. This type of network is “scale-free”, meaning that the degree distribution looks the same no matter what scale you look at it (like fractals, see Section 2.7). Scale-free networks can be found in a wide range of real-world situations, from connections between websites to scientific collaborations. Scale-free networks have a degree distribution that follows a power law, with some nodes having many links, but most having only a few. Scale-free networks are useful for studying the robustness and vulnerability of networks to targeted attacks on highly connected nodes. Removing hubs with high degree potentially split the network into disconnected components and impede the network’s functionality. Because most nodes in the network have a small degree (few connections), randomly removing nodes tends not to disrupt the network’s overall structure. Preferential attachment networks are often called complex because it exhibits non-trivial structural patterns.</p>
<p>Another type of complex network is the small-world network. This type of network consists of clusters, but there are also links between the clusters. As a result, the distance between any two nodes in the network is always relatively short. A famous example is the six-handshake rule (also known as the six degrees of separation), which states that all people are six or fewer handshakes away from each other. For this reason, small-world networks are useful for studying the spread of information or disease through social networks.</p>
<p>A prominent phase transition in graph theory is the emergence of a giant component. This happens when we start with a completely unconnected network of <span class="math inline">\(n\)</span> nodes and randomly add links. We simply take a random node and connect it to another node to which it has no connection. This leads to many small unconnected clusters at first, but then a giant component suddenly appears. This happens when about <span class="math inline">\(n/2\)</span> links have been added. You can verify this in the NetLogo model ‘Giant Component’. The implication is that randomly connected networks with a sufficient number of links are almost always connected networks.</p>
<p>This is just one example of network dynamics. We can distinguish between dynamics on node values (e.g., Lotka-Volterra models), on link values (connection strength in neural networks), and cases where the structure of the network is dynamic, as in the Giant Component example. These types of dynamics also coexist and interact. In neural networks, both node and link values are updated (on fast and slow time scales). We will see more examples in the next chapter.</p>
<p>A relatively new topic in complex networks concerns higher order interactions. In most networks we only consider pairwise interactions, but third order and even higher order interactions may play a role <span class="citation" data-cites="battistonPhysicsHigherorderInteractions2021">(<a href="references.html#ref-battistonPhysicsHigherorderInteractions2021" role="doc-biblioref">Battiston et al. 2021</a>)</span>. Other work considers hierarchical complex networks <span class="citation" data-cites="boccalettiStructureDynamicsMultilayer2014">(<a href="references.html#ref-boccalettiStructureDynamicsMultilayer2014" role="doc-biblioref"><strong>boccalettiStructureDynamicsMultilayer2014?</strong></a>)</span>. For more information on network concept and types, I first refer to Wikipedia. Another great (open) source is the book by <span class="citation" data-cites="barabasiNetworkScience2016">Barabási and Pósfai (<a href="references.html#ref-barabasiNetworkScience2016" role="doc-biblioref">2016</a>)</span>. A more concise overview is provided by <span class="citation" data-cites="boccalettiStructureDynamicsMultilayer2014">(<a href="references.html#ref-boccalettiStructureDynamicsMultilayer2014" role="doc-biblioref"><strong>boccalettiStructureDynamicsMultilayer2014?</strong></a>)</span>.</p>
</section>
</section>
<section id="psychological-network-models" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="psychological-network-models"><span class="header-section-number">6.3</span> Psychological network models</h2>
<p>The idea of emergentism, discussed in Chapter 1, is that there are multiple, hierarchically ordered levels of description, and that one need not always refer to lower levels to explain phenomena. Psychology seems to have a problem with this: We are missing levels. The lowest relevant level seems to be the neural level. Neural activity can be aggregated into the activity of neural groups or even brain areas. At the highest level we have observed behavior, for example motor and speech actions. We have a similar gap between genes and psychological phenotypes (e.g., intelligence, personality, disorders). One attempt to bridge this gap is the watershed model <span class="citation" data-cites="penkeEvolutionaryGeneticsPersonality2007">(<a href="references.html#ref-penkeEvolutionaryGeneticsPersonality2007" role="doc-biblioref">Penke, Denissen, and Miller 2007</a>)</span>, in which many small genetic factors culminate, in a watershed-like process, into the phenotype.</p>
<p>The problem is that the biological and psychological levels are simply too far apart. What current deep learning neural networks can do is very impressive, but for reasoning, planning, and problem solving, some kind of symbolic processing seems to be necessary. A simple example is the computation of the outcome of 16 x 12, which requires active and systematic manipulation of mathematical symbols in working memory. This is an active area of research, but I’m not aware of any generally accepted solution <span class="citation" data-cites="garcezNeuralSymbolicCognitiveReasoning2008">(<a href="references.html#ref-garcezNeuralSymbolicCognitiveReasoning2008" role="doc-biblioref">Garcez, Lamb, and Gabbay 2008</a>)</span>. The current success of large language models in AI shows that a purely associative neural network approach to language is impressively powerful. Semantic networks also provide a fruitful intermediate level of analysis. I will not discuss semantic networks in this chapter, but they are one of the most successful applications of network science in psychology <span class="citation" data-cites="kumarSemanticMemoryReview2021 steyversLargeScaleStructureSemantic2005">(<a href="references.html#ref-kumarSemanticMemoryReview2021" role="doc-biblioref">Kumar 2021</a>; <a href="references.html#ref-steyversLargeScaleStructureSemantic2005" role="doc-biblioref">Steyvers and Tenenbaum 2005</a>)</span>.</p>
<p>A final example of our struggle with a gap between levels is the use of latent variables in differential psychology. Latent variables are used in statistical modeling to represent unobservable or underlying factors that cannot be directly measured or observed. Differential psychology is concerned with individual differences, in contrast to experimental psychology that is concerned with mechanisms. This division comes from a renowned paper by <span class="citation" data-cites="cronbachTwoDisciplinesScientific1957">Cronbach (<a href="references.html#ref-cronbachTwoDisciplinesScientific1957" role="doc-biblioref">1957</a>)</span> on the two disciplines of scientific psychology.</p>
<p>Examples of extensively studied individual differences are personality and intelligence. Differential psychologists model relationships between observed behaviors, such as responses to test items and questionnaires, using latent variables. The statistical tools for analyzing latent variables come from modern test theory and structural equation modeling (SEM). These technically advanced tools are developed in a field called psychometrics.</p>
<p>However, despite this technical sophistication, it is not always clear what latent variables are in psychometric models. Some researchers tend to think of them as purely statistical constructs that help summarize relationships between variables and make predictions. But more often, either implicitly or explicitly, latent variables are interpreted as real constructs, as common causes of observed measures <span class="citation" data-cites="vanborkWhatPfactorPsychopathology2017">(<a href="references.html#ref-vanborkWhatPfactorPsychopathology2017" role="doc-biblioref">van Bork et al. 2017</a>)</span>.</p>
<p>The latent variable or factor approach has long been dominant in differential psychology. When studying individual differences in a trait, psychologists generally follow the same approach. They construct tests, collect data, perform factor analysis, and propose one or more latent traits to explain observed individual differences. The justification for this approach, particularly in intelligence research, rests primarily on its predictive power.</p>
<p>The psychological network approach was developed in response to the factor approach. The main reason is that underlying common causes are unsatisfactory if they cannot be identified independently of the observed relationships they are supposed to explain <span class="citation" data-cites="vandermaasDynamicalModelGeneral2006">(<a href="references.html#ref-vandermaasDynamicalModelGeneral2006" role="doc-biblioref">Van Der Maas et al. 2006</a>)</span>. One consequence is that such an explanation does not provide guidance for possible interventions.</p>
<section id="mutualism-model-the-case-of-general-intelligence" class="level3" data-number="6.3.1">
<h3 data-number="6.3.1" class="anchored" data-anchor-id="mutualism-model-the-case-of-general-intelligence"><span class="header-section-number">6.3.1</span> Mutualism model: the case of general intelligence</h3>
<section id="the-g-factor" class="level4" data-number="6.3.1.1">
<h4 data-number="6.3.1.1" class="anchored" data-anchor-id="the-g-factor"><span class="header-section-number">6.3.1.1</span> The g factor</h4>
<p>The factor analytic tradition in psychology began with the study of general intelligence, and so does the psychological network approach.</p>
<p>The factor or g model of general intelligence was proposed by <span class="citation" data-cites="spearmanGeneralIntelligenceObjectively1904">Spearman (<a href="references.html#ref-spearmanGeneralIntelligenceObjectively1904" role="doc-biblioref">1904</a>)</span> as an explanation of the positive manifold, i.e., the much replicated effect that subtests of intelligence test batteries are positively correlated. In the original simplest model, the observed test scores are statistically explained by a common factor, meaning that the correlations between test scores disappear when subjects have the same score on the common factor. In the Cattell-Horn-Carroll (CHC) model often referred to as the standard model, test scores load on subfactors such as visual processing (Gv) and fluid reasoning (Gf), which in turn are positively correlated. These latent correlations are explained by the general, higher order, factor g.</p>
<div id="fig-ch6-img4-old-73" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image4.jpg" class="img-fluid figure-img" style="width:4.61458in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.4: The Cattell-Horn-Carroll (CHC) model of general intelligence. Blocks represent test scores (narrow), explained by the broad factors, which in turn are determined by the general factor g.</figcaption>
</figure>
</div>
<p>This model has been criticized extensively, including for its alleged implications for group differences in observed IQ and intervention strategies <span class="citation" data-cites="fraserBellCurveWars2008">(<a href="references.html#ref-fraserBellCurveWars2008" role="doc-biblioref">Fraser 2008</a>)</span>. In my view, some of the criticism is unwarranted. For example, the positive manifold is a very robust and widely replicated empirical phenomenon. It does not much matter what tests are included. That is, any reliable measure of creativity, emotional or social intelligence correlates positively with other IQ subtests. Nor is there much wrong with factor analysis as a statistical technique. To me, the most questionable aspect of g-theory is that it is not really a theory at all. The “elephant in the room” question is simply: What is g? What could this single factor be that explains everything? A century of research has not produced a generally accepted answer to this question. And this is a problem for many factor explanations in psychology (e.g., the big five of personality, the p-factor of psychopathology).</p>
<p>It is important to note that factor explanations are not always problematic. I like to use the example of heart disease, say a loose heart valve. This leads to symptoms such as shortness of breath, swelling of the ankles, dizziness, rapid weight gain, and chest discomfort. The relationship between these symptoms is explained by the underlying factor of heart disease. Treating a single symptom may provide some relief for that symptom, but not more. Only intervening on the cause will bring about real change. This is an example of a reflective interpretation of the factor model. When the factor is merely an index and not a common cause, we speak of a formative factor. <a href="#fig-ch6-img5-old-74">Figure&nbsp;<span>6.5</span></a> explains the reflective and formative interpretations of the factor model.</p>
<div id="fig-ch6-img5-old-74" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image5.jpg" class="img-fluid figure-img" style="width:4.30288in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.5: The reflective and formative interpretations of the factor model cannot be distinguished with correlational data, but they are very different. In the reflective model, the latent factor is a common cause (e.g., temperature) that causes the observations (e.g., different thermometers). Intervening on one thermometer (heating) will only change that particular thermometer because the X’s have no outgoing connections. In the formative interpretation, the factor is just an index (e.g., an economic index) that summarizes the state of many interacting components (companies). In this case, only interventions on the X’s can have an overall effect.</figcaption>
</figure>
</div>
<p>So, the fact that factor models fit intelligence data well does not tell us anything about the status of g. Is it a common cause or just an index?</p>
</section>
<section id="mutualism-model" class="level4" data-number="6.3.1.2">
<h4 data-number="6.3.1.2" class="anchored" data-anchor-id="mutualism-model"><span class="header-section-number">6.3.1.2</span> Mutualism model</h4>
<p><span class="citation" data-cites="vandermaasDynamicalModelGeneral2006">Van Der Maas et al. (<a href="references.html#ref-vandermaasDynamicalModelGeneral2006" role="doc-biblioref">2006</a>)</span> proposed an alternative model that is consistent with the formative interpretation of the factor model. The idea is that our cognitive system consists of many cognitive functions that develop over time in an autocatalytic process based on experience and training, but also due to weak positive reciprocal interactions between developing cognitive functions. Examples of such mutualistic interactions are those between short-term memory and cognitive strategies, language and cognition (syntactic and semantic bootstrapping), cognition and metacognition, action and perception, and performance and motivation <span class="citation" data-cites="vandermaasNetworkModelsCognitive2017">(<a href="references.html#ref-vandermaasNetworkModelsCognitive2017" role="doc-biblioref">Van Der Maas et al. 2017</a>)</span>. For example, babies learn to grasp objects by repeatedly reaching out, coordinating their hand and finger movements, and adjusting their grip. Through these actions, they gather sensory feedback, refining their perception and improving their grasping skills in a reciprocal learning process <span class="citation" data-cites="needhamHowBabiesUse2023">(<a href="references.html#ref-needhamHowBabiesUse2023" role="doc-biblioref">Needham and Nelson 2023</a>)</span>.</p>
<p>To model this we used the mutualistic Lotka-Volterra model, which is:</p>
<p><span class="math display">\[\frac{dX_{i}}{dt} = a_{i}X_{i}\left( 1 - \frac{X_{i}}{K_{i}} \right) + a_{i}\sum_{\begin{array}{r}
j = 1 \\
j \neq i
\end{array}}^{W}\frac{M_{ij}X_{i}X_{j}}{K_{i}}\ \ \ for\ i = 1..W\]</span></p>
<p><span class="math display">\[\begin{array}{r}
K_{i} = c_{i}G_{i} + \left( 1 - c_{i} \right)E_{i} 42)
\end{array}\]</span></p>
<p>Where $X_{i}X_{w}$denote the cognitive processes, <span class="math inline">\(a\)</span> the growth rates, <span class="math inline">\(K\)</span> the limited resources for each <span class="math inline">\(X\)</span> (a weighted sum of a genetic (<span class="math inline">\(G\)</span>) and an environmental (<span class="math inline">\(E\)</span>) part), and <span class="math inline">\(M\)</span> the interaction matrix. The second equation, assuming simple linear effects of genetics and environment, is sufficient to explain some typical phenomena in twin research, such as the increase in heritability with age (see the 2006 paper).</p>
<div id="fig-ch6-img6-old-75" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image6.jpg" class="img-fluid figure-img" style="width:2.33386in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.6: The mutualism model. The self-loops, depicted in red, have an excitatory ($aX$) and an inhibitory part ($- aX^{2}/K$).</figcaption>
</figure>
</div>
<p>When <span class="math inline">\(M\)</span> contains mostly negative values, the model is known as a competitive Lotka-Volterra model. In this case, limit cycles and other nonlinear phenomena may occur <span class="citation" data-cites="hirschSystemsDifferentialEquations1985">(<a href="references.html#ref-hirschSystemsDifferentialEquations1985" role="doc-biblioref">Hirsch 1985</a>)</span>. For the mutualistic variant, with positive <span class="math inline">\(M\)</span>, we see either convergence to a positive state or exponential growth. This exponential growth is an unfortunate aspect of the Lotka-Volterra mutualism model. Robert May famously described this effect as an orgy of mutual benefaction <span class="citation" data-cites="mayTheoreticalEcologyPrinciples2007">(<a href="references.html#ref-mayTheoreticalEcologyPrinciples2007" role="doc-biblioref">May, Oxford, and McLean 2007</a>)</span>, which is not what we not see in nature, and all sorts of solutions have been proposed <span class="citation" data-cites="bascompteMutualisticNetworks2013">(<a href="references.html#ref-bascompteMutualisticNetworks2013" role="doc-biblioref">Bascompte and Jordano 2013</a>)</span>.</p>
<p>The mutualism model in Grind is specified as follows:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>mutualism <span class="ot">&lt;-</span> <span class="cf">function</span>(t, state, parms){</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">with</span>(<span class="fu">as.list</span>(<span class="fu">c</span>(state,parms)),{</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    X <span class="ot">&lt;-</span> state[<span class="dv">1</span><span class="sc">:</span>nr_var]</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    dX <span class="ot">&lt;-</span> a<span class="sc">*</span>X<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>X<span class="sc">/</span>k) <span class="sc">+</span> a<span class="sc">*</span>(X <span class="sc">*</span> M <span class="sc">%*%</span> X)<span class="sc">/</span>k <span class="co"># using matrix multiplication</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">list</span>(dX))</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>A simulation of the positive manifold requires us to run this model for multiple people and collect the <span class="math inline">\(X\)</span>-values after some time points (tmax=60) for each person. We can then compute the correlations and check if they are positive. For each person, we resample <span class="math inline">\(a\)</span>, <span class="math inline">\(K\)</span> and the initial values of <span class="math inline">\(X\)</span>, but <span class="math inline">\(M\)</span> is the same across persons. Note that the M-values should not be set to high because we then end up in May’s orgy of mutual benefaction. In the second part of this chapter, we will generate more data with this model and fit network and factor models.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">layout</span>(<span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>nr_var <span class="ot">&lt;-</span> <span class="dv">12</span> <span class="co"># number of tests, abilities (W)</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>nr_of_pp <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>,nr_of_pp,nr_var) <span class="co"># to collect the data in the simulation</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>M <span class="ot">&lt;-</span> <span class="fu">matrix</span>(.<span class="dv">05</span>,nr_var,nr_var)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>M[<span class="fu">diag</span>(nr_var)<span class="sc">==</span><span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">0</span> <span class="co"># set diagonal of M to 0</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nr_of_pp)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># sample a,K, starting values X from normal distributions for each person separately</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># note M is constant over persons.</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>  a <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(nr_var,.<span class="dv">2</span>,.<span class="dv">05</span>) </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>  k <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(nr_var,<span class="dv">10</span>,<span class="dv">2</span>)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>  x0 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(nr_var,<span class="dv">2</span>,<span class="fl">0.1</span>) <span class="co"># initial state of X</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>  s  <span class="ot">&lt;-</span> x0;p <span class="ot">&lt;-</span> <span class="fu">c</span>() <span class="co"># required for grind</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>  data[i,] <span class="ot">&lt;-</span> <span class="fu">run</span>(<span class="at">odes=</span>mutualism ,<span class="at">tmax=</span><span class="dv">60</span>, <span class="at">timeplot =</span> (i<span class="sc">==</span><span class="dv">1</span>),<span class="at">legend=</span>F) <span class="co"># collect data (end points)</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>  <span class="co">#plot person 1 only</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">cor</span>(data)[<span class="fu">cor</span>(data)<span class="sc">&lt;</span><span class="dv">1</span>],<span class="at">main=</span><span class="st">'positive manifold'</span>,</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">'between test correlations'</span>,<span class="at">col=</span><span class="st">'lightgreen'</span>) <span class="co"># positive manifold</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-ch6-img7-old-76" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image7.jpg" class="img-fluid figure-img" style="width:3.18726in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.7: A typical run of the mutualism model for one subject and the distribution of correlations between $X$ values across subjects.</figcaption>
</figure>
</div>
</section>
<section id="abnormal-development" class="level4" data-number="6.3.1.3">
<h4 data-number="6.3.1.3" class="anchored" data-anchor-id="abnormal-development"><span class="header-section-number">6.3.1.3</span> Abnormal development</h4>
<p>In <span class="citation" data-cites="vandermaasNetworkModelsCognitive2017">Van Der Maas et al. (<a href="references.html#ref-vandermaasNetworkModelsCognitive2017" role="doc-biblioref">2017</a>)</span>, this model is applied in several ways, for example, by incorporating Cattell’s idea of investment of fluid skills in crystalized abilities. In a recent paper, de <span class="citation" data-cites="ronGeneralModellingFramework2023">Ron et al. (<a href="references.html#ref-ronGeneralModellingFramework2023" role="doc-biblioref">2023</a>)</span> extends the mutualism model with resource competition to explain different patterns of abnormal development. One pattern of abnormal development is hyperspecialization, which is associated with rare variants of autism. In the process of modeling, we came to an interesting insight. Assuming that there is competition for scarce resources (time, money, educational support), hyperspecialization is the default outcome and it is ‘normal’ development that needs to be explained. The reason is the following insight from mathematical biology.</p>
<p>In basic resource competition models in population biology <span class="citation" data-cites="tilmanPhytoplanktonCommunityEcology1982">(<a href="references.html#ref-tilmanPhytoplanktonCommunityEcology1982" role="doc-biblioref">Tilman, Kilham, and Kilham 1982</a>)</span>, the growth of a species (<span class="math inline">\(1...W\)</span>) is determined by its current size <span class="math inline">\(X_{i}\)</span> and the sum over resources <span class="math inline">\(R_{j}\ (1...V)\)</span>. The parameters <span class="math inline">\(\mu_{ij}\)</span> determines how much species <span class="math inline">\(i\)</span> benefits from the resource <span class="math inline">\(j\)</span>. If no resources are available, <span class="math inline">\(X_{i}\)</span> dies out with death rate <span class="math inline">\(d_{i}\)</span>.</p>
<p>The growth of the resource <span class="math inline">\(r_{j}\)</span> consists of two parts. The first part models the growth by a concave function, which is determined by <span class="math inline">\(r\)</span> (i.e., the steepness of the concave function) up to <span class="math inline">\(r_{\max}\)</span>. The second part is the depletion by consumption of resources by <span class="math inline">\(X_{i}\)</span> at rates <span class="math inline">\(b_{ij}\)</span>. Two differential equations specify these dynamics <span class="citation" data-cites="ronGeneralModellingFramework2023">(see the appendix of de <a href="references.html#ref-ronGeneralModellingFramework2023" role="doc-biblioref">Ron et al. 2023</a>)</span> for the Grind code to study this model numerically):</p>
<p><span class="math display">\[\frac{dX_{i}\ }{dt} = X_{i}(\sum_{j = 1}^{V}{\mu_{ij}R_{j} - d_{i}})\]</span></p>
<p><span class="math display">\[\begin{array}{r}
\frac{dR_{j}\ }{dt} = {r\left( r_{\max} - R_{j} \right) - R}_{j}\sum_{i = 1}^{W}{b_{ij}X_{i}} 43)
\end{array}\]</span></p>
<p>What has been shown for this and related models is that you will not get more species surviving than there are resources. Another famous quote from Robert May is “There is no comfortable theorem assuring that increased diversity and complexity beget enhanced community stability; rather, as a mathematical generality, the opposite is true. The task, then, is to elucidate the devious strategies which make for stability in enduring natural systems. There will be no one simple answer to these questions.” Thus, given a limited number of resources (time, money, educational support), we should expect early specialization in only a few skills.</p>
<p>Biologists have proposed a number of mechanisms to deal with this problem <span class="citation" data-cites="meenaEmergentStabilityComplex2023">(<a href="references.html#ref-meenaEmergentStabilityComplex2023" role="doc-biblioref">Meena et al. 2023</a>)</span>. In de <span class="citation" data-cites="ronGeneralModellingFramework2023">Ron et al. (<a href="references.html#ref-ronGeneralModellingFramework2023" role="doc-biblioref">2023</a>)</span> we added three mechanisms: a) density dependent growth (see Section 5.1.2) of the abilities <span class="math inline">\(X\)</span> with a logistic term, b) mutualism between abilities as in the mutualism model, and c) growth-dependent depletion of resources. The idea of the latter is that especially the growth of abilities costs a lot of resources, the maintenance much less. Learning arithmetic or chess requires a lot of effort, but once a certain level of mastery is reached, it remains roughly at that level without further training (unfortunately, this is not the case with physical condition).</p>
<p>In this paper, we show that the combination of these mechanisms allows a balanced growth of several correlated abilities. Specially chosen parameter settings led to different patterns of abnormal development (such as hyperspecialization and delayed development). The final model is:</p>
<p><span class="math display">\[\begin{array}{r}
\frac{dX_{i}}{dt} = X_{i}\left( \sum_{j = 1}^{V}{\mu_{ij}R_{j}\overset{\text{Logistic growth}}{\overbrace{\left( 1 - \frac{X_{i}}{K_{i}} \right)}}} - d_{i} \right) + \overset{\text{Mutualism}}{\overbrace{\sum_{j = 1}^{W}{M_{ij}X_{i}X_{j}\text{/}}K_{i}}}
\end{array}\]</span></p>
<p><span class="math display">\[
\begin{array}{r}
\frac{dR_{j}}{dt} = r\left( r_{\max} - R_{j} \right) - R_{j}\sum_{i = 1}^{W}{b_{ij}\frac{dX_{i}}{dt}}\ \left\{ \begin{array}{r}
growth - dependent\  \\
resource\ depletion
\end{array} \right\}\# 44) \\
\end{array}
\]</span></p>
</section>
<section id="the-wiring-of-intelligence" class="level4" data-number="6.3.1.4">
<h4 data-number="6.3.1.4" class="anchored" data-anchor-id="the-wiring-of-intelligence"><span class="header-section-number">6.3.1.4</span> The wiring of intelligence</h4>
<p>A limitation of mutualism models is that only the activation of nodes is updated. The weight and structure of the network are fixed. While this may be sufficient to explain some developmental phenomena, it is ultimately unsatisfactory. The links themselves should be adaptable, as in the learning of neural networks. An example of learning in the form of updating weights is presented in a later section on the Ising Attitude model.</p>
<p>In <span class="citation" data-cites="saviWiringIntelligence2019">Savi et al. (<a href="references.html#ref-saviWiringIntelligence2019" role="doc-biblioref">2019</a>)</span> the case where both nodes and links are updated was considered. The idea is that cognitive growth is a process in which new nodes and links are added during development. For example, new facts (1+1=2) and procedures (addition) are developed in the process of learning arithmetic. Links between these nodes may prevent forgetting. In the paper we use the Fortuin-Kasteleyn model, a generalization of the Ising model, in which both nodes and links are random. An important property of the model is that whenever two abilities are connected, they are necessarily in the same state, i.e., they are either both present or both absent. It provides a parsimonious explanation of the positive manifold and hierarchical factor structure of intelligence. The dynamical variant suggests an explanation for the Matthew effect, i.e., the increase in individual differences in ability over the course of development.</p>
<p>However, it is difficult to create a growing network with Fortuin-Kasteleyn properties. A simple example of this problem is the random network. In random networks, there is a uniform probability that two nodes are connected. But if we add new nodes to such a network and connect them to existing nodes with the same probability, the existing nodes will have more connections on average. Thus, adding new nodes destroys the randomness of the network, that is the probability that two nodes are connected is not uniform over nodes anymore. Such a network is a non-equilibrium network <span class="citation" data-cites="dorogovtsevEvolutionNetworks2002">(<a href="references.html#ref-dorogovtsevEvolutionNetworks2002" role="doc-biblioref">Dorogovtsev and Mendes 2002</a>)</span>. Rewiring algorithms to achieve equilibrium exist, but they are not trivial.</p>
</section>
</section>
<section id="symptom-networks" class="level3" data-number="6.3.2">
<h3 data-number="6.3.2" class="anchored" data-anchor-id="symptom-networks"><span class="header-section-number">6.3.2</span> Symptom networks</h3>
<p>In the network perspective on psychopathology, a mental disorder can be viewed as a system of interacting symptoms. Network theory conceptualizes mental disorders as complex networks of symptoms that interact through feedback loops to create a self-sustaining syndromic constellation. Mental disorders can be understood as alternative stable states of highly interconnected networks of symptoms <span class="citation" data-cites="borsboomNetworkTheoryMental2017">(<a href="references.html#ref-borsboomNetworkTheoryMental2017" role="doc-biblioref">Borsboom 2017</a>)</span>.</p>
<p>As with the mutualism model, this is an alternative to the common cause view. Depression could be caused by some malfunction in the brain, a dysregulation of hormones, or even a genetic defect. But as with general intelligence, no such common cause has yet been found. Drugs work to some extent, but so do most interventions, even placebos and waiting lists <span class="citation" data-cites="posternakUntreatedShorttermCourse2001">(<a href="references.html#ref-posternakUntreatedShorttermCourse2001" role="doc-biblioref">Posternak and Miller 2001</a>)</span>. We explicitly offered the network approach as an alternative to the p-factor account of psychopathology <span class="citation" data-cites="vanborkWhatPfactorPsychopathology2017">(<a href="references.html#ref-vanborkWhatPfactorPsychopathology2017" role="doc-biblioref">van Bork et al. 2017</a>)</span>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> It is called the p-factor because it is thought to be conceptually parallel to the g-factor of general intelligence <span class="citation" data-cites="caspiFactorOneGeneral2014">(<a href="references.html#ref-caspiFactorOneGeneral2014" role="doc-biblioref">Caspi et al. 2014</a>)</span>. And again, no one seems to have any idea what p might be.</p>
<div id="fig-ch6-img8-old-77" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image8.jpg" class="img-fluid figure-img" style="width:6.26389in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.8: The small world of psychopathology. Symptoms are represented as nodes and connected by an edge whenever they figure in the same disorder. From: [@borsboomSmallWorldPsychopathology2011].</figcaption>
</figure>
</div>
<p>This lack of theoretical progress encouraged the development of network theory <span class="citation" data-cites="cramerComorbidityNetworkPerspective2010 cramerMajorDepressionComplex2016">(<a href="references.html#ref-cramerComorbidityNetworkPerspective2010" role="doc-biblioref">Cramer et al. 2010</a>; <a href="references.html#ref-cramerMajorDepressionComplex2016" role="doc-biblioref"><strong>cramerMajorDepressionComplex2016?</strong></a>)</span>. As mentioned in the introduction of this chapter, this line of research has become very popular. Most of this work consists of data analytic studies. In the simplest case, a questionnaire asking about the severity of symptoms is administered to a group of people, sometimes patients, sometimes a mixture of people who do and do not suffer from a disorder. A variety of psychometric approaches, discussed later in this chapter, are used to fit networks to the data. In this way, one learns to understand the structure of psychopathological networks. For example, comorbidity is modeled by bridging symptoms between network clusters <span class="citation" data-cites="cramerComorbidityNetworkPerspective2010 jonesBridgeCentralityNetwork2021">(<a href="references.html#ref-cramerComorbidityNetworkPerspective2010" role="doc-biblioref">Cramer et al. 2010</a>; <a href="references.html#ref-jonesBridgeCentralityNetwork2021" role="doc-biblioref">Jones, Ma, and McNally 2021</a>)</span>. In the case of major depression and generalized anxiety disorder, sleep problems seem to be a typical bridge symptom <span class="citation" data-cites="blankenRoleStabilizingCommunicating2018">(<a href="references.html#ref-blankenRoleStabilizingCommunicating2018" role="doc-biblioref">Blanken et al. 2018</a>)</span>.</p>
<p>The most popular application is to detect which symptoms are central to a disorder <span class="citation" data-cites="friedWhatAreGood2016">(<a href="references.html#ref-friedWhatAreGood2016" role="doc-biblioref">Eiko I. Fried et al. 2016</a>)</span>. However, centrality analysis based on cross-sectional data has its limitations <span class="citation" data-cites="bringmannWhatCentralityMeasures2019 spillerValidityCentralityHypothesis2020">(<a href="references.html#ref-bringmannWhatCentralityMeasures2019" role="doc-biblioref">Bringmann et al. 2019</a>; <a href="references.html#ref-spillerValidityCentralityHypothesis2020" role="doc-biblioref">Spiller et al. 2020</a>)</span>. This is one reason to focus on individual networks using timeseries data, often obtained in experience sampling methods (ESMs). Again, these techniques are still under development and not without problems <span class="citation" data-cites="dablanderNodeCentralityMeasures2019 haslbeckRecoveringWithinPersonDynamics2022">(<a href="references.html#ref-dablanderNodeCentralityMeasures2019" role="doc-biblioref">Dablander and Hinne 2019</a>; <a href="references.html#ref-haslbeckRecoveringWithinPersonDynamics2022" role="doc-biblioref">Haslbeck and Ryan 2022</a>)</span>. For a recent review of the network approach to psychopathology, <span class="citation" data-cites="robinaughNetworkApproachPsychopathology2020">(see <a href="references.html#ref-robinaughNetworkApproachPsychopathology2020" role="doc-biblioref">Robinaugh et al. 2020</a>)</span>.</p>
<p>In terms of building actual models, not as much work has been done. In <span class="citation" data-cites="cramerMajorDepressionComplex2016">(<a href="references.html#ref-cramerMajorDepressionComplex2016" role="doc-biblioref"><strong>cramerMajorDepressionComplex2016?</strong></a>)</span>, we proposed an Ising-type model, with node values of 0 and 1, representing symptoms being on or off. Nodes were turned on and off based on a probability computed with a logistic function <span class="math inline">\(P = 1/(1 + e^{(b_{i} - A_{i}^{t})}\)</span>. <span class="math inline">\(A_{i}^{t}\)</span> equals the sum of the weighted input from other connected nodes and <span class="math inline">\(b_{i}\)</span> is a node-specific threshold that normally keeps nodes in the zero state. A strong point of this model is that the connections and thresholds were estimated from data. This model is the origin of the connectivity hypothesis. The idea is that high connectivity within a network of symptoms could lead to a more persistent and severe disorder for a discussion, <span class="citation" data-cites="elovainioSymptomConnectivityReally2021">(see <a href="references.html#ref-elovainioSymptomConnectivityReally2021" role="doc-biblioref">Elovainio et al. 2021</a>)</span>.</p>
<p>Since thresholds are generally negative (the zero state of nodes is the default state), sufficient connectivity is required to have a depression as an alternative stable state. A limitation of this model is that although it is similar to the Ising model, the exact dynamics are not well understood.</p>
<p>A similar approach was used by <span class="citation" data-cites="lunanskyInterveningPsychopathologyNetworks2022">Lunansky et al. (<a href="references.html#ref-lunanskyInterveningPsychopathologyNetworks2022" role="doc-biblioref">2022</a>)</span> in order to define resilience and evaluate intervention targets. The model can be found in the NetLogo User Community Models under the name of ‘Vulnerability to Depression’ by Claudia van Borkulo (see <a href="#fig-ch6-img9-old-78">Figure&nbsp;<span>6.9</span></a>). Another relevant network modeling approach, based on causal loop diagrams, is proposed in <span class="citation" data-cites="wittenbornDepressionSystemicSyndrome2016">Wittenborn et al. (<a href="references.html#ref-wittenbornDepressionSystemicSyndrome2016" role="doc-biblioref">2016</a>)</span>. The panic disorder model discussed in the previous chapter is also an example.</p>
<div id="fig-ch6-img9-old-78" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image9.jpg" class="img-fluid figure-img" style="width:5.77471in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.9: The Vulnerability to Depression model in NetLogo.</figcaption>
</figure>
</div>
<p>The connection to resilience is interesting. In dynamic terms, resilience is not associated with the healthy or unhealthy state, but with the stability of these states (<a href="#fig-ch6-img10-old-79">Figure&nbsp;<span>6.10</span></a>). In Section 3.2.3 the less deep minimum is called the metastable state. These states have less resilience than the globally stable state.</p>
<p>This suggests a distinction between perturbations and interventions. With interventions, we change the equilibrium landscape to allow a sustainable change to a healthy state. Perturbations (a brief intervention or a positive or negative event) can have a permanent or temporary effect, depending on which state is more resilient. In the situation shown in the top panel of <a href="#fig-ch6-img10-old-79">Figure&nbsp;<span>6.10</span></a>, any intervention, whether it is a real treatment or an alternative (or even being on the waiting list), will work. In the situation on the bottom left, no intervention would have a lasting effect. This definition of resilience may help to understand the inconsistent results of studies of intervention effects. Monitoring the resilience of the unhealthy state (with catastrophe flags such as anomalous variance) may also be important for timing interventions <span class="citation" data-cites="hayesComplexSystemsApproach2020">(<a href="references.html#ref-hayesComplexSystemsApproach2020" role="doc-biblioref">Hayes and Andrews 2020</a>)</span>. Failed interventions, such as an attempt to quit smoking, are likely to reinforce the unhealthy state <span class="citation" data-cites="vangeliPredictorsAttemptsStop2011">(<a href="references.html#ref-vangeliPredictorsAttemptsStop2011" role="doc-biblioref">Vangeli et al. 2011</a>)</span>.</p>
<div id="fig-ch6-img10-old-79" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image10.jpg" class="img-fluid figure-img" style="width:4.54449in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.10: Resilience from a complex systems perspective. If the system is in a less resilient, metastable state, any perturbation will be effective. A perturbation to a metastable state will not last. Lasting interventions change the dynamic landscape of the system.</figcaption>
</figure>
</div>
</section>
<section id="ising-attitude-model" class="level3" data-number="6.3.3">
<h3 data-number="6.3.3" class="anchored" data-anchor-id="ising-attitude-model"><span class="header-section-number">6.3.3</span> Ising attitude model</h3>
<p>The network approach has been applied to many other domains outside of intelligence research and the study of psychopathology. Examples include emotion <span class="citation" data-cites="langeEmotionsOverlappingCausal2021">(<a href="references.html#ref-langeEmotionsOverlappingCausal2021" role="doc-biblioref">Lange and Zickfeld 2021</a>)</span>, personality <span class="citation" data-cites="costantiniStateARtPersonality2015">(<a href="references.html#ref-costantiniStateARtPersonality2015" role="doc-biblioref">Costantini et al. 2015</a>)</span>, interest <span class="citation" data-cites="sachisthalIntroducingScienceInterest2019">(<a href="references.html#ref-sachisthalIntroducingScienceInterest2019" role="doc-biblioref">Sachisthal et al. 2019</a>)</span>, and organizational behavior <span class="citation" data-cites="loweryBalancingActPerformance2021">(<a href="references.html#ref-loweryBalancingActPerformance2021" role="doc-biblioref">Lowery, Clark, and Carter 2021</a>)</span>. One area where it has been developed into a new theory is attitude research.</p>
<p>People have many attitudes, about food, politics, other people, horror movies, the police, etc. They help us make decisions and guide our behavior. Attitudes can be very stable and multifaceted, but they can also be inconsistent and inconsequential. Social psychology has studied attitudes for a long time, and many insights and theories have been developed.</p>
<p>Attitudes are complex constructs and typical phenomena, such as cognitive dissonance, imbalance, ambivalence, and political polarization, can be well described by a network model. The formalization of attitude theories has been dominated by the connectionist account <span class="citation" data-cites="monroeGeneralConnectionistModel2008 vanoverwalleConnectionistModelAttitude2005">(<a href="references.html#ref-monroeGeneralConnectionistModel2008" role="doc-biblioref">Monroe and Read 2008</a>; <a href="references.html#ref-vanoverwalleConnectionistModelAttitude2005" role="doc-biblioref">Van Overwalle and Siebler 2005</a>)</span>. In connectionist models, developed in the Parallel Distributed Processing (PDP) approach, attitude units (e.g., beliefs) form a connected network whose activations (between -1 and 1) are updated based on the weighted sum of internal inputs from other units and an external input. These weights or connections are updated according to either the delta rule (a supervised learning rule based on the difference between the produced and expected output of the network) or the Hebb rule (a simpler unsupervised rule). With this setup, these models can explain a number of phenomena in attitude research. Another network account has been put forward in sociology <span class="citation" data-cites="dellapostaPluralisticCollapseOil2020">(<a href="references.html#ref-dellapostaPluralisticCollapseOil2020" role="doc-biblioref">DellaPosta 2020</a>)</span>.</p>
<p>In this section, I will discuss our network approach to attitudes using the Ising model, which was developed in a series of recent papers. The advantages of this model over the connectionist PDP models are that it is derived from basic assumptions, is better understood mathematically, is easy to simulate, provides a psychological interpretation of the temperature parameter, and can be fitted to data <span class="citation" data-cites="dalegeNetworkAnalysisAttitudes2017">(<a href="references.html#ref-dalegeNetworkAnalysisAttitudes2017" role="doc-biblioref"><strong>dalegeNetworkAnalysisAttitudes2017?</strong></a>)</span>.</p>
<p>It was developed as an alternative to the tripartite factor model of attitudes, in which the attitude, a latent factor, consists of lower-order cognitive, affective, and behavioral factors, that each explain observed responses, similar to the CHC model of general intelligence. The causal attitude model <span class="citation" data-cites="dalegeFormalizedAccountAttitudes2016">(<a href="references.html#ref-dalegeFormalizedAccountAttitudes2016" role="doc-biblioref">Jonas Dalege et al. 2016</a>)</span>, maintains this distinction in cognitive, affective, and behavioral components, but now conceptualizes them as clusters within a network. In <span class="citation" data-cites="dalegeAttitudinalEntropyAE2018">Jonas Dalege et al. (<a href="references.html#ref-dalegeAttitudinalEntropyAE2018" role="doc-biblioref">2018</a>)</span>, this network model is formalized in the form of an Ising model with attention as the equivalent of (the inverse of) temperature. That is high attention ‘freezes’ the network and leads to consistent and stable positive or negative states of the attitude (the ‘mere thought effect’, see below).</p>
<section id="model-setup" class="level4" data-number="6.3.3.1">
<h4 data-number="6.3.3.1" class="anchored" data-anchor-id="model-setup"><span class="header-section-number">6.3.3.1</span> Model setup</h4>
<p>The basic assumptions of the Ising Attitude Model are that nodes are binary (e.g., one eats red meat or not), that nodes influence each other causally, and that they have specific thresholds (as in the model for depression). An external field (a campaign to eat less meat) could also affect the nodes. The orientation of nodes to other nodes and to the external field depends on one’s attention, <span class="math inline">\(A\)</span>, to the attitude object.</p>
<p>Given these simplifying assumptions, which can be relaxed in various ways, we arrive at the random field Ising model <span class="citation" data-cites="fytasReviewRecentDevelopments2018">Fytas et al. (<a href="references.html#ref-fytasReviewRecentDevelopments2018" role="doc-biblioref">2018</a>)</span>. This model is not too different from the Ising model described in Chapter 4, except that the first term now has two components, a general external effect (<span class="math inline">\(\tau\)</span>) and an effect of node-specific ($t_{i})\ $thresholds (‘I just like the taste of chicken a lot’). The random field Ising attitude model can then be defined as:</p>
<p><span class="math display">\[\begin{array}{r}
H\left( \mathbf{x} \right) = - \sum_{i}^{n}{(\tau + {t_{i})x}_{i}} - \sum_{&lt; ij &gt;}^{}{{W_{ij}x}_{i}x_{j}} 45)
\end{array}\]</span></p>
<p><span class="math display">\[\begin{array}{r}
P\left( \mathbf{X} = \mathbf{x} \right) = \frac{\exp\left( - AH\left( \mathbf{x} \right) \right)}{Z} 46)
\end{array}\]</span></p>
<p>Another difference from the original Ising model introduced in Chapter 4 is that the interactions are now weighted and can even be negative. The main problem is the same. To compute the probability of a state, one has to compute <span class="math inline">\(Z\)</span>, which is the <span class="math inline">\(\sum_{&lt; \mathbf{x} &gt;}^{}{exp( - AH\left( \mathbf{x} \right))}\)</span>, i.e., a sum over all possible states (<span class="math inline">\(2^{n}\)</span>). For large values of <span class="math inline">\(n\)</span> this is not feasible. One solution is to take a random initial state and use Glauber dynamics to update the states until an equilibrium state is reached. The Glauber algorithm does not require <span class="math inline">\(Z\)</span>. There are faster but less intuitive algorithms, the most popular being the Metropolis-Hastings algorithm, which is a slight modification of the Glauber dynamics presented in Chapter 4.</p>
<p>Another approach to understanding the dynamics of Ising-type models is the mean-field approximation. This requires the assumption that the network is fully and uniformly connected with equal thresholds (known as the Curie-Weiss model). In this approximation <span class="math inline">\(W_{ij}\)</span> and <span class="math inline">\(x_{j}\)</span> are replaced by their mean values, which greatly simplifies the energy function. It can be shown that the dynamics of the simple fully connected Ising model is very well approximated by the cusp, with the external field as normal and the inverse temperature as the splitting variable.</p>
<div id="fig-ch6-img11-old-80" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image11.jpg" class="img-fluid figure-img" style="width:2.71903in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.11: The mean field approximation of the Ising attitude model is the cusp. Attention is the psychological equivalent of inverse temperature.</figcaption>
</figure>
</div>
<p>This is an important result because it makes the use of the cusp in attitude research (see Chapter 3) less phenomenological. The cusp is now derived from more basic principles (<a href="#fig-ch6-img11-old-80">Figure&nbsp;<span>6.11</span></a>). Note that here we use attention as the splitting variable, whereas in Chapter 3 we used involvement. These are closely related concepts, the difference being the time scale. Attention can change in seconds or minutes, whereas involvement can change in weeks or months. I will use attention and involvement interchangeably.</p>
<p>This mean-field approximation is very robust. In <span class="citation" data-cites="vandermaasPolarizationIndividualsHierarchical2020">(<a href="references.html#ref-vandermaasPolarizationIndividualsHierarchical2020" role="doc-biblioref"><strong>vandermaasPolarizationIndividualsHierarchical2020?</strong></a>)</span> it is shown by simulation that networks with much fewer connections and a distribution of weights, some of which are negative, are still well described by the cusp. This can be easily checked with some R code or in NetLogo. We will make use of the IsingSampler package in R.</p>
</section>
<section id="simulation" class="level4" data-number="6.3.3.2">
<h4 data-number="6.3.3.2" class="anchored" data-anchor-id="simulation"><span class="header-section-number">6.3.3.2</span> Simulation</h4>
<p>The IsingSampler function runs the Metropolis-Hastings algorithm <span class="math inline">\(nIter\)</span> times and returns the last state. It can return multiple final states for <span class="math inline">\(N\)</span> runs. As input it takes a matrix of links (<span class="math inline">\(W\)</span>), which for the Curie Wiess model should be symmetric with zeroes on the diagonal. The <span class="math inline">\(thresholds\)</span> for each node should be equal. <span class="math inline">\(Beta\)</span> is the inverse of the temperature (<span class="math inline">\(1/T\)</span>).</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"IsingSampler"</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10</span> <span class="co"># nodes</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>W <span class="ot">&lt;-</span> <span class="fu">matrix</span>(.<span class="dv">1</span>,n,n); <span class="fu">diag</span>(W)<span class="ot">=</span><span class="dv">0</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>tau <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span> <span class="co"># replications</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>thresholds <span class="ot">&lt;-</span> <span class="fu">rep</span>(tau, n)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="fu">layout</span>(<span class="fu">t</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>))</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">IsingSampler</span>(N, W, <span class="at">nIter=</span><span class="dv">100</span>, thresholds, <span class="at">beta =</span> .<span class="dv">1</span>, <span class="at">responses =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">apply</span>(data,<span class="dv">1</span>,sum),<span class="at">main=</span><span class="st">"beta = .1"</span>,<span class="at">xlab=</span><span class="st">'sum of x'</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">IsingSampler</span>(N, W, <span class="at">nIter=</span><span class="dv">100</span>, thresholds, <span class="at">beta =</span> <span class="dv">2</span>, <span class="at">responses =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">apply</span>(data,<span class="dv">1</span>,sum), <span class="at">main=</span><span class="st">"beta = 2"</span>,<span class="at">xlab=</span><span class="st">'sum of x'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-ch6-img12-old-81" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image12.jpg" class="img-fluid figure-img" style="width:3.25752in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.12: The distribution of the attitude values (sum of node values) at low and high attention, respectively. This simple simulation shows the mere thought effect <span class="citation" data-cites="tesserSelfGeneratedAttitude1978">(<a href="references.html#ref-tesserSelfGeneratedAttitude1978" role="doc-biblioref">Tesser 1978</a>)</span>.</figcaption>
</figure>
</div>
<p>In <span class="citation" data-cites="dalegeAccurateBeingNoisy2020">Jonas Dalege and van der Maas (<a href="references.html#ref-dalegeAccurateBeingNoisy2020" role="doc-biblioref">2020</a>)</span>, we simulated the difference between implicit and explicit measures of attitude. The idea is that the individual thresholds contain information about the attitude that can only be detected when attention is moderately low. When attention is too high, the alignment between the nodes dominates the thresholds. Indeed, in implicit (indirect) measures of attitude, attention is much lower than in explicit measures such as an interview. This can be simulated as follows:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">layout</span>(<span class="dv">1</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">400</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>W <span class="ot">&lt;-</span> <span class="fu">matrix</span>(.<span class="dv">1</span>,n,n); <span class="fu">diag</span>(W) <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>thresholds <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="sc">-</span>.<span class="dv">2</span>,.<span class="dv">2</span>),n,<span class="at">replace=</span>T) <span class="co"># a random pattern of thresholds</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="dv">0</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>beta.range <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">3</span>,<span class="at">by=</span>.<span class="dv">05</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(beta <span class="cf">in</span> beta.range)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">IsingSampler</span>(N, W, <span class="at">nIter =</span> <span class="dv">100</span>, thresholds, <span class="at">beta =</span> beta, <span class="at">responses =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">c</span>(dat,<span class="fu">sum</span>(thresholds<span class="sc">*</span><span class="fu">apply</span>(data,<span class="dv">2</span>,sum))) <span class="co"># a simple measure of alignment</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(beta.range,dat,<span class="at">xlab=</span><span class="st">'beta'</span>,<span class="at">ylab=</span><span class="st">'alignment with thresholds'</span>,<span class="at">bty=</span><span class="st">'n'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-ch6-img13-old-82" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image13.jpg" class="img-fluid figure-img" style="width:3.37956in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.13: At low levels of attention (but not too low), the node values are determined by the thresholds. At higher levels of attention, they are overridden by the collective effect of other nodes. This may explain the difference between implicit and explicit attitude measures.</figcaption>
</figure>
</div>
<p>We see that for medium attention, the agreement with the thresholds is highest. When attention is zero or very low, nodes behave randomly and do not correlate with the thresholds. When attention is very high, the effects of node-specific thresholds are masked by the collective effects of other nodes. The principal problem of implicit measurement is that for low to medium attention, the network is quite noisy. This is why this paper is called “Accurate by being noisy”.</p>
</section>
<section id="learning" class="level4" data-number="6.3.3.3">
<h4 data-number="6.3.3.3" class="anchored" data-anchor-id="learning"><span class="header-section-number">6.3.3.3</span> Learning</h4>
<p>These connectionist attitude models are capable of “learning”, i.e., adjusting the weights. This can also be done in the Ising attitude model by using Hebbian learning. Hebbian learning, ‘what fires together, wires together’, can be formulated as:</p>
<p><em><br>
</em><span class="math display">\[\begin{array}{r}
\mathrm{\Delta}W_{i,j} = \epsilon\left( 1 - \left| W_{i,j} \right| \right)x_{i}x_{j} - \lambda W_{i,j} 47)
\end{array}\]</span></p>
<p>Weights will grow to 1 if the nodes they connect are consistently either both 1 or both -1. If they consistently differ in value, the weight grows to -1. If the nodes behave inconsistently, the weight shrinks to 0.</p>
<p>In R, this can be implemented as follows:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(qgraph)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>hamiltonian<span class="ot">=</span><span class="cf">function</span>(x,n,t,w) <span class="sc">-</span><span class="fu">sum</span>(t<span class="sc">*</span>x)<span class="sc">-</span><span class="fu">sum</span>(w<span class="sc">*</span>x<span class="sc">%*%</span><span class="fu">t</span>(x)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>glauber_step <span class="ot">=</span> <span class="cf">function</span>(x,n,t,w,beta)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  i <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>n,<span class="at">size=</span><span class="dv">1</span>) <span class="co"># take a random node</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  x_new<span class="ot">=</span>x;x_new[i]<span class="ot">=</span>x_new[i]<span class="sc">*-</span><span class="dv">1</span> <span class="co"># construct new state with flipped node</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  p<span class="ot">=</span><span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(beta<span class="sc">*</span>(<span class="fu">hamiltonian</span>(x_new,n,t,w)<span class="sc">-</span><span class="fu">hamiltonian</span>(x,n,t,w))))  <span class="co"># update probability</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="fu">runif</span>(<span class="dv">1</span>)<span class="sc">&lt;</span>p) x<span class="ot">=</span>x_new <span class="co"># update state</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(x)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="fu">layout</span>(<span class="fu">t</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>))</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>epsilon <span class="ot">&lt;-</span> .<span class="dv">002</span>;lambda <span class="ot">&lt;-</span> .<span class="dv">002</span> <span class="co"># low values = slow time scale</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>W <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n<span class="sc">^</span><span class="dv">2</span>,<span class="dv">0</span>,.<span class="dv">1</span>),n,n); W <span class="ot">&lt;-</span> <span class="fu">pmax</span>(W,<span class="fu">t</span>(W)) <span class="co"># to make W symmetric</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="fu">diag</span>(W) <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="fu">qgraph</span>(W); <span class="fu">title</span>(<span class="st">'before learning'</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>thresholds <span class="ot">&lt;-</span> <span class="fu">rep</span>(.<span class="dv">2</span>, n)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>),n,<span class="at">replace=</span>T)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">glauber_step</span>(x,n,thresholds,W,<span class="at">beta=</span><span class="dv">2</span>)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>W <span class="ot">&lt;-</span> W<span class="sc">+</span>epsilon<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">abs</span>(W))<span class="sc">*</span><span class="fu">outer</span>(x,x,<span class="st">"*"</span>)<span class="sc">-</span>lambda<span class="sc">*</span>W <span class="co"># Hebbian learning</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="fu">diag</span>(W) <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(W,<span class="dv">2</span>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="fu">qgraph</span>(W);<span class="fu">title</span>(<span class="st">'after learning'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-ch6-img14-old-83" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image14.jpg" class="img-fluid figure-img" style="width:2.7946in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.14: Through Hebbian learning, a random (unbalanced) network becomes balanced.</figcaption>
</figure>
</div>
<p>In this case we want to update the nodes values using the Glauber dynamics (Equation <span class="math inline">\(19\)</span>), which uses the computation of the energy of a particular state. Both functions (glauber_step and hamiltonian) are added to the R-code.</p>
<p>Due to Hebbian learning, the network evolves from an unbalanced network (random connections) to a consistently balanced network. Without learning, we need high attention to make the attitude network behave consistently. In the Learning Ising Attitude Model (LIMA), weights increase during periods of high attention. The advantage is that in later instances less attention is required for consistent network behavior <span class="citation" data-cites="dalegeFormalApproachAttitude2020">(chapter 8 of <a href="references.html#ref-dalegeFormalApproachAttitude2020" role="doc-biblioref">J. Dalege 2020</a>)</span>. In this way we can develop stable consistent attitudes.</p>
</section>
<section id="the-stability-of-attitudes-and-entropy-measures" class="level4" data-number="6.3.3.4">
<h4 data-number="6.3.3.4" class="anchored" data-anchor-id="the-stability-of-attitudes-and-entropy-measures"><span class="header-section-number">6.3.3.4</span> The stability of attitudes and entropy measures</h4>
<p>So, adding Hebbion learning to the Ising attitude model leads to stable and consistent attitudes. Computing the Gibbs entropy is the best way to quantify this <span class="citation" data-cites="dalegeAttitudinalEntropyAE2018">(proposition I.2 in <a href="references.html#ref-dalegeAttitudinalEntropyAE2018" role="doc-biblioref">Jonas Dalege et al. 2018</a>)</span>. Earlier the Boltzmann entropy was defined in Section 4.1.1 as the log of the number of ways (W) a particular macrostate can be realized. It measures the inconsistency of a particular attitude state <span class="citation" data-cites="dalegeAttitudinalEntropyAE2018">(proposition I.1 in <a href="references.html#ref-dalegeAttitudinalEntropyAE2018" role="doc-biblioref">Jonas Dalege et al. 2018</a>)</span>.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> Gibbs entropy is more general in that it does not assume that each microstate is equally probable. Instead, it deals with a probability distribution over the different microstates X. It is defined as:</p>
<p><span class="math display">\[\begin{array}{r}
- \sum_{&lt; \mathbf{x} &gt;}^{}{P\left( \mathbf{x} \right)\ln{P\left( \mathbf{x} \right)}} 48)
\end{array}\]</span></p>
<p>Note that we sum over all microstate (<span class="math inline">\(2^{n})\)</span>. For small networks we can compute this measure using the IsingEntrophy() function of the IsingSampler package. There is much more to say about the different entropy measures. For instance, Shannon entropy (a measure in information theory) and Gibbs entropy have the same mathematical definition but are derived from completely different lines of reasoning. An introduction to the discussion on entropy measures can be found at Entropy page of Wikipedia.</p>
</section>
<section id="tricriticality" class="level4" data-number="6.3.3.5">
<h4 data-number="6.3.3.5" class="anchored" data-anchor-id="tricriticality"><span class="header-section-number">6.3.3.5</span> Tricriticality</h4>
<p>A new direction of research concerns Ising type models with trichotomic node values (-1,0,1). In physics this case is known as the tricritical Ising model or the Blume Capel model <span class="citation" data-cites="saulTricriticalBehaviorBlumeCapel1974">(<a href="references.html#ref-saulTricriticalBehaviorBlumeCapel1974" role="doc-biblioref">Saul, Wortis, and Stauffer 1974</a>)</span>. In physics, the states +1 and -1 could represent the spin of a particle pointing up or down, while 0 could represent a non-magnetic or spinless state. In an attitude model, +1 and -1 may represent pro and con beliefs, while 0 represents a neutral belief. The Hamiltonian of the model includes a penalty for the -1 and +1 states:</p>
<p><span class="math display">\[\begin{array}{r}
H\left( \mathbf{x} \right) = - \sum_{i}^{n}{\tau x_{i}} - \sum_{&lt; i,j &gt;}^{}{x_{i}x_{j}} + D\sum_{i}^{n}{x_{i}}^{2}\#
\end{array}49)\]</span></p>
<p>You can compare this to equation <span class="math inline">\(17\)</span>. The last term penalizes (increases the energy) of the -1 and +1 states relative to the 0 state.</p>
<p>The dynamics of this model are more complicated. It resembles the butterfly catastrophe <span class="citation" data-cites="dattaguptaTricriticalPointQualitative1981">(<a href="references.html#ref-dattaguptaTricriticalPointQualitative1981" role="doc-biblioref">Dattagupta 1981</a>)</span>, which has a tricritical point. The potential function has three stable fixed points for some sets of parameters (see Section 3.2.5 and the exercise about the butterfly catastrophe). This is relevant to the modeling of attitudes because it opens up the possibility to have involved stable inbetween attitude positions (see <a href="#fig-ch6-img15-old-84">Figure&nbsp;<span>6.15</span></a>). In the Ising attitude model highly involved persons always radicalize, but this more advanced model allows for involved non-partisan positions.</p>
<div id="fig-ch6-img15-old-84" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image15.jpg" class="img-fluid figure-img" style="width:5.48611in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.15: The butterfly catastrophe, $V(X) = {- aX - \frac{1}{2}bX^{2} - \frac{1}{3}cX^{3} - \frac{1}{4}dX^{4} + \frac{1}{6}X}^{6}$, associated with the tricritical Ising model. The potential function can have three minima (a = c = 0, d = 5, b varies from 1 to -7).</figcaption>
</figure>
</div>
</section>
</section>
</section>
<section id="psychometric-network-techniques" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="psychometric-network-techniques"><span class="header-section-number">6.4</span> Psychometric network techniques</h2>
<p>So far, we have seen examples of theoretical psychological network models in the fields of cognitive, clinical, and social psychology. However, much of the popularity of this approach is due to the psychometric approach that has been developed to analyze data using networks. In the last 15 years, a family of statistical approaches has been developed for all kinds of data and empirical settings. Our psychosystems group (psychosystems.org) has published a book “Network Psychometrics with R: A Guide for Behavioral and Social Scientists” <span class="citation" data-cites="isvoranuNetworkPsychometricsGuide2022">(<a href="references.html#ref-isvoranuNetworkPsychometricsGuide2022" role="doc-biblioref">Isvoranu et al. 2022</a>)</span>. This resource is highly recommended. I will limit myself to a brief overview and some practical examples related to the models presented in the first part of this chapter.</p>
<section id="main-techniques" class="level3" data-number="6.4.1">
<h3 data-number="6.4.1" class="anchored" data-anchor-id="main-techniques"><span class="header-section-number">6.4.1</span> Main techniques</h3>
<p>An important aspect of Network Psychometrics is to visualize the network. This is the process of creating visual representations of the network structure. This helps in interpreting the data. The main R packages for visualization are igraph and qgraph. Both packages include many other useful functions.</p>
<p>A more advanced application of network psychometrics is network estimation. This involves using statistical methods to estimate the structure of the network, including which nodes are connected to each other and the strength of those connections. The most used methods for network estimation are Gaussian graphical models (packages bgms, BDgraph, ggm, psychonetrics, qgraph, BGGM, huge), partial correlation networks (qgraph, qgraphicalmodels), and Ising models (IsingFit, IsingSampler, rbinnet). The mgm package can be used to fit mixed graphical models, with a mixture of categorical and continuous valued nodes. The bgms package applies Bayesian estimation and allows testing for missing links. The huge package is used to represent the conditional dependence structure among many variables and is particularly useful when the number of variables is much larger than the sample size.</p>
<p>The estimation is usually followed by a centrality analysis. The most important nodes in the network are identified based on their degree of centrality, which measures the extent to which a node is connected to other nodes in the network. Centrality measures include degree centrality, betweenness centrality, bridge centrality, and eigenvector centrality, among others (packages psych, networktools).</p>
<p>Another important step is network comparison. Network comparison is the process of comparing the structure of two or more networks to determine if they are significantly different from each other. This can be done using techniques such as the network permutation test, bootstrapping and moderation analysis (R packages bootnet and NetworkComparisonTest).</p>
<p>We can perform network inference, inferring causal relationships between nodes, if we have time series data or if we have intervened in the network. Depending on the type of time series (N=1 time series, N&gt;1 time series, panel data), different modeling options and packages are available (packages psychonetrics, mgm, graphicalVar, mlVar). GVAR returns a temporal network, which is a directed network of temporal relationships, and a contemporaneous network, which is an undirected network of associations between the variables within the same time frame after controlling for temporal relationships.</p>
<p>For a detailed discussion of the reasons for using certain techniques, I again refer you to our recent book. The brief overview I have provided here may soon be obsolete. The CRAN Task View: Psychometric Models and Methods will give you an up-to-date overview. Another option is to use JASP. JASP is a free, open source, statistical analysis program developed under the supervision of Eric Jan Wagenmakers <span class="citation" data-cites="huthBayesianAnalysisCrosssectional2023 loveJASPGraphicalStatistical2019">(<a href="references.html#ref-huthBayesianAnalysisCrosssectional2023" role="doc-biblioref">Huth et al. 2023</a>; <a href="references.html#ref-loveJASPGraphicalStatistical2019" role="doc-biblioref">Love et al. 2019</a>)</span>. It is a user-friendly interface for accessing R packages. All major statistical analyses, both frequentist and Bayesian, are available in JASP (<a href="https://jasp-stats.org/features" class="uri">https://jasp-stats.org/features</a>). Many of the network R packages mentioned above are available. You may want to start by reading the blog post on doing network analysis in JASP (<a href="https://jasp-stats.org/2018/03/20/perform-network-analysis-jasp/" class="uri">https://jasp-stats.org/2018/03/20/perform-network-analysis-jasp/</a>).</p>
<p>Finally, I mention semantic network analysis again. A recent review of statistical approaches (available in R) is provided by <span class="citation" data-cites="christensenSemanticNetworkAnalysis2021">Christensen and Kenett (<a href="references.html#ref-christensenSemanticNetworkAnalysis2021" role="doc-biblioref">2021</a>)</span>.</p>
</section>
<section id="fitting-the-mutualism-model" class="level3" data-number="6.4.2">
<h3 data-number="6.4.2" class="anchored" data-anchor-id="fitting-the-mutualism-model"><span class="header-section-number">6.4.2</span> Fitting the mutualism model</h3>
<p>In the section on the mutualism model, I provided code to simulate data. These data can be fitted using JASP. By re-running the previous code and adding</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">write.table</span>(<span class="at">file=</span><span class="st">'mutualism.txt'</span>,data,<span class="at">ro=</span>F,<span class="at">sep=</span><span class="st">'</span><span class="sc">\t</span><span class="st">'</span>) <span class="co"># write data for JASP</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We have a data file ready to analyze in JASP. After opening this file, you will see the data. In the Network (Frequentist) tab, select all variables and the EBICglasso option. EBICglasso is an R function from the qgraph package. It calculates the Gaussian graphical model and applies the LASSO regularization to shrink the estimates of links to zero <span class="citation" data-cites="friedmanSparseInverseCovariance2008">(<a href="references.html#ref-friedmanSparseInverseCovariance2008" role="doc-biblioref">Friedman, Hastie, and Tibshirani 2008</a>)</span>. This prevents the presence of many irrelevant links without losing predictive value. Alternatively, one could use significant testing or a Bayesian procedure. In JASP one could use the partial correlation option. It is recommended to play around with some options and additional plots.</p>
<p>Mutualism is an alternative explanation for the positive manifold, which means that the fit of a factor model to such data does not prove that the factor ‘g’ theory is correct. It can be shown <span class="citation" data-cites="vandermaasDynamicalModelGeneral2006">(<a href="references.html#ref-vandermaasDynamicalModelGeneral2006" role="doc-biblioref">Van Der Maas et al. 2006</a>)</span> that the simple mutualism factor model with <span class="math inline">\(M_{ij} = c\)</span>, is equivalent to the one-factor model. This can be tested in JASP by fitting a one-factor model to the simulated data. The exploratory one-factor model with one factor will fit the data. The factor loadings should all be very similar.</p>
<p>As discussed, cross-sectional networks do not provide information about the direction of effects. We can illustrate this as follows.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>M[,<span class="dv">1</span>] <span class="ot">&lt;-</span> .<span class="dv">2</span> <span class="co"># strong influence of X1 on all others</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>M[<span class="dv">2</span>,] <span class="ot">&lt;-</span> .<span class="dv">2</span> <span class="co"># strong influence on X2 by all others</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>M[<span class="fu">diag</span>(nr_var)<span class="sc">==</span><span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">0</span> <span class="co"># set diagonal of m to 0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>If we rerun the code and create a centrality plot in JASP, we will see the risks of centrality analysis in cross-sectional networks. Node 2 is the most central, but we know from the simulation that this is because it is influenced by all the others. The node with the most causal power (node 1) does not turn out to be an important central node. With time series data, we can estimate the direction of the effects. We do this in R:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"graphicalVAR"</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># make time series for one persons with some stochastic effects</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">run</span>(<span class="at">odes=</span>mutualism, <span class="at">tmax=</span><span class="dv">1000</span>,<span class="at">table=</span>T,<span class="at">timeplot =</span> (i<span class="sc">==</span><span class="dv">1</span>),<span class="at">legend=</span>F, <span class="at">after=</span><span class="st">"state&lt;-state+rnorm(nr_var,mean=0,sd=1);state[state&lt;0]=.1"</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> data[,<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(data) <span class="ot">&lt;-</span> vars <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">'X'</span>,<span class="dv">1</span><span class="sc">:</span>nr_var,<span class="at">sep=</span><span class="st">''</span>,<span class="at">col=</span><span class="st">''</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>fit<span class="ot">=</span><span class="fu">graphicalVAR</span>(data[<span class="dv">50</span><span class="sc">:</span><span class="dv">1000</span>,], <span class="at">vars =</span> vars, <span class="at">gamma=</span><span class="dv">0</span>, <span class="at">nLambda =</span> <span class="dv">5</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit,<span class="st">"PDC"</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="fu">centralityPlot</span>(fit<span class="sc">$</span>PDC)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The results are shown in <a href="#fig-ch6-img16-old-85">Figure&nbsp;<span>6.16</span></a>. Only the time-series approach provides useful information about possible causal effects.</p>
<div id="fig-ch6-img16-old-85" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image16.jpg" class="img-fluid figure-img" style="width:6.26389in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.16: The top figure is based on cross-sectional data and incorrectly suggests that node V2 is the most important mode. The bottom figure is based on the time series of one individual and correctly shows that V2 is central because it is influenced by other nodes, while V1 is central because it influences other nodes and is therefore more important.</figcaption>
</figure>
</div>
<p>The M-matrix can take different forms. The typical multifactor structure can be achieved with a block structure.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>factors <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>M <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>,nr_var,nr_var)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>low <span class="ot">&lt;-</span> .<span class="dv">0</span>;high <span class="ot">&lt;-</span> .<span class="dv">1</span> <span class="co"># interaction between and within factors</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># loop to create M</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>cat <span class="ot">&lt;-</span> <span class="fu">cut</span>(<span class="dv">1</span><span class="sc">:</span>nr_var,factors)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nr_var)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nr_var)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(cat[i]<span class="sc">==</span>cat[j]) M[i,j] <span class="ot">&lt;-</span> high <span class="cf">else</span> M[i,j] <span class="ot">&lt;-</span> low</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>M[<span class="fu">diag</span>(nr_var)<span class="sc">==</span><span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">0</span> <span class="co"># set diagonal of m to 0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In JASP, you can perform network and confirmatory factor analysis. In the latter case, select 3 factors in the first window and select ‘assume uncorrelated factors’ in the model options. The resulting plots should look like this.</p>
<div id="fig-ch6-img17-old-86" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image17.jpg" class="img-fluid figure-img" style="width:6.26389in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.17: The block structure in the mutualism model can be represented as either a network or a factor model.</figcaption>
</figure>
</div>
</section>
<section id="fitting-ising-models" class="level3" data-number="6.4.3">
<h3 data-number="6.4.3" class="anchored" data-anchor-id="fitting-ising-models"><span class="header-section-number">6.4.3</span> Fitting Ising models</h3>
<p>With IsingFit we can easily fit cross-sectional data generated with the Ising attitude model. <a href="#fig-ch6-img18-old-87">Figure&nbsp;<span>6.18</span></a> shows a good fit of the model. The code for this analysis is:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"IsingSampler"</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"IsingFit"</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">8</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>W <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(n<span class="sc">^</span><span class="dv">2</span>,<span class="fl">0.5</span>,<span class="dv">2</span>),n,n); <span class="co"># random positive matrix</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>W <span class="ot">&lt;-</span> W <span class="sc">*</span> <span class="fu">matrix</span>(<span class="fu">sample</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>,n<span class="sc">^</span><span class="dv">2</span>,<span class="at">prob=</span><span class="fu">c</span>(.<span class="dv">8</span>,.<span class="dv">2</span>),<span class="at">replace=</span>T),n,n) <span class="co"># delete 90% of nodes</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>W <span class="ot">&lt;-</span> <span class="fu">pmax</span>(W,<span class="fu">t</span>(W)) <span class="co"># make symmetric </span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="fu">diag</span>(W) <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>thresholds <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">1</span>) </span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">IsingSampler</span>(n, W, thresholds, <span class="at">beta =</span> .<span class="dv">5</span>, <span class="at">responses =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">IsingFit</span>(data,<span class="at">family=</span><span class="st">'binomial'</span>, <span class="at">plot=</span><span class="cn">FALSE</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="fu">layout</span>(<span class="fu">t</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>))</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="fu">qgraph</span>(W,<span class="at">fade =</span> <span class="cn">FALSE</span>);<span class="fu">title</span>(<span class="st">"Original network"</span>,<span class="at">cex.main=</span><span class="dv">2</span>)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="fu">qgraph</span>(fit<span class="sc">$</span>weiadj,<span class="at">fade =</span> <span class="cn">FALSE</span>);<span class="fu">title</span>(<span class="st">"Estimated network"</span>,<span class="at">cex.main=</span><span class="dv">2</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(thresholds,<span class="at">type=</span><span class="st">'p'</span>,<span class="at">bty=</span><span class="st">'n'</span>,<span class="at">xlab=</span><span class="st">'node'</span>,<span class="at">ylab=</span><span class="st">'Threshold'</span>,<span class="at">cex=</span><span class="dv">2</span>,<span class="at">cex.lab=</span><span class="fl">1.5</span>);<span class="fu">lines</span>(fit[[<span class="dv">2</span>]],<span class="at">lwd=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-ch6-img18-old-87" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image18.jpg" class="img-fluid figure-img" style="width:3.93454in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.18: The true (original) and the estimated Ising model are in good agreement. The thresholds are also well estimated from the data.</figcaption>
</figure>
</div>
<p>An empirical example is provided in@dalegeNetworkAnalysisAttitudes2017. The open-access data (N = 5728) come from the American National Election Study (ANES) of 2012 on evaluative reactions toward Barack Obama. The items and abbreviations are:</p>
<table class="table">
<caption>Table 3: The abbreviation of items used in <a href="#fig-ch6-img19-old-88">Figure&nbsp;<span>6.19</span></a></caption>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Items tapping beliefs</strong></th>
<th style="text-align: left;"><strong>Abbreviation</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"> “Is moral”</td>
<td style="text-align: left;">Mor</td>
</tr>
<tr class="even">
<td style="text-align: left;"> “Would provide strong leadership”</td>
<td style="text-align: left;">Led</td>
</tr>
<tr class="odd">
<td style="text-align: left;"> “Really cares about people like you”</td>
<td style="text-align: left;">Car</td>
</tr>
<tr class="even">
<td style="text-align: left;"> “Is knowledgeable”</td>
<td style="text-align: left;">Kno</td>
</tr>
<tr class="odd">
<td style="text-align: left;"> “Is intelligent”</td>
<td style="text-align: left;">Int</td>
</tr>
<tr class="even">
<td style="text-align: left;"> “Is honest”</td>
<td style="text-align: left;">Hns</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Items tapping feelings</strong></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;"> “Angry”</td>
<td style="text-align: left;">Ang</td>
</tr>
<tr class="odd">
<td style="text-align: left;"> “Hopeful”</td>
<td style="text-align: left;">Hop</td>
</tr>
<tr class="even">
<td style="text-align: left;"> “Afraid of him”</td>
<td style="text-align: left;">Afr</td>
</tr>
<tr class="odd">
<td style="text-align: left;"> “Proud”</td>
<td style="text-align: left;">Prd</td>
</tr>
</tbody>
</table>
<p>We can use Isingfit and add community detection:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>Obama <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">"data/Obama.txt"</span>,<span class="at">header=</span>T) <span class="co"># see book data folder</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>ObamaFit <span class="ot">&lt;-</span> <span class="fu">IsingFit</span>(Obama,<span class="at">plot=</span>F)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>ObamaiGraph<span class="ot">&lt;-</span> <span class="fu">graph_from_adjacency_matrix</span>(<span class="fu">abs</span> (ObamaFit<span class="sc">$</span>weiadj), <span class="st">'undirected'</span>, <span class="at">weighted =</span> <span class="cn">TRUE</span>,     <span class="at">add.colnames =</span> <span class="cn">FALSE</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>ObamaCom <span class="ot">&lt;-</span> <span class="fu">cluster_walktrap</span>(ObamaiGraph)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="fu">qgraph</span>(ObamaFit<span class="sc">$</span>weiadj, <span class="at">layout =</span> <span class="st">'spring'</span>, <span class="at">cut =</span> .<span class="dv">8</span>, <span class="at">groups =</span> <span class="fu">communities</span>(ObamaCom), <span class="at">legend =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><a href="#fig-ch6-img19-old-88">Figure&nbsp;<span>6.19</span></a> shows the network. The red nodes represent negative feelings toward Barack Obama; the green nodes represent positive feelings toward Obama; the light blue nodes represent judgments primarily related to interpersonal warmth; and the purple nodes represent judgments related to Obama’s competence. This community structure is consistent with the postulate of the CAN model that similar evaluative responses cluster <span class="citation" data-cites="dalegeFormalizedAccountAttitudes2016">Jonas Dalege et al. (<a href="references.html#ref-dalegeFormalizedAccountAttitudes2016" role="doc-biblioref">2016</a>)</span> . <span class="citation" data-cites="finnemannTheoreticalStatisticalIsing2021">(<a href="references.html#ref-finnemannTheoreticalStatisticalIsing2021" role="doc-biblioref"><strong>finnemannTheoreticalStatisticalIsing2021?</strong></a>)</span> present additional examples and applications of other packages.</p>
<div id="fig-ch6-img19-old-88" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="media/ch6/image19.jpg" class="img-fluid figure-img" style="width:3.21487in"></p>
<figcaption class="figure-caption">Figure&nbsp;6.19: The attitude towards Obama</figcaption>
</figure>
</div>
</section>
</section>
<section id="challenges" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="challenges"><span class="header-section-number">6.5</span> Challenges</h2>
<p>Since the early work on network psychology, the mutualism model, and the paper on the network perspective on comorbidity, a tremendous amount of work has been done. In particular, network psychometrics has taken off in an unprecedented way. One could say that modern psychometrics is being reinvented from a network perspective. For every type of data and research question, a network approach seems to be available. For example, there are R packages for meta-analysis from a network perspective <span class="citation" data-cites="salantiEvaluatingQualityEvidence2014">(<a href="references.html#ref-salantiEvaluatingQualityEvidence2014" role="doc-biblioref"><strong>salantiEvaluatingQualityEvidence2014?</strong></a>)</span>. I also note that much work has been done to understand the relationship between network psychometrics and more traditional techniques such as item response theory <span class="citation" data-cites="marsmanIntroductionNetworkPsychometrics2018">(<a href="references.html#ref-marsmanIntroductionNetworkPsychometrics2018" role="doc-biblioref"><strong>marsmanIntroductionNetworkPsychometrics2018?</strong></a>)</span>, factor models <span class="citation" data-cites="waldorpRelationsNetworksRegression2022">(<a href="references.html#ref-waldorpRelationsNetworksRegression2022" role="doc-biblioref">Waldorp and Marsman 2022</a>)</span> and structural equation modeling <span class="citation" data-cites="epskampGeneralizedNetworkPsychometrics2017">(<a href="references.html#ref-epskampGeneralizedNetworkPsychometrics2017" role="doc-biblioref">Epskamp, Rhemtulla, and Borsboom 2017</a>)</span>. Nevertheless, there are still many challenges for both psychological network modeling and network psychometrics.</p>
<section id="psychological-network-modelling" class="level3" data-number="6.5.1">
<h3 data-number="6.5.1" class="anchored" data-anchor-id="psychological-network-modelling"><span class="header-section-number">6.5.1</span> Psychological network modelling</h3>
<p>Despite all the hard work on this, I can only conclude that this theoretical line of research is still in its infancy. The strength of the application to intelligence is that it provides an alternative to the g-factor approach, which is also nothing more than a sketch of a theory. The extensions of the mutualism model <span class="citation" data-cites="ronGeneralModellingFramework2023 saviWiringIntelligence2019">(<a href="references.html#ref-ronGeneralModellingFramework2023" role="doc-biblioref">Ron et al. 2023</a>; <a href="references.html#ref-saviWiringIntelligence2019" role="doc-biblioref">Savi et al. 2019</a>)</span> are new steps, but still rather limited models. One reason for this state of affairs is that it is really hard to pinpoint the elementary processes involved in intelligence, and indeed in any psychological system.</p>
<p>This is less of a problem in the factor account because the indicators are interchangeable in a reflective factor model. Once one has a sufficiently broad set of indicators, the common cause estimate will be robust. In a formative model, each indicator contributes a specific meaning to the index variable. However, this is not a reason to prefer the common cause model <span class="citation" data-cites="vandermaasIntelligenceWhatIntelligence2014">(<a href="references.html#ref-vandermaasIntelligenceWhatIntelligence2014" role="doc-biblioref">van der Maas, Kan, and Borsboom 2014</a>)</span>.</p>
<p>The other modeling examples suffer from the same problem. In the clinical psychology models, we define the nodes either as the symptoms specified in the DSM or as the questions asked in interviews or questionnaires, with the advantage that we then have data to fit the model. But again, we have no real way of knowing the elementary processes in clinical disorders and their interactions. If we miss important elementary nodes, this will seriously affect the validity of our models and psychometric network analyses <span class="citation" data-cites="friedMovingForwardChallenges2017">(<a href="references.html#ref-friedMovingForwardChallenges2017" role="doc-biblioref">Eiko I. Fried and Cramer 2017</a>)</span>.</p>
<p>A way out has been mentioned in the context of the Ising Attitude Model, using the mean field approximation. If we are only interested in the global behavior of the attitude (hysteresis, divergence), we can ignore the specification of the nodes (another interchangeable argument). But if one wants to intervene on specific nodes or links of a clinically depressed person, this is not sufficient.</p>
<p>Another critical point is that these models increase our understanding of psychological phenomena, but seemingly not our ability to predict or intervene. For example, the Ising Attitude model helps us understand the role of attention or involvement in the dynamics of attitudes. If this factor is too high, persuasion will be extremely difficult due to hysteresis. Anyone who has ever tried to argue with a conspiracy theorist knows what I mean. But too little attention is also a problem. In the model, these are people who are sensitive to the external field, e.g., you tell them to clean their room, but as soon as you leave, the attitude falls back into random fluctuations. The message gets through but does not stick. I find this insightful, but I must admit that it does not provide us with interventions. We don’t know how to control attention or engagement, although more work can and will be done on this.</p>
<p>For intelligence, the model suggests that the active establishment of near and far transfer might be effective. A disappointing lesson from developmental psychology is that transfer does not always occur automatically <span class="citation" data-cites="salaFarTransferCognitive2019">(e.g., <a href="references.html#ref-salaFarTransferCognitive2019" role="doc-biblioref">Sala et al. 2019</a>)</span>. However, strategies for improving transfer do exist <span class="citation" data-cites="barnettWhenWhereWe2002">(<a href="references.html#ref-barnettWhenWhereWe2002" role="doc-biblioref">Barnett and Ceci 2002</a>)</span> and according to the mutualism model, should have a general effect.</p>
<p>In Chapter 1, I mentioned the case of the shallow lake studied in ecology, where catching the fish was a very effective intervention, while addressing the cause, pollution, was ineffective due to hysteresis. Ecologists now know why this is so, and have developed models to explain this phenomenon. However, I did not mention that this intervention was not suggested by modeling work, but by owners of ponds who observed that ponds without fish sometimes spontaneously tipped to the clear state. This is not an uncommon path in science, and it may well occur in clinical psychology. The touted extraordinary successes of electroshock therapy for severe depression or new drugs (MDMA) for post-traumatic stress disorder could be our “fish”. But also these claims have been criticized <span class="citation" data-cites="borsboomBrainDisordersNot2019 readDepressionWhyDrugs2022">(e.g., <a href="references.html#ref-borsboomBrainDisordersNot2019" role="doc-biblioref">Borsboom, Cramer, and Kalis 2019/ed</a>; <a href="references.html#ref-readDepressionWhyDrugs2022" role="doc-biblioref">Read and Moncrieff 2022</a>)</span>.</p>
<p>Although much more progress can be made in network modeling of psychological systems, it is advisable to be realistic. Progress in mathematical modeling of ecosystems has also been slow. Ecosystems and human systems are devilishly complex. The formalization of psychological models is of interest for many reasons <span class="citation" data-cites="borsboomNetworkAnalysisMultivariate2021">(<a href="references.html#ref-borsboomNetworkAnalysisMultivariate2021" role="doc-biblioref"><strong>borsboomNetworkAnalysisMultivariate2021?</strong></a>)</span>, but will only be effective if we also make progress in other areas, such as measurement.</p>
</section>
<section id="psychometric-network-analysis" class="level3" data-number="6.5.2">
<h3 data-number="6.5.2" class="anchored" data-anchor-id="psychometric-network-analysis"><span class="header-section-number">6.5.2</span> Psychometric network analysis</h3>
<p>This approach is also not without its problems, some of which are related to the problems of psychological network modeling. For example, the definition of nodes and the risk of missing nodes in the data is a serious threat. Again, this is not a unique problem; simple regression analysis suffers from the same risks. Another common threat to many applications of psychometric network analysis is the reliance on self-report in interviews or questionnaires. Generalizability, which may depend more on the choice of sample and measurement method than on the statistical analysis itself, is another example of a common problem in psychology in general and psychometric network analysis, in particular.</p>
<p>Psychometric network analysis has been criticized because the result are difficult to replicate <span class="citation" data-cites="forbesEvidenceThatPsychopathology2017">(<a href="references.html#ref-forbesEvidenceThatPsychopathology2017" role="doc-biblioref">Forbes et al. 2017</a>)</span>. Replication of advanced statistical analyses, whether structural equation modelling, fMRI, or network psychometrics, is always an issue. For network analysis, a number of safeguards have been developed to increase replicability <span class="citation" data-cites="borsboomFalseAlarmComprehensive2017 borsboomRobustnessReplicabilityPsychopathology2018 burgerReportingStandardsPsychological2022">(<a href="references.html#ref-borsboomFalseAlarmComprehensive2017" role="doc-biblioref">Borsboom et al. 2017</a>, <a href="references.html#ref-borsboomRobustnessReplicabilityPsychopathology2018" role="doc-biblioref">2018</a>; <a href="references.html#ref-burgerReportingStandardsPsychological2022" role="doc-biblioref">Burger et al. 2022</a>)</span>.</p>
<p>A final important issue concerns causality. Network models estimated from cross-sectional data are descriptive rather than causal, that is, they do not provide information about the direction of causal relationships between variables. Developing methods for inferring causality from network models is an important challenge in the field.</p>
<p>The move to time series data (either N=1, N&gt;1, or panel data) partially solves this problem. With time series data, we can establish Granger causality, a weaker form of causality based on the predictive power of one time series over another in a time series analysis. However, the relationship may be spurious, influenced by other variables. Network analysis on time series often requires a lot of reliable and stationary data. An important issue is the sampling rate of the time series. In general, to accurately estimate a continuous time-varying signal, it is necessary to sample at twice the maximum frequency of the signal. This is called the Nyquist rate. Another issue is the assumption of equidistance between time points <span class="citation" data-cites="epskampGaussianGraphicalModel2018">(<a href="references.html#ref-epskampGaussianGraphicalModel2018" role="doc-biblioref">Epskamp et al. 2018</a>)</span>, which can be circumvented by using continuous time models <span class="citation" data-cites="voelkleSEMApproachContinuous2012">(<a href="references.html#ref-voelkleSEMApproachContinuous2012" role="doc-biblioref">Voelkle et al. 2012</a>)</span>.</p>
<p>While these problems are not unique to network psychometrics, they are common problems in practice <span class="citation" data-cites="hamakerModelingAffectDynamics2015 ryanChallengeGeneratingCausal2022">(see <a href="references.html#ref-hamakerModelingAffectDynamics2015" role="doc-biblioref">Hamaker et al. 2015</a>; <a href="references.html#ref-ryanChallengeGeneratingCausal2022" role="doc-biblioref">Ryan, Bringmann, and Schuurman 2022</a>)</span>. Finally, causal testing always requires direct intervention. The combination of observational and experimental data can provide sufficient information to properly estimate causal relationships in directed acyclic graphs <span class="citation" data-cites="dablanderCausalInference2021 kossakowskiSearchCausalityComparison2021">(<a href="references.html#ref-dablanderCausalInference2021" role="doc-biblioref">Dablander and van Bork 2021</a>; <a href="references.html#ref-kossakowskiSearchCausalityComparison2021" role="doc-biblioref">Kossakowski, Waldorp, and van der Maas 2021</a>)</span>.</p>
<p>But we can also think of other ways. A simple, but not easy to implement, procedure is to ask subjects about the links in their networks. If one claims not to eat meat because of its effect on the climate, one might consider adding a directed link to this individual’s network <span class="citation" data-cites="rosencransNetworkApproachPosttraumatic2021">(<a href="references.html#ref-rosencransNetworkApproachPosttraumatic2021" role="doc-biblioref">Rosencrans, Zoellner, and Feeny 2021</a>)</span>. <span class="citation" data-cites="desernoHighwaysHappinessAutistic2020">Deserno et al. (<a href="references.html#ref-desernoHighwaysHappinessAutistic2020" role="doc-biblioref">2020</a>)</span> used clinicians’ perceptions of causal relationships in autism. These relationships were consistent with those found in self-reported client data. The main problem is that there are many more possible links than nodes to report on, which makes the questionaries extremely long and tedious to fill out. Alternatively, one could try to estimate links from social media data, interviews or essays using automatic techniques <span class="citation" data-cites="petersQualitativeNetworkApproach2022">(<a href="references.html#ref-petersQualitativeNetworkApproach2022" role="doc-biblioref">Peters, Zörgő, and van der Maas 2022</a>)</span>.</p>
</section>
</section>
<section id="exercises" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="exercises"><span class="header-section-number">6.6</span> Exercises</h2>
<ol type="1">
<li><p>Reproduce the degree distribution of the Barabási-Albert model shown on the Wikipedia page on the scale-free network. Use sample_pa from the Igraph library. (*)</p></li>
<li><p>Open and run the ‘Preferential attachment’ model in NetLogo. Replace the line ‘report [one-of both-ends] of one-of links’ with ‘report one-of turtles’. New nodes will now connect to a random node. Does this result in a random network? (*)</p></li>
<li><p>Make a hysteresis plot in the ‘Vulnerability to Depression’ model in NetLogo. (*)</p></li>
<li><p>With the ADMINISTER-SHOCK button, you can deactivate all symptoms at once. It is as if you give the network an electric shock that resets all the symptoms. Try to find a setting of the CONNECTION-STRENGTH and EXTERNAL-ACTIVATION that creates a disordered network (above the black line in the NETWORK STATUS plot) whereby administering a shock, makes the system healthy again. Is this healthy state long term stable? (*)</p></li>
<li><p>Compute the Gibbs entropy for the learning Ising model during the learning process. Show in a plot that learning minimizes the Gibbs entropy. (**)</p></li>
<li><p>Install and open JASP (jasp-stats.org). Open the data library: 6. Factor. Read all the output and add a confirmatory factor analysis. What is the <em>standardized</em> factor loading of Residual Pitch in the confirmatory one-factor model?</p></li>
<li><p>Read the blog ‘How to Perform a Network Analysis in JASP’ (<a href="https://jasp-stats.org/2018/03/20/perform-network-analysis-jasp/" class="uri">https://jasp-stats.org/2018/03/20/perform-network-analysis-jasp/</a>. Reproduce the top plots of <a href="#fig-ch6-img16-old-85">Figure&nbsp;<span>6.16</span></a>. Generate the data using the R-code in the chapter, import the data into JASP and perform the network analysis. (*)</p></li>
<li><p>Study the R-code for the case where the M-matrix consists of three blocks. Generate the data and import into JASP. Fit the confirmatory 3 factor model. Does it fit? Add V1 to the second instead of the first factor. How do you see the misfit? (*)</p></li>
<li><p>How can you generate data for a higher order factor model using the mutualism model? What should be changed in the code of the M matrix for the case of three blocks? Show that the three-factor solution (assuming uncorrelated factors) does not fit the resulting data. Fit a higher order factor model and report the p-value of the goodness of fit. How does the network plot change?</p></li>
<li><p>Generate data for a network in a cycle (v1 -&gt; v2 -&gt; v3…v12 -&gt; v1). Fit a network and an exploratory factor model. Does this work? What does this tell us about the relationship between the class of all network models and all factor models? (**)</p></li>
<li><p>Fit a Bayesian network in JASP to the data generated for <span class="quarto-unresolved-ref">?fig-ch7-img1-old-89</span>. Warning: The GM in JASP expects (0,1) data. Check that only the simulated links have high Bayes factors. (*)</p></li>
</ol>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-barabasiNetworkScience2016" class="csl-entry" role="listitem">
Barabási, Albert-László, and Márton Pósfai. 2016. <em>Network <span>Science</span></em>. 1st edition. <span>Cambridge, United Kingdom</span>: <span>Cambridge University Press</span>.
</div>
<div id="ref-barnettWhenWhereWe2002" class="csl-entry" role="listitem">
Barnett, Susan M., and Stephen J. Ceci. 2002. <span>“When and Where Do We Apply What We Learn?: <span>A</span> Taxonomy for Far Transfer.”</span> <em>Psychological Bulletin</em> 128: 612–37. <a href="https://doi.org/10.1037/0033-2909.128.4.612">https://doi.org/10.1037/0033-2909.128.4.612</a>.
</div>
<div id="ref-bascompteMutualisticNetworks2013" class="csl-entry" role="listitem">
Bascompte, Jordi, and Pedro Jordano. 2013. <em>Mutualistic <span>Networks</span></em>. <span>Princeton University Press</span>.
</div>
<div id="ref-battistonPhysicsHigherorderInteractions2021" class="csl-entry" role="listitem">
Battiston, Federico, Enrico Amico, Alain Barrat, Ginestra Bianconi, Guilherme Ferraz de Arruda, Benedetta Franceschiello, Iacopo Iacopini, et al. 2021. <span>“The Physics of Higher-Order Interactions in Complex Systems.”</span> <em>Nature Physics</em> 17 (10): 1093–98. <a href="https://doi.org/10.1038/s41567-021-01371-4">https://doi.org/10.1038/s41567-021-01371-4</a>.
</div>
<div id="ref-blankenRoleStabilizingCommunicating2018" class="csl-entry" role="listitem">
Blanken, Tessa F., Marie K. Deserno, Jonas Dalege, Denny Borsboom, Peter Blanken, Gerard A. Kerkhof, and Angélique O. J. Cramer. 2018. <span>“The Role of Stabilizing and Communicating Symptoms Given Overlapping Communities in Psychopathology Networks.”</span> <em>Scientific Reports</em> 8 (1): 5854. <a href="https://doi.org/10.1038/s41598-018-24224-2">https://doi.org/10.1038/s41598-018-24224-2</a>.
</div>
<div id="ref-borsboomPsychometricPerspectivesDiagnostic2008" class="csl-entry" role="listitem">
Borsboom, Denny. 2008. <span>“Psychometric Perspectives on Diagnostic Systems.”</span> <em>Journal of Clinical Psychology</em> 64 (9): 1089–1108. <a href="https://doi.org/10.1002/jclp.20503">https://doi.org/10.1002/jclp.20503</a>.
</div>
<div id="ref-borsboomNetworkTheoryMental2017" class="csl-entry" role="listitem">
———. 2017. <span>“A Network Theory of Mental Disorders.”</span> <em>World Psychiatry</em> 16 (1): 5–13. <a href="https://doi.org/10.1002/wps.20375">https://doi.org/10.1002/wps.20375</a>.
</div>
<div id="ref-borsboomBrainDisordersNot2019" class="csl-entry" role="listitem">
Borsboom, Denny, Angélique O. J. Cramer, and Annemarie Kalis. 2019/ed. <span>“Brain Disorders? <span>Not</span> Really: <span>Why</span> Network Structures Block Reductionism in Psychopathology Research.”</span> <em>Behavioral and Brain Sciences</em> 42 (2019/ed): e2. <a href="https://doi.org/10.1017/S0140525X17002266">https://doi.org/10.1017/S0140525X17002266</a>.
</div>
<div id="ref-borsboomFalseAlarmComprehensive2017" class="csl-entry" role="listitem">
Borsboom, Denny, Eiko I. Fried, Sacha Epskamp, Lourens J. Waldorp, Claudia D. van Borkulo, Han L. J. van der Maas, and Angélique O. J. Cramer. 2017. <span>“False Alarm? <span>A</span> Comprehensive Reanalysis of <span>‘<span>Evidence</span> That Psychopathology Symptom Networks Have Limited Replicability’</span> by <span>Forbes</span>, <span>Wright</span>, <span>Markon</span>, and <span>Krueger</span> (2017).”</span> <em>Journal of Abnormal Psychology</em> 126: 989–99. <a href="https://doi.org/10.1037/abn0000306">https://doi.org/10.1037/abn0000306</a>.
</div>
<div id="ref-borsboomRobustnessReplicabilityPsychopathology2018" class="csl-entry" role="listitem">
Borsboom, Denny, Donald J. Robinaugh, Mijke Rhemtulla, and Angélique O. J. Cramer. 2018. <span>“Robustness and Replicability of Psychopathology Networks.”</span> <em>World Psychiatry</em> 17 (2): 143–44. <a href="https://doi.org/10.1002/wps.20515">https://doi.org/10.1002/wps.20515</a>.
</div>
<div id="ref-bringmannWhatCentralityMeasures2019" class="csl-entry" role="listitem">
Bringmann, Laura F., Timon Elmer, Sacha Epskamp, Robert W. Krause, David Schoch, Marieke Wichers, Johanna T. W. Wigman, and Evelien Snippe. 2019. <span>“What Do Centrality Measures Measure in Psychological Networks?”</span> <em>Journal of Abnormal Psychology</em> 128: 892–903. <a href="https://doi.org/10.1037/abn0000446">https://doi.org/10.1037/abn0000446</a>.
</div>
<div id="ref-burgerReportingStandardsPsychological2022" class="csl-entry" role="listitem">
Burger, Julian, Adela-Maria Isvoranu, Gabriela Lunansky, Jonas M. B. Haslbeck, Sacha Epskamp, Ria H. A. Hoekstra, Eiko I. Fried, Denny Borsboom, and Tessa F. Blanken. 2022. <span>“Reporting Standards for Psychological Network Analyses in Cross-Sectional Data.”</span> <em>Psychological Methods</em>, No Pagination Specified–. <a href="https://doi.org/10.1037/met0000471">https://doi.org/10.1037/met0000471</a>.
</div>
<div id="ref-caspiFactorOneGeneral2014" class="csl-entry" role="listitem">
Caspi, Avshalom, Renate M. Houts, Daniel W. Belsky, Sidra J. Goldman-Mellor, HonaLee Harrington, Salomon Israel, Madeline H. Meier, et al. 2014. <span>“The p <span>Factor</span>: <span>One General Psychopathology Factor</span> in the <span>Structure</span> of <span>Psychiatric Disorders</span>?”</span> <em>Clinical Psychological Science : A Journal of the Association for Psychological Science</em> 2 (2): 119–37. <a href="https://doi.org/10.1177/2167702613497473">https://doi.org/10.1177/2167702613497473</a>.
</div>
<div id="ref-christensenSemanticNetworkAnalysis2021" class="csl-entry" role="listitem">
Christensen, Alexander P., and Yoed N. Kenett. 2021. <span>“Semantic Network Analysis (<span>SemNA</span>): <span>A</span> Tutorial on Preprocessing, Estimating, and Analyzing Semantic Networks.”</span> <em>Psychological Methods</em>, No Pagination Specified–. <a href="https://doi.org/10.1037/met0000463">https://doi.org/10.1037/met0000463</a>.
</div>
<div id="ref-costantiniStateARtPersonality2015" class="csl-entry" role="listitem">
Costantini, Giulio, Sacha Epskamp, Denny Borsboom, Marco Perugini, René Mõttus, Lourens J. Waldorp, and Angélique O. J. Cramer. 2015. <span>“State of the <span class="nocase">aRt</span> Personality Research: <span>A</span> Tutorial on Network Analysis of Personality Data in <span>R</span>.”</span> <em>Journal of Research in Personality</em>, R <span>Special Issue</span>, 54 (February): 13–29. <a href="https://doi.org/10.1016/j.jrp.2014.07.003">https://doi.org/10.1016/j.jrp.2014.07.003</a>.
</div>
<div id="ref-cramerComorbidityNetworkPerspective2010" class="csl-entry" role="listitem">
Cramer, Angélique O. J., Lourens J. Waldorp, Han L. J. van der Maas, and Denny Borsboom. 2010. <span>“Comorbidity: A Network Perspective.”</span> <em>The Behavioral and Brain Sciences</em> 33 (2-3): 137-150; discussion 150-193. <a href="https://doi.org/10.1017/S0140525X09991567">https://doi.org/10.1017/S0140525X09991567</a>.
</div>
<div id="ref-cronbachTwoDisciplinesScientific1957" class="csl-entry" role="listitem">
Cronbach, Lee J. 1957. <span>“The Two Disciplines of Scientific Psychology.”</span> <em>American Psychologist</em> 12: 671–84. <a href="https://doi.org/10.1037/h0043943">https://doi.org/10.1037/h0043943</a>.
</div>
<div id="ref-dablanderNodeCentralityMeasures2019" class="csl-entry" role="listitem">
Dablander, Fabian, and Max Hinne. 2019. <span>“Node Centrality Measures Are a Poor Substitute for Causal Inference.”</span> <em>Scientific Reports</em> 9 (1): 6846. <a href="https://doi.org/10.1038/s41598-019-43033-9">https://doi.org/10.1038/s41598-019-43033-9</a>.
</div>
<div id="ref-dablanderCausalInference2021" class="csl-entry" role="listitem">
Dablander, Fabian, and Riet van Bork. 2021. <span>“Causal Inference.”</span> In <em>Network <span>Psychometrics</span> with <span>R</span></em>, 213–32. N <span>Isvoranu</span>, <span>A</span>. <span>M</span>., <span>Epskamp</span>, <span>S</span>., <span>Waldorp</span>, <span>L</span>. <span>J</span>., &amp; <span>Borsboom</span>, <span>D</span>. (<span>Eds</span>.). <span>Network</span> Psychometrics with <span>R</span>: <span>A</span> Guide for Behavioral and Social Scientists. <span>Routledge</span>, <span>Taylor</span> &amp; <span>Francis Group</span>. <span>Routledge</span>.
</div>
<div id="ref-dalegeFormalApproachAttitude2020" class="csl-entry" role="listitem">
Dalege, J. 2020. <span>“A Formal Approach to Attitude.”</span>
</div>
<div id="ref-dalegeFormalizedAccountAttitudes2016" class="csl-entry" role="listitem">
Dalege, Jonas, Denny Borsboom, Frenk van Harreveld, Helma van den Berg, Mark Conner, and Han L. J. van der Maas. 2016. <span>“Toward a Formalized Account of Attitudes: <span>The Causal Attitude Network</span> (<span>CAN</span>) Model.”</span> <em>Psychological Review</em> 123 (1): 2–22. <a href="https://doi.org/10.1037/a0039802">https://doi.org/10.1037/a0039802</a>.
</div>
<div id="ref-dalegeAttitudinalEntropyAE2018" class="csl-entry" role="listitem">
Dalege, Jonas, Denny Borsboom, Frenk van Harreveld, and Han L. J. van der Maas. 2018. <span>“The <span>Attitudinal Entropy</span> (<span>AE</span>) Framework as a General Theory of Individual Attitudes.”</span> <em>Psychological Inquiry</em> 29 (4): 175–93. <a href="https://doi.org/10.1080/1047840X.2018.1537246">https://doi.org/10.1080/1047840X.2018.1537246</a>.
</div>
<div id="ref-dalegeAccurateBeingNoisy2020" class="csl-entry" role="listitem">
Dalege, Jonas, and Han L. J. van der Maas. 2020. <span>“Accurate by Being Noisy: <span>A</span> Formal Network Model of Implicit Measures of Attitudes.”</span> <em>Social Cognition</em> 38 (Suppl): S26–41. <a href="https://doi.org/10.1521/soco.2020.38.supp.s26">https://doi.org/10.1521/soco.2020.38.supp.s26</a>.
</div>
<div id="ref-dattaguptaTricriticalPointQualitative1981" class="csl-entry" role="listitem">
Dattagupta, S. 1981. <span>“The Tricritical Point - - a Qualitative Review.”</span> <em>Bull Mat Sci</em> 3 (2): 133–39. <a href="https://doi.org/10.1007/BF02908488">https://doi.org/10.1007/BF02908488</a>.
</div>
<div id="ref-dellapostaPluralisticCollapseOil2020" class="csl-entry" role="listitem">
DellaPosta, Daniel. 2020. <span>“Pluralistic <span>Collapse</span>: <span>The</span> <span>‘<span>Oil Spill</span>’</span> <span>Model</span> of <span>Mass Opinion Polarization</span>.”</span> <em>American Sociological Review</em> 85 (3): 507–36. <a href="https://doi.org/10.1177/0003122420922989">https://doi.org/10.1177/0003122420922989</a>.
</div>
<div id="ref-desernoHighwaysHappinessAutistic2020" class="csl-entry" role="listitem">
Deserno, Marie K., Denny Borsboom, Sander Begeer, Riet van Bork, Max Hinne, and Hilde M. Geurts. 2020. <span>“Highways to Happiness for Autistic Adults? <span>Perceived</span> Causal Relations Among Clinicians.”</span> <em>PLOS ONE</em> 15 (12): e0243298. <a href="https://doi.org/10.1371/journal.pone.0243298">https://doi.org/10.1371/journal.pone.0243298</a>.
</div>
<div id="ref-dorogovtsevEvolutionNetworks2002" class="csl-entry" role="listitem">
Dorogovtsev, S. N., and J. F. F. Mendes. 2002. <span>“Evolution of Networks.”</span> <em>Advances in Physics</em> 51 (4): 1079–1187. <a href="https://doi.org/10.1080/00018730110112519">https://doi.org/10.1080/00018730110112519</a>.
</div>
<div id="ref-elovainioSymptomConnectivityReally2021" class="csl-entry" role="listitem">
Elovainio, Marko, Jari Lipsanen, Laura Pulkki-Råback, Jaana Suvisaari, and Christian Hakulinen. 2021. <span>“Is Symptom Connectivity Really the Most Important Issue in Depression? <span>Depression</span> as a Dynamic System of Interconnected Symptoms Revisited.”</span> <em>Journal of Psychiatric Research</em> 142 (October): 250–57. <a href="https://doi.org/10.1016/j.jpsychires.2021.08.004">https://doi.org/10.1016/j.jpsychires.2021.08.004</a>.
</div>
<div id="ref-epskampEstimatingPsychologicalNetworks2018" class="csl-entry" role="listitem">
Epskamp, Sacha, Denny Borsboom, and Eiko I. Fried. 2018. <span>“Estimating Psychological Networks and Their Accuracy: <span>A</span> Tutorial Paper.”</span> <em>Behavior Research Methods</em> 50 (1): 195–212. <a href="https://doi.org/10.3758/s13428-017-0862-1">https://doi.org/10.3758/s13428-017-0862-1</a>.
</div>
<div id="ref-epskampQgraphNetworkVisualizations2012" class="csl-entry" role="listitem">
Epskamp, Sacha, Angélique O. J. Cramer, Lourens J. Waldorp, Verena D. Schmittmann, and Denny Borsboom. 2012. <span>“Qgraph: <span>Network Visualizations</span> of <span>Relationships</span> in <span>Psychometric Data</span>.”</span> <em>Journal of Statistical Software</em> 48 (May): 1–18. <a href="https://doi.org/10.18637/jss.v048.i04">https://doi.org/10.18637/jss.v048.i04</a>.
</div>
<div id="ref-epskampGeneralizedNetworkPsychometrics2017" class="csl-entry" role="listitem">
Epskamp, Sacha, Mijke Rhemtulla, and Denny Borsboom. 2017. <span>“Generalized <span>Network Psychometrics</span>: <span>Combining Network</span> and <span>Latent Variable Models</span>.”</span> <em>Psychometrika</em> 82 (4): 904–27. <a href="https://doi.org/10.1007/s11336-017-9557-x">https://doi.org/10.1007/s11336-017-9557-x</a>.
</div>
<div id="ref-epskampGaussianGraphicalModel2018" class="csl-entry" role="listitem">
Epskamp, Sacha, Lourens J. Waldorp, René Mõttus, and Denny Borsboom. 2018. <span>“The <span>Gaussian Graphical Model</span> in <span>Cross-Sectional</span> and <span>Time-Series Data</span>.”</span> <em>Multivariate Behavioral Research</em> 53 (4): 453–80. <a href="https://doi.org/10.1080/00273171.2018.1454823">https://doi.org/10.1080/00273171.2018.1454823</a>.
</div>
<div id="ref-forbesEvidenceThatPsychopathology2017" class="csl-entry" role="listitem">
Forbes, Miriam K., Aidan G. C. Wright, Kristian E. Markon, and Robert F. Krueger. 2017. <span>“Evidence That Psychopathology Symptom Networks Have Limited Replicability.”</span> <em>Journal of Abnormal Psychology</em> 126: 969–88. <a href="https://doi.org/10.1037/abn0000276">https://doi.org/10.1037/abn0000276</a>.
</div>
<div id="ref-fraserBellCurveWars2008" class="csl-entry" role="listitem">
Fraser, Steven. 2008. <em>The <span>Bell Curve Wars</span>: <span>Race</span>, <span>Intelligence</span>, and the <span>Future</span> of <span>America</span></em>. <span>Basic Books</span>.
</div>
<div id="ref-friedMovingForwardChallenges2017" class="csl-entry" role="listitem">
Fried, Eiko I, and Angélique O J Cramer. 2017. <span>“Moving <span>Forward</span>: <span>Challenges</span> and <span>Directions</span> for <span>Psychopathological Network Theory</span> and <span>Methodology</span>.”</span> <em>Perspectives on Psychological Science</em> 12 (6): 999–1020. <a href="https://doi.org/10.1177/1745691617705892">https://doi.org/10.1177/1745691617705892</a>.
</div>
<div id="ref-friedWhatAreGood2016" class="csl-entry" role="listitem">
Fried, Eiko I., Sacha Epskamp, Randolph M. Nesse, Francis Tuerlinckx, and Denny Borsboom. 2016. <span>“What Are ’Good’ Depression Symptoms? <span>Comparing</span> the Centrality of <span>DSM</span> and Non-<span>DSM</span> Symptoms of Depression in a Network Analysis.”</span> <em>Journal of Affective Disorders</em> 189 (January): 314–20. <a href="https://doi.org/10.1016/j.jad.2015.09.005">https://doi.org/10.1016/j.jad.2015.09.005</a>.
</div>
<div id="ref-friedmanSparseInverseCovariance2008" class="csl-entry" role="listitem">
Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2008. <span>“Sparse Inverse Covariance Estimation with the Graphical Lasso.”</span> <em>Biostatistics</em> 9 (3): 432–41. <a href="https://doi.org/10.1093/biostatistics/kxm045">https://doi.org/10.1093/biostatistics/kxm045</a>.
</div>
<div id="ref-fytasReviewRecentDevelopments2018" class="csl-entry" role="listitem">
Fytas, Nikolaos G., Victor Martin-Mayor, Marco Picco, and Nicolas Sourlas. 2018. <span>“Review of Recent Developments in the Random-Field <span>Ising</span> Model.”</span> <em>Journal of Statistical Physics</em> 172 (2): 665–72. <a href="https://doi.org/10.1007/s10955-018-1955-7">https://doi.org/10.1007/s10955-018-1955-7</a>.
</div>
<div id="ref-garcezNeuralSymbolicCognitiveReasoning2008" class="csl-entry" role="listitem">
Garcez, Artur S. D’Avila, Luís C. Lamb, and Dov M. Gabbay. 2008. <em>Neural-<span>Symbolic Cognitive Reasoning</span></em>. <span>Springer Science &amp; Business Media</span>.
</div>
<div id="ref-hamakerModelingAffectDynamics2015" class="csl-entry" role="listitem">
Hamaker, E. L., E. Ceulemans, R. P. P. P. Grasman, and F. Tuerlinckx. 2015. <span>“Modeling <span>Affect Dynamics</span>: <span>State</span> of the <span>Art</span> and <span>Future Challenges</span>.”</span> <em>Emotion Review</em> 7 (4): 316–22. <a href="https://doi.org/10.1177/1754073915590619">https://doi.org/10.1177/1754073915590619</a>.
</div>
<div id="ref-haslbeckRecoveringWithinPersonDynamics2022" class="csl-entry" role="listitem">
Haslbeck, Jonas M. B., and Oisín Ryan. 2022. <span>“Recovering <span>Within-Person Dynamics</span> from <span>Psychological Time Series</span>.”</span> <em>Multivariate Behavioral Research</em> 57 (5): 735–66. <a href="https://doi.org/10.1080/00273171.2021.1896353">https://doi.org/10.1080/00273171.2021.1896353</a>.
</div>
<div id="ref-hayesComplexSystemsApproach2020" class="csl-entry" role="listitem">
Hayes, Adele M., and Leigh A. Andrews. 2020. <span>“A Complex Systems Approach to the Study of Change in Psychotherapy.”</span> <em>BMC Medicine</em> 18 (1): 197. <a href="https://doi.org/10.1186/s12916-020-01662-2">https://doi.org/10.1186/s12916-020-01662-2</a>.
</div>
<div id="ref-hirschSystemsDifferentialEquations1985" class="csl-entry" role="listitem">
Hirsch, Morris W. 1985. <span>“Systems of <span>Differential Equations</span> That Are <span>Competitive</span> or <span>Cooperative II</span>: <span>Convergence Almost Everywhere</span>.”</span> <em>SIAM Journal on Mathematical Analysis</em> 16 (3): 423–39. <a href="https://doi.org/10.1137/0516030">https://doi.org/10.1137/0516030</a>.
</div>
<div id="ref-huthBayesianAnalysisCrosssectional2023" class="csl-entry" role="listitem">
Huth, Karoline, Jill de Ron, Judy Luigjes, Anneke Goudriaan, Reza Mohammadi, Ruth van Holst, Eric-Jan Wagenmakers, and Maarten Marsman. 2023. <span>“Bayesian <span>Analysis</span> of <span class="nocase">Cross-sectional Networks</span>: <span>A Tutorial</span> in <span>R</span> and <span>JASP</span>.”</span> <span>PsyArXiv</span>. <a href="https://doi.org/10.31234/osf.io/ub5tc">https://doi.org/10.31234/osf.io/ub5tc</a>.
</div>
<div id="ref-isvoranuNetworkPsychometricsGuide2022" class="csl-entry" role="listitem">
Isvoranu, Adela-Maria, Sacha Epskamp, Lourens J. Waldorp, and Denny Borsboom. 2022. <em>Network <span>Psychometrics</span> with <span>R</span>: <span>A Guide</span> for <span>Behavioral</span> and <span>Social Scientists</span></em>. <span>Taylor &amp; Francis Limited</span>.
</div>
<div id="ref-jonesBridgeCentralityNetwork2021" class="csl-entry" role="listitem">
Jones, Payton J., Ruofan Ma, and Richard J. McNally. 2021. <span>“Bridge <span>Centrality</span>: <span>A Network Approach</span> to <span>Understanding Comorbidity</span>.”</span> <em>Multivariate Behavioral Research</em> 56 (2): 353–67. <a href="https://doi.org/10.1080/00273171.2019.1614898">https://doi.org/10.1080/00273171.2019.1614898</a>.
</div>
<div id="ref-kossakowskiSearchCausalityComparison2021" class="csl-entry" role="listitem">
Kossakowski, Jolanda J., Lourens J. Waldorp, and Han L. J. van der Maas. 2021. <span>“The Search for Causality: <span>A</span> Comparison of Different Techniques for Causal Inference Graphs.”</span> <em>Psychological Methods</em> 26: 719–42. <a href="https://doi.org/10.1037/met0000390">https://doi.org/10.1037/met0000390</a>.
</div>
<div id="ref-kumarSemanticMemoryReview2021" class="csl-entry" role="listitem">
Kumar, Abhilasha A. 2021. <span>“Semantic Memory: <span>A</span> Review of Methods, Models, and Current Challenges.”</span> <em>Psychonomic Bulletin &amp; Review</em> 28 (1): 40–80. <a href="https://doi.org/10.3758/s13423-020-01792-x">https://doi.org/10.3758/s13423-020-01792-x</a>.
</div>
<div id="ref-langeEmotionsOverlappingCausal2021" class="csl-entry" role="listitem">
Lange, Jens, and Janis H. Zickfeld. 2021. <span>“Emotions as <span>Overlapping Causal Networks</span> of <span>Emotion Components</span>: <span>Implications</span> and <span>Methodological Approaches</span>.”</span> <em>Emotion Review</em> 13 (2): 157–67. <a href="https://doi.org/10.1177/1754073920988787">https://doi.org/10.1177/1754073920988787</a>.
</div>
<div id="ref-loveJASPGraphicalStatistical2019" class="csl-entry" role="listitem">
Love, Jonathon, Ravi Selker, Maarten Marsman, Tahira Jamil, Damian Dropmann, Josine Verhagen, Alexander Ly, et al. 2019. <span>“<span>JASP</span>: <span>Graphical Statistical Software</span> for <span>Common Statistical Designs</span>.”</span> <em>Journal of Statistical Software</em> 88 (January): 1–17. <a href="https://doi.org/10.18637/jss.v088.i02">https://doi.org/10.18637/jss.v088.i02</a>.
</div>
<div id="ref-loweryBalancingActPerformance2021" class="csl-entry" role="listitem">
Lowery, Megan R., Malissa A. Clark, and Nathan T. Carter. 2021. <span>“The Balancing Act of Performance: <span>Psychometric</span> Networks and the Causal Interplay of Organizational Citizenship and Counterproductive Work Behaviors.”</span> <em>Journal of Vocational Behavior</em> 125 (March): 103527. <a href="https://doi.org/10.1016/j.jvb.2020.103527">https://doi.org/10.1016/j.jvb.2020.103527</a>.
</div>
<div id="ref-lunanskyInterveningPsychopathologyNetworks2022" class="csl-entry" role="listitem">
Lunansky, Gabriela, Jasper Naberman, Claudia D. van Borkulo, Chen Chen, Li Wang, and Denny Borsboom. 2022. <span>“Intervening on Psychopathology Networks: <span>Evaluating</span> Intervention Targets Through Simulations.”</span> <em>Methods</em> 204 (August): 29–37. <a href="https://doi.org/10.1016/j.ymeth.2021.11.006">https://doi.org/10.1016/j.ymeth.2021.11.006</a>.
</div>
<div id="ref-marsmanGuestEditorsIntroduction2022" class="csl-entry" role="listitem">
Marsman, Maarten, and Mijke Rhemtulla. 2022. <span>“Guest <span>Editors</span>’ <span>Introduction</span> to <span>The Special Issue</span> <span>‘<span>Network Psychometrics</span> in <span>Action</span>’</span>: <span>Methodological Innovations Inspired</span> by <span>Empirical Problems</span>.”</span> <em>Psychometrika</em> 87 (1): 1–11. <a href="https://doi.org/10.1007/s11336-022-09861-x">https://doi.org/10.1007/s11336-022-09861-x</a>.
</div>
<div id="ref-mayTheoreticalEcologyPrinciples2007" class="csl-entry" role="listitem">
May, Edited by Professor Lord Robert, of Oxford, and Angela McLean, eds. 2007. <em>Theoretical <span>Ecology</span>: <span>Principles</span> and <span>Applications</span></em>. Third Edition, Third Edition. <span>Oxford, New York</span>: <span>Oxford University Press</span>.
</div>
<div id="ref-meenaEmergentStabilityComplex2023" class="csl-entry" role="listitem">
Meena, Chandrakala, Chittaranjan Hens, Suman Acharyya, Simcha Haber, Stefano Boccaletti, and Baruch Barzel. 2023. <span>“Emergent Stability in Complex Network Dynamics.”</span> <em>Nature Physics</em>, April, 1–10. <a href="https://doi.org/10.1038/s41567-023-02020-8">https://doi.org/10.1038/s41567-023-02020-8</a>.
</div>
<div id="ref-monroeGeneralConnectionistModel2008" class="csl-entry" role="listitem">
Monroe, Brian M., and Stephen J. Read. 2008. <span>“A General Connectionist Model of Attitude Structure and Change: <span>The ACS</span> (<span>Attitudes</span> as <span>Constraint Satisfaction</span>) Model.”</span> <em>Psychological Review</em> 115: 733–59. <a href="https://doi.org/10.1037/0033-295X.115.3.733">https://doi.org/10.1037/0033-295X.115.3.733</a>.
</div>
<div id="ref-needhamHowBabiesUse2023" class="csl-entry" role="listitem">
Needham, Amy Work, and Eliza L. Nelson. 2023. <span>“How Babies Use Their Hands to Learn about Objects: <span>Exploration</span>, Reach-to-Grasp, Manipulation, and Tool Use.”</span> <em>WIREs Cognitive Science</em> n/a (n/a): e1661. <a href="https://doi.org/10.1002/wcs.1661">https://doi.org/10.1002/wcs.1661</a>.
</div>
<div id="ref-penkeEvolutionaryGeneticsPersonality2007" class="csl-entry" role="listitem">
Penke, Lars, Jaap J. A. Denissen, and Geoffrey F. Miller. 2007. <span>“The Evolutionary Genetics of Personality.”</span> <em>European Journal of Personality</em> 21 (5): 549–87. <a href="https://doi.org/10.1002/per.629">https://doi.org/10.1002/per.629</a>.
</div>
<div id="ref-petersQualitativeNetworkApproach2022" class="csl-entry" role="listitem">
Peters, Gjalt Jorn Ygram, Szilvia Zörgő, and Han van der Maas. 2022. <span>“The <span>Qualitative Network Approach</span> (<span>QNA</span>.”</span> <a href="https://doi.org/10.31234/osf.io/cvf52">https://doi.org/10.31234/osf.io/cvf52</a>.
</div>
<div id="ref-posternakUntreatedShorttermCourse2001" class="csl-entry" role="listitem">
Posternak, Michael A., and Ivan Miller. 2001. <span>“Untreated Short-Term Course of Major Depression: A Meta-Analysis of Outcomes from Studies Using Wait-List Control Groups.”</span> <em>Journal of Affective Disorders</em> 66 (2): 139–46. <a href="https://doi.org/10.1016/S0165-0327(00)00304-9">https://doi.org/10.1016/S0165-0327(00)00304-9</a>.
</div>
<div id="ref-readDepressionWhyDrugs2022" class="csl-entry" role="listitem">
Read, John, and Joanna Moncrieff. 2022. <span>“Depression: Why Drugs and Electricity Are Not the Answer.”</span> <em>Psychological Medicine</em> 52 (8): 1401–10. <a href="https://doi.org/10.1017/S0033291721005031">https://doi.org/10.1017/S0033291721005031</a>.
</div>
<div id="ref-robinaughNetworkApproachPsychopathology2020" class="csl-entry" role="listitem">
Robinaugh, Donald J., Ria H. A. Hoekstra, Emma R. Toner, and Denny Borsboom. 2020. <span>“The Network Approach to Psychopathology: A Review of the Literature 2008 and an Agenda for Future Research.”</span> <em>Psychological Medicine</em> 50 (3): 353–66. <a href="https://doi.org/10.1017/S0033291719003404">https://doi.org/10.1017/S0033291719003404</a>.
</div>
<div id="ref-ronGeneralModellingFramework2023" class="csl-entry" role="listitem">
Ron, Jill de, Marie Deserno, Donald Robinaugh, Denny Borsboom, and Han van der Maas. 2023. <span>“Towards a <span>General Modelling Framework</span> of <span>Resource Competition</span> in <span>Cognitive Development</span>.”</span> <span>OSF Preprints</span>. <a href="https://doi.org/10.31219/osf.io/sh6w7">https://doi.org/10.31219/osf.io/sh6w7</a>.
</div>
<div id="ref-rosencransNetworkApproachPosttraumatic2021" class="csl-entry" role="listitem">
Rosencrans, Peter L., Lori A. Zoellner, and Norah C. Feeny. 2021. <span>“A Network Approach to Posttraumatic Stress Disorder: <span>Comparing</span> Interview and Self-Report Networks.”</span> <em>Psychological Trauma: Theory, Research, Practice, and Policy</em>, No Pagination Specified–. <a href="https://doi.org/10.1037/tra0001151">https://doi.org/10.1037/tra0001151</a>.
</div>
<div id="ref-ryanChallengeGeneratingCausal2022" class="csl-entry" role="listitem">
Ryan, Oisín, Laura F. Bringmann, and Noémi K. Schuurman. 2022. <span>“The <span>Challenge</span> of <span>Generating Causal Hypotheses Using Network Models</span>.”</span> <em>Structural Equation Modeling: A Multidisciplinary Journal</em> 29 (6): 953–70. <a href="https://doi.org/10.1080/10705511.2022.2056039">https://doi.org/10.1080/10705511.2022.2056039</a>.
</div>
<div id="ref-sachisthalIntroducingScienceInterest2019" class="csl-entry" role="listitem">
Sachisthal, Maien S. M., Brenda R. J. Jansen, Thea T. D. Peetsma, Jonas Dalege, Han L. J. van der Maas, and Maartje E. J. Raijmakers. 2019. <span>“Introducing a Science Interest Network Model to Reveal Country Differences.”</span> <em>Journal of Educational Psychology</em> 111: 1063–80. <a href="https://doi.org/10.1037/edu0000327">https://doi.org/10.1037/edu0000327</a>.
</div>
<div id="ref-salaFarTransferCognitive2019" class="csl-entry" role="listitem">
Sala, Giovanni, N. Deniz Aksayli, K. Semir Tatlidil, Tomoko Tatsumi, Yasuyuki Gondo, and Fernand Gobet. 2019. <span>“Near and <span>Far Transfer</span> in <span>Cognitive Training</span>: <span>A Second-Order Meta-Analysis</span>.”</span> Edited by Rolf Zwaan and Peter Verkoeijen. <em>Collabra: Psychology</em> 5 (1): 18. <a href="https://doi.org/10.1525/collabra.203">https://doi.org/10.1525/collabra.203</a>.
</div>
<div id="ref-saulTricriticalBehaviorBlumeCapel1974" class="csl-entry" role="listitem">
Saul, D. M., Michael Wortis, and D. Stauffer. 1974. <span>“Tricritical Behavior of the <span>Blume-Capel</span> Model.”</span> <em>Physical Review B</em> 9 (11): 4964–80. <a href="https://doi.org/10.1103/PhysRevB.9.4964">https://doi.org/10.1103/PhysRevB.9.4964</a>.
</div>
<div id="ref-saviWiringIntelligence2019" class="csl-entry" role="listitem">
Savi, Alexander O., Maarten Marsman, Han L. J. van der Maas, and Gunter K. J. Maris. 2019. <span>“The <span>Wiring</span> of <span>Intelligence</span>.”</span> <em>Perspectives on Psychological Science</em> 14 (6): 1034–61. <a href="https://doi.org/10.1177/1745691619866447">https://doi.org/10.1177/1745691619866447</a>.
</div>
<div id="ref-spearmanGeneralIntelligenceObjectively1904" class="csl-entry" role="listitem">
Spearman, C. 1904. <span>“’<span>General</span> Intelligence,’ Objectively Determined and Measured.”</span> <em>The American Journal of Psychology</em> 15: 201–93. <a href="https://doi.org/10.2307/1412107">https://doi.org/10.2307/1412107</a>.
</div>
<div id="ref-spillerValidityCentralityHypothesis2020" class="csl-entry" role="listitem">
Spiller, Tobias R., Ofir Levi, Yuval Neria, Benjamin Suarez-Jimenez, Yair Bar-Haim, and Amit Lazarov. 2020. <span>“On the Validity of the Centrality Hypothesis in Cross-Sectional Between-Subject Networks of Psychopathology.”</span> <em>BMC Medicine</em> 18 (1): 297. <a href="https://doi.org/10.1186/s12916-020-01740-5">https://doi.org/10.1186/s12916-020-01740-5</a>.
</div>
<div id="ref-steyversLargeScaleStructureSemantic2005" class="csl-entry" role="listitem">
Steyvers, Mark, and Joshua B. Tenenbaum. 2005. <span>“The <span>Large-Scale Structure</span> of <span>Semantic Networks</span>: <span>Statistical Analyses</span> and a <span>Model</span> of <span>Semantic Growth</span>.”</span> <em>Cognitive Science</em> 29 (1): 41–78. <a href="https://doi.org/10.1207/s15516709cog2901_3">https://doi.org/10.1207/s15516709cog2901_3</a>.
</div>
<div id="ref-tesserSelfGeneratedAttitude1978" class="csl-entry" role="listitem">
Tesser, Abraham. 1978. <span>“Self-<span>Generated Attitude</span>.”</span> In <em>Advances in <span>Experimental Social Psychology</span></em>, edited by Leonard Berkowitz, 11:289–338. <span>Academic Press</span>. <a href="https://doi.org/10.1016/S0065-2601(08)60010-6">https://doi.org/10.1016/S0065-2601(08)60010-6</a>.
</div>
<div id="ref-tilmanPhytoplanktonCommunityEcology1982" class="csl-entry" role="listitem">
Tilman, D, S S Kilham, and P Kilham. 1982. <span>“Phytoplankton <span>Community Ecology</span>: <span>The Role</span> of <span>Limiting Nutrients</span>.”</span> <em>Annual Review of Ecology and Systematics</em> 13 (1): 349–72. <a href="https://doi.org/10.1146/annurev.es.13.110182.002025">https://doi.org/10.1146/annurev.es.13.110182.002025</a>.
</div>
<div id="ref-vanborkWhatPfactorPsychopathology2017" class="csl-entry" role="listitem">
van Bork, Riet, Sacha Epskamp, Mijke Rhemtulla, Denny Borsboom, and Han L. J. van der Maas. 2017. <span>“What Is the p-Factor of Psychopathology? <span>Some</span> Risks of General Factor Modeling.”</span> <em>Theory &amp; Psychology</em> 27 (6): 759–73. <a href="https://doi.org/10.1177/0959354317737185">https://doi.org/10.1177/0959354317737185</a>.
</div>
<div id="ref-vandermaasDynamicalModelGeneral2006" class="csl-entry" role="listitem">
Van Der Maas, Han L. J., Conor V. Dolan, Raoul P. P. P. Grasman, Jelte M. Wicherts, Hilde M. Huizenga, and Maartje E. J. Raijmakers. 2006. <span>“A Dynamical Model of General Intelligence: <span>The</span> Positive Manifold of Intelligence by Mutualism.”</span> <em>Psychological Review</em> 113 (4): 842–61. <a href="https://doi.org/c3jm44">https://doi.org/c3jm44</a>.
</div>
<div id="ref-vandermaasIntelligenceWhatIntelligence2014" class="csl-entry" role="listitem">
van der Maas, Han L. J., Kees-Jan Kan, and Denny Borsboom. 2014. <span>“Intelligence <span>Is What</span> the <span>Intelligence Test Measures</span>. <span>Seriously</span>.”</span> <em>Journal of Intelligence</em> 2 (1): 12–15. <a href="https://doi.org/10.3390/jintelligence2010012">https://doi.org/10.3390/jintelligence2010012</a>.
</div>
<div id="ref-vandermaasNetworkModelsCognitive2017" class="csl-entry" role="listitem">
Van Der Maas, Han L. J., Kees-Jan Kan, Maarten Marsman, and Claire E. Stevenson. 2017. <span>“Network <span>Models</span> for <span>Cognitive Development</span> and <span>Intelligence</span>.”</span> <em>Journal of Intelligence</em> 5 (2): 16. <a href="https://doi.org/10.3390/jintelligence5020016">https://doi.org/10.3390/jintelligence5020016</a>.
</div>
<div id="ref-vanoverwalleConnectionistModelAttitude2005" class="csl-entry" role="listitem">
Van Overwalle, Frank, and Frank Siebler. 2005. <span>“A Connectionist Model of Attitude Formation and Change.”</span> <em>Personality and Social Psychology Review: An Official Journal of the Society for Personality and Social Psychology, Inc</em> 9 (3): 231–74. <a href="https://doi.org/10.1207/s15327957pspr0903_3">https://doi.org/10.1207/s15327957pspr0903_3</a>.
</div>
<div id="ref-vangeliPredictorsAttemptsStop2011" class="csl-entry" role="listitem">
Vangeli, Eleni, John Stapleton, Eline Suzanne Smit, Ron Borland, and Robert West. 2011. <span>“Predictors of Attempts to Stop Smoking and Their Success in Adult General Population Samples: A Systematic Review.”</span> <em>Addiction (Abingdon, England)</em> 106 (12): 2110–21. <a href="https://doi.org/10.1111/j.1360-0443.2011.03565.x">https://doi.org/10.1111/j.1360-0443.2011.03565.x</a>.
</div>
<div id="ref-voelkleSEMApproachContinuous2012" class="csl-entry" role="listitem">
Voelkle, Manuel C., Johan H. L. Oud, Eldad Davidov, and Peter Schmidt. 2012. <span>“An <span>SEM</span> Approach to Continuous Time Modeling of Panel Data: <span>Relating</span> Authoritarianism and Anomia.”</span> <em>Psychological Methods</em> 17: 176–92. <a href="https://doi.org/10.1037/a0027543">https://doi.org/10.1037/a0027543</a>.
</div>
<div id="ref-waldorpRelationsNetworksRegression2022" class="csl-entry" role="listitem">
Waldorp, Lourens, and Maarten Marsman. 2022. <span>“Relations Between <span>Networks</span>, <span>Regression</span>, <span>Partial Correlation</span>, and the <span>Latent Variable Model</span>.”</span> <em>Multivariate Behavioral Research</em> 57 (6): 994–1006. <a href="https://doi.org/10.1080/00273171.2021.1938959">https://doi.org/10.1080/00273171.2021.1938959</a>.
</div>
<div id="ref-wittenbornDepressionSystemicSyndrome2016" class="csl-entry" role="listitem">
Wittenborn, A. K., H. Rahmandad, J. Rick, and N. Hosseinichimeh. 2016. <span>“Depression as a Systemic Syndrome: Mapping the Feedback Loops of Major Depressive Disorder.”</span> <em>Psychological Medicine</em> 46 (3): 551–62. <a href="https://doi.org/10.1017/S0033291715002044">https://doi.org/10.1017/S0033291715002044</a>.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>The original title of this paper was “No reason to p,” but the editor did not think it was funny.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Assuming that all the attitude states (items) are reencoded as positive (or negative) valued items.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ch5.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Building dynamic system models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link">
        <span class="nav-page-text">References</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>