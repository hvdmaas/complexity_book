[
  {
    "objectID": "ch2.html#introduction",
    "href": "ch2.html#introduction",
    "title": "2  Chaos and unpredictability",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nChaos is one of the three most spectacular phenomena in complex systems and as psychologists we should know the basic results of chaos theory. It is also great fun to learn about chaos and it allows me to introduce many key concepts that we need in later chapters.\nIn my opinion, the applicability of chaos theory to psychology and social science is somewhat limited. For a long time, researchers have tried to show chaos in time series of psychophysiological measures, but this seems to be difficult. I will briefly review this work at the end of the chapter. The relevance of chaos theory may lie not in its application, but in its implications for prediction. What chaos theory basically shows is that even in the best of circumstances, where we have very accurate models and data, long-term prediction is impossible. This is known as the butterfly effect: A butterfly flaps its wings in India and that tiny change in air pressure could eventually cause a tornado in Iowa.\nChaos theory consists of many deep mathematical results, but understanding the basics of chaos is not so hard. Below I will explain chaos in difference equations at a very basic level of mathematics and programming. The elementary example is the famous logistic map, usually introduced as a model of population growth, for instance, of rabbits. Suppose we have rabbits on an island, and they start to multiply, what would be a mathematical model for such a process?\nPopulation growth is a typical example of a dynamical system, it is a model of change. In general, in a dynamical system, the change or growth of a variable (say \\(X\\)) depends on the current state and some parameters. Time plays a very special role. We can use discrete or continuous time steps. In the first case, which is the focus of this chapter, we use difference equations; in the second case, we use differential equations. In the logistic map, time is discrete (population growth takes place in generations). The simplest model for the population growth of rabbits is:\n\\[\nX_{t + 1} = rX_{t} \\tag{2.1}\\]\nIn this equation \\(r\\) is the growth rate. We can simulate this model by choosing a value for \\(r\\), \\(r=2\\), for instance. We also need an initial value, say \\(X_{0} = 1.\\) If this is completely new to you, enter some values repeatedly. You will see exponential growth (\\(X_{1} = 2,\\ X_{2} = 4,X_{3} = 8,X_{4} = 16,\\ etc.)\\). In R we can simulate this using a for loop.\n\nn &lt;- 15\nr &lt;- 2\nx &lt;- 2 # initial state X0 = 1 and thus X1 = 2\nfor (i in 1:(n - 1))\n  x[i + 1] &lt;- r * x[i]\nplot(x, type = 'b', xlab = 'time', bty = 'n')\n\n\n\n\n\n\n\nFigure 2.1: Exponential growth\n\n\nNote that we can find any \\(X_{t}\\) given \\(X_{0}\\) by iterating the model as we do in the for loop. \\(X_{t}\\) is called the solution. Simulation is a bit odd in this case. We can compute the solution analytically. It is \\(X_{t} = X_{0}r^{t}\\). Thus for \\(X_{15} = 1 \\times 2^{15} = 32768\\). However, for more complex models the analytical solution is often not available, and we have to use simulation (the numerical solution).\nNote that the exponential model ignores the fact that population growth is limited by resources. At some point food will become scarce. One way of making the model, introduced by Verhulst in 1838, more realistic is to add a growth-limiting term:\n\\[\nX_{t + 1} = f\\left( X_{t} \\right) = rX_{t}\\left( 1 - \\frac{X_{t}}{K} \\right) \\tag{2.2}\\]\nWhat is the effect of this addition to the equation? If \\(X\\) is much smaller than the resource \\(K\\) then the second term, \\(\\left( 1 - \\frac{X_{t}}{K} \\right),\\) is close to 1 and we will see exponential growth. But as \\(X\\) approaches \\(K\\), this term becomes very small, reducing the effect of exponential growth. \\(X\\) does not actually grow up to \\(K\\), but to a lower value, if it converges at all. We are going to see this in a moment. It also turns out that the actual value of K is not of interest. Changing K does not change the qualitative behavior. Therefore, \\(K\\) is usually set to 1, scaling the population \\(X\\) between 0 and 1. The only remaining parameter is \\(r\\). Changing \\(r\\), however, leads to a number of surprising behaviors.1"
  },
  {
    "objectID": "ch2.html#stable-and-unstable-fixed-points",
    "href": "ch2.html#stable-and-unstable-fixed-points",
    "title": "2  Chaos and unpredictability",
    "section": "2.2 Stable and unstable fixed points",
    "text": "2.2 Stable and unstable fixed points\nLet us first study a simple ‘boring’ case, \\(r = 2\\) (Figure 2.2).\n\nn &lt;- 15; r &lt;- 2; x &lt;- .01 # initial state\nfor (i in 1:(n - 1))\n  x[i + 1] = r * x[i] * (1 - x[i])\nplot(x, type = 'b', xlab = 'time', bty = 'n')\n\n\n\n\nFigure 2.2: The \\(r=2\\) case\n\n\nThis is the simple case. The population initially develops exponentially but then levels off and reached a stable state at \\(X = .5\\). We need to understand a bit more about it. What you see here is that we have gone from an unstable initial state to a stable state, a point attractor. The next code shows that this point attractor attracts from a wide range of initial values, but not all. If we start exactly at zero, \\(X\\) stays at zero. So, zero is an equilibrium too, but a special one. It is an unstable fixed point. A small perturbation will cause \\(X\\) to move to .5, the stable fixed point. All initial values in close proximity of 0 will move away from 0 (repellent), but if \\(X = 0\\) exactly, then it remains 0 for all time. So, \\(X = 0\\) is a fixed point but unstable.\n\nn &lt;- 30; r &lt;- 2\nfor (x in seq(0, .7, by = .01))\n  # start form different initials values\n{\n  for (i in 1:(n - 1))\n    x[i + 1] &lt;- r * x[i] * (1 - x[i])\n  if (x[i] == 0)\n    plot(x,type = 'l',xlab = 'time',bty = 'n',ylim = c(0, .8),col = 'red')\n  else\n    lines(x)\n}\n\n\n\n\nFigure 2.3: Illustration of stable and unstable fixed points. For many initial values, \\(X = .5\\) is an attractor. \\(X = 0\\) is an unstable fixed point. Only if we start exactly at 0 do we stay there.\n\n\nThis concept of equilibrium, stable or unstable, is crucial for later chapters. The essence of the next chapter is to change a control parameter, here \\(r\\), and study how the pattern of equilibria (the equilibrium landscape) changes. You can easily do this yourself by setting \\(r = .9\\). For \\(r &lt; 1\\), there is only stable attractor (zero).\nSimulating this is again not really necessary. One has to realize that a fixed point (\\(X^{*}\\)) is found when \\(X_{t + 1} = X_{t} = X^{*}\\). See for yourself that:\n\\[{X_{t + 1} = X_{t} = X^{*}\n}{X^{*} = rX^{*}\\left( 1 - X^{*} \\right)\n}{X^{*} = 0\\ or\\ 1 = r - rX^{*}\n}{X^{*} = 0\\ or\\ X^{*} = \\frac{r - 1}{r}}\\]\nSo 0 and \\((r - 1)/r\\) are fixed points. Indeed for \\(r = 2\\), we have seen that 0 and .5 are equilibria, one stable and one unstable. To determine whether fixed points are stable we look at the derivative of the function, \\(f^{'}(x)\\), which, as you can easily check, is \\(r - 2rX\\).\nI will not explain why, however, the rule is that the fixed point is stable if the absolute value of the derivative in the fixed-point value is less than 1.2 For \\(r = 2\\) the fixed points are 0 and .5. \\(\\left| f^{'}\\left( X^{*} = 0 \\right) \\right| = |2 - 0| = 2\\), which is greater than 1 and thus \\(X^{*} = 0\\) is unstable. \\(\\left| f^{'}\\left( X^{*} = .5 \\right) \\right| = |2 - 2 \\times 2 \\times .5| = 0\\), which is less than 1 and thus \\(X^{*} = .5\\) is stable. You can check for yourself that \\(X^{*}\\)=\\(\\frac{r - 1}{r}\\) is stable for \\(1 &lt; r &lt; 3\\), both with the r-code and with the absolute value of the derivative."
  },
  {
    "objectID": "ch2.html#limit-cycles",
    "href": "ch2.html#limit-cycles",
    "title": "2  Chaos and unpredictability",
    "section": "2.3 Limit cycles",
    "text": "2.3 Limit cycles\nSo at \\(r = 3\\) the fixed point or \\((r - 1)/r\\) becomes unstable. Let’s study some cases. Plot are made with the code of Figure 2.2.\n\n\n\nFigure 2.4: Qualitative different behavior of the logistic map for different values of \\(r\\).\n\n\nFor \\(r = 2.9\\) we see that the series converges to the fixed point \\(\\frac{1.9}{2.9} = .66,\\) but in a process of over- and undershooting. For \\(r = 3.1\\) and \\(r = 3.3\\) a limit cycle of period 2 arises. The population oscillates between two values. For \\(r = 3.5\\) this gets even stranger, we see a limit cycle of period 4. For slightly larger values we could get cycles with even higher periods.\nIt has been claimed that these limit cycles occur in real population dynamics. Intuitively, it can be understood as a process of over- and undershooting, which dampens out for \\(r\\) a little below 3, but not for \\(r &gt; 3\\)."
  },
  {
    "objectID": "ch2.html#chaos",
    "href": "ch2.html#chaos",
    "title": "2  Chaos and unpredictability",
    "section": "2.4 Chaos",
    "text": "2.4 Chaos\nThis doubling of periods when we increase$ r$at some point leads to even stranger behavior.\nThis is what the time series looks like for \\(r = 4\\).\n\n\n\nFigure 2.5: Chaos for \\(r = 4\\).\n\n\nThere seems to be no regularity. This is what we call deterministic chaos. This time series is unpredictable, even though we now have the equation, and the system is deterministic. What exactly do we mean by this? Let me illustrate.\n\nr &lt;- 4; x &lt;- .001; n &lt;- 50\nfor (i in 1:(n - 1))\n  x[i + 1] &lt;- r * x[i] * (1 - x[i])\nplot(x, type = 'l', xlab = 'time', bty = 'n')\nx &lt;- .0010001\n# restart with sightly different initial state\nfor (i in 1:(n - 1))\n  x[i + 1] &lt;- r * x[i] * (1 - x[i])\nlines(x, col = 'red')\n\n\n\n\nFigure 2.6: The butterfly effect: A small difference in initial state causes divergence in the long run.\n\n\nWe can see that a run with a slightly different initial value will at first follow the same path, but then it will diverge sharply. A tiny perturbation (the butterfly flapping its wings) propagates through the system and dramatically changes the long-term course of the system.\nNote that some uncertainty about the exact value of the initial state is always inevitable. Suppose we have an equation like the logistic map for temperature in the weather system, and this equation perfectly describes that system. To make a prediction, we need to feed the current temperature into the computer. But we cannot measure temperature with infinite precision. And even if we could, we do not have a computer that can handle numbers with an infinite number of digits. So, we make a small error in setting the initial state, and this will always mess up our long-term forecast. This is why long-term weather will never be possible, even if we develop much more precise mathematical models, take more intensive and more accurate measurements and use more powerful computers. The weather turns out to be a chaotic system. Sensitivity to initial conditions is actually one of three conditions for deterministic chaos. For a discussion on the definition of chaos I refer to (Banks et al. 1992).\nThe Lyapunov coefficient quantifies chaos. The idea is to take two very close initial conditions with a difference of \\(\\varepsilon\\). In the next iteration this difference might be smaller, the same, or bigger. In the last case the time series diverge, which is typical for chaos. The Lyapunov coefficient is defined as:\n\\[\n{\\lambda_{L} = \\lim_{n \\rightarrow \\infty}}{\\frac{1}{n}}{\\sum_{i}^{n}{\\ln\\left| f^{'}\\left( X_{i} \\right) \\right|}} \\tag{2.3}\\]\nwhere \\(f^{'}\\left( X_{i} \\right) = r - 2rX\\) for the logistic map and \\(\\lambda_{L} &gt; 0\\) indicates chaos. You may verify in a simulation that \\(\\lambda_{L} &gt; 0\\) for $r = 4,$indicating chaos."
  },
  {
    "objectID": "ch2.html#phase-plot-and-bifurcation-diagrams",
    "href": "ch2.html#phase-plot-and-bifurcation-diagrams",
    "title": "2  Chaos and unpredictability",
    "section": "2.5 Phase plot and bifurcation diagrams",
    "text": "2.5 Phase plot and bifurcation diagrams\nEquation 2.2 is very simple. It is just one equation, a deterministic difference equation specifying how \\(X_{t + 1}\\) depends on \\(X_{t}\\), but the variety of behavior is astonishing. One way to better understand its behavior is to use phase plots. A phase plot is a graphical representation of the relationship between two or more variables that change over time. In one-dimensional systems we plot \\(X_{t}\\) against \\(X_{t + 1}\\).\n\nlayout(matrix(1:6,2,3))\nr &lt;- 3.3; x &lt;- .001; n &lt;- 200\nfor(i in 1:(n-1)) x[i+1] = r*x[i]*(1-x[i])\nx &lt;- x[-1:-100]\nplot(x,type='l',xlab='time',bty='n', main=paste('r = ',r),ylim=0:1,cex.main=2) \nplot(x[-length(x)],x[-1],xlim=0:1,ylim=0:1,xlab='Xt',ylab='Xt+1',bty='n')\nr &lt;- 4; x &lt;- .001; n &lt;- 200\nfor(i in 1:(n-1)) x[i+1] &lt;- r*x[i]*(1-x[i])\nx &lt;- x[-1:-100]\nplot(x,type='l',xlab='time',bty='n',main=paste('r = ',r),cex.main=2) \nplot(x[-length(x)],x[-1],xlim=0:1,ylim=0:1,xlab='Xt',ylab='Xt+1',bty='n')\nx &lt;- runif(200,0,1)\nx &lt;- x[-1:-100]\nplot(x,type='l',xlab='time',bty='n',main='random noise',cex.main=2) \nplot(x[-length(x)],x[-1],xlim=0:1,ylim=0:1,xlab='Xt',ylab='Xt+1',bty='n')\n\n\n\n\nFigure 2.7: Time (top) and phase (bottom) plots for three cases. Chaos and random noise can be distinguished using the phase plots.\n\n\nThe top figures are time plots and lower figures are phase plots. The first column shows a limit cycle of period 2, the second deterministic chaos and the third noise generated from a uniform distribution. Although the time series of the second and third cases look similar, the phase diagram reveals hidden structure in the chaos time series. Phase plots can help us to distinguish chaos from noise.\nThe second useful graph is the bifurcation graph. It summarizes the behavior of the logistic map for different values of \\(r\\) in one figure. The idea is to plot the equilibria as y-values for a range of \\(r\\)-values on the \\(x\\)-axes. This means that if we take an\\(r\\) value \\((r &lt; 1)\\), we will only plot zero’s, as only \\(X^{*} = 0\\) is a stable fixed point. Between 1 and 3, we will also see one fixed point equal to \\((r - 1)/r\\). For \\(r = 3.3\\), we expect to see 2 points as the attractor is a limit cycle with period 2. For higher \\(r\\) we get chaos. How does this all look? It looks amazing!\nIt is actually a good challenge to program this yourself. The trick is to create time series for a range of values of \\(r\\), delete the first part of this series (we only want the equilibrium behavior) and plot these as y values. So, if the logistic map has period two (\\(r = 3.3\\)), we repeatedly plot only two points. For \\(r = 4\\) we get the whole chaos band.\nA clever way to do this is to use the sapply function in r.\n\nlayout(1)\nf &lt;- function(r, x, n, m){\n  x &lt;- rep(x,n)\n  for(i in 1:(n-1)) x[i+1] &lt;- r*x[i]*(1-x[i])\n  x[c((n-m):n)] # only return last m iterations\n}\nr.range &lt;- seq(0, 2.5, by=0.01) \nr.range &lt;- c(r.range,seq(2.5, 4, by=0.001)) \nn &lt;- 200; m &lt;-100 \nequilibria &lt;- as.vector(sapply(r.range, f,  x=0.1, n=n, m=m-1))\nr &lt;- sort(rep(r.range, m))\nplot(equilibria ~ r, pch=19,cex=.01,bty='n')\n\n\n\n\nFigure 2.8: The bifurcation diagram of the logistic map.\n\n\nHere we see indeed fixed stable points for \\(r &lt; 3\\), the period doubling of the limit cycles for \\(r &gt; 3\\), followed by chaos.\nA recurring phenomenon in many chaotic maps are fractals. Fractals are figures in which certain patterns reappear when we zoom in on the figure, and this happens again and again when we zoom in further. You can see this by zooming in on the interval of r between 3.83 and 3.86 (see exercise 2). The three equilibria in the limit cycle split again into period doubling cycles, as we saw in the overall plot between \\(r\\) in 3 and 3.5.\nOne famous result on this period doubling route to chaos is the Feigenbaum constant. The ratios of distances between consecutive period doubling points (e.g., the distance between first and second divided by the distance between the second and third point), converge to a value of approximately 4.6692. The amazing thing is that this happens for any unimodal map, not only the logistic map."
  },
  {
    "objectID": "ch2.html#what-did-we-learn",
    "href": "ch2.html#what-did-we-learn",
    "title": "2  Chaos and unpredictability",
    "section": "2.6 What did we learn",
    "text": "2.6 What did we learn\nI find these results stunning. I note again that the generating function is deceptively simple, but its behavior is utterly complex and beautiful to me. Mathematicians have studied every detail of these plots and most of it is beyond my comprehension. The Wikipedia on the logistic map will introduce you to some more advanced concepts, but for our purposes the present introduction will suffice.\nActually, it is good to realize which concepts we have already learned. The first is the concept of equilibrium. The states of dynamical systems tend to converge to certain values. The simplest of these is the fixed point. Fixed points can be stable or unstable (more on this in the next chapter). If we start a system exactly at its unstable fixed point (and there is no noise in the system), it will stay there. But any small perturbation will cause it to escape and move to the fixed stable point.\nThe bifurcation diagram summarizes this behavior and also shows how the equilibria change when a control parameter changes. For example, at \\(r = 1\\) we see a bifurcation in the logistic map. Initially 0 was the stable fixed point and \\((r\\  - 1)/r\\) was unstable. At \\(r = 1\\) this is reversed. At \\(r = 3\\) we see another bifurcation when limit cycles appear.\nWe have learnt that there are all sorts of equilibria. The strangest ones are called strange attractors, which are associated with deterministic chaos. You can see them by making a phase diagram. Phase diagrams for other famous maps are often stunning. The most famous is the Mandelbrot set (look on the internet). There is an R-blog about the Mandelbrot set. I recommend you check it out. Simulation helps understanding!\nThe last thing we learned is that even if our world were deterministic (it is not!), and we knew all the laws of motion (say, the logistic map), and knew initial states with enormous precision, the world is unpredictable.\nThis statement needs some nuance. I have already mentioned that the weather can be chaotic and unpredictable. But the weather is not always so unpredictable. Sometimes longer forecasts are possible. But forecasts beyond, say, 10 days seem out of reach. We also see in the logistic map that when \\(r\\) is close to 4, the forecast suffers from the butterfly effect, but for \\(r = 2\\) the time course is very predictable, even more predictable than in many linear systems. This is because there is only one stable fixed point (.5). The initial state does not matter, we always end up at .5! So the logistic map is extremely predictable or extremely unpredictable depending on \\(r\\)."
  },
  {
    "objectID": "ch2.html#other-maps-and-fractals",
    "href": "ch2.html#other-maps-and-fractals",
    "title": "2  Chaos and unpredictability",
    "section": "2.7 Other maps and fractals",
    "text": "2.7 Other maps and fractals\nThere are many accessible sources on chaos theory. As always, Wikipedia is a great resource. It helps me a lot by actually doing things, i.e., doing computer simulations. One example is the Henon map, which consists of two coupled difference equations:\n\\[\nX_{t + 1} = 1 - aX_{t}^{2} + Y_{t} \\\\\nY_{t + 1} = bX_{t} \\\\\n\\tag{2.4}\\]\nUsing the code example from the logistic map, you should be able to generate time series and a phase diagram for this model. Try to reproduce the first image on the Henon map wiki page. The amazing three-dimensional bifurcation diagram may be more challenging.\nFractals are another topic for further study. Another look at Wikipedia is recommended. Making your own fractals in R is made easy by the R blog by Martin Stefan (2020)."
  },
  {
    "objectID": "ch2.html#detecting-chaos-in-psychophysiological-data",
    "href": "ch2.html#detecting-chaos-in-psychophysiological-data",
    "title": "2  Chaos and unpredictability",
    "section": "2.8 Detecting chaos in psychophysiological data",
    "text": "2.8 Detecting chaos in psychophysiological data\nChaos theory and the logistic map were popularized about 50 years ago, and since then researchers have been looking for chaos in all kinds of time series (Ayers 1997; Robertson and Combs 2014; Schiepek et al. 2017). One idea behind this work is the hypothesis that chaos might be healthy (Pool 1989) or be helpful. It would be helpful in learning algorithms, such as neutral networks, to prevent getting stuck in local minima (Bertschinger and Natschläger 2004). My very first publication was about chaos in neural networks (van der Maas, Verschure, and Molenaar 1990).\nMany publications appeared on the detection of chaos in psychophysiological data. Examples are EEG (Pritchard and Duke 1992) heart beat (Freitas et al. 2009) and EMG (Lei, Wang, and Feng 2001). This is all but easy because these signals are inevitably contaminated with noise. I’m not aware of any recent meta-analyses of these different lines of research but there are still appearing new papers on this topic.\nThere exist many techniques for chaos detection in times series. There are several packages available in R, including new methods based on machine learning techniques (Sandubete and Escot 2021; Toker, Sommer, and D’Esposito 2020). With the Lyapunov function in the package DChaos you can compute the Lyapunov coefficient for times series generated with the logistic map. You may verify that for \\(r = 4\\) you get the Lyapunov coefficient as computed with the derivative earlier."
  },
  {
    "objectID": "ch2.html#exercises",
    "href": "ch2.html#exercises",
    "title": "2  Chaos and unpredictability",
    "section": "2.9 Exercises",
    "text": "2.9 Exercises\n\nFor r=3.5, the logistic map iterates between four points. For which value(s) does it iterate between 8 points? (*)\nIn the bifurcation plot, you can zoom in by changing r.range to seq(3.4, 4, by=0.0001)), perhaps also changing cex=.01 to a lower value. Now zoom in on the interval of r between 3.83 and 3.86. In this interval the chaos suddenly disappears and limit cycles with period 3 appear. Check this with a time series plot for a particular value of r. Provide your r-code and figure (*).\nReproduce the first image from the Henon map wiki page. Provide your r-code and figure (*).\nMake the bifurcation diagram of the Ricker model (see wiki). Provide your r-code and figure. What is the advantage of this model over the logistic map?\nAlso reproduce the three-dimensional bifurcation diagram of the Henon map (**).\nVerify that for r=4 the DChaos package gives the Lyapunov coefficient equal to the one calculated with the derivative (Equation 2.3) (**).\nUse the Rmusic library (installed with devtools::install_github(“keithmcnulty/Rmusic”, build_vignettes = TRUE)) to create a chaos sound machine. Make one for white noise too. Can you hear the difference? (**)\nFind a paper on chaos detection in psychology or psychophysiology and summarize it in 300-400 words (*).\n\n\n\n\n\nAyers, Susan. 1997. “The Application of Chaos Theory to Psychology.” Theory & Psychology 7 (June): 373. https://doi.org/10.1177/0959354397073005.\n\n\nBanks, J., J. Brooks, G. Cairns, G. Davis, and P. Stacey. 1992. “On Devaney’s Definition of Chaos.” The American Mathematical Monthly 99 (4): 332–34. https://doi.org/10.1080/00029890.1992.11995856.\n\n\nBertschinger, Nils, and Thomas Natschläger. 2004. “Real-Time Computation at the Edge of Chaos in Recurrent Neural Networks.” Neural Computation 16 (7): 1413–36. https://doi.org/10.1162/089976604323057443.\n\n\nFreitas, Ubiratan, Elise Roulin, Jean-François Muir, and Christophe Letellier. 2009. “Identifying Chaos from Heart Rate: The Right Task?” Chaos: An Interdisciplinary Journal of Nonlinear Science 19 (2): 028505. https://doi.org/10.1063/1.3139116.\n\n\nLei, Min, Zhizhong Wang, and Zhengjin Feng. 2001. “Detecting Nonlinearity of Action Surface EMG Signal.” Physics Letters A 290 (5): 297–303. https://doi.org/10.1016/S0375-9601(01)00668-5.\n\n\nPool, Robert. 1989. “Is It Healthy to Be Chaotic?” Science 243 (4891): 604–7. https://doi.org/10.1126/science.2916117.\n\n\nPritchard, Walter s., and Dennis w. Duke. 1992. “Measuring Chaos in the Brain: A Tutorial Review of Nonlinear Dynamical Eeg Analysis.” International Journal of Neuroscience 67 (1-4): 31–80. https://doi.org/10.3109/00207459208994774.\n\n\nRobertson, Robin, and Allan Combs, eds. 2014. Chaos Theory in Psychology and the Life Sciences. New York: Psychology Press. https://doi.org/10.4324/9781315806280.\n\n\nSandubete, Julio, E., and Lorenzo Escot. 2021. “DChaos: An R Package for Chaotic Time Series Analysis.” The R Journal 13 (1): 232. https://doi.org/10.32614/RJ-2021-036.\n\n\nSchiepek, Günter K., Kathrin Viol, Wolfgang Aichhorn, Marc-Thorsten Hütt, Katharina Sungler, David Pincus, and Helmut J. Schöller. 2017. “Psychotherapy Is Chaotic(not Only) in a Computational World.” Frontiers in Psychology 8. https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00379.\n\n\nStefan, Martin. 2020. “RPubs - Fractals with R.” https://rpubs.com/mstefan-rpubs/fractals.\n\n\nToker, Daniel, Friedrich T. Sommer, and Mark D’Esposito. 2020. “A Simple Method for Detecting Chaos in Nature.” Communications Biology 3 (1): 1–13. https://doi.org/10.1038/s42003-019-0715-9.\n\n\nvan der Maas, Han L. J., Paul F. M. J. Verschure, and Peter C. M. Molenaar. 1990. “A Note on Chaotic Behavior in Simple Neural Networks.” Neural Networks 3 (1): 119–22. https://doi.org/10.1016/0893-6080(90)90050-U."
  },
  {
    "objectID": "ch2.html#footnotes",
    "href": "ch2.html#footnotes",
    "title": "2  Chaos and unpredictability",
    "section": "",
    "text": "Verhulst proposed this model in the form of a differential equation in continuous time. We will discuss this type of model in Chapter 5. In continuous time, nothing particularly spectacular happens and we only see the kind of behavior displayed in Figure 2.2.↩︎\nWhy this is, is not too difficult to understand. If you google ‘fixed points of difference equations’, you will quickly arrive at stackexchange.com, where several insightful explanations are given.↩︎"
  },
  {
    "objectID": "ch1.html#what-are-complex-systems",
    "href": "ch1.html#what-are-complex-systems",
    "title": "1  Introduction",
    "section": "1.1 What are complex systems?",
    "text": "1.1 What are complex systems?\nSome things in life are simple. When you open the tap, water starts to flow. If you open it further, it flows faster, and if you close it, it stops. Cause-and-effect relationships like this are clear and roughly linear. Such relationships are rare in psychology. Let’s take fear as an example. A fear stimulus, for example a barking dog, can lead to fear and flight, but also to anger and attack. Whether the stimulus is perceived as fearful might depend on subtle differences in context. It has also been debated whether the flight response precedes the feeling of fear or vice versa. Fear could also suddenly change into a panic attack. In psychology, cause and effect relationships are rarely simple, and effects are often non-linear.\nThese difficulties are not unique to psychology (Weaver 1948). Many systems studied in physics, chemistry, and biology show such complex behavior. They are complex systems. Unfortunately, there is no full consensus on the definition of a complex system (Ladyman, Lambert, and Wiesner 2013; Mitchell 2009), but some criteria can be specified (Simon 1962). First, complex systems are made up of many smaller interacting subsystems. These interactions are typically local and fast, as between neurons in our brain. Second, complex systems are open systems, meaning that energy can be absorbed from the environment. Third, complex systems have three types of emergent phenomena. They are fundamentally unpredictable (chaos), they can change very suddenly (phase transitions), and they exhibit globally organized behavior on a slow time scale (self-organization). These remarkable behavioral properties will be discussed in depth in chapters 2, 3 and 4. In this introduction I will present some key examples of complex systems, introduce some general concepts, and discuss the applicability to psychology. I start with the brain.\nThe brain can be considered the ultimate complex system. Compared to computers, brains are extremely energy efficient, but they do consume energy (the equivalent of a light bulb according to (Attwell and Iadecola 2002). About a hundred billion neurons interact with thousands of other neurons in their neighborhood. Fast local interactions somehow form global waves of electrical activity that make up thought processes and even consciousness. The letters you are reading activate retinal neurons that initiate a cascade of electrical waves across billions of neurons that somehow create your understanding of this text (Roberts et al. 2019; Schöner 2020). How is this possible? For me, this is the most fascinating scientific question of all time. It’s the main reason why I’m a psychologist and not a physicist. It is also an extremely difficult question. But we can learn a lot by studying similar systems in physics, chemistry, and biology. Many physical, chemical, and biological systems fall into this category of complex systems.\nAnother fascinating example of a complex system is a flock of birds (Figure 1.1). Flocks of birds move in a beautiful choreography as they glide through the air, their formations shifting and morphing as they twist and turn across the sky. Flocks are well understood and easy to simulate, as we will see in Chapter 4. Flocks fulfill all the criteria of a complex system. They are open systems as birds use energy to fly. Next, each bird responds only to birds in its local neighborhood. They follow roughly three rules. They try to fly in the same direction as their neighbors, stay close to their neighbors and avoid collisions. These are fast and local interactions. I suggest you watch some videos of flocks of birds on the internet. What you see is globally organized behavior on a much slower time scale than the local interactions. This is a prime example of self-organization. There is evidently no one bird in control ordering other birds to change direction. The globally organized behavior of a flock is a form of spontaneous order. What you can also see in these movies is that stable patterns, say an oval shape, can suddenly change. The birds may change direction or split up. Such bifurcations or catastrophes (to be explained in chapter 3) are very typical of complex systems. You can also see that the behavior of these swarms is rather unpredictable. As said, swarms are well understood and can be easily simulated on a computer, but this does not mean that we can predict these systems, an issue that will be discussed further in the next chapter.\n\n\n\nFigure 1.1: A flock of birds\n\n\nThe units or subsystems of a complex system are not necessarily biological systems. Tornados, for example, are made up of air molecules that also interact locally. Tornadoes are unpredictable, self-organizing, global weather phenomena. A famous chemical example is the Belousov-Zhabotinsky reaction, a chemical oscillator (Kuramoto 1984). Again, watching a YouTube video is highly recommended.\nA very inspiring example for me comes from the study of shallow lakes (Scheffer 2004). Shallow lakes tend to be either in a ‘healthy’ state, with clear water and a diverse population of fish and plants, or in an ‘unhealthy’ turbid state. I like to compare these complex lake systems in the turbid state to a patient suffering from depression. This turbid state usually occurs suddenly. There is a critical phosphorus load at which the system “turns over” from being healthy to complete dominance by algae and bream. Typical of this type of transition is the hysteresis effect (Figure 1.2). This means that the turning point from clear to turbid and from turbid to clear does not occur at the same phosphorus load. The turning point to clear water only occurs at much lower phosphorus loads. These tipping points may be so far apart that reducing the cause, the phosphorus load, is not a viable option. Of course, all sorts of interventions have been studied, such as supplemental oxygen, chemicals, sunscreens and stocking predatory fish. These interventions have not been very successful, or only in specific cases. The fact that they had some level of success brings to mind the partial effectiveness of clinical interventions, such as those used in the treatment of major depressive disorder.\n\n\n\nFigure 1.2: The transitions between clear and turbid states of shallow lakes do not occur at the same phosphorus load. This delay in jumps is called hysteresis. Hysteresis explains why transitions are often difficult to reverse. This concept is discussed in detail in Chapter 3.\n\n\nA breakthrough occurred in the 1980s. Catching all the fish proved to be a very effective intervention. The ecologists caught almost all the fish with nets during the winter. In the spring, a new, healthy equilibrium emerged, characterized by aquatic plants, other fish species and clear water. This new state is often stable for long periods of time. Remarkably, the analysis of the cause, the phosphorus load, was not part of the solution: although the increasing phosphorus load is the primary cause of the transition towards a turbid state, decreasing the phosphorus lead does not cause the system to transition back into the clear state. The dogma of intervention, that the cause of the problem is the key to the solution, does not necessarily apply to complex systems. What this means for our thinking about depressed patients will be discussed later."
  },
  {
    "objectID": "ch1.html#psychology-and-the-social-sciences",
    "href": "ch1.html#psychology-and-the-social-sciences",
    "title": "1  Introduction",
    "section": "1.2 Psychology and the social sciences",
    "text": "1.2 Psychology and the social sciences\nThe study of complex systems in the natural sciences (Figure 1.3) is highly technical. I like to think of the field of complex systems as a toolbox of empirical paradigms and mathematical models and techniques (Grauwin et al. 2012). Models are often formulated in the form of difference or differential equations and subjected to, for example, bifurcation analysis. These are mathematical ways of describing the behavior of complex systems. In addition, advanced numerical analysis, computer simulation, is standard. However, educational programs in psychology do not usually include courses in algebra, calculus and programming. Psychologists, and social scientists in general, lack the basic knowledge and skills to apply the toolbox of complex systems theory, as these are not ordinarily part of the psychology curriculum. Complex systems research simply seems too complex for psychologists and social scientists.\nMoreover, there are additional complications in applying this toolbox to our field. First, our subjects are much more complex than flocks of birds or tornadoes and display astonishing behavior. They can do science! They can also walk out of the lab because they find the experiment boring. This does not happen with lasers.\nSecond, we have to deal with the ethical constraints of experimenting on our subjects. We cannot take them apart, a very successful approach in the natural sciences. Finally, there is the measurement issue (Lumsden 1976; Michell 1999). We tend to forget how incredibly precise the natural sciences, especially physics, are. In 1985, Richard Feynman famously claimed that the accuracy of calculating the size of the magnetic moment of the electron was equivalent to measuring the distance from Los Angeles to New York, a distance of over 3,000 miles, to the width of a human hair. I find that shocking. Less famously, I would argue that social scientists have not yet discovered America and have no idea where New York is. Our instruments generally fail to meet elementary requirements of reliability and validity, we are plagued by replication failures, and our theories are often imprecise (Eronen and Bringmann 2021). Navigating the behavioral and social sciences and knowing which data to trust and which empirical phenomena to model is an art in itself.\n\n\n\nFigure 1.3: An overview of the toolbox of complex system science (source: Wikipedia)\n\n\nThis is all unfortunate because not only our brains, but every subject in our field seems to have the characteristics of a complex system. Any social system is a complex system, made up of individuals interacting to produce emergent phenomena such as cultures and economics. The human brain, the most complex system we know, is embedded in different hierarchies of very complex social systems such as families, education, economies, and cultures. We need the toolbox!\nDespite all these problems, I’m not pessimistic. I would also argue that tangible progress in the behavioral and social sciences is possible. It is not that these sciences are completely unsuccessful. We know a lot about people’s attitudes, addictive behavior, cognition, and the social systems in which they interact. We study these, with some success, using advanced experimental designs, and we have developed verbal theories about almost everything.\nWe also have no choice; we must make progress. Personally, I feel a strong tension between our struggle to elevate the behavioral and social sciences as a science on the one hand, and the enormous expectations of society to deliver on the other. Our most pressing global problems - climate change, overpopulation, war and violence, poverty, inequality, infectious diseases, addiction, to name but a few - are unsolvable without breakthroughs in the behavioral and social sciences.\nThe realization that the human mind in its social context is an amazingly complex system also offers opportunities. Despite their obvious differences, complex systems show remarkable similarities. A predecessor of complex system theory, general systems theory (Bertalanffy 1969), explicitly assumed that all systems share important characteristics. Certain mechanisms and phenomena seem to operate in similar ways at all possible levels of description. In the following, I will discuss three reasons to be somewhat optimistic, based on three key observations about complex systems. The first key observation has to do with simplification, the second with the tendency of complex systems to be characterized by a limited number of stable states, and the third key observations is that all complex systems seem to be describable as some kind of network. Simplification is perhaps the most important one, which I first discuss under the heading of emergentism."
  },
  {
    "objectID": "ch1.html#emergentism",
    "href": "ch1.html#emergentism",
    "title": "1  Introduction",
    "section": "1.3 Emergentism",
    "text": "1.3 Emergentism\nA difficult question, which I will not discuss in depth, is the relationship between complexity and reductionism (the idea that complex phenomena can be explained by reducing them to the interactions of their individual parts or components). The first question is why it is possible to do science in any field other than physics, since ultimately chemistry, biology, and even psychology, are all about interacting elementary particles. Should we not first finish the study of physics before starting to think about complex molecules, cells, neurons, or higher-order human cognition?\nPhilip Anderson’s renowned paper on “More is Different” convincingly argues that the answer to this question is a resounding no (Anderson 1972). Science is possible at many different levels of description without fully understanding the lower levels. Why this is possible is not entirely clear. There is much to be said for reductionism, but somehow the laws of quantum mechanics are irrelevant when studying interactions between neurons or people. I don’t think that emergence in complex systems is inconsistent with a reductionist view of science (Bechtel and Abrahamsen 2005). One could say that complex systems theory explains why emergent phenomena such as swarms can be used as entities at a higher level of description to explain new higher order phenomena, without being a dualist.\nA fascinating and instructive example is the traffic jam, which is made up of many people, with their amazingly complex brains, in modern cars full of advanced technology. Where to start? The answer is astonishing. It seems that we can reduce people in cars to simple blocks in a lane, speeding up when there is space in front of the artificial car and braking when they get too close to the car in front. This is even simpler than a flock of birds.\nIt is not difficult to set up a computer simulation for this case. I recommend that you spend some time playing around with an example (https://www.traffic-simulation.de/). It does not take long to see that traffic jams can easily form and have an unexpected property: while cars move forward, traffic jams move backwards! Another interesting observation is that variance in speed causes congestion. But the variance is not in any of the cars. Variance and congestion are properties at a higher level of description. With this simulation, you can study different types of traffic situations and interventions. This type of simulation seems to be very useful for the design of motorways (Barceló 2010; Treiber, Hennecke, and Helbing 2000).\nThe traffic example shows that extreme simplification is sometimes possible and necessary. In complex systems, the qualitative properties of large-scale phenomena do not depend on microscopic details. Only higher-level properties are relevant to global behavior (Castellano, Muñoz, and Pastor-Satorras 2009). To me, the art of doing science is, for a large part, finding the right level of simplification. Suppose we are studying smoking. Do we model the effects of nicotine on blood vessels, how the hand with the cigarette moves from the mouth to the ashtray, or the number of cigarettes smoked per day? Do we include the effects of marketing and the smoker’s social network?\nWhat is relevant and what can be ignored? It can be challenging to provide a definitive answer for specific cases. Nevertheless, in general, it can be stated that there is a limit to the lower levels that must be considered. When examining traffic jams, it is necessary to incorporate certain characteristics of individuals and vehicles, but delving deeper into topics like neuronal firing, DNA replication, or the intricate workings of car batteries becomes irrelevant. At that level of modeling, there is no relevant information that would alter the explanation of a traffic jam. This fundamental principle of emergence is what allows disciplines like psychology to exist as distinct and independent fields of science (Fodor 1974).\nThe second, more controversial, question is whether emergent phenomena have an independent causal role (strong emergence) or mainly have descriptive value (weak emergence). Strong emergence is often associated with downward causation (Chalmers 2006; Flack 2017; Kim 2006). Downward or circular causation is the idea that higher-level entities or properties can influence the behavior of lower-level entities or properties. I like to link this to the flocking example. Flocks of birds are emergent phenomena that do not determine the behavior of the individual birds. The birds only follow the local rules. Flocking is an example of weak emergence. However, when predators enter the scene things change. Predators get confused by flocks of prey, not by the behavior of individual birds. So, the flock has some causal power. Moreover, the birds react to the movements of the predator. This could be seen as an example of downwards causation and thus strong emergence (Figure 1.4). Recent work attempts to quantify such causal emergence effects (Hoel, Albantakis, and Tononi 2013).\nIt is also argued that emergence is a consequence of symmetry breaking (Krakauer 2023). Symmetry breaking occurs when a system transitions from a symmetric state to an asymmetric state, resulting in the emergence of distinct properties or behaviors. An example of symmetry breaking can be observed in the formation of snowflakes. Initially, ice crystals have a symmetrical hexagonal shape due to the underlying molecular structure of water. However, as the crystal continues to grow, environmental factors such as temperature and humidity influence its growth pattern. Minute variations in these factors lead to the breaking of initial symmetry and the formation of diverse and beautiful snowflake structures.\n\n\n\nFigure 1.4: An illustration of downwards or circular causation in flocks due to a predator responding to the emerging patterns of the flock and subsequently influencing the flight of individual birds. (adapted from https://arxiv.org/abs/1108.1682).\n\n\nIn my view, the arguments against strong emergence and downward causation may be difficult to entirely dismiss, yet they seem rather futile. Our minds, encompassing conscious thought, self-awareness, reasoning abilities, natural language comprehension, emotions, and attitudes, are not mere artifacts and cannot be simply reduced to intricate patterns of neural activity. These mental constructs possess their own causal influence, and psychology stands as a scientific discipline in its own right."
  },
  {
    "objectID": "ch1.html#theory-construction-methodology",
    "href": "ch1.html#theory-construction-methodology",
    "title": "1  Introduction",
    "section": "1.4 Theory construction methodology",
    "text": "1.4 Theory construction methodology\nFinding the right level of simplification is key but not a simple task at all. In Borsboom et al. (2021) we propose a theory construction methodology (TCM) consisting of five steps. The first step is to identify the empirical phenomena that become the target of explanation. The second step is to formulate a set of theoretical principles that putatively explain these phenomena. Third, this set or prototheory is used to construct a formal model, a set of model equations that encode the explanatory principles. Fourth, we analyze the explanatory adequacy of the model, i.e., whether it actually reproduces the phenomena identified in step one. Fifth, we determine whether the explanatory principles are sufficiently parsimonious and substantively plausible. The article explains these steps in detail and provides an example, the mutualism model of general intelligence, which is explained in chapter five of this book.\nI will add a few comments to this list of steps. First of all, step 1 is key. It is crucial to be precise about what the phenomena to be explained are. Phenomena are not the same as data. Data are particular empirical patterns (a concrete data set), whereas phenomena refer to general empirical patterns, stable and general features of the world (Haig 2014). As noted above, in the behavioral and social sciences it is not always clear which data patterns can be trusted. In the last 10 years, the replication crisis has led to a revolution in psychological methods, but many results are collected using potentially biased methods. One problem is publication bias. Negative results are still harder to publish than results that support hypotheses. In other cases, the results of different studies contradict each other, and meta-analyses show weak effects at best. Drawing up a list of the most important phenomena on a topic, such as depression, forgetting or discrimination, is often a challenge.\nThe second observation is that taking these steps is not a linear process. Often, when you are building a model, you realize that there is crucial information missing from the list of phenomena. For example, you might be modelling addiction, but suddenly you need information about the combination of addictive substances that people use. And such simple questions are often impossible to answer. I spent days searching the literature for information that I expected to be readily available, only to find that many basic things are simply unknown.\nA third observation is that formal modelling is mostly a matter of analogical reasoning. You have to study many examples of complex system models to understand how to build such a model. Indeed, in my own work I often use established models developed in physics and biology as a base model. We will see many examples of this later.\nFourth, good models do not build in phenomena, but explain them from basic principles. We will see examples of phenomenological models of complex systems, as well as explanatory models, where the latter are based on fundamental principles. Building real explanatory models in our fields is extremely difficult.\nFifth, it is my conviction that a metaphorical use of the complex systems approach should be avoided by using concrete formal models. It is crucial to strive for the highest level of scientific rigor. There are no special, more lenient, methodological rules for complex systems research (van der Maas 1995)."
  },
  {
    "objectID": "ch1.html#a-limited-number-of-equilibria",
    "href": "ch1.html#a-limited-number-of-equilibria",
    "title": "1  Introduction",
    "section": "1.5 A limited number of equilibria",
    "text": "1.5 A limited number of equilibria\nThat complex systems can be simplified was the first key observation. The second key observation is that complex systems tend to be characterized by a limited number of equilibria. An important example is water. Water normally exists in either a solid, liquid or gaseous state (leaving aside the plasma state). These are stable states over wide ranges of temperature and pressure.\nA biological example is the life stages of a butterfly (egg, caterpillar, chrysalis and butterfly). Most of the time these insects are in one of these four relatively stable states. Another example is the horse, which is either standing still, walking, trotting or galloping. I am convinced that we must always start by identifying the equilibria of a complex system. This also applies to psychological and social science applications. A bipolar disorder seems to be characterized by two stable states (depressive and manic). In case of addiction we may think of a state of non-use, recreational use, and heavy use (Epskamp et al. 2022). Similarly, we should identify the stages in falling in love, in understanding of calculus, in sleeping and in radicalization.\nThis turns out to be more difficult than it first appears. There is an ongoing discussion about the number of stages, even for something like sleep stages (de Mooij et al. 2020). It is often possible to come up with more substages. For instance, in the case of horse movement people tend to further subdivide trot into three forms (working, medium, and collected). Subdivisions are also made in the case of heavy alcohol consumption (Leggio et al. 2009). It is possible to use objective statistical methods to support such classifications using modern machine learning techniques (automatic clustering) as well as more traditional means (finite mixture models, latent class analysis). I will say more about this in Chapter 3.\nA further complication is that equilibria come in different forms. The simplest form consists of fixed points or point attractors, an example being a ball lying in a valley. Under undisturbed conditions, the ball could also be resting on top of a hill, which is an unstable equilibrium. An equilibrium could also be a limit cycle or oscillator. For example, two pendulums could swing in phase or out of phase. It gets even weirder when we get to strange attractors, which often take the form of fractals. This will be explained in more detail in the next chapter.\nAlthough complex systems tend to be in one attractor state most of the time, they occasionally change states. If certain control parameters slowly change their values, the current equilibrium can become unstable and a transition to another equilibrium can occur. This is what happens when we lower the temperature of water to below zero. Transitions can occur in many ways, also depending on the types of equilibria involved. The family of transition models is described by bifurcation theory. This is explained in more detail in Chapter 3, where we focus on a very important transition model, the cusp catastrophe, and in Chapter 5, which considers dynamical systems models."
  },
  {
    "objectID": "ch1.html#networks-are-everywhere",
    "href": "ch1.html#networks-are-everywhere",
    "title": "1  Introduction",
    "section": "1.6 Networks are everywhere",
    "text": "1.6 Networks are everywhere\nThe third key observation of great relevance to the attempt to use complex systems modelling in psychology is that complex systems are networks, as they consist of interacting sub-elements. For me, the network is the most interdisciplinary research topic in modern science. Magnets, ecosystems, the brain, the Internet, and social networks are prime examples. Network science is a huge area of research with many fundamental insights.\nIn psychology, two applications are well known: the first is the study of neural networks, which started 70 years ago and has become the main foundation of the AI revolution of the last 10 years. In Chapter 4 I will discuss neural networks. The second is social networks, the simplest example being dyadic interactions. Social media such as Facebook are large examples. Key ideas relate to concepts such as weak and strong ties, central hubs and homophily, which are discussed in Chapter 6 and 7. The analysis of social network data is an exciting area of research (Scott 2011). It focuses on understanding how social entities are connected and how these connections influence various outcomes and behaviors. Connections between nodes (e.g., individuals, organizations, communities) can be based on different dimensions, such as friendship, communication, collaboration, information flow, or any other form of social interaction. These interactions may also change over time, which is studied in social network dynamics (Snijders 2001). The statnet.org website provides an overview of R packages for social network analysis.\nChapter 6 focuses on another use of networks, which we call network psychology. This is a level of description between neural networks and social networks. It involves modelling intelligence, attitudes, and psychological disorders at the individual level. Intelligence, for example, is modelled as an ecosystem of cooperating cognitive functions. This differs from the standard view that general intelligence is due to g, a single underlying source. Similarly, depression can be seen as a network of mutually reinforcing symptoms. This new view of mental disorders originated in our research group and is now very popular (Robinaugh et al. 2020). One reason for this is that many statistical techniques have been developed to investigate this network approach.\nThe latest line of research is the integrated study of psychological and social networks. Chapter 7 deals with models in which psychological network models of attitudes are nested within social networks of opinion change."
  },
  {
    "objectID": "ch1.html#other-work-and-sources",
    "href": "ch1.html#other-work-and-sources",
    "title": "1  Introduction",
    "section": "1.7 Other work and sources",
    "text": "1.7 Other work and sources\nThe complex systems approach is often introduced as the next new thing, but those days are gone. Even in psychology it can no longer be considered a new approach. Many different research groups have used the toolbox of complex systems research in many areas of psychology. This book will give many examples. One could even argue that a lot of work has been done that could be considered complex systems research but has not been published under that heading. For example, most neural network models of psychological processes are complex systems models because they investigate emergent computational properties of the interaction of neural units. This is also true of much work in mathematical psychology, for example when differential equations are used to study dynamical systems. Older work in complex systems research has often been published with reference to nonlinear dynamical systems, which is a related concept. Other related approaches are computational social science and agent-based modeling.\nToday, there are many interdisciplinary centers or hubs for complexity research. The Santa Fe Institute in Santa Fe, New Mexico, is one of the pioneers of complexity science. Its summer schools are highly recommended. Other famous ones are the Institute for Advanced Study in Princeton, the Complexity Science Hub in Vienna, and the Centre for Complexity Science at the University of Warwick. In my own country, the Netherlands, we have at least four of these centers. I’m a principal investigator at the Institute for Advanced Study in Amsterdam and an external faculty member at the Santa Fe Institute.\nIt is impossible to give a balanced review of all past and ongoing work on complex systems. I’m naturally somewhat biased towards our own work and contributions, but I’ll do my best to point out relevant work. As a general resource to complex systems research with a bit less technical approach I recommend Mitchell’s book (Mitchell 2009), for a bit more mathematical approach (but still doable), I recommend the book of Serra and Zanarini (Serra and Zanarini 1990). Overviews of work in psychology are provided by Guastello, Koopmans, and Pincus (2008) and Port and Gelder (1995). Other great books are written by Heath (2000) and Kelso (1995)."
  },
  {
    "objectID": "ch1.html#exercises",
    "href": "ch1.html#exercises",
    "title": "1  Introduction",
    "section": "1.8 Exercises",
    "text": "1.8 Exercises\n\nVisit https://www.traffic-simulation.de/. In what direction do traffic jams move? For roundabouts: what is a bad priority rule? Do traffic jams appear and disappear for the same values of critical parameters? Take for instance the ‘ring’ road and vary Politeness. (*)\nGive your own example of a psychological process or theory where different stable stage or states are distinguished. (*)\nCould consciousness be seen as a process of downwards causation. Explain your answer. (**)\n\n\n\n\n\nAnderson, P. W. 1972. “More Is Different.” Science 177 (4047): 393–96. https://doi.org/10.1126/science.177.4047.393.\n\n\nAttwell, David, and Costantino Iadecola. 2002. “The Neural Basis of Functional Brain Imaging Signals.” Trends in Neurosciences 25 (12): 621–25. https://doi.org/10.1016/S0166-2236(02)02264-6.\n\n\nBarceló, Jaume, ed. 2010. Fundamentals of Traffic Simulation. Vol. 145. International Series in Operations Research & Management Science. New York, NY: Springer New York. https://doi.org/10.1007/978-1-4419-6142-6.\n\n\nBechtel, William, and Adele Abrahamsen. 2005. “Explanation: A Mechanist Alternative.” Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences, Mechanisms in biology, 36 (2): 421–41. https://doi.org/10.1016/j.shpsc.2005.03.010.\n\n\nBertalanffy, Ludwig Von. 1969. General System Theory: Foundations, Development, Applications. Revised edition. New York, NY: George Braziller Inc.\n\n\nBorsboom, Denny, Han L J van der Maas, Jonas Dalege, Rogier A Kievit, and Brian D Haig. 2021. “Theory Construction Methodology: A Practical Framework for Building Theories in Psychology.” Perspectives on Psychological Science 16 (4): 756–66. https://doi.org/10.1177/1745691620969647.\n\n\nCastellano, Claudio, Miguel A. Muñoz, and Romualdo Pastor-Satorras. 2009. “Nonlinear $q$-Voter Model.” Physical Review E 80 (4): 041129. https://doi.org/10.1103/PhysRevE.80.041129.\n\n\nChalmers, David J. 2006. “Strong and Weak Emergence.” https://philpapers.org/rec/chasaw.\n\n\nde Mooij, Susanne M. M., Tessa F. Blanken, Raoul P. P. P. Grasman, Jennifer R. Ramautar, Eus J. W. Van Someren, and Han L. J. van der Maas. 2020. “Dynamics of Sleep: Exploring Critical Transitions and Early Warning Signals.” Computer Methods and Programs in Biomedicine 193 (September): 105448. https://doi.org/10.1016/j.cmpb.2020.105448.\n\n\nEpskamp, Sacha, Han L. J. van der Maas, Roseann E. Peterson, Hanna M. van Loo, Steven H. Aggen, and Kenneth S. Kendler. 2022. “Intermediate Stable States in Substance Use.” Addictive Behaviors 129 (June): 107252. https://doi.org/10.1016/j.addbeh.2022.107252.\n\n\nEronen, Markus I., and Laura F. Bringmann. 2021. “The Theory Crisis in Psychology: How to Move Forward.” Perspectives on Psychological Science 16 (4): 779–88. https://doi.org/10.1177/1745691620970586.\n\n\nFlack, Jessica C. 2017. “Coarse-Graining as a Downward Causation Mechanism.” Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 375 (2109): 20160338. https://doi.org/10.1098/rsta.2016.0338.\n\n\nFodor, J. A. 1974. “Special Sciences (or: The Disunity of Science as a Working Hypothesis).” Synthese 28 (2): 97–115. https://doi.org/10.1007/BF00485230.\n\n\nGrauwin, Sebastian, Guillaume Beslon, Éric Fleury, Sara Franceschelli, Celine Robardet, Jean-Baptiste Rouquier, and Pablo Jensen. 2012. “Complex Systems Science: Dreams of Universality, Interdisciplinarity Reality.” Journal of the American Society for Information Science and Technology 63 (7): 1327–38. https://doi.org/10.1002/asi.22644.\n\n\nGuastello, Stephen J., Matthijs Koopmans, and David Pincus. 2008. Chaos and Complexity in Psychology: The Theory of Nonlinear Dynamical Systems. Cambridge University Press.\n\n\nHaig, Brian D. 2014. Investigating the Psychological World: Scientific Method in the Behavioral Sciences. MIT Press.\n\n\nHeath, Richard A. 2000. Nonlinear Dynamics: Techniques and Applications in Psychology. 1st edition. Mahwah, N.J: Psychology Press.\n\n\nHoel, Erik P., Larissa Albantakis, and Giulio Tononi. 2013. “Quantifying Causal Emergence Shows That Macro Can Beat Micro.” Proceedings of the National Academy of Sciences 110 (49): 19790–95. https://doi.org/10.1073/pnas.1314922110.\n\n\nKelso, J. A. S. 1995. Dynamic Patterns: The Self-Organization of Brain and Behavior. Dynamic Patterns: The Self-Organization of Brain and Behavior. Cambridge, MA, US: The MIT Press.\n\n\nKim, Jaegwon. 2006. “Emergence: Core Ideas and Issues.” Synthese 151 (3): 547–59. https://doi.org/10.1007/s11229-006-9025-0.\n\n\nKrakauer, David C. 2023. “Symmetrysimplicity, Broken Symmetrycomplexity.” Interface Focus 13 (3): 20220075. https://doi.org/10.1098/rsfs.2022.0075.\n\n\nKuramoto, Yoshiki. 1984. “Chemical Turbulence.” In Chemical Oscillations, Waves, and Turbulence, edited by Yoshiki Kuramoto, 111–40. Springer Series in Synergetics. Berlin, Heidelberg: Springer. https://doi.org/10.1007/978-3-642-69689-3_7.\n\n\nLadyman, James, James Lambert, and Karoline Wiesner. 2013. “What Is a Complex System?” European Journal for Philosophy of Science 3 (1): 33–67. https://doi.org/10.1007/s13194-012-0056-8.\n\n\nLeggio, Lorenzo, George A. Kenna, Miriam Fenton, Erica Bonenfant, and Robert M. Swift. 2009. “Typologies of Alcohol Dependence. From Jellinek to Genetics and Beyond.” Neuropsychology Review 19 (1): 115–29. https://doi.org/10.1007/s11065-008-9080-z.\n\n\nLumsden, James. 1976. “Test Theory.” Annual Review of Psychology 27: 251–80. https://doi.org/10.1146/annurev.ps.27.020176.001343.\n\n\nMichell, Joel. 1999. Measurement in Psychology: A Critical History of a Methodological Concept. Cambridge University Press.\n\n\nMitchell, Melanie. 2009. Complexity: A Guided Tour. Oxford University Press.\n\n\nPort, Robert F., and Timothy Van Gelder. 1995. Mind as Motion: Explorations in the Dynamics of Cognition. MIT Press.\n\n\nRoberts, James A., Leonardo L. Gollo, Romesh G. Abeysuriya, Gloria Roberts, Philip B. Mitchell, Mark W. Woolrich, and Michael Breakspear. 2019. “Metastable Brain Waves.” Nature Communications 10 (1): 1056. https://doi.org/10.1038/s41467-019-08999-0.\n\n\nRobinaugh, Donald J., Ria H. A. Hoekstra, Emma R. Toner, and Denny Borsboom. 2020. “The Network Approach to Psychopathology: A Review of the Literature 2008 and an Agenda for Future Research.” Psychological Medicine 50 (3): 353–66. https://doi.org/10.1017/S0033291719003404.\n\n\nScheffer, Marten. 2004. Ecology of Shallow Lakes. Dordrecht: Springer Netherlands. https://doi.org/10.1007/978-1-4020-3154-0.\n\n\nSchöner, Gregor. 2020. “The Dynamics of Neural Populations Capture the Laws of the Mind.” Topics in Cognitive Science 12 (4): 1257–71. https://doi.org/10.1111/tops.12453.\n\n\nScott, John. 2011. “Social Network Analysis: Developments, Advances, and Prospects.” Social Network Analysis and Mining 1 (1): 21–26. https://doi.org/10.1007/s13278-010-0012-6.\n\n\nSerra, Roberto, and Gianni Zanarini. 1990. Complex Systems and Cognitive Processes. Berlin, Heidelberg: Springer. https://doi.org/10.1007/978-3-642-46678-6.\n\n\nSimon, Herbert A. 1962. “The Architecture of Complexity.” Proceedings of the American Philosophical Society 106 (6): 467–82. https://www.jstor.org/stable/985254.\n\n\nSnijders, Tom A. B. 2001. “The Statistical Evaluation of Social Network Dynamics.” Sociological Methodology 31 (1): 361–95. https://doi.org/10.1111/0081-1750.00099.\n\n\nTreiber, Martin, Ansgar Hennecke, and Dirk Helbing. 2000. “Congested Traffic States in Empirical Observations and Microscopic Simulations.” Physical Review E 62 (2): 1805–24. https://doi.org/10.1103/PhysRevE.62.1805.\n\n\nvan der Maas, H. L. J. 1995. “Beyond the Metaphor?” Cognitive Development 10.\n\n\nWeaver, Warren. 1948. “Science and Complexity.” American Scientist 36 (4): 536–44. https://www.jstor.org/stable/27826254."
  },
  {
    "objectID": "ch3.html#introduction",
    "href": "ch3.html#introduction",
    "title": "3  Transitions in complex systems",
    "section": "3.1 Introduction",
    "text": "3.1 Introduction\nThe second key observation about complex systems was that complex systems tend to be characterized by a limited number of equilibria. As we have seen in the previous chapter these equilibria can take many different forms, but in this chapter, we consider only stable and unstable fixed points. We are particularly interested in the case where the configuration of stable and unstable points changes due to a smooth change in some external variable, a control variable. In such a case a discontinuous change or a (first order) phase transition can occur. A transition or tipping point is the second of the three intriguing properties of complex systems (chaos being the first).\nI call it an intriguing property because in the linear systems we are used to, smooth changes in control variables lead to similar (proportional) changes in behavior variables. We may see a big change in some behavior, but this requires a big change in the controls. An example would be the speed of your bike and the force you apply. But in the case of fear or panic, this process is often non-linear. If a smooth change in an independent or control variable, such as the smell of smoke, leads to a sudden jump in fear (e.g., panic), we are likely to be dealing with a phase transition.\nA key example is the change in state of water. Between, say, 10 and 80 degrees Celsius, a smooth change in temperature results in only a slight change in the liquid state of water. But if we change the temperature very slowly, close to the thresholds of 0 or 100 degrees Celsius, we see sudden phase transitions.\nWe saw something similar for the logistic map when \\(r\\) crossed the boundary \\(r = 1\\). However, this did not lead to a sudden change in \\(X^{*}\\). This is often called a second order phase transition, meaning that the configuration of stable and unstable points changes, but there is no discontinuous change in behavior.\n\n\n\nFigure 3.1: A first order (discontinuous) and second order (continuous) phase transition. (from: https://polymerdatabase.com/polymer%20physics/ThemalTransitions.html)\n\n\nDiscontinuous phase transitions such as melting and freezing occur in many systems. Famous examples from the natural sciences include collapsing bridges, turning over ships, cell division, and climate transitions such as the onset of ice ages. Examples from the social sciences include conflict, war, and revolution. Some examples from psychology are falling asleep, outbursts of aggression, radicalization, falling in love, sudden insights, relapses into depression or addiction, panic, and multistable perception.\n\n\n\nFigure 3.2: Transitions in the perception of the Necker cube. The perception of the middle cube is bistable, and sudden transitions occur between the left (‘front’) and right (‘back’) percepts.\n\n\nMy dissertation research was on the theory of Piaget, who proposed a stage theory of cognitive development. These stages were separated by transitions. One such transition should occur between the pre-operational and concrete-operational stages. In the latter stage, children learn logical, concrete physical rules about objects, such as weight, height, and volume. The most famous test to distinguish between the two stages is the conservation task.\nThere are many conservation tasks, but the setup is always the same. For example, you show a child two equal balls of clay, ask for confirmation that they weigh the same, roll one into a sausage shape, and then ask again for confirmation of equal weight. A non-conserving child will now claim that the longer sausage weighs more. One can do this with two rows of fiches (spreading one row out) or glasses of water (pouring the water from one glass into a smaller longer glass). It is actually a fascinating task, a real fun task to do with children between 5 and 8 years old.\nFrom the 1960’s to the 1980’s, this was a topic of major interest in developmental psychology, and hundreds of papers were published on the subject. A key question was whether there was actually a stage transition, and there was a lot of confusion about what a transition actually was. It was my task to clarify this and to prove Piaget’s hypothesis. I think I succeeded in clarifying the question, but whether I succeeded in proving the stage theory is debatable.1\nThe idea of Peter Molenaar, my supervisor, was to use catastrophe theory to define the concept of a transition in a precise way, to use the so-called catastrophe flags to test the hypothesis of a transition, and also to fit a cusp model to the conservation data. It took me, with the help of many people, more than 20 years to do all these steps.\nWhat is catastrophe theory, what are these flags, and what is the cusp? These are the first questions I will answer in this chapter. But this chapter is also about statistics. We will learn how to fit a cusp model to data. I will present a methodology for studying transitions in areas where we do not have a mathematical description of the underlying system. I will present examples from very different subfields of psychology. Finally, I will discuss the criticisms that were made in response to the hype around catastrophe theory about 50 years ago. This is a long chapter, but I have included only what is necessary to make intelligent use of this approach. This requires some basic understanding of the mathematics of catastrophe theory, a good overview of the possibilities for testing cusp models, and knowledge of the controversies from the early days of the popularization of this theory."
  },
  {
    "objectID": "ch3.html#bifurcation-and-catastrophe-theory",
    "href": "ch3.html#bifurcation-and-catastrophe-theory",
    "title": "3  Transitions in complex systems",
    "section": "3.2 Bifurcation and Catastrophe theory",
    "text": "3.2 Bifurcation and Catastrophe theory\nBifurcation theory is a branch of mathematics that studies changes in the qualitative or topological structure of a given family of dynamical systems as parameters are smoothly varied. Such changes are called bifurcations when, for example, equilibria disappear, appear, or split. Simply put, it studies how small changes in parameters or conditions can lead to large changes in outcomes in mathematical systems.\nCatastrophe theory can be viewed of as a branch of bifurcation theory, describing a subclass of bifurcations. It was developed by Rene Thom (1977) and popularized by Zeeman (1976). The reason I chose to focus on catastrophe theory in this chapter is fourfold: Firstly, it provides one of the few systematic treatments of bifurcations. A systematic treatment is more effective than simply listing all types of bifurcations. Secondly, once you have a grasp of the basics of catastrophe theory, it becomes easier to learn about other bifurcations not encompassed by this theory. Thirdly, it is most widely used approach in psychology and the social sciences. Finally, the field has developed an empirical program and statistical procedures for the practical application of catastrophe theory.\nCatastrophe theory is concerned with gradient systems, in which some quantity is minimized or maximized. These are dynamic systems that can be described by a potential function. Potential functions can be thought of as landscapes with minima and maxima in which we throw a ball and see where it ends up. The simplest case, discussed in the next section, is the quadratic minimum. We can also study what happens to the ball if the landscape changes shape smoothly and a minimum disappears. Then sudden jumps can occur.\nMinima and maxima are called critical points, points where the first derivative of the potential function is zero. Catastrophe theory analyzes so-called degenerate critical points of the potential function — points where not only the first derivative, but also the second derivative of the potential function is zero. Phase transitions can occur at these bifurcation points. Thom proved that there are only seven fundamental types of catastrophes (given a limited set of control parameters). I will start with a mathematical introduction and, after explaining the main concepts, give some psychological examples. An in depth discussion of the role of potential functions in catastrophe theory can be found in the introduction of Chapter 1 of Gilmore (1993).\n\n3.2.1 The quadratic case\nThom’s theorems are known to be highly complicated, but the basic concepts are actually not that difficult to grasp. The simplest potential function is\n\\[\nV(X) = X^{2}\n\\tag{3.1}\\]\n\n\n\nFigure 3.3: The quadratic potential function\n\n\nYou can imagine a ball in a landscape. The ball will roll to the minimum of the potential function. We learned in school that this is the point where the first derivative is zero and the second derivative is positive. The first and second derivatives are \\(V^{'}(X) = 2X\\) and \\(V^{''}(X) = 2\\), respectively. At \\(X = 0\\) we find the minimum.\nThe potential function describes a dynamical system defined by\n\\[\n\\frac{dX}{dt} = - V^{'}(X).\n\\tag{3.2}\\]\nThis makes sense. When the ball is in \\((1,1)\\), \\(- V^{'}(X) = - 2\\) and the ball will move towards \\(X = 0\\). But if \\(X = 0\\), \\(- V^{'}(X) = 0\\), and the ball will not move anymore. In the case of the quadratic potential function, there is only one fixed point. By adding parameters and lower order terms to V, i.e., \\({aX + X}^{2}\\), we can move its location, but the qualitative form (one stable fixed point) will not change. Also note that the second derivative is positive, which tells us that we are dealing with a minimum and not a maximum (the so-called second derivative test).\nMany dynamical systems behave according to this potential function. Nothing spectacular happens: no bifurcations and no jumps. This is different when we consider potential functions with higher order terms.\n\n\n3.2.2 The fold catastrophe\nThe fold catastrophe is defined by the potential function\n\\[\nV(X) = {- aX + X}^{3}.\n\\tag{3.3}\\]\nThis function has a degenerate critical (bifurcation) point at \\(X = 0,\\ \\ a = 0\\), because at this point \\(V^{'}(X) = - a + 3X^{2} = 0\\) and \\(V^{''}(X) = 6X = 0\\), so both the first and second derivative are zero. What makes this point so special? This is illustrated in Figure 16.\n\n\n\nFigure 3.4: A bifurcation at \\(a = 0\\): the equilibria change in qualitative way.\n\n\n\nlayout(t(1:3))\nv &lt;- function(x,a) -a * x + x^3 \ncurve(v(x,a=-2),-3,3,bty='n')\ncurve(v(x,a=0),-3,3,bty='n')\ncurve(v(x,a=2),-3,3,bty='n')\n\nIn the left plot, \\(a &lt; 0\\) and there is no fixed point, the ball rolls away to minus infinity. This can be checked by setting the first derivative to zero, which gives \\(X = \\pm \\sqrt{\\frac{a}{3}}\\). For negative \\(a\\) there is no solution. A positive value of \\(a\\) gives two solutions, as shown on the right for \\(a = 2\\). The positive solution \\(X = \\sqrt{\\frac{2}{3}\\ }\\)is a stable fixed point because the second derivative in this point is positive. The negative solution \\(X = - \\sqrt{\\frac{2}{3}\\ }\\) is an unstable fixed point because the second derivative in this point is negative.\nThe middle figure depicts the case just in between these two cases. Here the equilibrium is an inflection point, a degenerate critical point. The bifurcation occurs at this point as we go from a landscape with no fixed points to one with two, one stable and one unstable.\nAnother way to visualize this is making a bifurcation diagram as we did for the logistic map. On the x-axis we put \\(a\\), from -1 to 2. On the y-axis we plot \\(X^{*}\\), the fixed points of equation \\(7\\). We use lines for stable fixed points and dashed lines for unstable points. The diagram is shown in Figure 17.\n\n\n\nFigure 3.5: The bifurcation diagram of the fold catastrophe\n\n\nThis bifurcation diagram may not look as spectacular as the logistic map, but its importance cannot be overstated. The fold is everywhere! In a fascinating book, The Seduction of Curves (McRobie 2017), McRobie shows that whenever we see an edge, we see a fold. Figure 18 is from the book where he demonstrates how different catastrophes appear in art. I also recommend his YouTube lecture.\n\n\n\nFigure 3.6: The fold in drawings (from McRobie, 2017).\n\n\nThe fold catastrophe has been studied in fields ranging from evolution theory (Dodson and Hallam 1977) to buoyancy in diving (Güémez, Fiolhais, and Fiolhais 2002). In addition, higher order catastrophes are composed of folds. The fold catastrophe is also known as a saddle node, tangential or blue-sky bifurcation. It is an example of a second order phase transition.\n\n\n3.2.3 The cusp catastrophe\nSudden jumps between stable states are associated with first order phase transitions. The cusp, the best-known catastrophe, is the simplest catastrophe with this behavior. The potential function of the cusp is\n\\[ V(X) = {- aX - \\frac{1}{2}bX^{2} + \\frac{1}{4}X}^{4}.  \\tag{3.4}\\]\nThe half and quarter are added to make later derivations a little easier. The highest power is now 4. The first two terms contain the control variables \\(a\\) and \\(b\\), known as the normal and splitting variables. You might ask why there is no third order term. The non-technical answer is that such a term would not change the qualitative behavior of the bifurcation. Catastrophe theory studies bifurcations that are structurally stable, meaning that perturbing the equations (and not just the parameters) does not fundamentally change the behavior (see Section 3.2.6 and Stewart 1982 for further explication).\nIt is advisable to do some minimal research on this equation yourself, using an online graphic claculator tool like Desmos or GeoGebra (paste f(X)=a X-(1/2) b X^2+(1/4) X^4). For example, set \\(a = 1\\) and \\(b = 3\\) and look at the graph of the potential function. Think in terms of the ball moving to a stable fixed point. What you should see is that there are three fixed points, of which the middle one is unstable. This bistability is important. Again, there is a relationship to unpredictability. Although you know the potential function and the values of \\(a\\) and \\(b\\), you are still not sure where the ball is. It could be in either of the minima.\nOther typical behavior occurs when we slowly vary \\(a\\ (\\)up and down from -2 to 2), for a positive \\(b\\) value (\\(b = 2).\\) This is shown in Figure 19. At about \\(a = 1.5\\) we see the sudden jump. The left fixed point loses its stability and the ball rolls to the other minimum.\n\n\n\nFigure 3.7: The change in the potential function of the cusp by varying \\(a\\).\n\n\nNow consider what will happen if we decrease \\(a\\) from 2 to -2. In this case the ball will stay in the right minimum until \\(a = - 1.5\\). Where the jump takes place depends on the direction of the change in \\(a\\), the normal variable. This lagging behind, or resistance to change, is called hysteresis. Hysteresis is of great importance in understanding change or lack of change in complex systems. The state in which the ball is the less deep minimum (for \\(a = 0.5\\) in Figure 19) is often called a metastable or locally stable state. Metastable states appear to be stable for some time but are not in their globally stable state.\nGilmore (1993) made an important point about noise in the system. If there is a lot of noise, the jumps occur earlier and we see less or no hysteresis effect. This is called the Maxwell convention as opposed to the ‘delay’ convention. Demonstrating hysteresis therefore requires precise experimental control.\nAnother very interesting pattern occurs when \\(a = 0\\) and \\(b\\) is increased.\n\n\n\nFigure 3.8: The change in the potential function of the cusp by varying \\(b\\).\n\n\nFor low \\(b\\) there is one stable fixed point that becomes unstable. It splits up in two new attractors. As we did for the fold, we can make bifurcation diagrams showing the equilibria of X as a function of \\(a\\) and \\(b\\). Along the \\(a\\)-axis we see hysteresis and along the \\(b\\)-axis we see divergence or what is often called a pitchfork bifurcation.\n\n\n\nFigure 3.9: Bifurcation diagrams along the \\(a\\) and \\(b\\) axes. The area in the dotted box is a fold.\n\n\nTo depict the combined effects of \\(a\\) and \\(b\\), we require a three-dimensional plot, which combines the hysteresis and pitchfork diagrams.\n\n\n\nFigure 3.10: The cusp catastrophe combines hysteresis along the normal axis (\\(a\\)), and the pitchfork along the splitting axis (\\(b\\)). At the back of the cusp, changes in \\(a\\) only lead to smooth changes in the equilibrium behavior \\(X^{*}\\). At the front, sudden jumps occur when we cross the bifurcation lines. These jumps are typical of first order phase transitions. The area between the bifurcation lines is called the bifurcation set. In this area there are two stable and one instable equilibrium (colored grey).\n\n\nThe cusp diagram can be expressed mathematically by setting the first derivative to zero:\n\\[\nV^{'}(X) = {- a - bX + X}^{3} = 0.\n\\tag{3.5}\\]\nThis type of equation is called a cubic equation.2 The degenerate critical points of the cusp can be found by setting the first and second derivative to zero. This is just within reach of your high school mathematics training and I leave this as an exercise. The result is:\n\\[\n27a^{2} = 4b^{3}.\n\\tag{3.6}\\]\nThis equation defines the bifurcation lines where the first and second derivatives are both zero and sudden jumps occur (see Figure 22). The region between the bifurcation lines is the bifurcation set. In this region, the bifurcation has three fixed points, the middle of which is unstable. These unstable states in the middle are called the inaccessible area, colored gray in the cusp diagram. The bifurcation lines meet at (0,0,0). At this point, the third derivative is also zero. This is the cusp point.\n\n\n3.2.4 Examples of cusp models\nTo illustrate the cusp, I always use the business card (Figure 23). I strongly recommend that you test this example (not with your credit card). You can play with two forces. \\(Fv\\) is the vertical force and the splitting control variable (\\(b\\)) in the cusp. \\(Fh\\) is the horizontal force and the normal variable (\\(a\\)) in the cusp. Note that you will only get smooth changes when \\(Fv = 0\\), but sudden jumps and hysteresis when you employ vertical force. One very important phenomenon is that the card has no ‘memory’ when the \\(Fv = 0\\). You can push the card to a position, but as soon as you release this force (\\(Fh\\) back to zero), the card moves back to the center position. This is not the case with vertical pressure. If we force the card to the left or right position it will stay there, even if we remove the horizontal force. The card has a ‘memory’.\n\n\n\nFigure 3.11: A simple business card can be used to illustrate all the properties of the cusp (see text).\n\n\nThis seems simple but the mathematical analysis of such elastic bending structures is a huge topic in itself (Poston and Stewart 2014). The freezing of water is also a cusp. As an approximation, we could say that the density of water is the behavioral variable, temperature is the normal variable, and pressure acts as a splitting variable (see chapter 14 of Poston and Stewart 2014, for a more nuanced analysis). It is very instructive to study the full phase diagram of water. We do not have to know what a triple point is. What we do need to understand is that this can be viewed as a map of the equilibria. This type of mapping would be extremely useful in psychology and the social sciences.\n\nA psychological example of a cusp concerns sudden jumps in attitudes (Latané and Nowak 1994; van der Maas, Kolstein, and van der Pligt 2003). Attitudes will be discussed in much more detail in later chapters. In general, we have relatively stable attitudes toward many things in life (politics, snakes, hamburgers, and sports), but sometimes they change, and in rare cases they change radically. For example, you may suddenly become a conspiracy theorist, an atheist, or a vegetarian. One example is the attitude toward abortion.\n\n\n\nFigure 3.12: The cusp model of attitudes (toward abortion). Because of hysteresis, it is very difficult to persuade highly involved people with new information, but if they change it will be a sudden jump.\n\n\nCusp modeling begins by the definition of the states of the behavioral variable. In this case the two states of the bistable cusp are the two opposing positions, pro-life and pro-choice. The other state associated with \\(a = 0, b = 0\\) is the neutral state, an ‘I don’t know’ or ‘I don’t care’ position.\nThe normal (\\(a\\)) and splitting (\\(b\\)) variable are interpreted as information and involvement. Information is a collection of factors that influence whether people tend to be in the pro-life and pro-choice position. Political and religious orientation as well as personal experiences add to this overall factor. One way to construct this information variable is through a factor analysis or principal component analysis.\nThe splitting factor, involvement, also combines a number of effects (importance, attention). The main idea is that there are two types of independent variables. Some will work (mainly) along the normal axis and some will (mainly) impact the splitting axis.\nThe implications of this model are that for low involvement change is continuous (Figure 25). Presenting people with some new information supporting the pro-life and pro-choice position will have a moderate effect. One problem, as demonstrated with the business card, is that the uninvolved person has “no memory”. As soon as you stop influencing this person, he drifts to the neutral ‘I don’t care’ position. We have another problem when people are highly involved. Because of the hysteresis effect, it will be very difficult to persuade people with new information. When this hysteresis effect is high, persuasion just does not work. If you have been involved in political discussions, you probably have experienced that yourself.\nBut if the underlying change in information is large enough, attitudes can show a sudden jump. There is a lot of anectodical evidence for this, but it is very hard to capture such an effect in actual time series of attitude measures. Another effect that is consistent with the cusp model is ambivalence. In the cusp, ambivalence is not the same thing as being neutral. The neutral point is at the back of the cusp and is associated with low involvement. Ambivalence is associated with high involvement. Highly involved people with balanced information (\\(a = 0)\\), may oscillate between extreme positions (see Figure 50 in Chapter 5). Finally, the pitchfork bifurcation can explain issue or political polarization. When involvement increases in a group of neutral people, e.g., due to discussion, they may split into two extreme positions.\nAnother psychological example of the cusp is multistable perception. Stewart and Peregoy (1983) proposed a model in which the perception of male phase or female figure is used as a behavioral variable, the splitting variable is the amount of detail, and the normal variable is a change in detail related to the male/female distinction. The results are shown in Figure 26.\n\n\n\nFigure 3.13: From (Stewart & Peregoy, 1983). The fitted bifurcation lines were calculated using Cobb’s method, which is explained in section 3.3.3.\n\n\n\n\n3.2.5 Higher order catastrophes\nNote that the cusp is made up of folds. This is best seen in the hysteresis diagram in Figure 21 (see the dotted rectangle). Higher order catastrophes yield elements of cusps and folds. The swallowtail catastrophe with potential function \\(V(X) = {- aX - \\frac{1}{2}bX^{2} - \\frac{1}{3}cX}^{3} + \\frac{1}{5}X^{5}\\) consists of three surfaces of fold bifurcations meeting in two lines of cusp bifurcations, which in turn meet in a single swallowtail bifurcation point. We need a four-dimensional space to visualize this, which is difficult. The Wikipedia page on Catastrophe theory has some rotating graphs that may help. The butterfly catastrophe has \\(X^{6}\\) as the highest term (and four control variables).\nThe butterfly catastrophe is of interest when we observe trimodal behavior. We will discuss this catastrophe in Chapter 6 in relation to the modeling of attitudes. I note that the butterfly catastrophe and the butterfly effect in chaos theory are two completely unrelated concepts. Other catastrophes have two instead of one behavioral variable. However, the vast majority of applications of catastrophe theory focus on the cusp, which will also be the focus of the remaining of this chapter. There are many good (but not easy) books that present the full scope of catastrophe theory (Gilmore 1993; Poston and Stewart 2014).\n\n\n3.2.6 Other bifurcations\nCatastrophe theory is limited to structurally stable, local bifurcations. Bifurcation theory also deals with non-structurally stable bifurcations and so-called global bifurcations.\nExamples of nonstructural stable local bifurcations are the transcritical bifurcation (\\(\\frac{dX}{dt} = aX - X^{2})\\) and pitchfork bifurcation (\\(\\frac{dX}{dt} = bX - X^{3})\\). The pitchfork is part of the cusp and is not structurally stable because it can be perturbed by an additional term \\(a\\), which, if unequal to 0, will distort the pitchfork (see Figure 27).\n\n\n\nFigure 3.14: Perturbed pitchfork bifurcation (\\(a = .1\\)). For \\(a = 0\\) we would get the pitchfork bifurcation as shown in Figure 21. Thus, a perturbation in a model parameter leads to qualitative change in this bifurcation, and this is the reason why it is not considered structurally stable.\n\n\nAnother one we have already seen is the period doubling bifurcation. This happened in the logistic map when the fixed point changed in a limit cycle of period 2. Finally, global bifurcations cannot be localized to a small neighborhood in the phase space, such as when a limit cycle diverges (Guckenheimer and Holmes 1983). However, I don’t know of any applications of global bifurcations in psychology or the social sciences."
  },
  {
    "objectID": "ch3.html#testing-catastrophe-models",
    "href": "ch3.html#testing-catastrophe-models",
    "title": "3  Transitions in complex systems",
    "section": "3.3 Testing catastrophe models",
    "text": "3.3 Testing catastrophe models\n\n3.3.1 Phenomenological versus mechanistic models\nThe model of the attitude towards abortion is called a phenomenological model, as opposed to a mechanistic model. In the former one, we assume the presence of a cusp, and make hypotheses about the involved variables. In the latter, the cusp is derived from basic assumptions or first principles. The mechanistic approach is much more common in the physical and life sciences. An example is the phase transition in water described by the van der Waals equation (see Wikipedia). Poston and Stewart (2014) show how the van der Waal equation can be reparametrized to take the form of the cusp equation. The advantage is that we learn how exactly temperature and pressure are related to the control variables of the cusp. This gives us a full understanding of the dynamics of this phase transition.\nA case that we will analyze further in Chapter 5 is the model of the spruce budworm outbreak, which occurs every 30 to 40 years and results in the defoliation of tens of millions of hectares of trees. The model is\n\\[\n\\frac{dN}{dt} = r_{b}N\\left( 1 - \\frac{N}{K} \\right) - \\frac{BN^{2}}{A^{2} + N^{2}}.\n\\tag{3.7}\\]\nWhere \\(N\\) is the size of budworm population, \\(r_{b}\\) is the growth rate, \\(K\\) is the carrying capacity, \\(B\\) is the upper limit of predation, and \\(1/A\\) is the responsiveness of the predator.\nThe first part is the logistic growth equation. \\(N\\) will grow to \\(K\\) at a rate \\(r_{b}\\). Note that this is a differential equation, not a difference equation. There is no chaos in logistic growth in continuous time. The second part is the predation function and has a concave shape flattening out at \\(B\\). The curvature of this function is determined by \\(A\\). High \\(A\\) makes the concave shape less steep, meaning that predation rather slowly reacts to the increase in budworms (more about the construction of this model later).\nThe analytical approach to this model is to reparametrize the model so that it takes the form of a cusp. Such reparameterizations are not so easy to do yourself. The idea is to create a smaller set of new variables that are functions of the model parameters. For this model a convenient reparameterization is\n\\[\nr = \\frac{A\\ r_{b}}{B}\\ and\\ q = \\frac{K}{A}.\n\\tag{3.8}\\]\nUsing these two ‘constructed’ control variables, we can depict the bifurcation lines of the cusp as:\n\n\n\nFigure 3.15: The bifurcation diagram of the Spruce Budworm model (Copied from Modeling the Spruce Budworm, Jacai deNeveu, 2015).\n\n\nLater we will discuss a psychological example of a mechanistic approach, but these are rare. The phenomenological approach is much more common. Phenomenological models are less persuasive than mechanistic models. One disadvantage of phenomenological models is that they may not provide a deep understanding of the underlying mechanisms that drive the system. Phenomenological models are often used to describe the behavior of a system without providing an explanation of how the behavior arises. But in psychology and the social sciences we cannot be too picky. Compared to many other, verbally stated, attitude models, the cusp attitude model is quite precise. It implies a number of phenomena and is testable. This will be the subject of the next section.\nI suggest some guidelines for setting up a phenomenological cusp model. First, define the behavioral variable. It is important to think about the bistable modes. What are they? What is the inaccessible state in-between? Can you have jumps between these states? What is neutral state at the back of the cusp? If you cannot answer these questions, you should reconsider whether a cusp is an appropriate model.\nSecond, select the control variables. What could be a normal variable and what could be a splitting variable. These are not easy questions. Sometimes there are too many candidates. For the cusp model of attitudes, instead of involvement, we could suggest interest, importance, emotional value, etc. In this case, I think of the splitting axis as a common factor of all these slightly different variables. In other cases, we have no good candidates. In the example in Figure 26, it is not clear exactly what is being manipulated along the normal axis. If you made a choice, it is good to check whether, at high values of the splitting values, variation of the normal variable may lead to sudden jumps and hysteresis. Also check whether the pitchfork bifurcation makes sense.\nThere is another issue here. In some phenomenological models the control variables are rotated by 45 degrees. The most famous example is Zeeman’s (1976) model dog aggression.\n\n\n\nFigure 3.16: Zeeman [-@zeemanCatastropheTheory1976] dog aggression model with rage and fear as rotated control variables.\n\n\nThe control variables are fear and rage (see Figure 29). In such a rotation the normal variable is the difference between fear and rage, while the splitting variable is the sum of fear and rage. Another example can be found in our model of the speed-accuracy trade- off in reaction time tasks (Dutilh et al. 2011). When constructing a phenomenological model, these two options for setting the control variable should be considered.\nThere are many other examples of phenomenological cusp model in psychology. For example, cusp models have been proposed for addiction (S. J. Guastello 1984; Mazanov and Byrne 2006; Witkiewitz et al. 2007), for performance in work and sports (Cohen, Pargman, and Tenenbaum 2003; S. Guastello, Correro, and Marra 2019; Hardy 1996) and for humor (Paulos 2008). More examples can easily be found online.3\n\n\n3.3.2 The catastrophe flags\nA question I often get is: How sudden is sudden? It is claimed that climate changes are transitions between stages (e.g., ice ages), but these transitions can take hundreds of years. Even when the ball is rolling towards its new minimum, it takes time to roll. So sudden transitions are not instantaneous.\nBut then what is the difference with an acceleration, such as we see in a logistic growth pattern? The time course of an acceleration and a sudden jump will look something like this:\n\n\n\nFigure 3.17: Continuous and discontinuous growth curves my look very similar.\n\n\nThus, in terms of time series data, they may look exactly the same. The difference is that in the continuous case the intermediate values are stable. It can be understood as a quadratic minimum that changes its position quickly. If we stop the process by freezing the manipulated control variable in the process, the state will remain at an intermediate value. These intermediate values are all stable values. If we freeze the manipulated variable in a discontinuous process, it will continue to move to a stable state. In this case, the intermediate state is unstable. The ball keeps rolling.\nIn practice using data, this is a difficult distinction to make. It means that simple time series are not sufficient to distinguish accelerations from phase transitions. So how do we distinguish between the two processes? In the context of catastrophe theory, Gilmore (1993) proposed the catastrophe flags. These are cusp related phenomena that can be seen in the data. While no single one of these is enough to indicate the cusp, when considered together they provide compelling evidence for its existence.\nIn the upcoming subsections, I will provide definitions for the flags and illustrate their applications in psychology using examples. The first flag is the sudden jump.\n\n3.3.2.1 Sudden jump\nThe sudden jump is large fast change in equilibrium behavior. Although the sudden jump is not sufficient (it could be due to an acceleration), demonstrating a sudden jump in time series is useful (also in relation to other flags). Statistical detection of sudden jumps is possible using a number of techniques. Figure 31 presents raw weekly measurements of depressive symptoms using the SCL-90-R depression subscale of a patient who gradually quitted antidepressant medication during the study. The participant and researchers were blind to the dose reduction scheme (Wichers, Groot, and Psychosystems 2016). One question was whether this reduction led to a sudden jump to the depressed state. Using a change point detection method (James and Matteson 2014), we found a jump at 18 weeks with a bootstrapped p-value of .005 (with the null hypothesis of no change point).\n\nFigure 31: A sudden jump to depression (score at the SLC-90) in a patient who gradually quitted antidepressant medication during the study.\nMany methods for change point analysis have been developed and compared in Burg and Williams (2022).\nThe code for this figure is:\n\nlayout(t(1)); par(mar=c(4,4,1,1))\nx &lt;- read.table('data/PNAS_patient_data.txt',header=T)\nlibrary(ecp) # if error: install.packages('ecp')\ne1 &lt;- e.divisive(matrix(x$dep,,1),sig=.01,min.size=10)\nplot(x$week,x$dep,type='b',pch=(e1$cluster-1)*16+1,xlab='Week',ylab='SLC-90',bty='n',main='Jump to depression')\n\n\n\n3.3.2.2 Multimodality\nMultimodality (in the case of the cusp bimodality) is an important and easy-to-use flag, as it can be tested with cross-sectional data. Finite mixture models have been developed to test for multimodality in frequency distributions (McLachlan, Lee, and Rathnayake 2019).\nAn example is shown in Figure 32. These data come from a conservation anticipation task, where children have to predict the level of water in the second glass when it is poured over. The resulting data and the fit of a mixture of two normal distributions are shown on the right. The data are clearly bimodal supporting the hypothesis of a transition in conservation learning (Van der Maas and Molenaar 1992). These data were used in Dolan and van der Maas (1998) to fit multivariate normal mixture distributions subject to a structural equation model.\n\n\n\nFigure 3.18: Bimodality in the expected heights of water when it is poured into a wider glass. This variation of the Piagetian maintenance task is used with children ages 5-8.\n\n\nThe code is:\n\nx=unlist(read.table('data/conservation_anticipation_item3.txt'))\nlibrary(mixtools) # if error: install.packages('mixtools')\nresult=normalmixEM(x)\nplot(result,whichplot=2,breaks=30)\n\nThere is a whole field in statistics focused on multimodality, mixtures and clustering. There are some blogs that present overviews of the relevant R-packages (Arnaud 2021). Several detailed examples from psychology, using hidden Markov models, are presented in Visser and Speekenbrink (2022).\nThe advantage of multimodality over the sudden jump is that we can use it with cross-sectional data. To capture a sudden jump in a development process, you need a lot of high-frequency data. Sudden shifts in opinion are also rare. But it is easy to collect data on large numbers of people who are asked to make judgments about statements on an issue such as abortion. If these judgments are bimodally distributed, this is consistent with a phase transition. Bimodal data may also be produced by a process of acceleration, with time series consisting mainly of data values before and after the acceleration. So, bimodality is not sufficient. It can be considered necessary, so I always suggest starting with cross-sectional multimodal studies. If they fail, you might reconsider your hypothesis. I have often looked for multimodality in measures of arithmetic learning and never found anything convincing, which made me rethink my hypothesis.\n\n\n3.3.2.3 Inaccessibility\nInaccessibility means that certain values of the behavioral variable are unstable. The business card is a good example. Given some vertical pressure, we can try what we want but we cannot force the card to stay in the middle position, it is unstable. Inaccessibility is relevant to reject the alternative hypothesis that the sudden jump and bimodality are due to an acceleration.\nIn Experiment 2 of Dutilh et al. (2011) we focused on this flag. Our hypothesis was that in simple choice response tasks there is a phase transition between a fast-guessing state and a slower stimulus-driven response state. The idea is that if we force subjects to speed up, there will be a catastrophic jump in performance (from almost 100% correct to 50% correct).\nWe created a game in which subjects responded to a series of simple choice items (a lexical decision task). The length of the series was not known to the subject. At the end of a series, they were rewarded according to how close their percentage correct was to 75%. Speed was also rewarded, but much less. So, we asked the subject to be in the inaccessible state. The alternative hypothesis, based on information accumulation models, was that there was no phase transition and that responding with 75% accuracy required the correct setting of a boundary (see Section 5.2.1).\nIt appeared that subjects solved the task by switching between the fast-guessing mode and the slower stimulus-controlled mode, even when instructed according to the alternative model. Thus, the 75% intermediate state appears to be unstable.\n\n\n3.3.2.4 Divergence\nDivergence or the pitchfork bifurcation requires the manipulation of the splitting variable. In the case of attitudes, we hypothesize this to be involvement or some related variable. In van der Maas, Kolstein, and van der Pligt (2003) we re-analyzed a dataset from Stouffer et al. (1949), which Latané and Nowak (1994) presented as evidence for the cusp model. The attitude concerned demobilization (from 0, unfavorable, to 6, favorable) and respondents were asked to indicate how strongly they felt about their answer (from intensity 0 to intensity 5). For low intensities of feeling the data are normally distributed whereas for higher intensities data are bimodally distributed (see Figure 33).\n\n\n\nFigure 3.19: The pitchfork bifurcation in attitudes. The dotted lines represent the fit of the cusp model to these data. This technique will be discussed in the final section in this chapter.\n\n\n\n\n3.3.2.5 Hysteresis\nHysteresis requires sophisticated manipulation of the normal control variable. We need to slowly increase and decrease this variable and test whether sudden jumps occur with a delay. We have demonstrated hysteresis with some success for proportional reasoning (Jansen and Van der Maas 2001), for the speed-accuracy trade-off (Dutilh et al. 2011), and for multistable perception (Ploeger, Van Der Maas, and Hartelman 2002).\nIn the latter case we used the quartet motion paradigm, in which two lights are presented simultaneously, first a pair from two of the diagonally opposite corners of the rectangle, and then a second pair from the other two diagonally opposite corners of the rectangle. Usually, either vertical or horizontal apparent motion is perceived. By gradually increasing or decreasing the aspect ratio (i.e., the ratio of height to width of the quartet), hysteresis in the jumps between the two percepts was demonstrated (see Figure 34).\nIn Ploeger, Van Der Maas, and Hartelman (2002) we used a special design, the method of modified limits, to rule out the alternative explanation that hysteresis is simply due to delayed responses. It could be that the switches always occur in the middle (at an aspect ratio of 1), but the self-report is delayed. In the modified limits method, subjects do not respond during a trial, but only after the entire trial. By varying the length of the trials, it is possible to determine at which parameter value the subject perceives a switch.\n\n\n\nFigure 3.20: Hysteresis in the perception of apparent motion. Switches between the perception in of vertical or horizontal apparent motion occur when the aspect ratio (horizontal axis) is varied. The aspect ratio is the ratio of height to width of the quartet.\n\n\n\n\n3.3.2.6 Anomalous variance, divergence of linear response and critical slowing down\nGilmore’s last three flags, anomalous variance, divergence of linear response and critical slowing down, are indicators that occur near the bifurcation lines. They are also known as early warning systems and are a popular line of research (Dakos et al. 2012).\nAnomalous variance occurs because near a bifurcation point the second derivative diminishes, meaning that the minimum becomes less deep. Assuming there is always some perturbation of the state, this will lead to larger fluctuations in the state.\nDivergence of linear response is the size of the effect of a small perturbation of the state, which will be greater near a bifurcation point. It will also take longer to return to equilibrium. The latter is known as critical slowing down and is also studied in other approaches to nonlinear dynamical systems (e.g., synergetics (Haken 1977). Examples of applications in psychology can be found in Leemput et al. (2014) and Olthof et al. (2020). A somewhat critical review is provided in Dablander et al. (2020).\nIn my experience, the problem with early warning signals is that both type 1 and type 2 errors should be low for predicting transitions. This is challenging even in simulations, let alone in noisy psychological data. It would be fantastic if these early warnings really worked. For example, being able to predict a relapse into depression or addiction would be of great therapeutic value.\nThe catastrophe flags together provide a research methodology for phase transition research in psychology. A single flag may not be sufficient, but the combination is. For example, the combination of evidence for inaccessibility and hysteresis is convincing. I have given psychological examples of most of the flags. Which flags to use in a particular case depends on the knowledge and experimental control of the control variables. Another approach is to fit the cusp model directly to the data. This is the subject of the next section.\n\n\n\n3.3.3 Fitting the cusp to cross-sectional data\n\n3.3.3.1 Cobb’s maximum likelihood approach\nIn a series of papers Loren Cobb an colleagues (Cobb and Zacks 1985; Cobb 1978) developed a maximum likelihood approach to fit the cusp catastrophe to data consisting of cross-sectional measurements of \\(X\\), \\(a\\) and \\(b\\). We have implemented this approach in a cusp R package described in Grasman, van der Maas, and Wagenmakers (2009).\nThe basic idea is to make catastrophe theory, a deterministic theory, stochastic by adding a stochastic term, called Wiener noise (with variance \\(\\sigma^{2})\\), to Equation \\(6\\)4:\n\\[\ndX = - V^{'}(X)dt + \\sigma dW(t). \\tag{3.9}\\]\nWe will discuss this type of stochasticity later, but it is important to note that it is not the same as measurement noise. Measurement noise, i.e., \\(\\varepsilon\\) in \\(Y = X + \\varepsilon\\), does not affect the dynamics of \\(X\\). Wiener noise does, it is part of the updating equation of \\(X\\) itself. This stochastic differential equation is associated with a probability distribution of the form\n\\[\nf(X) = \\frac{1}{{Z\\sigma}^{2}}e^{\\frac{- V(X)}{\\sigma^{2}}}, \\tag{3.10}\\]\nwhere Z is a normalizing constant5 necessary to ensure that the area under \\(f(X)\\) is 1. This may look complicated but for the quadratic case \\(V(X) = {\\frac{1}{2}X}^{2}\\), this results in the standard normal distribution, with \\(Z = \\frac{\\sqrt{2\\pi}}{\\sigma}\\).\nAs in the case of the normal distribution we want to allow for some transformations of the variables. To simplify the necessary statistical notation, we write the cusp as \\(V(y) = {- \\alpha y - \\frac{1}{2}\\beta y^{2} + \\frac{1}{4}y}^{4}\\). The probability distribution for the cusp is\n\\[\nf(y) = \\frac{1}{{Z\\sigma}^{2}}e^{\\frac{\\alpha y + \\frac{1}{2}\\beta y^{2} - \\frac{1}{4}y^{4}}{\\sigma^{2}}}. \\tag{3.11}\\]\nAs in regression models, the cusp variables are modelled as linear function of measured variables. That is, the dependent variables \\(Y_{i1},\\ Y_{i2},\\ldots,Y_{ip}\\) and the independent variables \\(X_{i1},\\ X_{i2},\\ldots,X_{iq}\\), for subjects \\(i = 1,\\ldots,n\\), are related to the cusp variables as follows:\n\nBy estimating these regression parameters, we fit the cusp model to empirical data. The cusp package in R makes this possible. I will first demonstrate this using simulated data. This is my number one rule when using statistical techniques: never use a statistical technique on real data before you have tested it on simulated data. First, it forces you to understand what the statistical technique actually does, and second, it gives you a way to test the power and investigate violations of the technique’s assumptions.\n\nlibrary(cusp) # if error: install.packages('cusp')\nset.seed(1)\nX1 &lt;- runif(1000) # independent variable 1\nX2 &lt;- runif(1000) # independent variable 2\n# to be estimated parameters\nw0 &lt;- 2; w1 &lt;- 4; a0 &lt;- -2; a1 &lt;- 3; b0 &lt;- -2; b1 &lt;- 4 \n# sample Y1 according to cusp using rcusp and the chosen parameter values\nY1 &lt;- -w0/w1 + (1/w1) * Vectorize(rcusp)(1, a0+a1*X1, b0+b1*X2) \ndata &lt;- data.frame(X1, X2, Y1) # collect ‘measured’ variables in data\n\nI recommend doing some descriptive analysis first. With hist(data$Y1) we can inspect whether there is some indication of bimodality. X2 is the splitting variable so perhaps we see stronger bimodality with hist(data$Y1[data$X2&gt;mean(data$X2)]). The function pairs in R, pairs(data), is also always recommended. In this perfect simulated case, you will already see strong indications of the cusp. Now we fit the full model with alpha and beta both as function of X1 and X2.\n\nfit &lt;- cusp(y ~ Y1, alpha ~ X1+X2, beta ~ X1+X2, data) \nsummary(fit) \n\nSummary provides the following table:\n\nTable 1: The parameter estimates including standard errors and p-values generated by the cusp package.\n\n\n\n\n\n\n\n\n\n\nCoefficients:\nEstimate\nStd.Error\nz-value\nPr(&gt;|z|)\n\n\n\n\n\na[(Intercept)]\n-2.13\n0.19\n-11.0\n&lt; 2e-16\n***\n\n\na[X1]\n3.11\n0.22\n14.2\n&lt; 2e-16\n***\n\n\na[X2]\n0.15\n0.17\n0.9\n0.39\n\n\n\nb[(Intercept)]\n-2.29\n0.34\n-6.7\n2.66e-11\n***\n\n\nb[X1]\n-0.09\n0.33\n-0.3\n0.79\n\n\n\nb[X2]\n4.40\n0.27\n16.5\n&lt; 2e-16\n***\n\n\nw[(Intercept)]\n1.98\n0.07\n27.6\n&lt; 2e-16\n***\n\n\nw[Y1]\n3.97\n0.10\n38.0\n&lt; 2e-16\n***\n\n\n\nNote that we fit a model with too many parameters. We also estimated \\(a_{2}\\) and \\(b_{1}\\) (because the model was specified as alpha ~ X1+X2, beta ~ X1+X2). These estimates are not significantly different from 0. The other parameters are estimated reasonably close to their true values, since the true values fall within the confidence interval of the estimates (defined by twice the standard error on either side). We expect a better fit in terms of AIC and BIC if we fit a reduced model without \\(a_{2}\\) and \\(b_{1}\\).\n\nfit_correct_model &lt;- cusp(y ~ Y1, alpha ~ X1, beta ~ X2, data) \nsummary(fit_correct_model)\n\n\nTable 2: The comparative fit measures, AIC, AICc, and BIC indicate that the reduced model should be the model of choice.\n\n\n\n\n\n\n\n\n\n\n\n\nR.Squared\nlogLik\nnpar\nAIC\nAICc\nBIC\n\n\n\n\nFull model\n0.428\n-1058.7\n8\n2133.3\n2133.5\n2172.6\n\n\nReduced model\n0.426\n-1059.0\n6\n2130.0\n2130.1\n2159.5\n\n\n\nThe next simulation demonstrates that we can detect hysteresis using this approach. We simulate data with \\(- 2 &lt; \\alpha &lt; 2,\\) and fixed \\(\\beta\\). If \\(\\beta &lt; 0\\) we have no hysteresis, but if \\(\\beta &gt; 0\\) we do have hysteresis. With the code below we simulate datasets for different \\(\\beta\\), and compare the goodness of fit between the linear and cusp model. The figure summarizes the results. Note that a lower BIC indicated the better fitting model.\n\nset.seed(10)\nn &lt;- 500\nX1 &lt;- seq(-1,1,le=n) # rnorm(n) #runif(1000) # independent variable 1\na0 &lt;- 0; a1 &lt;- 2; b0 &lt;- 2 # to be estimated parameters\nb0s &lt;- seq(-1,2,by=.25)\ni &lt;- 0\ndat &lt;- matrix(0,length(b0s),7)\nfor (b0 in b0s)\n{\n  i &lt;- i + 1\n  Y1 &lt;- Vectorize(rcusp)(1, a1 * X1, b0)\n  data &lt;- data.frame(X1, Y1) # collect ‘measured’ variables in data\n  fit &lt;- cusp(y ~ Y1, alpha ~ X1, beta ~ 1, data)\n  sf &lt;- summary(fit)\n  dat[i, ] &lt;- c(b0, sf$r2lin.r.squared[1], sf$r2cusp.r.squared[1],sf$r2lin.bic[1], sf$r2cusp.bic[1],sf$r2lin.aic[1], sf$r2cusp.aic[1])\n}\npar(mar=c(4,5,1,1))\nmatplot(dat[,1],dat[,4:5],ylab='Bic',xlab='b0',bty='n',type='b',pch=1:2,cex.lab=1.5)\nlegend('right',legend=c('linear','cusp'),lty=1:2,pch=1:2,col=1:2,cex=1.5)\nabline(v=0,lty=3)\ntext(-.5,800, 'no hysteresis',cex=1.5)\ntext(.5,800, 'hysteresis',cex=1.5)\n\n\n\n\nFigure 3.21: At the back of the cusp (low \\(b0\\)), the cusp is approximately linear and cuspfit prefers this simpler model over the cusp model.\n\n\n\n\n3.3.3.2 Empirical examples\nIn Grasman, van der Maas, and Wagenmakers (2009) we present several examples with real data. As another example, we use Stoufer’s data, which we used as an example of divergence before (see Figure 33).\n\nx &lt;- read.table('data/stoufer.txt')\ncolnames(x) &lt;- c('IntensityofFeeling','Attitude')\nfit &lt;- cusp(y ~ Attitude, alpha ~ IntensityofFeeling, beta ~ IntensityofFeeling, x)\nsummary(fit)\n\nInspection of the parameter estimates shows that, as expected, Intensity of Feeling only loads on the splitting axis and not on the normal axis. This is the location of the data in the bifurcation set (plot(fit)).\n\n\n\nFigure 3.22: Placement of the data of Figure 33 in the bifurcation set.\n\n\nAnother example is the conservation data set of Bentler (1970), which contains the scores on a 12 item test from a conservation test of 560 children from 8 different age groups. These data are expected to be bimodal and to move along the normal axis (Van der Maas and Molenaar 1992).\n\nx &lt;- read.table('data/bentler.txt',header=T)\nlayout(t(1:8))\nage &lt;- c('age 4 to 4.5','age 4.5 to 5','age 5 to 5.5','age 5.5 to 6','age 6 to 6.5','age 6.5 to 7','age 7 to 7.5','age 7.5 to 8')\nfor(i in 1:8)\n{\n  if(i==1) {par(mar=c(4,3,2,1));names=0:12} else {names='';par(mar=c(4,1,2,1))}\n  barplot(table(factor(x[x[,1]==i,2],levels=0:12)),horiz=T,axes=F,main=age[i],xlab='',names=names,cex.main=1.5,cex.names=1.5)\n}\nfit &lt;- cusp(y ~ score, alpha ~ age_range, beta ~ age_range, x)\nsummary(fit)\nplot(fit)\n\nThis is supported by results of cuspfit. You can verify that a model with beta ~ 1, fits better according to the AIC and BIC.\n\n\n\nFigure 3.23: The fit of Bentler conservation data.\n\n\nA great exercise we have often used in the classroom is to build a Zeeman machine, collect data with the machine and fit the cusp model to the data (see Grasman, van der Maas, and Wagenmakers (2009), for details). This machine was invented by Zeeman to demonstrate the properties of the cusp. Our students were rewarded for the quality of the model and the artistic value of their Zeeman machine.\n\n\n\nFigure 3.24: Zeemans’s catastrophe machine. One end of the elastic (red dot) is moved by hand through the control plan. The strap point moves according to the cusp catastrophe. Data is gathered by collecting a set of X, Y and Z values. Typically, 50 to 100 data points are sufficient to run Cuspfit.\n\n\n\n\n3.3.3.3 Evaluation\nI make a few final remarks. First, Cobb’s method is not valid for time series. Data points should be independent. To test for hysteresis in time series other approaches are required. One option is to use hidden Markov models as in Dutilh et al. (2011).\nThe second remark is that there are some issues with the approach of Cobb that are due to fundamental differences between probability distributions and potential functions. The latter can be transformed in many ways (so called local diffeomorphisms) without changing the qualitative properties of the cusp. With the added constraint on probability distributions (area = 1), the same transformations can lead to qualitative effects, such as a change in the number of modes. Wagenmakers et al. (2005) suggest a solution to this problem for time series.\nThe third remark is that two alternative approaches have been proposed. Both Guastello’s (1982) change score least square regression approach and the Gemcat approach (1987) use the first derivative of the cusp as point of departure. A problem with both approaches is that they do not distinguish between stable and unstable equilibrium states. Data points in the inaccessible region improve the fit of the model, whereas they should decrease the fit. Alexander et al. (1992) provide a detailed critique."
  },
  {
    "objectID": "ch3.html#criticism-of-catastrophe-theory",
    "href": "ch3.html#criticism-of-catastrophe-theory",
    "title": "3  Transitions in complex systems",
    "section": "3.4 Criticism of catastrophe theory",
    "text": "3.4 Criticism of catastrophe theory\nOne often speaks of the rise and the fall of catastrophe theory (Rosser 2007). The hype following Zeeman’s famous Scientific American paper (Zeeman 1976) led to a strongly worded reply by Zahler and Sussmann (1977) in Nature.\nBecause people still refer to this paper when we use catastrophe theory in our work, let us briefly respond to the main points of criticism made by Zahler and Sussmann. I note that in the introduction to their paper they state that there may be legitimate uses of catastrophe theory in physics and engineering. Moreover, they do not question the correctness or importance of catastrophe theory as a purely mathematical subject.\nThey raise ten points, some of which we have already addressed. For example, their first point is about how sudden a jump actually is, but they call this a less serious criticism. A number of points are about inferring a cusp from data, which was indeed done rather superficially in Zeeman’s earlier work. They pointed out that there are no testable predictions, that the location of the cusp can be shifted, and that there is no way to decide whether the data fit the cusp. We hope to have shown that these problems are largely solved. The catastrophe flags allow us to make new testable predictions, and with Cobb’s maximum likelihood approach we can fit the model as we would any statistical model in modern science. Of course, one can be critical of the use of statistics in psychology and the social sciences, but these criticisms are not specific to catastrophe theory.\nAnother somewhat inconsistent line of criticism is that many of catastrophe models in psychology and the social sciences are just wrong and inconsistent with the data (which could be true), while it is also claimed that Zeeman’s models are not falsifiable. Despite this inconsistency, they have a point. It is important to really think about falsifiability. Theories in psychology tend to be moving targets. As soon as someone finds an empirical result that contradicts the theory, the theory is quickly modified.\nThen they point out that catastrophe theory theorists often try to make a discrete variable into a continuous one. Their example is aggression, which they believe is inherently discrete. They call Zeeman’s interpretation of aggression as a continuous family of behaviors absurd and utterly meaningless. This may be a bit strong. We can think of situations in which aggression can vary from mild to severe. Aggression can vary from verbal to physical, directed at a person’s belongings, mild physical directed at the person, to severe physical. I may be problematic to claim a quantitative dimension of aggression here, but a rich ordering of aggressive acts is very useful for describing domestic violence. A discrete description in aggressive/not aggressive is clearly insufficient. Whether such an ordering can be treated as a real continuum is one of the most difficult questions in our field (Borsboom et al. 2016; Michell 2008).\nThe last point of Zahler and Sussmann is that there are better alternatives, such as quantum mechanics, discrete mathematics, and bifurcation theory. There is work on quantum mechanics in psychology (especially in the context of consciousness), but whether this will lead to breakthroughs in this field remains to be seen. Discrete mathematics may be an alternative in some cases (e.g., to model symbolic thinking). I see catastrophe theory as a special branch of bifurcation theory, especially useful when the system under study is difficult to describe in terms of mathematical equations. This goes back to the distinction between phenomenological and mechanistic models. I think we should put more effort into developing mechanistic models based on first principles. More on this in the next chapters.\nLoehle (1989) present an excellent discussion on the usefulness of catastrophe theory in the context of modelling ecosytems. He concluded that “an unresolved problem in applying catastrophe models is that of testing the goodness of fit of the model to data”, but this problem has now been largely solved.\nI also recommend the BBC documentary “Case Study Catastrophe Theory Maths Foundation Course”\n(https://www.youtube.com/watch?v=myDvcvox1V4&t=1435s) to see Zeeman at work."
  },
  {
    "objectID": "ch3.html#exercises",
    "href": "ch3.html#exercises",
    "title": "3  Transitions in complex systems",
    "section": "3.5 Exercises",
    "text": "3.5 Exercises\n\nThe equilibria of the fold are \\(X = \\pm \\sqrt{\\frac{a}{3}}\\). This can can be checked by setting the first derivative to zero. Show this. (*)\nIn Zeeman’s dog aggression model fear and rage are ‘rotated’ control variables. How can we translate this to a model with unrotated axes? Provide the equations that specify the normal and splitting axis as function of fear and rage. (*)\nDerive the equation for the bifurcation lines of the cusp (\\(27a^{2} = 4b^{3})\\), by setting the first and second derivatives to zero. Plot the bifurcation lines in GeoGebra or Desmos. (**)\nSome insight into the butterfly catastrophe \\(V(X) = {- aX - bX^{2} - cX}^{3} - dX^{4} + X^{6}\\) can be gained by entering the equation in free online graphing calculators such as DesMos or GeoGebra. Set a, b, c, d to 0, -5, 0, 5. Then start varying a and c. What is the difference in the effect of these two parameters on the attractors? (*)\nSet up a phenomenological cusp for falling in love. Follow my guidelines (see Section 3.3.1). (**)\nCheck whether indeed the Bentler data fit better with when age_range only loads on the normal axis (according to the AIC and BIC). What is the correct specification of beta in cusp() in this case? (*)\n\nn=500\nz = Vectorize(rcusp)(1, .7*rnorm(n), 2+2*rnorm(n)) # sample z \nx = rnorm(n) \ny = rnorm(n) \ndata &lt;- data.frame(z,x,y) # collect variables in data\n\n\nWhat is the best fitting cusp model (according to the BIC) for this tricky data set? Why? (**)\n\nBuild a Zeeman machine, collect data and fit the cusp (see Example III of Grasman, van der Maas, and Wagenmakers 2009). What is your best fitting model? Provide a plot of the data in the bifurcation set and a picture of your Zeeman machine. (**)\n\n\n\n\n\nAlexander, Ralph A., Glenn R. Herbert, Richard P. DeShon, and Paul J. Hanges. 1992. “An Examination of Least-Squares Regression Modeling of Catastrophe Theory.” Psychological Bulletin 111: 366–74. https://doi.org/10.1037/0033-2909.111.2.366.\n\n\nArnaud, M. 2021. “Mixture Modelling from Scratch, in R.” Medium. https://towardsdatascience.com/mixture-modelling-from-scratch-in-r-5ab7bfc83eef.\n\n\nBentler, P. M. 1970. “Evidence Regarding Stages in the Development of Conservation.” Perceptual and Motor Skills 31 (3): 855–59. https://doi.org/10.2466/pms.1970.31.3.855.\n\n\nBorsboom, D., M. Rhemtulla, A. O. J. Cramer, H. L. J. van der Maas, M. Scheffer, and C. V. Dolan. 2016. “Kinds Versus Continua: A Review of Psychometric Approaches to Uncover the Structure of Psychiatric Constructs.” Psychological Medicine 46 (8): 1567–79. https://doi.org/10.1017/S0033291715001944.\n\n\nBurg, Gerrit J. J. van den, and Christopher K. I. Williams. 2022. “An Evaluation of Change Point Detection Algorithms.” arXiv. https://doi.org/10.48550/arXiv.2003.06222.\n\n\nCobb, Loren. 1978. “Stochastic Catastrophe Models and Multimodal Distributions.” Behavioral Science 23 (4): 360–74. https://doi.org/10.1002/bs.3830230407.\n\n\nCobb, Loren, and Shelemyahu Zacks. 1985. “Applications of Catastrophe Theory for Statistical Modeling in the Biosciences.” Journal of the American Statistical Association 80 (392): 793–802. https://doi.org/10.1080/01621459.1985.10478184.\n\n\nCohen, Alexander, David Pargman, and Gershon Tenenbaum. 2003. “Critical Elaboration and Empirical Investigation of the Cusp Catastrophe Model: A Lesson for Practitioners.” Journal of Applied Sport Psychology 15 (2): 144–59. https://doi.org/10.1080/10413200305393.\n\n\nDablander, Fabian, Anton Pichler, Arta Cika, and Andrea Bacilieri. 2020. “Anticipating Critical Transitions in Psychological Systems Using Early Warning Signals: Theoretical and Practical Consideration.”\n\n\nDakos, Vasilis, Stephen R. Carpenter, William A. Brock, Aaron M. Ellison, Vishwesha Guttal, Anthony R. Ives, Sonia Kéfi, et al. 2012. “Methods for Detecting Early Warnings of Critical Transitions in Time Series Illustrated Using Simulated Ecological Data.” PloS One 7 (7): e41010. https://doi.org/10.1371/journal.pone.0041010.\n\n\nDodson, M. M., and A. Hallam. 1977. “Allopatric Speciation and the Fold Catastrophe.” The American Naturalist 111 (979): 415–33. https://doi.org/10.1086/283176.\n\n\nDolan, Conor V., and Han L. J. van der Maas. 1998. “Fitting Multivariage Normal Finite Mixtures Subject to Structural Equation Modeling.” Psychometrika 63 (3): 227–53. https://doi.org/10.1007/BF02294853.\n\n\nDutilh, Gilles, Eric-Jan Wagenmakers, Ingmar Visser, and van der Han L. J. Maas. 2011. “A Phase Transition Model for the Speed-Accuracy Trade-Off in Response Time Experiments.” Cognitive Science 35 (2): 211–50. https://doi.org/10.1111/j.1551-6709.2010.01147.x.\n\n\nGilmore, Robert. 1993. Catastrophe Theory for Scientists and Engineers. Courier Corporation.\n\n\nGrasman, Raoul, Han L. J. van der Maas, and Eric-Jan Wagenmakers. 2009. “Fitting the Cusp Catastrophe in R: A Cusp Package Primer.” Journal of Statistical Software 032 (i08).\n\n\nGuastello, Stephen J. 1982. “Moderator Regression and the Cusp Catastrophe: Application of Two-Stage Personnel Selection, Training, Therapy, and Policy Evaluation.” Behavioral Science 27 (3): 259–72. https://doi.org/10.1002/bs.3830270305.\n\n\n———. 1984. “Cusp and Butterfly Catastrophe Modeling of Two Opponent Process Models: Drug Addiction and Work Performance.” Behavioral Science 29 (4): 258–62. https://doi.org/10.1002/bs.3830290405.\n\n\nGuastello, Stephen, Anthony Correro, and David Marra. 2019. “Cusp Catastrophe Models for Cognitive Workload and Fatigue in Teams.” Applied Ergonomics, September.\n\n\nGuckenheimer, John, and Philip Holmes. 1983. “Global Bifurcations.” In Nonlinear Oscillations, Dynamical Systems, and Bifurcations of Vector Fields, edited by John Guckenheimer and Philip Holmes, 289–352. Applied Mathematical Sciences. New York, NY: Springer. https://doi.org/10.1007/978-1-4612-1140-2_6.\n\n\nGüémez, J., C. Fiolhais, and M. Fiolhais. 2002. “The Cartesian Diver and the Fold Catastrophe.” American Journal of Physics 70 (7): 710–14. https://doi.org/10.1119/1.1477433.\n\n\nHaken, Herman. 1977. “Synergetics.” Physics Bulletin 28 (9): 412. https://doi.org/10.1088/0031-9112/28/9/027.\n\n\nHardy, Lew. 1996. “Testing the Predictions of the Cusp Catastrophe Model of Anxiety and Performance.” The Sport Psychologist 10 (2): 140–56. https://doi.org/10.1123/tsp.10.2.140.\n\n\nJames, Nicholas A., and David S. Matteson. 2014. “Ecp : An R Package for Nonparametric Multiple Change Point Analysis of Multivariate Data.” Journal of Statistical Software 62 (7). https://doi.org/10.18637/jss.v062.i07.\n\n\nJansen, Brenda R. J., and Han L. J. Van der Maas. 2001. “Evidence for the Phase Transition from Rule I to Rule II on the Balance Scale Task.” Developmental Review 21 (4): 450–94. https://doi.org/10.1006/drev.2001.0530.\n\n\nLatané, Bibb, and Andrzej Nowak. 1994. “Attitudes as Catastrophes: From Dimensions to Categories with Increasing Involvement.” In Dynamical Systems in Social Psychology, 219–49. San Diego, CA, US: Academic Press.\n\n\nLeemput, van de Ingrid A., Marieke Wichers, Angélique O. J. Cramer, Denny Borsboom, Francis Tuerlinckx, Peter Kuppens, van Egbert H. Nes, et al. 2014. “Critical Slowing down as Early Warning for the Onset and Termination of Depression.” Proceedings of the National Academy of Sciences 111 (1): 87–92. https://doi.org/10.1073/pnas.1312114110.\n\n\nLoehle, Craig. 1989. “Catastrophe Theory in Ecology: A Critical Review and an Example of the Butterfly Catastrophe.” Ecological Modelling 49 (1): 125–52. https://doi.org/10.1016/0304-3800(89)90047-1.\n\n\nMazanov, Jason, and D. G. Byrne. 2006. “A Cusp Catastrophe Model Analysis of Changes in Adolescent Substance Use: Assessment of Behavioural Intention as a Bifurcation Variable.” Nonlinear Dynamics, Psychology, and Life Sciences 10: 445–70.\n\n\nMcLachlan, Geoffrey J., Sharon X. Lee, and Suren I. Rathnayake. 2019. “Finite Mixture Models.” Annual Review of Statistics and Its Application 6 (1): 355–78. https://doi.org/10.1146/annurev-statistics-031017-100325.\n\n\nMcRobie, Allan. 2017. The Seduction of Curves: The Lines of Beauty That Connect Mathematics, Art, and the Nude. Princeton University Press.\n\n\nMichell, Joel. 2008. “Is Psychometrics Pathological Science?” Measurement: Interdisciplinary Research and Perspectives 6 (January): 7–24. https://doi.org/10.1080/15366360802035489.\n\n\nOliva, Terence A., Wayne S. Desarbo, Diana L. Day, and Kamel Jedidi. 1987. “Gemcat: A General Multivariate Methodology for Estimating Catastrophe Models.” Behavioral Science 32 (2): 121–37. https://doi.org/10.1002/bs.3830320205.\n\n\nOlthof, Merlijn, Fred Hasselman, Guido Strunk, Marieke van Rooij, Benjamin Aas, Marieke A. Helmich, Günter Schiepek, and Anna Lichtwarck-Aschoff. 2020. “Critical Fluctuations as an Early-Warning Signal for Sudden Gains and Losses in Patients Receiving Psychotherapy for Mood Disorders.” Clinical Psychological Science 8 (1): 25–35. https://doi.org/10.1177/2167702619865969.\n\n\nPaulos, John Allen. 2008. Mathematics and Humor. University of Chicago Press.\n\n\nPloeger, Annemie, Han L. J. Van Der Maas, and Pascal A. I. Hartelman. 2002. “Stochastic Catastrophe Analysis of Switches in the Perception of Apparent Motion.” Psychonomic Bulletin & Review 9 (1): 26–42. https://doi.org/10.3758/BF03196255.\n\n\nPoston, Tim, and Ian Stewart. 2014. Catastrophe Theory and Its Applications. Courier Corporation.\n\n\nRosser, J. Barkley. 2007. “The Rise and Fall of Catastrophe Theory Applications in Economics: Was the Baby Thrown Out with the Bathwater?” Journal of Economic Dynamics and Control 31 (10): 3255–80. https://doi.org/10.1016/j.jedc.2006.09.013.\n\n\nStewart, Ian. 1982. “Catastrophe Theory in Physics.” Reports on Progress in Physics 45 (2): 185–221. https://doi.org/10.1088/0034-4885/45/2/002.\n\n\nStewart, Ian, and P. L. Peregoy. 1983. “Catastrophe Theory Modeling in Psychology.” Psychological Bulletin 94: 336–62. https://doi.org/10.1037/0033-2909.94.2.336.\n\n\nStouffer, Samuel A., Edward A. Suchman, Leland C. Devinney, Shirley A. Star, and Robin M. Williams Jr. 1949. The American Soldier: Adjustment During Army Life. (Studies in Social Psychology in World War II), Vol. 1. The American Soldier: Adjustment During Army Life. (Studies in Social Psychology in World War II), Vol. 1. Oxford, England: Princeton Univ. Press.\n\n\nThom, René. 1977. “Structural Stability, Catastrophe Theory, and Applied Mathematics.” SIAM Review 19 (2): 189–201. https://doi.org/10.1137/1019036.\n\n\nvan der Maas, Han L. J., Rogier Kolstein, and Joop van der Pligt. 2003. “Sudden Transitions in Attitudes.” Sociological Methods & Research 32 (2): 125–52. https://doi.org/10.1177/0049124103253773.\n\n\nVan der Maas, Han L., and Peter C. Molenaar. 1992. “Stagewise Cognitive Development: An Application of Catastrophe Theory.” Psychological Review 99 (3): 395–417. https://doi.org/10.1037/0033-295X.99.3.395.\n\n\nVisser, Ingmar, and Maarten Speekenbrink. 2022. Mixture and Hidden Markov Models with R. Springer International Publishing.\n\n\nWagenmakers, Eric-Jan, Peter C. M. Molenaar, Raoul P. P. P. Grasman, Pascal A. I. Hartelman, and Han L. J. van der Maas. 2005. “Transformation Invariant Stochastic Catastrophe Theory.” Physica D: Nonlinear Phenomena 211 (3): 263–76. https://doi.org/10.1016/j.physd.2005.08.014.\n\n\nWichers, Marieke, Peter C. Groot, and ESM Group Psychosystems. 2016. “Critical Slowing Down as a Personalized Early Warning Signal for Depression.” Psychotherapy and Psychosomatics 85 (2): 114–16. https://doi.org/10.1159/000441458.\n\n\nWitkiewitz, Katie, Han L. J. van der Maas, Michael R. Hufford, and G. Alan Marlatt. 2007. “Nonnormality and Divergence in Posttreatment Alcohol Use: Reexamining the Project MATCH Data \"Another Way.\".” Journal of Abnormal Psychology 116: 378–94. https://doi.org/10.1037/0021-843X.116.2.378.\n\n\nZahler, Raphael S., and Hector J. Sussmann. 1977. “Claims and Accomplishments of Applied Catastrophe Theory.” Nature 269 (October): 759–63. https://doi.org/10.1038/269759a0.\n\n\nZeeman, E. C. 1976. “Catastrophe Theory.” Scientific American 234 (4): 65–83."
  },
  {
    "objectID": "ch3.html#footnotes",
    "href": "ch3.html#footnotes",
    "title": "3  Transitions in complex systems",
    "section": "",
    "text": "Learning a particular conservation task does seem to be rather sudden, but there could easily be two years between learning conservation of number and conservation of volume [[CSL STYLE ERROR: reference with no printed form.]]. This is inconsistent with the stage theory.↩︎\nThe cubic equation that cannot solved easily. This is due to the fact that the cusp is not a function of the form \\(y = f(x)\\). Functions assign to each element of \\(x\\) exactly one element of \\(y\\). But in bistable systems we assign two values of \\(y\\) to one value of \\(x\\).↩︎\nGiven these guidelines and examples it is an interesting exercise to develop one’s own cusp model, for example, for falling in love. This is a tricky exercise.↩︎\nMany different t notations exist for his. Perhaps clearer is \\(dX(t) = - V^{'}\\left( X(t) \\right)dt + \\sigma dW(t)\\), as \\(dX\\) and $ dW\\ $ depend on time.↩︎\nFor consistency with later chapters, I define \\(Z\\) differently from the notation in (Grasman, van der Maas, and Wagenmakers 2009). It is the inverse of \\(Z\\) in that paper.↩︎"
  },
  {
    "objectID": "ch4.html#key-examples-from-the-natural-sciences",
    "href": "ch4.html#key-examples-from-the-natural-sciences",
    "title": "4  Self-organization",
    "section": "4.1 Key examples from the natural sciences",
    "text": "4.1 Key examples from the natural sciences\n\n4.1.1 Physics\nOne physical example of self-organization is the laser. An important founder of complex systems theory is Herman Haken (Herman Haken 1977). He developed synergetics, a specific approach to the study of self-organization and complexity in systems that is also popular in psychology. Synergetics originated in Haken’s work on lasers. We will not discuss lasers in detail here, but the phenomenon is fascinating. Light from an ordinary lamp is irregular (unsynchronized). By increasing the energy in a laser, a transition to powerful coherent light occurs. In the field of synergetics, the order parameter is the term used to describe the coherent laser light wave that emerges. It is a measure that signifies how ordered or structured a system is. The individual atoms within this system move in a manner that aligns with this emergent property, which is known as enslavement. Interestingly, the motion of these atoms contributes to the formation of the order parameter, i.e., the laser light wave. Conversely, the laser light wave dominates the movement of the individual atoms. This interaction exhibits a cyclical cause-and-effect relationship or strong emergence (cf. Figure 1.4). Synergetics has been applied, as we will see later, to perception (Hermann Haken 1992) and coordinated human movement (Fuchs and Kelso 2018).\nAnother famous example, which will be very important for psychological modeling later, is the Ising model of magnetism. This very simple model (replaced by more advanced models of magnetism in modern physics) has found applications in many sciences. In the standard 2d version of the model, atoms are locations on a two-dimensional grid. Atoms have up or down spins. Only when the spins are aligned (all up or all down), we have an effective magnet. If they are not aligned, the effect of the individual spins is canceled out. Two variables control the behavior of the magnet. These are the temperature of the magnet and the external magnetic field. The lower the temperature the more the spins align. At high temperatures, all the atoms behave randomly, and the magnet loses its magnetic effect. The temperature at which the magnet loses its magnetic force is called the Curie point (see YouTube for some fun demonstrations). With an external field we can force the spins to be all up or all down. This external field could be caused another magnet.\n\n\n\nFigure 4.1: Schematic picture of the magnet\n\n\nThe main model equations of the Ising model are:\n\\[\nH\\left( \\mathbf{x} \\right) = - \\sum_{i}^{n}{\\tau x_{i}} - \\sum_{&lt; i,j &gt;}^{}{x_{i}x_{j}} \\tag{4.1}\\] 17\n\\[\nP\\left( \\mathbf{X} = \\mathbf{x} \\right) = \\frac{\\exp\\left( - \\beta H\\left( \\mathbf{x} \\right) \\right)}{Z}. \\tag{4.2}\\] 18\nThe first equation defines the energy of a given state vector \\(\\mathbf{x}\\) (for \\(n\\) spins with states -1 and 1). The notation \\(&lt; i,j &gt;\\) in the summation means that we sum over all neighboring, or linked, pairs.\nThe external field and temperature are \\(\\tau\\) and \\(\\frac{1}{\\beta}\\), respectively. The first equation simply states that nodes congruent with the external field lower the energy. Also, neighboring nodes$$with equal spins lower the energy. Suppose we have only four connected positive spins (top row of Figure 4.1) and no external field, then we have \\(\\mathbf{x} = (1,1,1,1)\\) and \\(H = - 6\\). This is also the case for \\(\\mathbf{x} = ( - 1, - 1, - 1, - 1)\\), but any other state has a higher energy.\nThe second equation defines the probability of a certain state (e.g., all spins up). This probability requires a normalization,\\(Z\\), to ensure that the probabilities over all possible states sum up to 1. For large systems (\\(N &gt; 20\\)), the computation of \\(Z\\) is a substantive issue as the number of possible states grows exponentially. If the temperature is very high, that is, \\(\\beta\\) is close to zero, \\(\\exp\\left( - \\beta H\\left( \\mathbf{x} \\right) \\right)\\) will be 1 for all possible states, and the spins will behave randomly. The differences in energy between states do not matter anymore.\nThe randomness of the behavior is captured by the concept of entropy. Entropy is a measure of the degree of disorder or randomness in a system. To explain this a bit better we need to distinguish the micro- and macrostate of an Ising system. The microstate is defined by the configuration \\(\\mathbf{x}\\) of spins, while the macrostate is determined by the sum of spins (similar to how magnetization is defined). The Boltzmann entropy is a function of the number of ways (\\(W\\)) a particular macrostate can be realized. For \\(\\sum_{}^{}x = 4\\) there is only one way (\\(\\mathbf{x} = 1,1,1,1)\\). But for \\(\\sum_{}^{}x = 0\\), there are 6 ways (\\(W = 6\\)). The Boltzmann entropies (\\(\\ln W)\\) for these two cases are 0 and 1.79, respectively. The concept of entropy will be important in later discussions.\nIn the simulation of this model, we take a random spin, calculate the energy of the current \\(\\mathbf{x}\\) and the \\(\\mathbf{x}\\) with that particular spin flipped. The difference in energy determines the probability of a flip:\n\\[\nP\\left( x_{i} \\rightarrow - x_{i} \\right) = \\frac{1}{\\left( 1 + e^{- \\beta\\left( H\\left( x_{i} \\right) - H\\left( - x_{i} \\right) \\right)} \\right)}. \\tag{4.3}\\] 19\nIf we do these flips repeatedly, we find equilibria of the model. This is called the Glauber dynamics (more efficient algorithms do exist). The beauty of these algorithms is that the normalization constant Z falls out of the equation. In this way we can simulate Ising systems with \\(N\\) much larger than 20.\nIn the case of a fully connected Ising network (also called the Curie-Weiss model), the emergent behavior, what is called the mean field behavior, can be described by the cusp (Section 3.2.3, Abe et al. 2017; Poston and Stewart 2014). The external field is the normal variable and temperature acts as a splitting variable. The relationship to self-organization is that when we cool a hot magnet, at some threshold the spins begin to align and soon are all up or down. This is the pitchfork bifurcation, creating order out of disorder.1\nIn the 2D Ising model (see Figure 4.1), the connections are sparse (only local) and more complicated (self-organizing) behavior occurs. We will simulate this in NetLogo later in this chapter and as a model of attitudes in chapter 6.\n\n\n4.1.2 Chemistry\nAnother founder of self-organizing systems research is Ilya Prigogine. Prigogine won the 1977 Nobel Prize in Chemistry for his work on self-organization in dissipative systems. These are systems far from thermodynamic equilibrium (due to high energy input) in which complex, sometimes chaotic, structures form due to long-range correlations between interacting particles. One notable example of such behavior is the Belousov-Zhabotinsky reaction, an intriguing nonlinear chemical oscillator, which I mentioned earlier.\nCollaborating with Stengers, he authored the influential book “Order out of Chaos” in 1978. This work significantly influenced the scientific community, particularly through their formulation of the second law of thermodynamics. This law states that the total entropy of an isolated system always increases over time and never decreases, meaning that spontaneous processes in nature tend to move towards a state of increasing disorder or randomness. Another way of stating the second law is that heat flows spontaneously from hot objects to cold objects, and not the other way around, unless external work is applied to the system. A more appealing example might be the student room that never naturally becomes clean and tidy, but rather the opposite.\nStengers and Prigogine (1978) argued that while entropy may indeed decrease in a closed system, the process of self-organization in such systems can create ordered structures that compensate for the entropy increase, resulting in a net increase in what they called “local entropy”. Prigogine and his colleagues placed particular emphasis on irreversible transitions, highlighting their importance in understanding complex systems. While the catastrophe models we previously discussed exhibited symmetrical transitions (sudden jumps in the business card are symmetric), Prigogine’s research revealed that this symmetry does not always hold true.\nTo illustrate this point, consider the analogy of frying an egg. The process of transforming raw eggs into a fried form represents a transition, but it is impossible to reverse this change and “unfry” the egg. Prigogine linked these irreversible transitions to a profound question regarding the direction of time, commonly known as the arrow of time. Although a fascinating topic in itself, we will not explore it further here.\n\n\n4.1.3 Biology\nThere is no shortage of founders of complex systems science. Another fantastic book is Kaufmann’s Origin of Order (Kauffman 1993), which introduces the concept of self-organization into evolutionary theory. He argues that the small incremental steps in neo-Darwinistic processes cannot fully explain natural evolution. If you want to know about adaptive walks and niche hopping in rugged fitness landscapes, you need to read his book. Another influential theory is that of punctuated equilibria, which proposes that species undergo long periods of stability interrupted by relatively short bursts of rapid evolutionary change (Eldredge and Gould 1972).\nA neat example of the role of self-organization in evolution is the work on spiral wave structures in prebiotic evolution by Boerlijst and Hogeweg (1991). This work builds on the classic work of Eigen and Schuster (1979)]on the information threshold. Evolution requires the copying of long molecules. But in a system of self-replicating molecules, the length of the molecules is limited by the accuracy of replication, which is related to the mutation rate. Eigen and Schuster showed that this threshold can be overcome if such molecules are organized in a cycle in which each molecule catalyzes its nearest neighbor (a hypercycle). However, the hypercycle was shown to be vulnerable to parasites. These are molecules that benefit from one neighbor but do not help another. This molecule will outcompete the others and we are back to the limited one-molecule system.\nWhat Boerlijst and Hogeweg did was to implement the hypercycle in a cellular automaton (CA). A CA is basically a two-dimensional grid of cells, where cells interact with their neighbors, as in the Ising model. In the hypercycle simulation, cells could be empty (dead) or filled with one out of several colors. Colors die with some probability but are also copied to empty cells with a probability that depends on whether there is a catalyzing color in the local neighborhood. One of the colors is a parasite, catalyzed by one color, but not catalyzing any other colors. The amazing effect, and you will see this later using NetLogo, is that moving global spirals emerge that isolate the parasites so that a stable hypercycle prevails.\nMany examples of self-organization come from ecosystem biology. We will see simulations of flocking below, but I would also like to mention ants. \nAnts exhibit amazing forms of globally organized behavior. They build bridges, nests, and rafts, and they fight off predators. I once saw a documentary on an ant nest that somehow decided to move to another location 50 meters away. Ant colonies utilize pheromones and swarm intelligence to relocate to a new location. Scouts search for potential sites, leaving pheromone trails. If a promising location is found, more ants follow the trail, reinforcing the signal. Unsuitable sites result in fading trails. Once a decision is made, the colony collectively moves to the chosen site, transporting their brood and establishing a new nest.\nIt is not a strange idea to think of an ant society as a living organism. Note that all this behavior is self-organized. In other words, there is clearly no super ant or management team that has a blueprint for building bridges and telling the rest of the ants to do certain things. The same is true of flocks of birds. There is no bird that chirps commands to move collectively to the left, to the right, or to split up. It is also clear that this is true of our brain. Each neuron is not intelligent at all. Our intelligence is based on the collective behavior of billions of neurons.\n\n\n4.1.4 Computer science\nAnother crucially important area of research on self-organisation has been computer science. A simple but utterly amazing example is the work on Conways’ game of life (Berlekamp, Conway, and Guy 2004). The rules are depicted in Figure 4.2.\n\n\n\nFigure 4.2: The rules of the Game of Life\n\n\nFor each cell, given the current neighbors, the next state for all cells is computed. This is called synchronous updating.2 It is hard to predict what will happen if we start from a random initial state. But you may already realize that a block of 4 squares is stable, and a line of three blocks will oscillate between a horizontal and a vertical line.\nA great tool for playing around with the Game of Life is Golly, which is freely available for computers and mobile phones. I ask you to download and open Golly, draw some random lines, press Enter and see what happens. Often you will see it converging to a stable state (with oscillating sub-patterns). Occasionally you will see walkers or gliders (zoom out). These are patterns that move around the field.\nRandom initial patterns rarely lead to anything remarkable, but by choosing special initial states, surprising results can be achieved. First, take a look at the Life within Patterns folder. Take, for example, the line-puffer superstable or the spaceship types. One of my favorites is the metapixel-galaxy in the HashLife folder. Note that with + and - you can speed up and slow down the simulation. What this does is simulate the game of life in the game of life! Zoom in and zoom out to see what really happens. I’ve seen this many times and I’m still amazed. A small childish experiment is to disturb the metapixel galaxy in a few cells. This leads to a big disturbance and a collapse of the pattern.\nIt is even possible to create the (universal) Turing machine in the Game of Life (Rendell 2016). The Turing machine is a theoretical machine, developed by Alan Turing in 1936, that despite its simplicity can implement any computer algorithm. This raises the question of whether we can build self-organizing intelligent systems in this way. Actually, we can to some extent, but by using a different setup, based on brain-like mechanisms (see the next section).\n\n\n\nFigure 4.3: The Turing Machine built in the Game of Life\n\n\nAnother root of complex systems theory and the role of self-organization in computational systems is cybernetics (Ashby 1956; Wiener 2019). To give you an idea of this highly original work, I will only mention the titles of a few chapters of Norman Wiener’s book, originally published in 1948: Gestalt and Universals, Cybernetics and Psychopathology, On Learning and Self-reproducing Machines, and finally, Brainwaves and Self-organization. And this was written in 1948.\nThe interest in self-organization is not only theoretical. In optimization, the search for the best parameters of a model describing some data, techniques inspired by cellular automata and self-organization have been applied (Langton 1990; Xue and Shen 2020). I have always been fascinated with genetic algorithms (Holland 1992a; Mitchell 1998), where the solution to a problem (sets of parameter values) are individuals in an evolving population. Through mutation and crossover, better individuals evolve. This is a slow but very robust way of optimizing, preventing convergence to local minima. John Henry Holland is considered one of the founding fathers of the complex systems approach in the United States. He has written a number of influential books on complex systems. His most famous book, Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control theory, and artificial intelligence (Holland 1992b), has been cited over 75,000 times.\nA self-organizing algorithm that has played a large role in my work is the Elo rating system developed for chess competitions (Elo 1978). Based on the outcomes of games, ratings of chess players are estimated, which in turn are used to match players in future games. The ratings converge over time, but adjusted when players suddenly improve their skills. We have adapted this system for use in online learning systems where children play against math and language exercises (Maris and van der Maas 2012). The ratings of children and exercises are estimated on the fly in a large-scale educational system (Brinkhuis et al. 2018; Klinkenberg, Straatemeier, and van der Maas 2011).\n\n\n4.1.5 Neural networks\nThe current revolution in AI, which is having a huge impact on our daily lives, is due to a number of ‘self-organizing’ computational techniques. Undoubtedly, deep learning neural networks have played the largest role. A serious overview of the field of neural networks is clearly beyond the scope of this book, but one cannot understand the role of complex systems in psychology without knowing at least the basics of artificial neural networks (ANN), i.e., networks of artificial neurons.\nArtificial neurons are characterized by their response to input from other neurons in the network, which is typically weighted and summed before being passed through an activation function. This activation function may produce either a binary output or a continuous value that reflects the level of activation of the neuron. The input could be images, for example, and the output could be a classification of these images. The important thing is that neural networks learn from examples.\nUnsupervised learning is based on the structure of the input. A famous unsupervised learning rule is the Hebb rule (Hebb 1949), which states that what fires together, wires together. Thus, neurons that correlate in activity strengthen their connection (and otherwise connections decay). In supervised learning connections are updated based on the mismatch between model output and intended output (the supervised output). Backpropagation is a mechanism to update specific connections such that this mismatch or error is minimized over time. These are just two of the learning mechanisms used in modern ANNs.\nModern large language models large language models, like GPT, differ from traditional backpropagation networks in terms of their architecture, training objective, pre-training process, scale, and application. Large language models use transformer architectures, undergo unsupervised pre-training followed by supervised fine-tuning, are trained on massive amounts of unlabeled data, are much larger in size, and are primarily used for natural language processing tasks.\nAn interesting unsupervised model is the Boltzmann machine. It is basically an Ising model (see section 4.1.1) where the connections between nodes have continuous values. These weights can be updated according to the Hebbian rule. A simple setup of the Boltzmann machine is to take a network of connected artificial neurons, present the inputs to be learned in some sequence by setting the states of these neurons equal to the input. The Hebb rule should change the weights between neurons so that the Boltzmann machine builds a memory for these input states. This is the training phase. In the test phase, we present partial states by setting some, but not all, nodes to the values of a particular learned input pattern. By the Glauber’s dynamics, we update the remaining states that should take on the values belonging to the pattern. This pattern completion task is typical for ANN’s.\nThis setup is called the general or unrestricted Boltzmann machine, where any node can be connected to any other node and each node is an input node. The restricted Boltzmann machine (RBM) is much more popular because of its computational efficiency. In an RBM, nodes are organized in layers, with connections between layers but not within layers. In a deep RBM we stack many of these layers, which can be trained in pairs. I recommend Timo Matzen’s R package for a hands-on explanation (https://github.com/TimoMatzen/RBM). Other famous approaches are the Kohonen self-organizing maps and the Hopfield neural network.\n\n\n\nFigure 4.4: The deep learning restricted Boltzmann machine\n\n\nIn supervised learning, connections between artificial neurons are updated based on the difference between the output and the desired or expected output of the output neurons. The first supervised ANN, the perceptron, consisted of multiple input nodes and one output node and was able to classify input patterns from linearly separable classes. This included the OR and AND relation but excluded the XOR relation. In the XOR pattern, the combinations of 00 and 11 are false, 01 and 10 are true. In this case the sum of the two bits is not useful for classification. By adding a hidden layer to the perceptron, the XOR can be solved, but it took many years to develop a backpropagating rule for multi-layer networks, such that they can learn this non-linear classification from examples. We will do a simple simulation in NetLogo later. Although extremely powerful, it is debatable whether backprop networks are self-organizing systems. Self-organizing systems are characterized by their ability to adapt to their environment without explicit instructions. Unsupervised neural networks are more interesting in this respect.\nAll these models were known at the end of the 20th century, but their usefulness was limited. This has changed due to some improvements in algorithms but especially in hardware. Current deep-learning ANNs consist of tens of layers within billions of nodes, trained on billions of inputs using dedicated parallel processors (e.g., Schmidhuber 2015).\nNeural networks are at the heart of the AI revolution, but other developments have also played a key role. Reinforcement learning is essential in AI systems that need to behave or act on the environment. Examples are game engines, robots, and self-driving cars. Note that the study of reinforcement learning also has its roots in psychology (see Chapter 1 of Sutton and Barto 2018).\nI was most amazed by the construction and performance of AlphaZero chess. AlphaZero chess (Silver et al. 2018) combines a deep learning neural network that evaluates positions and predicts next moves with a variant of reinforcement learning (Monte Carlo tree search). Amazingly, AlphaZero learns chess over millions of self-played games. This approach is a radical departure from classic chess programs, where brute force search and built-in indexes of openings and endgames were the key to success. AlphaZero Chess is a self-organizing chess program with a phase transition in learning after 64000 training steps (see fig.7 in McGrath et al. 2022). For an analysis of the interrelations between psychology and modern AI, I refer to Han L. J. van der Maas, Snoek, and Stevenson (2021).\n\n\n4.1.6 The concept of self-organization\nI trust that you now possess some understanding of self-organization and its applications across various scientific fields. Self-organization is a generally applicable concept that transcends various disciplines, yet it maintains strong connections with specific examples within each discipline.\nAs previously mentioned, the precise definition of self-organization remains under discussion, and a range of criteria continue to be debated. Key questions, such as the degree of order necessary for a system to be deemed self-organized, whether any external influences are permissible, whether a degree of randomness within the system is acceptable, and whether the emergent state must be irreversible, are among the issues that lack definitive resolutions.\nThis ambiguity in the definition isn’t unusual for psychologists, as many non-formal concepts lack strict definitions. The value of the self-organization concept is primarily found in its concrete examples, its broad applicability, such as in the field of artificial intelligence, and our capability to create simulations of it. The focus of the next section will be on such simulations."
  },
  {
    "objectID": "ch4.html#netlogo",
    "href": "ch4.html#netlogo",
    "title": "4  Self-organization",
    "section": "4.2 NetLogo",
    "text": "4.2 NetLogo\n\n4.2.1 Examples\nNetLogo (Wilensky and Rand 2015) is based on Logo, a revolutionary educational programming language from the early days of computer languages, in which an on-screen turtle, a cursor, could be moved around to create graphics. The turtle is still there, but there is much more that you can do with NetLogo.\nI strongly recommend that you download and install NetLogo for the next part of this chapter.\nThe Ising model:\nWhen you start NetLogo, you see an interface with a black area (the world), a 33 by 33 matrix of patches (cells). You can change the world using the settings (see top right). Interface and Code are the most important tabs.\nFirst, we open the Model library (menu ‘File: Model Library’) and find and open ‘Ising’. Click on ‘setup’ and ‘go’. That is all. Verify that high temperature indeed causes random spin behavior. Also verify that lowering the temperature causes a pitchfork bifurcation. The random state becomes unstable and all spins become either positive or negative (light or dark blue). Now go to settings and set max-pxcor and max-pycor to 200 and patch size to 1. With these settings you will see self-organized global patterns, constantly moving clusters of positive and negative spins.\nHypercycles:\nSome models are available in NetLogo, others can be found on the website of NetLogo (see Community). Download Hypercycle by Maarten Boerlijst and read the information. You have to run the model with 8 species for 20000 iterations or ticks (to speed up, deselect view updates) and then add parasites. The spirals keep the growth of the parasites under control. If you do this earlier, the parasites will quickly take over. I think this is a beautiful example of functional self-organization. The implementation in the form of a cellular automata is essential for the success of this model. If we implement this model in the form of coupled differential equations, the parasite will simply win.\nFlocking:\nNetLogo 3D allows us to create three-dimensional plots of self-organizing patterns. Start NetLogo 3D and load the flocking model 3D Alternate. I recommend editing the Population slider by ‘right-clicking’ it and setting the max to 1000. This will result in more realistic swarms. Play around with the controls and don’t kill all the birds.\nTraffic:\nIn the models library of NetLogo (not 3D) you will find ‘Traffic 2 Lanes’. Run the model with 20 cars and notice that the congestion actually moves backwards. Play around with the number of cars as well. Is there a clear threshold where you get congestion as you slowly increase the number of cars? And what happens when you decrease the number of cars? Is there a threshold where congestion dissipates? I hope you see that finding hysteresis in this way is quite difficult. There are clearly sudden changes, but finding hysteresis requires very precise and patient experimentation.\nNeural networks:\nIn the Model Library you will find a perceptron and a multilayer network. Start with the perceptron. Set the target function to ‘and’, train the model for a few seconds, and test the perceptron. You will see that it correctly classifies 11 as 1 and the other patterns as -1. The graph on the bottom right is particularly instructive. It shows how the patterns are separated. The perceptron can do linear separation. This is sufficient for most of the logical rules that can be learned, but not for the XOR. You will see that the linear separation just jumps around and the XOR cannot be learned. Also train the multilayer model on the XOR. Another nice tool to play around with can be found on the internet by searching for ‘A Neural Network Playground’.\nOf course, these are just illustrative tools. But building serious deep learning ANNs is not that hard either. Many resources and books are available (e.g., Ghatak 2019).\nThe sandpile model:\nBak, Tang, and Wiesenfeld (1988) introduced the concept of self-organized criticality. In systems such as the Ising model, there are parameters (e.g., temperature) that must be precisely tuned for the system to reach criticality. The Bak-Tang-Wiesenfeld sandpile model exhibits critical phenomena without any parameters. In the sandpile model, grains of sand are added to the center of the pile. When the difference in height between the center column and its neighbors exceeds a critical value, a grain of sand rolls to that neighboring location. This occasionally results in avalanches. The point is that no matter how we start, we get to a critical state where these avalanches occur. Thus, the sandpile model spontaneously evolves toward its critical point, which is why this phenomenon has been called self-organized criticality.\nThe NetLogo model ‘Sandpile’ in the Models library demonstrates this behavior (use ‘setup uniform’, ‘center’ drop location and ‘animate avalanches’). We now drop grains of sand onto the center of a table, one at a time, creating avalanches. The plots on the right show an important characteristic of self-organized criticality. The frequencies of avalanche sizes and durations follow a power law. This means that the log-log plot should be linear, which can be verified by running the model for some time. One of the key features of power law distributions is that they exhibit a high degree of variability or heterogeneity. This means that there are many small events or phenomena, and a few very large ones, with a smooth distribution of sizes in between. Power law systems are scale invariant, meaning that we see the same behavior at any scale of the sand pile. For this reason, they are sometimes called ‘scale-free distributions’.\nOther models:\nI recommend running a few other models (e.g., sunflowers, beatbox, and the B-Z reaction). One thing we haven’t done yet is click on the Code tab. Read the code for the B-Z reaction and notice one thing: it is surprisingly short!\n\n\n4.2.2 A bit of NetLogo programming\nI find NetLogo programming very easy and very hard at the same time. Hard because it requires a different way of thinking. Uri Wilensky’s examples are often extremely elegant and much shorter than my clumsy code. NetLogo resembles object-oriented programming languages, quite different from (base) R. There are three types of objects, the patches, which refer to cells in a world grid (CA), turtles, which are agents that move around, and links, which connect turtles. Note that turtles are not necessarily turtles. We have already seen turtles in the form of neural nodes and cars.\nIn NetLogo, you “ask” objects to do something. A typical line would be:\nask turtles with [pcolor = red] set pcolor green\nThis would make red turtles green. To get started, I highly recommend watching the videos on the NetLogo page ‘The Beginner’s Guide to NetLogo Programming’ and following these examples. Here we make our own Game of Life.\n\n4.2.2.1 Game of Life\nThe first thing to do is to create two buttons in the interface, a setup and a go button. In Command, name them setup and go. In the settings of the go button, select ‘forever’. Now we go to the Code tab and define these two functions as:\nto setup\n  clear-all\n  reset-ticks\nend\n\nto go\n  tick\nend\nTicks count the iterations in NetLogo, and with this code we are really just resetting things. Now add this last line to setup (with “;” we add comments to code):\nask patches\n    [set pcolor one-of [white blue]] ; white is dead, blue is alive\nTo do a synchronous update, we need to store the update state in a temporary variable called new-state. Put this line at the top of your code\npatches-own [new-state]\nIn the ‘go’ function, we add the life rules.\nask patches[\n  if(count(neighbors with [pcolor = blue]) &gt; 3) [set new-state white]\n  if(count(neighbors with [pcolor = blue]) &lt; 2) [set new-state white]\n  if(count(neighbors with [pcolor = blue]) = 3) [set new-state blue]\n]\n\nask patches [set pcolor new-state]\nThe last line updates the state to the new state. That is all! We build a Game of Life simulation. Use Setting to create a larger world. You can take a look at the code of the Game of Life program in the Model Library to see some extensions to this code.\nIn the help menu, you will find the very useful NetLogo dictionary. Just reading through this dictionary will teach you a lot of useful tricks. NetLogo is similar to R in the sense that you should use the built-in functions as much as possible.\n\n\n4.2.2.2 The Ising model\nBuilding a NetLogo from scratch requires quite some experience, adapting a program is much easier. The Ising model in NetLogo was not complete, as there is no slider for the external field. Try to add this yourself. Add a slider for the external field ‘tau’. The code only needs to be changed in this line (study Equation 4.1):\nlet Ediff 2 * spin * sum [ spin ] of neighbors4\nIf successful, you can test for hysteresis and divergence. For tau = 0, decreasing the temperature should give the pitchfork bifurcation. For a positive temperature (say 1.5), moving tau up and down should give hysteresis.\nActually, this should work better if all spins are connected to all spins. To do this, ‘neighbors4’ should be replaced by ‘patches’. To normalize the effect of so many spins, it is recommended to use:\nlet 0.001 * Ediff 2 * spin * sum [ spin ] of patches\nNow you should see hysteresis and the pitchfork better. However, in this case the typical self-organized patterning that occurred in the Ising model with only local interactions is not present."
  },
  {
    "objectID": "ch4.html#self-organization-in-psychology-and-social-systems.",
    "href": "ch4.html#self-organization-in-psychology-and-social-systems.",
    "title": "4  Self-organization",
    "section": "4.3 Self-organization in psychology and social systems.",
    "text": "4.3 Self-organization in psychology and social systems.\nIn the final section of this chapter, I provide illustrations of research on self-organization within various psychological systems, spanning several subfields of psychology. The discussion begins with an exploration of self-organization in the context of the brain and concludes with an examination of its implications within human organizations. In the final part of the chapter, I offer specific case studies to illustrate self-organization, while also referencing relevant literature to guide further exploration in other areas.\n\n4.3.1 The brain\nMany different psychological and social processes involve self-organization. As discussed above, at the lowest level it plays a role in neural systems. Self-organization in the brain is an active area of research (Breakspear 2017; Chialvo 2010; Cocchi et al. 2017; Ooyen and Butz-Ostendorf 2017; Plenz et al. 2021). Dresp-Langley (2020)] distinguished seven key properties of self-organization clearly identified in brain systems: 1) modular connectivity, 2) unsupervised learning, 3) adaptive ability, 4) functional resiliency, 5) functional plasticity, 6) from-local-to-global functional organization, and 7) dynamic system growth.\nA key example is Walter Freeman’s work on the representation of odors in the brain (Skarda and Freeman 1987). He used EEG measurements to support his nonlinear system model of the brain. Freeman’s theory proposes that the brain operates through the generation of dynamic patterns of electrical activity, which he called “attractors”. These attractors represent stable states of neural activity that arise spontaneously from the interactions between large populations of neurons.\nAnother influential theory was proposed by neuroscientist Gerald Edelman. His theory of Neural Darwinism suggests that the development of the brain’s neural connections is based on a process of competition and selection, rather than being pre-wired in the genes (Edelman 1987). According to Edelman’s theory, the brain is a complex, dynamic system made up of many interconnected neurons that constantly interact with each other and the outside world. The process of competition and selection occurs through the formation of ensembles of neurons that respond to specific stimuli or experiences. Over time, the connections between neurons in successful ensembles become stronger, while those in unsuccessful ensembles weaken or disappear.\nIt has also been claimed that self-organized criticality (SOC, see the Sandpile model in Section 4.2.1) plays a role in the brain (Bak, Tang, and Wiesenfeld 1988). It is hypothesized that when a system is close to criticality, small perturbations can have large, cascading effects, which can allow the system to rapidly switch between different states of activity in response to changes in the environment. One of the key pieces of evidence for SOC in the brain comes from studies of the distribution of sizes of neural activity events, which has been found to follow a power law distribution, but alternative explanations have been provided (Bédard, Kröger, and Destexhe 2006). This is a technical area of research with many methodological challenges (Lurie et al. 2020; O’Byrne and Jerbi 2022).\nA promising general approach to understanding the so called “predictive” brain functions is the free energy account (Clark 2013), which implements a form of self-organization (Friston 2009). The idea is that the brain is constantly making predictions about the sensory inputs it receives from the environment. The brain is not simply reacting to the world around us but is actively generating predictions about what we will see, hear, feel, and experience, based on our past experiences and knowledge. The predictive brain theory suggests that the brain’s predictions are generated through a process of hierarchical inference, in which information from lower-level sensory areas is combined and integrated in higher-level areas to generate more complex predictions about the world. These predictions are then compared to the incoming sensory inputs, and any discrepancies between the predictions and the actual inputs are used to update the predictions and improve the brain’s accuracy over time.\n\n\n4.3.2 Visual illusions\nFrom the earliest days of psychology as a scientific discipline, researchers were interested in the organizational properties of perception. Gestalt psychologists such as Wertheimer and Koffka claimed that we perceive whole patterns or configurations, not just individual components. One might say that visual perception was one of the first applications of self-organization, even before anything like complexity science existed. The Gestalt psychologist formulated a number of Gestalt principles such as grouping, proximity, similarity, and continuity. A review of a century of research and an analysis of their current role in vision research is provided by Wagemans et al. (2012). Much of the modeling of the self-organizing processes in perception has been done in the tradition of synergetics. Excellent sources include (Kelso 1995; and Kruse and Stadler 2012). Grossberg and Pinna (2012) discuss neural implementations of the Gestalt principles.\nAnother related approach is the ecological approach to visual perception by Gibson (2014). In Gibson’s approach, perception is not just a process of analyzing sensory input, but an active process that involves the perceiver’s relationship to the environment, including the perception of affordances (i.e., opportunities for action) in the environment that guide and shape perception.\nA combination of Gestalt principles, when acting in opposite directions, can lead to all kinds of perceptual illusions. The Optical Illusion model in NetLogo’s model library illustrates some of them. Check out the codes for each illusion, they are extremely short and elegant.\n\n\n\nFigure 4.5: The ‘Kindergarten’ Illusion from The Optical Illusion model in NetLogo\n\n\nIn Chapter 3, I provided examples of sudden jumps and hysteresis in multistable perception. NetLogo is also a great tool for experimenting with these effects. Download ‘Motion Quartet’ from the NetLogo community website and explore hysteresis in your own perception.\n\n\n4.3.3 Motor action\nMany body motions are periodic in nature, think of walking, swimming, dancing, and galloping. Key to these motions is the synchronization of the movements of body parts. A famous paradigm for studying coordinative movement patterns is the finger movement task, in which one has to move both index fingers up and down (or right and left), either in phase or out of phase. Figure 4.6 explains the setup and data showing the transition between two in-phase or out-of-phase oscillations.\n\n\n\nFigure 4.6: The finger movement task. Two fingers move up and down (x1 and x2). They can move in phase or out of phase with a phase difference of 0 and \\(\\pi\\) (bottom left figures). The model is shown on the right side. The potential function either has two stable states (a phase difference\\(\\ \\varphi\\) of 0 or \\(\\pi\\) (\\(- \\pi\\) is the same state) or only one stable state (a phase difference of 0). Coupling strength (\\(b/a\\)) and heterogeneity (\\(\\Delta w)\\) are control variables. Adapted from H. Haken, Kelso, and Bunz (1985) and Kelso (2021).\n\n\nThe Haken–Kelso–Bunz (HKB) model, developed in the tradition of synergetics, explains the phase transition between in phase and anti-phase motions in a way we have seen in the previous chapter (the phenomenological cusp model). They set-up a potential function in the form of\n\\[\nV(\\varphi) = - \\Delta w\\varphi - b\\cos\\varphi - a\\cos{2\\varphi} \\tag{4.4}\\] 20\nWhere \\(\\varphi\\) is the order or behavioral variable, the phase difference between the two fingers. The main control parameter is \\(b/a\\). According to Kelso (2021) coupling strength (\\(b/a\\)) corresponds to the velocity or frequency of the oscillations in the experiments. \\(\\Delta w\\) is the difference (heterogeneity, diversity) between the natural frequencies of the individual oscillatory elements. In the finger movement task this parameter is expected to be 0. The behavior of this protentional function is cusp like. It has two stable states 0 and \\(\\pm \\pi\\), and increasing and decreasing the frequency leads to hysteresis. The effects of \\(\\Delta w\\) is similar to the fold catastrophe (see Chapter 3).\nThis potential function is proposed as the simplest form that explains the experimental results. This is why I would call this a phenomenological model. However, H. Haken, Kelso, and Bunz (1985) also present a more mechanistic model, a combination of Van der Pol and Rayleigh oscillators (Alderisio, Bardy, and di Bernardo 2016). The stochastic variant of the HKB model also predicts early warnings such as critical slowing down (see the catastrophe flags, Section 3.3.2). The presence of critical slowing down and other flags has been confirmed experimentally (Kelso, Scholz, and Schöner 1986).\nOne difference with the catastrophe approach is that the synergetic models that incorporate hysteresis typically do not have a splitting control variable. The concept of structural stability, which is fundamental to catastrophe theory, is not used in synergetics. What the splitting factor might be in this model is not so clear. I have never understood why coupling strength \\(b/a\\) (see Figure 4.6) and the frequency of the oscillations are equated in the basic version of the HKB model (see also P. J. Beek, Peper, and Daffertshofer 2002). Clearly, uncoupled oscillators would have a rather random phase difference. Strengthening the coupling would lead to a kind of pitchfork bifurcation.\nThis coupling/uncoupling is a also a phenomenon in the visual coordination of rhythmic movements between people. Schmidt, Carello, and Turvey (1990) used an experimental paradigm in which two people swing a leg up and down, while sitting side by side. A metronome was used to manipulate the frequency of the swing. Clear jumps from out-of-phase to in-phase movement were demonstrated.\nKelso (2021) provide an overview of the impressive amount of work on the HKB model. Repp and Su (2013) review empirical work in many different motor domains. Interestingly, learning motor tasks sometimes involves learning to couple movements (walking), and sometimes the uncoupling of movements (to drum more complex rhythms). Juggling is a fascinating case that has been studied in great detail (Peter J. Beek and Lewbel 1995). Another popular mathematical approach to synchronization phenomena is the Kuramoto model (Acebrón et al. 2005) with the synchronous flashing of fireflies as a basic example. A second-order multi-adaptive neural agent to interpersonal synchrony can be found in Hendrikse, Treur, and Koole (2023).\n\n\n4.3.4 Robotics\nA major challenge in robotics is to build walking robots. Bipedal robots have evolved from clumsy mechanical walkers to flexible dynamic walkers and runners. Current legged robots can walk on slippery, uneven natural terrain, jump, do backflips, recover from rear shocks, and dance (see some videos on humanoid robots such as Atlas, Asimo). These successes are based on a combination of new technologies, but the principles of self-organization play a key role. An important concept is dynamic stability. In old-school robots, the path and momentum of each step had to be precisely calculated in advance to keep the robot’s center of mass continuously balanced at every point. A dynamically stable robot maintains balance the same way a human does: by catching itself mid-fall with each step (Pavlus 2016).\nAn intriguing application is called passive dynamics, which refers to robotic walking without external energy supply (McGeer 1990; Reher and Ames 2021). The idea is that truly dynamic locomotion should be based on the nonlinear dynamics in natural walking systems. An amazing demonstration is the artwork, Strandbeest, by Theo Jansen. His YouTube videos are strongly recommended.  ### Developmental processes\nThe early roots of interest in nonlinear dynamics and self-organization can be found in the seminal work of the French psychologist Jean Piaget. In order to understand the origin of knowledge, he studied the origin of intelligence in the child (Piaget 1952). His theorizing was inspired by both biological models and observations of children solving puzzles. He saw cognitive development as the building of structures on earlier knowledge structures in a process of equilibration. The idea was that the child would assimilate or accommodate to potentially conflicting external information.\nIn the case of assimilation, the child modifies the information to fit the current cognitive structure, while in the case of accommodation, the structure is modified. Such a modification could be the addition of an exception to the rule (‘Longer sausages of clay normally weigh more, but not when this professor rolls the clay ball into a sausage’). In the long run, this does not work, the cognitive conflicts intensify, and the cognitive structure is destabilized. In this state of disequilibrium, a new structure can be formed on top of the earlier structure. An example of this is the conservation task I introduced in the introduction of Chapter 3. The pre-operational structure, in which form and quantity are equated, leads to incorrect predictions in the conservation anticipation task. The child may ignore this (assimilation), create an ad hoc rule for this exception (accommodation), but the cognitive conflict is not resolved, and the pre-operational structure becomes unstable. This instability allows the formation of the more advanced concrete operational structure in which form and quantity are independent constructs. Piaget argued that cognitive development is a spontaneous, natural process that occurs as children interact with the world around them.\nI would say that this is self-organization theory avant la letter, as was the case for the Gestalt psychologists. I see my own work in developmental psychology (e.g., Savi et al. 2019; Van Der Maas et al. 2006; Van der Maas and Molenaar 1992) as a formalization of these classical ideas of Piaget. The idea of stages and equilibrium lived on in neo-Piagetian theories.\nIn the late twentieth century developmental theories inspired by work in embodied cognition, nonlinear dynamics, synergetics and neural networks (e.g., Edelman’s neural Darwinism) became popular. A key example is Esther Thelen’s work on the development of walking and reaching (Thelen 1995). Another famous Piagetian task, the A not B error plays a central role in this. The A-not-B error typically occurs in a simple game where an adult hides an object in a known location (A) in front of the infant several times. After a few trials, the adult hides the object in a new location (B) while the infant is watching. Despite watching the object being hidden in the new location, infants tend to continue searching for the object in the old location (A).\nThe book by Thelen and Smith (1994) had a strong influence on developmental psychology, although I was rather critical in my youthful enthusiasm (H. L. J. van der Maas 1995). Concrete mathematical dynamical models for A not B error have been developed in Dynamic Field theory (Schöner and Spencer 2016). Dynamic field theory posits that cognitive processes are represented as dynamic fields, which are patterns of neural activity that evolve over time. These fields can be thought of as distributed representations that encode information about specific aspects of a task or behavior. For example, there may be a dynamic field representing the position of an object in space or the intended movement trajectory of a limb. In this theory, complex behaviors arise from the coordination and integration of multiple dynamic fields. Dynamic Field theory is a very active area of research (more information on https://dynamicfieldtheory.org/).\nFinally, I note that some recent work considers the educational system itself as a complex system (Jacobson, Levin, and Kapur 2019; Lemke and Sabelli 2008).\n\n\n4.3.5 Psychological disorders\nSomewhat dated but interesting reviews of the application of the self-organization concept in clinical psychology are provided by Barton (1994) and Ayers (1997). A recent review is provided by Olthof et al. (2023). Barton’s review begins: “There is perhaps no other area in which chaos theory, nonlinear dynamics, and self-organizing systems are so intuitively appealing yet so analytically difficult as in clinical psychology.” Ayers also concludes that most applications in this field have been rather metaphorical.\nIn recent work, both the modelling and the empirical work have become more concrete (Schiepek and Perlitz 2009). In later chapters I will discuss the mathematical model of marriage (Gottman et al. 2002) and the network approach to psychopathology (Borsboom 2017; Cramer et al. 2010).\nThe network approach to psychological disorders suggests that psychological disorders arise from complex interactions among symptoms, rather than being caused by a single underlying factor. It views disorders as interconnected networks of symptoms, where each symptom influences and is influenced by other symptoms. This approach emphasizes the dynamic nature of psychological disorders and highlights the importance of understanding the relationships between symptoms in order to effectively diagnose and treat them. Network modeling is accompanied by a new family of statistical techniques (Epskamp, Borsboom, and Fried 2018). An introduction to these techniques is given in chapter 6.\n\n\n4.3.6 Social relations\nA key publication in this area is the book on Dynamical Systems in Social Psychology, edited by Vallacher and Nowak (1994). Concepts such as dissonance (Festinger 1962), balance (Heider 1946), and harmony (Smolensky 1986) reflect the idea that we optimize internal consistency when forming attitudes and knowledge. A formal implementation of these ideas was proposed using PDP-type connectionist models (e.g., Monroe and Read 2008). Our own model (Dalege and van der Maas 2020; Dalege et al. 2018, 2016) is based on the Ising model and the Boltzmann machine, as in Smolensky’s proposal, which can be fitted to data. I will explain this work in more detail in Chapter 6.\nA simple but famous example of social self-organization concerns pedestrian dynamics as studied by Helbing and Molnár (1995). They proposed a simple physics-based model for panic evacuation. For an excellent overview of crowd simulation, I again, refer to Wikipedia. Some of this work is rooted in the social sciences. An example in NetLogo is the model “Path”.\nFamous is the work of the sociologist Mark Granovetter (1973) on strong and weak ties in social networks (belonging to the best cited paper in the history of the social sciences). The idea is that weak ties in social networks are often more valuable than strong ties, as they provide access to new information and opportunities that may not be available within one’s close circle of friends and acquaintances.\nAnother of his contributions is the threshold model of collective behavior (Mark Granovetter 1978). I like to explain this work using the “Guy starts dance party” video on YouTube. The idea is that people have some threshold, between 0 and 1, to join the dancers. These thresholds have some distribution, a flexible one is the beta distribution. With this R-code we can simulate this effect:\n\nlayout(1:2)\nn &lt;- 1000 # number of persons\ninterations &lt;- 50\nthreshold &lt;- rbeta(n,1,2) # sample individual thresholds for dancing\nhist(threshold,col='grey')\ndancers &lt;- rep(0,n) # nobody dances\ndancers[1] &lt;- 1 # but one guy\nnumber_of_dancers &lt;- rep(0,interations) # keep track of number of dancers\nfor(i in 1:interations)\n{\n  number_of_dancers[i] &lt;- sum(dancers) # keep track of number of dancers\n  dancers[threshold&lt;(number_of_dancers[i]/n)] &lt;- 1 \n# if my threshold &lt; proportion of dancers, I dance\n}\nplot(number_of_dancers,xlab='time',ylab='#dancers',ylim=c(0,1000),type='b',bty='n')\n\nDepending on the parameters of the beta distribution you will see a phase transition to collective dancing. This basic setup can be extended in many ways.\nAnother classic contribution, explained in more detail in Chapter 7, is Schelling’s agent-based model of segregation (Schelling 1971). The idea is that even if individuals have only a small preference for in-group neighbors, segregated societies will form. For a broad overview of complex systems research on human cooperation, I refer to Perc et al. (2017).\n\n\n4.3.7 Collective Intelligence\nCollective intelligence research examines how groups can collectively outperform individual members in problem solving, decision making, and idea generation. One famous concept is the idea of the wisdom of crowds (Surowiecki 2005). A key example, often cited to illustrate the wisdom of the crowds, is the “Guess the Weight of the Ox” contest that took place at the West of England Fat Stock and Poultry Exhibition in 1906. While individual guesses varied widely, the average guess was remarkably close to the actual weight of the ox. The average guess was only one pound off the actual weight, which was 1,198 pounds.\nHowever, there is a fine line between the wisdom of the crowd and the stupidity of the crowd (Galesic et al. 2023). It is extremely useful to know when that line is crossed. The wisdom of crowds tends to work when there is a diverse group of independent individuals, each making their own judgments or estimates about a particular question or problem. It is more likely to be effective when the group is large, has a wide range of knowledge and perspectives, and the judgments are made independently, without undue influence from others (Brush, Krakauer, and Flack 2018; Centola 2022). There is an extensive and up-to-date Wikipedia on collective intelligence, discussing findings from various disciplines, the idea of a collective intelligence factor c, biological examples (swarm intelligence), and an overview of applications (such as open source software, crowdsourcing, the Delphi technique and Wikipedia itself).\n\n\n4.3.8 Game theory\nOf particular importance is game theory, which consists of mathematical models of strategic interactions among rational agents. A great historical overview can be found at Wikipedia. One of the most famous paradigms is the prisoner’s dilemma. You and your buddy are arrested, and you both independently talk to the police. The options are to remain silent or to tell. The dilemma is that remaining silent is the best option if you both choose it, but the worst option if your friend betrays you (see the payoff matrix). In this game, loyalty to one’s friend is irrational, an outcome related to the tragedy of the commons (Hardin 1968). The tragedy of the commons can be studied in the hubnet extension of NetLogo, where multiple users can participate in NetLogo simulations.\n\n\n\nFigure 4.7: The prisoner’s dilemma\n\n\nA major topic in game theory is altruism. In many cases, individualistic choices lead to an unsatisfactory (Nash) equilibrium. A Nash equilibrium is a set of strategies in which no player can improve their payoff by unilaterally changing their strategy, given the strategies of the other players. The public goods game is a good example. In this game, everyone invests some money, which is then multiplied by an external party (the government). Then everyone gets an equal share of the multiplied total. The problem is that free riders, who do not invest, win the most, which in iterated public good games leads to a situation where no one invests and no one wins. Punishment (shaming and blaming) is known to help combat free riding. But punishment also requires investment. I like to tell my students when they are working in groups on an assignment that the problem of this one student doing nothing happens because nice, hard-working students refuse to betray their fellow students to me. These nice, hard-working students are what are called second-order free riders (Fowler 2005).\n\n\n4.3.9 Self-organization in organizations\nTranslating this basic research into real-world applications is far from straightforward (Anderson 1999; Morel and Ramanujam 1999). Human organizations can be placed on a scale from extreme hierarchy to radical forms of self-organization (Volberda and Lewin 2003). Note also that our economic system is a mixture of self-organization (pure capitalism) and top-down regulation (through laws, taxes and other regulations). Black markets are critical cases of unregulated self-organized systems (Tesfatsion 2002).\nA concrete modeling example is the team assembly model by Guimerà et al. (2005). They study how the way creative teams self-assemble determine the structure of collaboration networks. The idea is that effective teams find a balance between being large enough to allow for specialization and efficient division of labor among members, while also being small enough to avoid excessive costs associated with coordinating group efforts. Agents in the model have only a few basic characteristics that influence their behavior: whether they are a newcomer or incumbent and what previous connections they have with other agents if they are incumbents.\nThree parameters that can be adjusted to influence behavior in the baseline assembly model: the team size, the probability of choosing an incumbent (\\(p\\)), and the probability of choosing a previous collaborator (\\(q\\)). The two probability parameters signify assumptions about agent motivations for team member selection. Low incumbent probability leads to preference for newcomers and new ideas, while high incumbent probability means a focus on experience. Low collaborator probability prioritizes experienced strangers, and high collaborator probability prioritizes previous collaborators. The model is part of the build in NetLogo models (“team assembly”). By simulating the model, it can be shown that the emergence of a large, connected community of practitioners can be described as a phase transition.\nGuimerà et al. (2005) estimated the parameters \\(p\\) and \\(q\\) for the community formation in four scientific disciplines (social psychology, economics, ecology, and astronomy). Only the field of astronomy had a very dense collaboration structure. In the other fields the estimates of \\(p\\) and \\(q\\) of teams publishing in certain journals correlated well with impact factor. Interestingly, \\(p\\) correlates positively and \\(q\\) negatively with impact.\n\n\n\nFigure 4.8: Team assembly model. Newcomers and incumbents are added to growing networks based on probabilities p and q. If p is sufficiently high, a dense network emerges."
  },
  {
    "objectID": "ch4.html#zooming-out",
    "href": "ch4.html#zooming-out",
    "title": "4  Self-organization",
    "section": "4.4 Zooming out",
    "text": "4.4 Zooming out\nI hope I have succeeded in giving an organized and practical overview of a very disorganized and interdisciplinary field of research. For each subfield, I have provided key references that should help you find recent and specialized contributions. I find the examples of self-organization in the natural sciences fascinating and inspiring. I hope I have also shown that applications of this concept in psychology and the social sciences hold great promise. In the next chapters, I will present more concrete examples.\nI believe that understanding models requires working with models, for example through simulation. NetLogo is a great tool for this, although there are many alternatives available (Abar et al. 2017). I haven’t mentioned all the uses of NetLogo, but it’s good to know about the BehaviorSpace option. BehaviorSpace runs models repeatedly and in parallel (without visualization), systematically varying model settings and parameters, and recording the results of each model run. These results can then be further analyzed in R. An example will be provided in chapter 7."
  },
  {
    "objectID": "ch4.html#exercises",
    "href": "ch4.html#exercises",
    "title": "4  Self-organization",
    "section": "4.5 Exercises",
    "text": "4.5 Exercises\n\nWhat does the rice cooker have to do with the Ising model?\nWhat is the Boltzmann entropy for the state \\(\\sum_{}^{}x = 0\\) in an Ising model (with nodes states -1 and 1) with 10 nodes and no external field? (*).\nGo to the webpage ‘A Neural Network Playground’. What is the minimal network to solve the XOR with 100% success? Use only the x1 and x2 feature. (*)\nIn the Granovetter model (Section 4.3.7), people may also stop dancing (with probability .1). Add this to the model. What changes? (*)\nAdd the external field to the Ising model in NetLogo (neighbors4 case). Report the changed line in the NetLogo code. What did you change in the interface?\nSet the temperature to 1.5. Change tau slowly. At which values of tau do the hysteresis jumps occur? (*)\nTest whether the Ising model is indeed a cusp. Run the Ising model in NetLogo using the BehaviorSpace tool. Use the model in which all spins are connected to all spins (see Section 4.2.2.2). Vary tau (-.3 to .3 in .05 increments) and temperature (0 to 3, in .5 increments). One iteration per combination of parameter values is sufficient. Stop after 10000 ticks and collect only the final magnetization. Import the data into R and fit the cusp. Which cusp model best describes the data? (**)\nOpen the Sandpile 3D model in NetLogo3D. Grains of sand fall at random place. Change one line of code such that they all fall in the middle. What did you change? (*)\nDownload ‘Motion Quartet’ from the NetLogo community website and explore hysteresis in your own perception. What could be a splitting variable? (*)\nImplement the Granovetter model in NetLogo (max 40 lines of code) (**)\n\n\n\n\n\nAbar, Sameera, Georgios K. Theodoropoulos, Pierre Lemarinier, and Gregory M. P. O’Hare. 2017. “Agent Based Modelling and Simulation Tools: A Review of the State-of-Art Software.” Computer Science Review 24 (May): 13–33. https://doi.org/10.1016/j.cosrev.2017.03.001.\n\n\nAbe, Yayoi, Muneyuki Ishida, Erika Nozawa, Takayoshi Ootsuka, and Ryoko Yahagi. 2017. “Cusp Singularity in Mean Field Ising Model.” European Journal of Physics 38 (6): 065102. https://doi.org/10.1088/1361-6404/aa82fc.\n\n\nAcebrón, Juan A., L. L. Bonilla, Conrad J. Pérez Vicente, Félix Ritort, and Renato Spigler. 2005. “The Kuramoto Model: A Simple Paradigm for Synchronization Phenomena.” Reviews of Modern Physics 77 (1): 137–85. https://doi.org/10.1103/RevModPhys.77.137.\n\n\nAlderisio, Francesco, Benoît G. Bardy, and Mario di Bernardo. 2016. “Entrainment and Synchronization in Networks of Rayleighvan Der Pol Oscillators with Diffusive and Haken Couplings.” Biological Cybernetics 110 (2): 151–69. https://doi.org/10.1007/s00422-016-0685-7.\n\n\nAnderson, Philip. 1999. “Perspective: Complexity Theory and Organization Science.” Organization Science 10 (3): 216–32. https://doi.org/10.1287/orsc.10.3.216.\n\n\nAshby, W. R. 1956. “An Introduction to Cybernetics.” An Introduction to Cybernetics.\n\n\nAyers, Susan. 1997. “The Application of Chaos Theory to Psychology.” Theory & Psychology 7 (June): 373. https://doi.org/10.1177/0959354397073005.\n\n\nBak, Per, Chao Tang, and Kurt Wiesenfeld. 1988. “Self-Organized Criticality.” Physical Review A 38 (1): 364–74. https://doi.org/10.1103/PhysRevA.38.364.\n\n\nBarton, Scott. 1994. “Chaos, Self-Organization, and Psychology.” American Psychologist. https://doi.org/10.1037/0003-066X.49.1.5.\n\n\nBédard, C., H. Kröger, and A. Destexhe. 2006. “Does the $1/f$ Frequency Scaling of Brain Signals Reflect Self-Organized Critical States?” Physical Review Letters 97 (11): 118102. https://doi.org/10.1103/PhysRevLett.97.118102.\n\n\nBeek, P. J, C. E Peper, and A Daffertshofer. 2002. “Modeling Rhythmic Interlimb Coordination: Beyond the Haken.” Brain and Cognition 48 (1): 149–65. https://doi.org/10.1006/brcg.2001.1310.\n\n\nBeek, Peter J., and Arthur Lewbel. 1995. “The Science of Juggling.” Scientific American 273 (5): 92–97. https://doi.org/10.1038/scientificamerican1195-92.\n\n\nBerlekamp, Elwyn R., John H. Conway, and Richard K. Guy. 2004. Winning Ways for Your Mathematical Plays, Volume 4. 2nd ed. New York: A K Peters/CRC Press. https://doi.org/10.1201/9780429487309.\n\n\nBoerlijst, M. C., and P. Hogeweg. 1991. “Spiral Wave Structure in Pre-Biotic Evolution: Hypercycles Stable Against Parasites.” Physica D: Nonlinear Phenomena 48 (1): 17–28. https://doi.org/10.1016/0167-2789(91)90049-F.\n\n\nBorsboom, Denny. 2017. “A Network Theory of Mental Disorders.” World Psychiatry 16 (1): 5–13. https://doi.org/10.1002/wps.20375.\n\n\nBreakspear, Michael. 2017. “Dynamic Models of Large-Scale Brain Activity.” Nature Neuroscience 20 (3): 340–52. https://doi.org/10.1038/nn.4497.\n\n\nBrinkhuis, Matthieu J. S., Alexander O. Savi, Abe D. Hofman, Frederik Coomans, Han L. J. van der Maas, and Gunter Maris. 2018. “Learning As It Happens: A Decade of Analyzing and Shaping a Large-Scale Online Learning System.” Journal of Learning Analytics 5 (2): 29–46. https://doi.org/10.18608/jla.2018.52.3.\n\n\nBrush, Eleanor R., David C. Krakauer, and Jessica C. Flack. 2018. “Conflicts of Interest Improve Collective Computation of Adaptive Social Structures.” Science Advances 4 (1): e1603311. https://doi.org/10.1126/sciadv.1603311.\n\n\nCentola, Damon. 2022. “The Network Science of Collective Intelligence.” Trends in Cognitive Sciences 26 (11): 923–41. https://doi.org/10.1016/j.tics.2022.08.009.\n\n\nChialvo, Dante R. 2010. “Emergent Complex Neural Dynamics.” Nature Physics 6 (10): 744–50. https://doi.org/10.1038/nphys1803.\n\n\nClark, Andy. 2013. “Whatever Next? Predictive Brains, Situated Agents, and the Future of Cognitive Science.” Behavioral and Brain Sciences 36 (3): 181–204. https://doi.org/10.1017/S0140525X12000477.\n\n\nCocchi, Luca, Leonardo L. Gollo, Andrew Zalesky, and Michael Breakspear. 2017. “Criticality in the Brain: A Synthesis of Neurobiology, Models and Cognition.” Progress in Neurobiology 158 (November): 132–52. https://doi.org/10.1016/j.pneurobio.2017.07.002.\n\n\nCramer, Angélique O. J., Lourens J. Waldorp, Han L. J. van der Maas, and Denny Borsboom. 2010. “Comorbidity: A Network Perspective.” The Behavioral and Brain Sciences 33 (2-3): 137-150; discussion 150-193. https://doi.org/10.1017/S0140525X09991567.\n\n\nDalege, Jonas, Denny Borsboom, Frenk van Harreveld, Helma van den Berg, Mark Conner, and Han L. J. van der Maas. 2016. “Toward a Formalized Account of Attitudes: The Causal Attitude Network (CAN) Model.” Psychological Review 123 (1): 2–22. https://doi.org/10.1037/a0039802.\n\n\nDalege, Jonas, Denny Borsboom, Frenk van Harreveld, and Han L. J. van der Maas. 2018. “The Attitudinal Entropy (AE) Framework as a General Theory of Individual Attitudes.” Psychological Inquiry 29 (4): 175–93. https://doi.org/10.1080/1047840X.2018.1537246.\n\n\nDalege, Jonas, and Han L. J. van der Maas. 2020. “Accurate by Being Noisy: A Formal Network Model of Implicit Measures of Attitudes.” Social Cognition 38 (Suppl): S26–41. https://doi.org/10.1521/soco.2020.38.supp.s26.\n\n\nDresp-Langley, Birgitta. 2020. “Seven Properties of Self-Organization in the Human Brain.” Big Data and Cognitive Computing 2 (4): 10.\n\n\nEdelman, Gerald M. 1987. Neural Darwinism: The Theory of Neuronal Group Selection. Neural Darwinism: The Theory of Neuronal Group Selection. New York, NY, US: Basic Books.\n\n\nEigen, Manfred, and Peter Schuster. 1979. The Hypercycle. Berlin, Heidelberg: Springer. https://doi.org/10.1007/978-3-642-67247-7.\n\n\nEldredge, Niles, and Stephen Jay Gould. 1972. “Punctuated Equilibria: An Alternative to Phyletic Gradualism.” In Models in Paleobiology, edited by Thomas J. M. Schopf, 82–115. Freeman Cooper.\n\n\nElo, Arpad E. 1978. The Rating of Chessplayers, Past and Present. New York: Arco Pub.\n\n\nEpskamp, Sacha, Denny Borsboom, and Eiko I. Fried. 2018. “Estimating Psychological Networks and Their Accuracy: A Tutorial Paper.” Behavior Research Methods 50 (1): 195–212. https://doi.org/10.3758/s13428-017-0862-1.\n\n\nFestinger, Leon. 1962. A Theory of Cognitive Dissonance. A Theory of Cognitive Dissonance. Palo Alto, CA, US: Stanford Univer. Press.\n\n\nFowler, James H. 2005. “Second-Order Free-Riding Problem Solved?” Nature 437 (7058): E8–8. https://doi.org/10.1038/nature04201.\n\n\nFriston, Karl. 2009. “The Free-Energy Principle: A Rough Guide to the Brain?” Trends in Cognitive Sciences 13 (7): 293–301. https://doi.org/10.1016/j.tics.2009.04.005.\n\n\nFuchs, Armin, and Scott Kelso. 2018. “Coordination Dynamics and Synergetics: From Finger Movements to Brain Patterns and Ballet Dancing.” In Complexity and Synergetics, 301–16. https://doi.org/10.1007/978-3-319-64334-2_23.\n\n\nGalesic, Mirta, Daniel Barkoczi, Andrew M. Berdahl, Dora Biro, Giuseppe Carbone, Ilaria Giannoccaro, Robert L. Goldstone, et al. 2023. “Beyond Collective Intelligence: Collective Adaptation.” Journal of The Royal Society Interface 20 (200): 20220736. https://doi.org/10.1098/rsif.2022.0736.\n\n\nGhatak, Abhijit. 2019. Deep Learning with R. Singapore: Springer. https://doi.org/10.1007/978-981-13-5850-0.\n\n\nGibson, James J. 2014. The Ecological Approach to Visual Perception: Classic Edition. New York: Psychology Press. https://doi.org/10.4324/9781315740218.\n\n\nGottman, John M., James D. Murray, Catherine C. Swanson, Rebecca Tyson, and Kristin R. Swanson. 2002. The Mathematics of Marriage: Dynamic Nonlinear Models. The Mathematics of Marriage: Dynamic Nonlinear Models. Cambridge, MA, US: MIT Press.\n\n\nGranovetter, M. 1973. “The Strength of Weak Ties.” American Journal of Sociology 78 (6): 1360–80. https://doi.org/10.1086/225469.\n\n\nGranovetter, Mark. 1978. “Threshold Models of Collective Behavior.” The American Journal of Sociology 83 (6): 1420–43. https://doi.org/10.1086/226707.\n\n\nGrossberg, Stephen, and Baingio Pinna. 2012. “Neural Dynamics of Gestalt Principles of Perceptual Organization: From Grouping to Shape and Meaning.” GESTALT THEORY 34.\n\n\nGuimerà, Roger, Brian Uzzi, Jarrett Spiro, and Luís A. Nunes Amaral. 2005. “Team Assembly Mechanisms Determine Collaboration Network Structure and Team Performance.” Science 308 (5722): 697–702. https://doi.org/10.1126/science.1106340.\n\n\nHaken, Herman. 1977. “Synergetics.” Physics Bulletin 28 (9): 412. https://doi.org/10.1088/0031-9112/28/9/027.\n\n\nHaken, Hermann. 1992. “Synergetics in Psychology.” In Self-Organization and Clinical Psychology: Empirical Approaches to Synergetics in Psychology, edited by Wolfgang Tschacher, Günter Schiepek, and Ewald Johannes Brunner, 32–54. Springer Series in Synergetics. Berlin, Heidelberg: Springer. https://doi.org/10.1007/978-3-642-77534-5_2.\n\n\nHaken, H., J. A. S. Kelso, and H. Bunz. 1985. “A Theoretical Model of Phase Transitions in Human Hand Movements.” Biological Cybernetics 51 (5): 347–56. https://doi.org/10.1007/BF00336922.\n\n\nHardin, Garrett. 1968. “The Tragedy of the Commons” 162.\n\n\nHebb, D. O. 1949. The Organization of Behavior; a Neuropsychological Theory. The Organization of Behavior; a Neuropsychological Theory. Oxford, England: Wiley.\n\n\nHeider, Fritz. 1946. “Attitudes and Cognitive Organization.” The Journal of Psychology 21 (1): 107–12. https://doi.org/10.1080/00223980.1946.9917275.\n\n\nHelbing, Dirk, and Péter Molnár. 1995. “Social Force Model for Pedestrian Dynamics.” Physical Review E 51 (5): 4282–86. https://doi.org/10.1103/PhysRevE.51.4282.\n\n\nHendrikse, Sophie, Jan Treur, and Sander Koole. 2023. “Modeling Emerging Interpersonal Synchrony and Its Related Adaptive Short-Term Affiliation and Long-Term Bonding: A Second-Order Multi-Adaptive Neural Agent Model.” International Journal of Neural Systems, April. https://doi.org/10.1142/S0129065723500387.\n\n\nHolland, John H. 1992a. “Genetic Algorithms.” Scientific American 267 (1): 66–73. https://doi.org/10.1038/scientificamerican0792-66.\n\n\n———. 1992b. Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence. MIT Press.\n\n\nJacobson, Michael J., James A. Levin, and Manu Kapur. 2019. “Education as a Complex System: Conceptual and Methodological Implications.” Educational Researcher 48 (2): 112–19. https://doi.org/10.3102/0013189X19826958.\n\n\nKalantari, Somayeh, Eslam Nazemi, and Behrooz Masoumi. 2020. “Emergence Phenomena in Self-Organizing Systems: A Systematic Literature Review of Concepts, Researches, and Future Prospects.” Journal of Organizational Computing and Electronic Commerce 30 (3): 224–65. https://doi.org/10.1080/10919392.2020.1748977.\n\n\nKauffman, Stuart A. 1993. The Origins of Order: Self-Organization and Selection in Evolution. 1st edition. New York: Oxford University Press.\n\n\nKelso, J. A. S. 1995. Dynamic Patterns: The Self-Organization of Brain and Behavior. Dynamic Patterns: The Self-Organization of Brain and Behavior. Cambridge, MA, US: The MIT Press.\n\n\n———. 2021. “The Haken (HKB) Model: From Matter to Movement to Mind.” Biological Cybernetics 115 (4): 305–22. https://doi.org/10.1007/s00422-021-00890-w.\n\n\nKelso, J. A. S., J. P. Scholz, and G. Schöner. 1986. “Nonequilibrium Phase Transitions in Coordinated Biological Motion: Critical Fluctuations.” Physics Letters A 118 (6): 279–84. https://doi.org/10.1016/0375-9601(86)90359-2.\n\n\nKlinkenberg, S., M Straatemeier, and H. van der Maas. 2011. “Computer Adaptive Practice of Maths Ability Using a New Item Response Model for on the Fly Ability and Difficulty Estimation.” Computers & Education 57: 1813–24.\n\n\nKruse, Peter, and Michael Stadler. 2012. Ambiguity in Mind and Nature: Multistable Cognitive Phenomena. Springer Science & Business Media.\n\n\nLangton, Chris G. 1990. “Computation at the Edge of Chaos: Phase Transitions and Emergent Computation.” Physica D: Nonlinear Phenomena 42 (1): 12–37. https://doi.org/10.1016/0167-2789(90)90064-V.\n\n\nLemke, Jay L., and Nora H. Sabelli. 2008. “Complex Systems and Educational Change: Towards a New Research Agenda.” In Complexity Theory and the Philosophy of Education, 112–23. John Wiley & Sons, Ltd. https://doi.org/10.1002/9781444307351.ch8.\n\n\nLurie, Daniel J., Daniel Kessler, Danielle S. Bassett, Richard F. Betzel, Michael Breakspear, Shella Kheilholz, Aaron Kucyi, et al. 2020. “Questions and Controversies in the Study of Time-Varying Functional Connectivity in Resting fMRI.” Network Neuroscience 4 (1): 30–69. https://doi.org/10.1162/netn_a_00116.\n\n\nMaris, Gunter, and Han van der Maas. 2012. “Speed-Accuracy Response Models: Scoring Rules Based on Response Time and Accuracy.” Psychometrika 77 (4): 615–33. https://doi.org/10.1007/s11336-012-9288-y.\n\n\nMcGeer, T. 1990. “Passive Walking with Knees.” In, IEEE International Conference on Robotics and Automation Proceedings, 1640–1645 vol.3. https://doi.org/10.1109/ROBOT.1990.126245.\n\n\nMcGrath, Thomas, Andrei Kapishnikov, Nenad Tomašev, Adam Pearce, Martin Wattenberg, Demis Hassabis, Been Kim, Ulrich Paquet, and Vladimir Kramnik. 2022. “Acquisition of Chess Knowledge in AlphaZero.” Proceedings of the National Academy of Sciences 119 (47): e2206625119. https://doi.org/10.1073/pnas.2206625119.\n\n\nMitchell, Melanie. 1998. An Introduction to Genetic Algorithms. MIT Press.\n\n\nMonroe, Brian M., and Stephen J. Read. 2008. “A General Connectionist Model of Attitude Structure and Change: The ACS (Attitudes as Constraint Satisfaction) Model.” Psychological Review 115: 733–59. https://doi.org/10.1037/0033-295X.115.3.733.\n\n\nMorel, Benoit, and Rangaraj Ramanujam. 1999. “Through the Looking Glass of Complexity: The Dynamics of Organizations as Adaptive and Evolving Systems.” Organization Science 10 (3): 278–93. https://doi.org/10.1287/orsc.10.3.278.\n\n\nO’Byrne, Jordan, and Karim Jerbi. 2022. “How Critical Is Brain Criticality?” Trends in Neurosciences 45 (11): 820–37. https://doi.org/10.1016/j.tins.2022.08.007.\n\n\nOlthof, Merlijn, Fred Hasselman, Freek Oude Maatman, Anna M. T. Bosman, and Anna Lichtwarck-Aschoff. 2023. “Complexity Theory of Psychopathology.” Journal of Psychopathology and Clinical Science 132: 314–23. https://doi.org/10.1037/abn0000740.\n\n\nOoyen, Arjen van, and Markus Butz-Ostendorf. 2017. The Rewiring Brain: A Computational Approach to Structural Plasticity in the Adult Brain. Academic Press.\n\n\nPavlus, John. 2016. “The Clumsy Quest to Perfect the Walking Robot.” Scientific American. https://www.scientificamerican.com/article/the-clumsy-quest-to-perfect-the-walking-robot/. https://doi.org/10.1038/scientificamerican0716-60.\n\n\nPerc, Matjaž, Jillian J. Jordan, David G. Rand, Zhen Wang, Stefano Boccaletti, and Attila Szolnoki. 2017. “Statistical Physics of Human Cooperation.” Physics Reports, Statistical physics of human cooperation, 687 (May): 1–51. https://doi.org/10.1016/j.physrep.2017.05.004.\n\n\nPiaget, Jean. 1952. The Origins of Intelligence in Children. Edited by Margaret Cook. The Origins of Intelligence in Children. New York, NY, US: W W Norton & Co. https://doi.org/10.1037/11494-000.\n\n\nPlenz, Dietmar, Tiago L. Ribeiro, Stephanie R. Miller, Patrick A. Kells, Ali Vakili, and Elliott L. Capek. 2021. “Self-Organized Criticality in the Brain.” Frontiers in Physics 9. https://doi.org/10.3389/fphy.2021.639389.\n\n\nPoston, Tim, and Ian Stewart. 2014. Catastrophe Theory and Its Applications. Courier Corporation.\n\n\nReher, Jenna, and Aaron D. Ames. 2021. “Dynamic Walking: Toward Agile and Efficient Bipedal Robots.” Annual Review of Control, Robotics, and Autonomous Systems 4 (1): 535–72. https://doi.org/10.1146/annurev-control-071020-045021.\n\n\nRendell, Paul. 2016. “Game of Life Universal Turing Machine.” In Turing Machine Universality of the Game of Life, edited by Paul Rendell, 71–89. Emergence, Complexity and Computation. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-19842-2_5.\n\n\nRepp, Bruno H., and Yi-Huang Su. 2013. “Sensorimotor Synchronization: A Review of Recent Research (2006).” Psychonomic Bulletin & Review 20 (3): 403–52. https://doi.org/10.3758/s13423-012-0371-2.\n\n\nSavi, Alexander O., Maarten Marsman, Han L. J. van der Maas, and Gunter K. J. Maris. 2019. “The Wiring of Intelligence.” Perspectives on Psychological Science 14 (6): 1034–61. https://doi.org/10.1177/1745691619866447.\n\n\nSchelling, Thomas C. 1971. “Dynamic Models of Segregation.” The Journal of Mathematical Sociology 1 (2): 143–86. https://doi.org/10.1080/0022250X.1971.9989794.\n\n\nSchiepek, Günter, and Volker Perlitz. 2009. “Self-Organization in Clinical Psychology.” In Synergetics, edited by Axel Hutt and Haken, 263–85. New York, NY: Springer US. https://doi.org/10.1007/978-1-0716-0421-2_472.\n\n\nSchmidhuber, Jürgen. 2015. “Deep Learning in Neural Networks: An Overview.” Neural Networks 61 (January): 85–117. https://doi.org/10.1016/j.neunet.2014.09.003.\n\n\nSchmidt, R. C., C. Carello, and M. T. Turvey. 1990. “Phase Transitions and Critical Fluctuations in the Visual Coordination of Rhythmic Movements Between People.” Journal of Experimental Psychology. Human Perception and Performance 16 (2): 227–47. https://doi.org/10.1037//0096-1523.16.2.227.\n\n\nSchöner, Gregor, and John P. Spencer. 2016. Dynamic Thinking: A Primer on Dynamic Field Theory. Oxford University Press.\n\n\nSilver, David, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, et al. 2018. “A General Reinforcement Learning Algorithm That Masters Chess, Shogi, and Go Through Self-Play.” Science 362 (6419): 1140–44. https://doi.org/10.1126/science.aar6404.\n\n\nSkarda, Christine A., and Walter J. Freeman. 1987. “How Brains Make Chaos in Order to Make Sense of the World.” Behavioral and Brain Sciences 10 (2): 161–73. https://doi.org/10.1017/S0140525X00047336.\n\n\nSmolensky, Paul. 1986. “Information Processing in Dynamical Systems: Foundations of Harmony Theory.”\n\n\nStengers, Isabelle, and Ilya Prigogine. 1978. Order Out of Chaos: Man’s New Dialogue with Nature. London.\n\n\nSurowiecki, James. 2005. The Wisdom of Crowds. Knopf Doubleday Publishing Group.\n\n\nSutton, Richard S., and Andrew G. Barto. 2018. Reinforcement Learning, Second Edition: An Introduction. MIT Press.\n\n\nTesfatsion, Leigh. 2002. “Agent-Based Computational Economics: Growing Economies From the Bottom Up.” Artificial Life 8 (1): 55–82. https://doi.org/10.1162/106454602753694765.\n\n\nThelen, Esther. 1995. “Motor Development: A New Synthesis.” American Psychologist 50: 79–95. https://doi.org/10.1037/0003-066X.50.2.79.\n\n\nThelen, Esther, and Linda B. Smith. 1994. A Dynamic Systems Approach to the Development of Cognition and Action. MIT Press.\n\n\nVallacher, Robin R., and Andrzej Nowak, eds. 1994. Dynamical Systems in Social Psychology. Dynamical Systems in Social Psychology. San Diego, CA, US: Academic Press.\n\n\nvan der Maas, H. L. J. 1995. “Beyond the Metaphor?” Cognitive Development 10.\n\n\nVan Der Maas, Han L. J., Conor V. Dolan, Raoul P. P. P. Grasman, Jelte M. Wicherts, Hilde M. Huizenga, and Maartje E. J. Raijmakers. 2006. “A Dynamical Model of General Intelligence: The Positive Manifold of Intelligence by Mutualism.” Psychological Review 113 (4): 842–61. https://doi.org/c3jm44.\n\n\nvan der Maas, Han L. J., Lukas Snoek, and Claire E. Stevenson. 2021. “How Much Intelligence Is There in Artificial Intelligence? A 2020 Update.” Intelligence 87 (July): 101548. https://doi.org/10.1016/j.intell.2021.101548.\n\n\nVan der Maas, Han L., and Peter C. Molenaar. 1992. “Stagewise Cognitive Development: An Application of Catastrophe Theory.” Psychological Review 99 (3): 395–417. https://doi.org/10.1037/0033-295X.99.3.395.\n\n\nVolberda, Henk W., and Arie Y. Lewin. 2003. “Co-Evolutionary Dynamics Within and Between Firms: From Evolution to Co-evolution.” Journal of Management Studies 40 (8): 2111–36. https://doi.org/10.1046/j.1467-6486.2003.00414.x.\n\n\nWagemans, Johan, James H. Elder, Michael Kubovy, Stephen E. Palmer, Mary A. Peterson, Manish Singh, and Rüdiger von der Heydt. 2012. “A Century of Gestalt Psychology in Visual Perception: I. Perceptual Grouping and Figureground Organization.” Psychological Bulletin 138: 1172–1217. https://doi.org/10.1037/a0029333.\n\n\nWiener, Norbert. 2019. Cybernetics or Control and Communication in the Animal and the Machine, Reissue of the 1961 Second Edition. MIT Press.\n\n\nWilensky, Uri, and William Rand. 2015. An Introduction to Agent-Based Modeling: Modeling Natural, Social, and Engineered Complex Systems with NetLogo. Cambridge, Massachusetts: The MIT Press.\n\n\nXue, Jiankai, and Bo Shen. 2020. “A Novel Swarm Intelligence Optimization Approach: Sparrow Search Algorithm.” Systems Science & Control Engineering 8 (1): 22–34. https://doi.org/10.1080/21642583.2019.1708830."
  },
  {
    "objectID": "ch4.html#footnotes",
    "href": "ch4.html#footnotes",
    "title": "4  Self-organization",
    "section": "",
    "text": "An extremely useful application of this principle is the rice cooker!↩︎\nIn a synchronous update, all cells of the cellular automata update their state simultaneously. This implies that the new state of each cell at a given time step depends only on the states of its neighbors at the previous time step. In asynchronous update, cells update their state one at a time, rather than all at once. The order in which cells update can be deterministic (in a sequence), or it can be stochastic (random). These two different update schemes can lead to very different behaviors in cellular automata.↩︎"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Abar, Sameera, Georgios K. Theodoropoulos, Pierre Lemarinier, and\nGregory M. P. O’Hare. 2017. “Agent Based Modelling\nand Simulation Tools: A Review of the\nState-of-Art Software.” Computer Science Review 24\n(May): 13–33. https://doi.org/10.1016/j.cosrev.2017.03.001.\n\n\nAbe, Yayoi, Muneyuki Ishida, Erika Nozawa, Takayoshi Ootsuka, and Ryoko\nYahagi. 2017. “Cusp Singularity in Mean Field Ising\nModel.” European Journal of Physics 38 (6): 065102. https://doi.org/10.1088/1361-6404/aa82fc.\n\n\nAcebrón, Juan A., L. L. Bonilla, Conrad J. Pérez Vicente, Félix Ritort,\nand Renato Spigler. 2005. “The Kuramoto Model:\nA Simple Paradigm for Synchronization Phenomena.”\nReviews of Modern Physics 77 (1): 137–85. https://doi.org/10.1103/RevModPhys.77.137.\n\n\nAlderisio, Francesco, Benoît G. Bardy, and Mario di Bernardo. 2016.\n“Entrainment and Synchronization in Networks of\nRayleighvan Der Pol Oscillators with Diffusive\nand Haken Couplings.” Biological\nCybernetics 110 (2): 151–69. https://doi.org/10.1007/s00422-016-0685-7.\n\n\nAlexander, Ralph A., Glenn R. Herbert, Richard P. DeShon, and Paul J.\nHanges. 1992. “An Examination of Least-Squares Regression Modeling\nof Catastrophe Theory.” Psychological Bulletin 111:\n366–74. https://doi.org/10.1037/0033-2909.111.2.366.\n\n\nAnderson, P. W. 1972. “More Is Different.”\nScience 177 (4047): 393–96. https://doi.org/10.1126/science.177.4047.393.\n\n\nAnderson, Philip. 1999. “Perspective: Complexity\nTheory and Organization Science.”\nOrganization Science 10 (3): 216–32. https://doi.org/10.1287/orsc.10.3.216.\n\n\nArnaud, M. 2021. “Mixture Modelling from Scratch, in\nR.” Medium.\nhttps://towardsdatascience.com/mixture-modelling-from-scratch-in-r-5ab7bfc83eef.\n\n\nAshby, W. R. 1956. “An Introduction to Cybernetics.” An\nIntroduction to Cybernetics.\n\n\nAttwell, David, and Costantino Iadecola. 2002. “The Neural Basis\nof Functional Brain Imaging Signals.” Trends in\nNeurosciences 25 (12): 621–25. https://doi.org/10.1016/S0166-2236(02)02264-6.\n\n\nAyers, Susan. 1997. “The Application of Chaos\nTheory to Psychology.” Theory &\nPsychology 7 (June): 373. https://doi.org/10.1177/0959354397073005.\n\n\nBak, Per, Chao Tang, and Kurt Wiesenfeld. 1988. “Self-Organized\nCriticality.” Physical Review A 38 (1): 364–74. https://doi.org/10.1103/PhysRevA.38.364.\n\n\nBanks, J., J. Brooks, G. Cairns, G. Davis, and P. Stacey. 1992.\n“On Devaney’s Definition of\nChaos.” The American Mathematical Monthly\n99 (4): 332–34. https://doi.org/10.1080/00029890.1992.11995856.\n\n\nBarceló, Jaume, ed. 2010. Fundamentals of Traffic\nSimulation. Vol. 145. International Series in\nOperations Research & Management Science.\nNew York, NY: Springer New York. https://doi.org/10.1007/978-1-4419-6142-6.\n\n\nBarton, Scott. 1994. “Chaos, Self-Organization, and\nPsychology.” American Psychologist. https://doi.org/10.1037/0003-066X.49.1.5.\n\n\nBechtel, William, and Adele Abrahamsen. 2005. “Explanation: A\nMechanist Alternative.” Studies in History and Philosophy of\nScience Part C: Studies in History and Philosophy of Biological and\nBiomedical Sciences, Mechanisms in biology, 36 (2): 421–41. https://doi.org/10.1016/j.shpsc.2005.03.010.\n\n\nBédard, C., H. Kröger, and A. Destexhe. 2006. “Does the $1/f$\nFrequency Scaling of Brain Signals Reflect\nSelf-Organized Critical States?” Physical Review\nLetters 97 (11): 118102. https://doi.org/10.1103/PhysRevLett.97.118102.\n\n\nBeek, P. J, C. E Peper, and A Daffertshofer. 2002. “Modeling\nRhythmic Interlimb Coordination: Beyond the\nHaken.” Brain and Cognition 48 (1): 149–65.\nhttps://doi.org/10.1006/brcg.2001.1310.\n\n\nBeek, Peter J., and Arthur Lewbel. 1995. “The Science\nof Juggling.” Scientific American 273 (5):\n92–97. https://doi.org/10.1038/scientificamerican1195-92.\n\n\nBentler, P. M. 1970. “Evidence Regarding Stages in\nthe Development of Conservation.”\nPerceptual and Motor Skills 31 (3): 855–59. https://doi.org/10.2466/pms.1970.31.3.855.\n\n\nBerlekamp, Elwyn R., John H. Conway, and Richard K. Guy. 2004.\nWinning Ways for Your Mathematical Plays,\nVolume 4. 2nd ed. New York: A K\nPeters/CRC Press. https://doi.org/10.1201/9780429487309.\n\n\nBertalanffy, Ludwig Von. 1969. General System Theory:\nFoundations, Development,\nApplications. Revised edition. New York,\nNY: George Braziller Inc.\n\n\nBertschinger, Nils, and Thomas Natschläger. 2004. “Real-Time\nComputation at the Edge of Chaos in\nRecurrent Neural Networks.” Neural\nComputation 16 (7): 1413–36. https://doi.org/10.1162/089976604323057443.\n\n\nBoerlijst, M. C., and P. Hogeweg. 1991. “Spiral Wave Structure in\nPre-Biotic Evolution: Hypercycles Stable Against\nParasites.” Physica D: Nonlinear Phenomena 48 (1):\n17–28. https://doi.org/10.1016/0167-2789(91)90049-F.\n\n\nBorsboom, Denny. 2017. “A Network Theory of Mental\nDisorders.” World Psychiatry 16 (1): 5–13. https://doi.org/10.1002/wps.20375.\n\n\nBorsboom, Denny, Han L J van der Maas, Jonas Dalege, Rogier A Kievit,\nand Brian D Haig. 2021. “Theory Construction\nMethodology: A Practical Framework for\nBuilding Theories in Psychology.”\nPerspectives on Psychological Science 16 (4): 756–66. https://doi.org/10.1177/1745691620969647.\n\n\nBorsboom, D., M. Rhemtulla, A. O. J. Cramer, H. L. J. van der Maas, M.\nScheffer, and C. V. Dolan. 2016. “Kinds\nVersus Continua: A Review of Psychometric\nApproaches to Uncover the Structure of Psychiatric Constructs.”\nPsychological Medicine 46 (8): 1567–79. https://doi.org/10.1017/S0033291715001944.\n\n\nBreakspear, Michael. 2017. “Dynamic Models of Large-Scale Brain\nActivity.” Nature Neuroscience 20 (3): 340–52. https://doi.org/10.1038/nn.4497.\n\n\nBrinkhuis, Matthieu J. S., Alexander O. Savi, Abe D. Hofman, Frederik\nCoomans, Han L. J. van der Maas, and Gunter Maris. 2018. “Learning\nAs It Happens: A Decade of\nAnalyzing and Shaping a Large-Scale\nOnline Learning System.” Journal of Learning\nAnalytics 5 (2): 29–46. https://doi.org/10.18608/jla.2018.52.3.\n\n\nBrush, Eleanor R., David C. Krakauer, and Jessica C. Flack. 2018.\n“Conflicts of Interest Improve Collective Computation of Adaptive\nSocial Structures.” Science Advances 4 (1): e1603311. https://doi.org/10.1126/sciadv.1603311.\n\n\nBurg, Gerrit J. J. van den, and Christopher K. I. Williams. 2022.\n“An Evaluation of Change Point Detection\nAlgorithms.” arXiv. https://doi.org/10.48550/arXiv.2003.06222.\n\n\nCastellano, Claudio, Miguel A. Muñoz, and Romualdo Pastor-Satorras.\n2009. “Nonlinear $q$-Voter Model.” Physical Review\nE 80 (4): 041129. https://doi.org/10.1103/PhysRevE.80.041129.\n\n\nCentola, Damon. 2022. “The Network Science of Collective\nIntelligence.” Trends in Cognitive Sciences 26 (11):\n923–41. https://doi.org/10.1016/j.tics.2022.08.009.\n\n\nChalmers, David J. 2006. “Strong and Weak Emergence.”\nhttps://philpapers.org/rec/chasaw.\n\n\nChialvo, Dante R. 2010. “Emergent Complex Neural Dynamics.”\nNature Physics 6 (10): 744–50. https://doi.org/10.1038/nphys1803.\n\n\nClark, Andy. 2013. “Whatever Next? Predictive Brains,\nSituated Agents, and the Future of Cognitive Science.”\nBehavioral and Brain Sciences 36 (3): 181–204. https://doi.org/10.1017/S0140525X12000477.\n\n\nCobb, Loren. 1978. “Stochastic Catastrophe Models and Multimodal\nDistributions.” Behavioral Science 23 (4): 360–74. https://doi.org/10.1002/bs.3830230407.\n\n\nCobb, Loren, and Shelemyahu Zacks. 1985. “Applications of\nCatastrophe Theory for Statistical Modeling in\nthe Biosciences.” Journal of the American\nStatistical Association 80 (392): 793–802. https://doi.org/10.1080/01621459.1985.10478184.\n\n\nCocchi, Luca, Leonardo L. Gollo, Andrew Zalesky, and Michael Breakspear.\n2017. “Criticality in the Brain: A Synthesis of\nNeurobiology, Models and Cognition.” Progress in\nNeurobiology 158 (November): 132–52. https://doi.org/10.1016/j.pneurobio.2017.07.002.\n\n\nCohen, Alexander, David Pargman, and Gershon Tenenbaum. 2003.\n“Critical Elaboration and Empirical\nInvestigation of the Cusp Catastrophe Model: A\nLesson for Practitioners.” Journal of\nApplied Sport Psychology 15 (2): 144–59. https://doi.org/10.1080/10413200305393.\n\n\nCramer, Angélique O. J., Lourens J. Waldorp, Han L. J. van der Maas, and\nDenny Borsboom. 2010. “Comorbidity: A Network Perspective.”\nThe Behavioral and Brain Sciences 33 (2-3): 137-150; discussion\n150-193. https://doi.org/10.1017/S0140525X09991567.\n\n\nDablander, Fabian, Anton Pichler, Arta Cika, and Andrea Bacilieri. 2020.\n“Anticipating Critical Transitions in\nPsychological Systems Using Early Warning\nSignals: Theoretical and Practical\nConsideration.”\n\n\nDakos, Vasilis, Stephen R. Carpenter, William A. Brock, Aaron M.\nEllison, Vishwesha Guttal, Anthony R. Ives, Sonia Kéfi, et al. 2012.\n“Methods for Detecting Early Warnings of Critical Transitions in\nTime Series Illustrated Using Simulated Ecological Data.”\nPloS One 7 (7): e41010. https://doi.org/10.1371/journal.pone.0041010.\n\n\nDalege, Jonas, Denny Borsboom, Frenk van Harreveld, Helma van den Berg,\nMark Conner, and Han L. J. van der Maas. 2016. “Toward a\nFormalized Account of Attitudes: The Causal Attitude\nNetwork (CAN) Model.” Psychological\nReview 123 (1): 2–22. https://doi.org/10.1037/a0039802.\n\n\nDalege, Jonas, Denny Borsboom, Frenk van Harreveld, and Han L. J. van\nder Maas. 2018. “The Attitudinal Entropy\n(AE) Framework as a General Theory of Individual\nAttitudes.” Psychological Inquiry 29 (4): 175–93. https://doi.org/10.1080/1047840X.2018.1537246.\n\n\nDalege, Jonas, and Han L. J. van der Maas. 2020. “Accurate by\nBeing Noisy: A Formal Network Model of Implicit Measures of\nAttitudes.” Social Cognition 38 (Suppl): S26–41. https://doi.org/10.1521/soco.2020.38.supp.s26.\n\n\nde Mooij, Susanne M. M., Tessa F. Blanken, Raoul P. P. P. Grasman,\nJennifer R. Ramautar, Eus J. W. Van Someren, and Han L. J. van der Maas.\n2020. “Dynamics of Sleep: Exploring Critical\nTransitions and Early Warning Signals.” Computer Methods and\nPrograms in Biomedicine 193 (September): 105448. https://doi.org/10.1016/j.cmpb.2020.105448.\n\n\nDodson, M. M., and A. Hallam. 1977. “Allopatric\nSpeciation and the Fold Catastrophe.”\nThe American Naturalist 111 (979): 415–33. https://doi.org/10.1086/283176.\n\n\nDolan, Conor V., and Han L. J. van der Maas. 1998. “Fitting\nMultivariage Normal Finite Mixtures Subject to Structural Equation\nModeling.” Psychometrika 63 (3): 227–53. https://doi.org/10.1007/BF02294853.\n\n\nDresp-Langley, Birgitta. 2020. “Seven Properties of\nSelf-Organization in the Human Brain.”\nBig Data and Cognitive Computing 2 (4): 10.\n\n\nDutilh, Gilles, Eric-Jan Wagenmakers, Ingmar Visser, and van der Han L.\nJ. Maas. 2011. “A Phase Transition Model for the\nSpeed-Accuracy Trade-Off in Response Time\nExperiments.” Cognitive Science 35 (2): 211–50.\nhttps://doi.org/10.1111/j.1551-6709.2010.01147.x.\n\n\nEdelman, Gerald M. 1987. Neural Darwinism:\nThe Theory of Neuronal Group Selection. Neural\nDarwinism: The Theory of Neuronal Group\nSelection. New York, NY, US: Basic Books.\n\n\nEigen, Manfred, and Peter Schuster. 1979. The\nHypercycle. Berlin, Heidelberg:\nSpringer. https://doi.org/10.1007/978-3-642-67247-7.\n\n\nEldredge, Niles, and Stephen Jay Gould. 1972. “Punctuated\nEquilibria: An Alternative to Phyletic\nGradualism.” In Models in\nPaleobiology, edited by Thomas J. M. Schopf, 82–115.\nFreeman Cooper.\n\n\nElo, Arpad E. 1978. The Rating of Chessplayers, Past and\nPresent. New York: Arco Pub.\n\n\nEpskamp, Sacha, Denny Borsboom, and Eiko I. Fried. 2018.\n“Estimating Psychological Networks and Their Accuracy:\nA Tutorial Paper.” Behavior Research\nMethods 50 (1): 195–212. https://doi.org/10.3758/s13428-017-0862-1.\n\n\nEpskamp, Sacha, Han L. J. van der Maas, Roseann E. Peterson, Hanna M.\nvan Loo, Steven H. Aggen, and Kenneth S. Kendler. 2022.\n“Intermediate Stable States in Substance Use.”\nAddictive Behaviors 129 (June): 107252. https://doi.org/10.1016/j.addbeh.2022.107252.\n\n\nEronen, Markus I., and Laura F. Bringmann. 2021. “The Theory\nCrisis in Psychology: How to Move\nForward.” Perspectives on Psychological Science\n16 (4): 779–88. https://doi.org/10.1177/1745691620970586.\n\n\nFestinger, Leon. 1962. A Theory of Cognitive Dissonance. A\nTheory of Cognitive Dissonance. Palo Alto, CA, US:\nStanford Univer. Press.\n\n\nFlack, Jessica C. 2017. “Coarse-Graining as a Downward Causation\nMechanism.” Philosophical Transactions of the Royal Society\nA: Mathematical, Physical and Engineering Sciences 375 (2109):\n20160338. https://doi.org/10.1098/rsta.2016.0338.\n\n\nFodor, J. A. 1974. “Special Sciences (or: The\nDisunity of Science as a Working Hypothesis).” Synthese\n28 (2): 97–115. https://doi.org/10.1007/BF00485230.\n\n\nFowler, James H. 2005. “Second-Order Free-Riding Problem\nSolved?” Nature 437 (7058): E8–8. https://doi.org/10.1038/nature04201.\n\n\nFreitas, Ubiratan, Elise Roulin, Jean-François Muir, and Christophe\nLetellier. 2009. “Identifying Chaos from Heart Rate:\nThe Right Task?” Chaos: An Interdisciplinary\nJournal of Nonlinear Science 19 (2): 028505. https://doi.org/10.1063/1.3139116.\n\n\nFriston, Karl. 2009. “The Free-Energy Principle: A Rough Guide to\nthe Brain?” Trends in Cognitive Sciences 13 (7):\n293–301. https://doi.org/10.1016/j.tics.2009.04.005.\n\n\nFuchs, Armin, and Scott Kelso. 2018. “Coordination\nDynamics and Synergetics: From Finger\nMovements to Brain Patterns and Ballet\nDancing.” In Complexity and\nSynergetics, 301–16. https://doi.org/10.1007/978-3-319-64334-2_23.\n\n\nGalesic, Mirta, Daniel Barkoczi, Andrew M. Berdahl, Dora Biro, Giuseppe\nCarbone, Ilaria Giannoccaro, Robert L. Goldstone, et al. 2023.\n“Beyond Collective Intelligence: Collective\nAdaptation.” Journal of The Royal Society Interface 20\n(200): 20220736. https://doi.org/10.1098/rsif.2022.0736.\n\n\nGhatak, Abhijit. 2019. Deep Learning with\nR. Singapore: Springer. https://doi.org/10.1007/978-981-13-5850-0.\n\n\nGibson, James J. 2014. The Ecological Approach to\nVisual Perception: Classic Edition.\nNew York: Psychology Press. https://doi.org/10.4324/9781315740218.\n\n\nGilmore, Robert. 1993. Catastrophe Theory for\nScientists and Engineers. Courier\nCorporation.\n\n\nGottman, John M., James D. Murray, Catherine C. Swanson, Rebecca Tyson,\nand Kristin R. Swanson. 2002. The Mathematics of Marriage:\nDynamic Nonlinear Models. The Mathematics of Marriage:\nDynamic Nonlinear Models. Cambridge, MA, US:\nMIT Press.\n\n\nGranovetter, M. 1973. “The Strength of Weak Ties.”\nAmerican Journal of Sociology 78 (6): 1360–80. https://doi.org/10.1086/225469.\n\n\nGranovetter, Mark. 1978. “Threshold Models of\nCollective Behavior.” The American Journal of\nSociology 83 (6): 1420–43. https://doi.org/10.1086/226707.\n\n\nGrasman, Raoul, Han L. J. van der Maas, and Eric-Jan Wagenmakers. 2009.\n“Fitting the Cusp Catastrophe in R:\nA Cusp Package Primer.” Journal of\nStatistical Software 032 (i08).\n\n\nGrauwin, Sebastian, Guillaume Beslon, Éric Fleury, Sara Franceschelli,\nCeline Robardet, Jean-Baptiste Rouquier, and Pablo Jensen. 2012.\n“Complex Systems Science: Dreams of Universality,\nInterdisciplinarity Reality.” Journal of the American Society\nfor Information Science and Technology 63 (7): 1327–38. https://doi.org/10.1002/asi.22644.\n\n\nGrossberg, Stephen, and Baingio Pinna. 2012. “Neural\nDynamics of Gestalt Principles of\nPerceptual Organization: From Grouping to\nShape and Meaning.” GESTALT\nTHEORY 34.\n\n\nGuastello, Stephen J. 1982. “Moderator Regression and the Cusp\nCatastrophe: Application of Two-Stage Personnel Selection,\nTraining, Therapy, and Policy Evaluation.” Behavioral\nScience 27 (3): 259–72. https://doi.org/10.1002/bs.3830270305.\n\n\n———. 1984. “Cusp and Butterfly Catastrophe Modeling of Two\nOpponent Process Models: Drug Addiction and Work\nPerformance.” Behavioral Science 29 (4): 258–62. https://doi.org/10.1002/bs.3830290405.\n\n\nGuastello, Stephen J., Matthijs Koopmans, and David Pincus. 2008.\nChaos and Complexity in Psychology:\nThe Theory of Nonlinear Dynamical\nSystems. Cambridge University Press.\n\n\nGuastello, Stephen, Anthony Correro, and David Marra. 2019. “Cusp\nCatastrophe Models for Cognitive Workload and\nFatigue in Teams.” Applied\nErgonomics, September.\n\n\nGuckenheimer, John, and Philip Holmes. 1983. “Global\nBifurcations.” In Nonlinear\nOscillations, Dynamical Systems, and\nBifurcations of Vector Fields, edited by\nJohn Guckenheimer and Philip Holmes, 289–352. Applied Mathematical\nSciences. New York, NY: Springer. https://doi.org/10.1007/978-1-4612-1140-2_6.\n\n\nGüémez, J., C. Fiolhais, and M. Fiolhais. 2002. “The\nCartesian Diver and the Fold Catastrophe.”\nAmerican Journal of Physics 70 (7): 710–14. https://doi.org/10.1119/1.1477433.\n\n\nGuimerà, Roger, Brian Uzzi, Jarrett Spiro, and Luís A. Nunes Amaral.\n2005. “Team Assembly Mechanisms Determine Collaboration\nNetwork Structure and Team Performance.”\nScience 308 (5722): 697–702. https://doi.org/10.1126/science.1106340.\n\n\nHaig, Brian D. 2014. Investigating the Psychological\nWorld: Scientific Method in the Behavioral\nSciences. MIT Press.\n\n\nHaken, Herman. 1977. “Synergetics.” Physics\nBulletin 28 (9): 412. https://doi.org/10.1088/0031-9112/28/9/027.\n\n\nHaken, Hermann. 1992. “Synergetics in\nPsychology.” In Self-Organization\nand Clinical Psychology: Empirical Approaches\nto Synergetics in Psychology, edited by\nWolfgang Tschacher, Günter Schiepek, and Ewald Johannes Brunner, 32–54.\nSpringer Series in Synergetics. Berlin,\nHeidelberg: Springer. https://doi.org/10.1007/978-3-642-77534-5_2.\n\n\nHaken, H., J. A. S. Kelso, and H. Bunz. 1985. “A Theoretical Model\nof Phase Transitions in Human Hand Movements.” Biological\nCybernetics 51 (5): 347–56. https://doi.org/10.1007/BF00336922.\n\n\nHardin, Garrett. 1968. “The Tragedy of the\nCommons” 162.\n\n\nHardy, Lew. 1996. “Testing the Predictions of the\nCusp Catastrophe Model of Anxiety and\nPerformance.” The Sport Psychologist 10\n(2): 140–56. https://doi.org/10.1123/tsp.10.2.140.\n\n\nHeath, Richard A. 2000. Nonlinear Dynamics:\nTechniques and Applications in\nPsychology. 1st edition. Mahwah, N.J:\nPsychology Press.\n\n\nHebb, D. O. 1949. The Organization of Behavior; a Neuropsychological\nTheory. The Organization of Behavior; a Neuropsychological Theory.\nOxford, England: Wiley.\n\n\nHeider, Fritz. 1946. “Attitudes and Cognitive\nOrganization.” The Journal of Psychology 21 (1):\n107–12. https://doi.org/10.1080/00223980.1946.9917275.\n\n\nHelbing, Dirk, and Péter Molnár. 1995. “Social Force Model for\nPedestrian Dynamics.” Physical Review E 51 (5): 4282–86.\nhttps://doi.org/10.1103/PhysRevE.51.4282.\n\n\nHendrikse, Sophie, Jan Treur, and Sander Koole. 2023. “Modeling\nEmerging Interpersonal Synchrony and Its Related\nAdaptive Short-Term Affiliation and Long-Term\nBonding: A Second-Order Multi-Adaptive Neural Agent\nModel.” International Journal of Neural Systems,\nApril. https://doi.org/10.1142/S0129065723500387.\n\n\nHoel, Erik P., Larissa Albantakis, and Giulio Tononi. 2013.\n“Quantifying Causal Emergence Shows That Macro Can Beat\nMicro.” Proceedings of the National Academy of Sciences\n110 (49): 19790–95. https://doi.org/10.1073/pnas.1314922110.\n\n\nHolland, John H. 1992a. “Genetic Algorithms.”\nScientific American 267 (1): 66–73. https://doi.org/10.1038/scientificamerican0792-66.\n\n\n———. 1992b. Adaptation in Natural and Artificial\nSystems: An Introductory Analysis with\nApplications to Biology, Control,\nand Artificial Intelligence. MIT Press.\n\n\nJacobson, Michael J., James A. Levin, and Manu Kapur. 2019.\n“Education as a Complex System:\nConceptual and Methodological\nImplications.” Educational Researcher 48 (2):\n112–19. https://doi.org/10.3102/0013189X19826958.\n\n\nJames, Nicholas A., and David S. Matteson. 2014.\n“Ecp : An\nR Package for Nonparametric\nMultiple Change Point Analysis of Multivariate\nData.” Journal of Statistical Software 62 (7). https://doi.org/10.18637/jss.v062.i07.\n\n\nJansen, Brenda R. J., and Han L. J. Van der Maas. 2001. “Evidence\nfor the Phase Transition from Rule I to\nRule II on the Balance Scale Task.”\nDevelopmental Review 21 (4): 450–94. https://doi.org/10.1006/drev.2001.0530.\n\n\nKalantari, Somayeh, Eslam Nazemi, and Behrooz Masoumi. 2020.\n“Emergence Phenomena in Self-Organizing Systems: A Systematic\nLiterature Review of Concepts, Researches, and Future Prospects.”\nJournal of Organizational Computing and Electronic Commerce 30\n(3): 224–65. https://doi.org/10.1080/10919392.2020.1748977.\n\n\nKauffman, Stuart A. 1993. The Origins of\nOrder: Self-Organization and\nSelection in Evolution. 1st edition.\nNew York: Oxford University Press.\n\n\nKelso, J. A. S. 1995. Dynamic Patterns: The\nSelf-Organization of Brain and Behavior. Dynamic Patterns:\nThe Self-Organization of Brain and Behavior.\nCambridge, MA, US: The MIT Press.\n\n\n———. 2021. “The Haken (HKB) Model: From\nMatter to Movement to Mind.” Biological Cybernetics 115\n(4): 305–22. https://doi.org/10.1007/s00422-021-00890-w.\n\n\nKelso, J. A. S., J. P. Scholz, and G. Schöner. 1986.\n“Nonequilibrium Phase Transitions in Coordinated Biological\nMotion: Critical Fluctuations.” Physics Letters A 118\n(6): 279–84. https://doi.org/10.1016/0375-9601(86)90359-2.\n\n\nKim, Jaegwon. 2006. “Emergence: Core Ideas and\nIssues.” Synthese 151 (3): 547–59. https://doi.org/10.1007/s11229-006-9025-0.\n\n\nKlinkenberg, S., M Straatemeier, and H. van der Maas. 2011.\n“Computer Adaptive Practice of Maths Ability Using a\nNew Item Response Model for on the Fly Ability and Difficulty\nEstimation.” Computers & Education 57: 1813–24.\n\n\nKrakauer, David C. 2023. “Symmetrysimplicity, Broken\nSymmetrycomplexity.” Interface Focus 13 (3): 20220075.\nhttps://doi.org/10.1098/rsfs.2022.0075.\n\n\nKruse, Peter, and Michael Stadler. 2012. Ambiguity in\nMind and Nature: Multistable Cognitive\nPhenomena. Springer Science & Business\nMedia.\n\n\nKuramoto, Yoshiki. 1984. “Chemical\nTurbulence.” In Chemical\nOscillations, Waves, and\nTurbulence, edited by Yoshiki Kuramoto, 111–40.\nSpringer Series in Synergetics. Berlin,\nHeidelberg: Springer. https://doi.org/10.1007/978-3-642-69689-3_7.\n\n\nLadyman, James, James Lambert, and Karoline Wiesner. 2013. “What\nIs a Complex System?” European Journal for Philosophy of\nScience 3 (1): 33–67. https://doi.org/10.1007/s13194-012-0056-8.\n\n\nLangton, Chris G. 1990. “Computation at the Edge of Chaos:\nPhase Transitions and Emergent Computation.”\nPhysica D: Nonlinear Phenomena 42 (1): 12–37. https://doi.org/10.1016/0167-2789(90)90064-V.\n\n\nLatané, Bibb, and Andrzej Nowak. 1994. “Attitudes as Catastrophes:\nFrom Dimensions to Categories with Increasing\nInvolvement.” In Dynamical Systems in Social Psychology,\n219–49. San Diego, CA, US: Academic Press.\n\n\nLeemput, van de Ingrid A., Marieke Wichers, Angélique O. J. Cramer,\nDenny Borsboom, Francis Tuerlinckx, Peter Kuppens, van Egbert H. Nes, et\nal. 2014. “Critical Slowing down as Early Warning for the Onset\nand Termination of Depression.” Proceedings of the National\nAcademy of Sciences 111 (1): 87–92. https://doi.org/10.1073/pnas.1312114110.\n\n\nLeggio, Lorenzo, George A. Kenna, Miriam Fenton, Erica Bonenfant, and\nRobert M. Swift. 2009. “Typologies of Alcohol\nDependence. From Jellinek to Genetics\nand Beyond.” Neuropsychology Review 19 (1):\n115–29. https://doi.org/10.1007/s11065-008-9080-z.\n\n\nLei, Min, Zhizhong Wang, and Zhengjin Feng. 2001. “Detecting\nNonlinearity of Action Surface EMG Signal.”\nPhysics Letters A 290 (5): 297–303. https://doi.org/10.1016/S0375-9601(01)00668-5.\n\n\nLemke, Jay L., and Nora H. Sabelli. 2008. “Complex\nSystems and Educational Change:\nTowards a New Research Agenda.” In\nComplexity Theory and the Philosophy of\nEducation, 112–23. John Wiley & Sons,\nLtd. https://doi.org/10.1002/9781444307351.ch8.\n\n\nLoehle, Craig. 1989. “Catastrophe Theory in Ecology: A Critical\nReview and an Example of the Butterfly Catastrophe.”\nEcological Modelling 49 (1): 125–52. https://doi.org/10.1016/0304-3800(89)90047-1.\n\n\nLumsden, James. 1976. “Test Theory.” Annual Review of\nPsychology 27: 251–80. https://doi.org/10.1146/annurev.ps.27.020176.001343.\n\n\nLurie, Daniel J., Daniel Kessler, Danielle S. Bassett, Richard F.\nBetzel, Michael Breakspear, Shella Kheilholz, Aaron Kucyi, et al. 2020.\n“Questions and Controversies in the Study of Time-Varying\nFunctional Connectivity in Resting fMRI.” Network Neuroscience 4 (1):\n30–69. https://doi.org/10.1162/netn_a_00116.\n\n\nMaris, Gunter, and Han van der Maas. 2012. “Speed-Accuracy\nResponse Models: Scoring Rules Based on Response Time and\nAccuracy.” Psychometrika 77 (4): 615–33. https://doi.org/10.1007/s11336-012-9288-y.\n\n\nMazanov, Jason, and D. G. Byrne. 2006. “A Cusp Catastrophe\nModel Analysis of Changes in Adolescent\nSubstance Use: Assessment of Behavioural\nIntention as a Bifurcation Variable.”\nNonlinear Dynamics, Psychology, and Life Sciences 10: 445–70.\n\n\nMcGeer, T. 1990. “Passive Walking with Knees.” In,\nIEEE International Conference on Robotics and\nAutomation Proceedings, 1640–1645 vol.3. https://doi.org/10.1109/ROBOT.1990.126245.\n\n\nMcGrath, Thomas, Andrei Kapishnikov, Nenad Tomašev, Adam Pearce, Martin\nWattenberg, Demis Hassabis, Been Kim, Ulrich Paquet, and Vladimir\nKramnik. 2022. “Acquisition of Chess Knowledge in\nAlphaZero.” Proceedings of the National Academy\nof Sciences 119 (47): e2206625119. https://doi.org/10.1073/pnas.2206625119.\n\n\nMcLachlan, Geoffrey J., Sharon X. Lee, and Suren I. Rathnayake. 2019.\n“Finite Mixture Models.” Annual Review of\nStatistics and Its Application 6 (1): 355–78. https://doi.org/10.1146/annurev-statistics-031017-100325.\n\n\nMcRobie, Allan. 2017. The Seduction of\nCurves: The Lines of Beauty That Connect\nMathematics, Art, and the Nude.\nPrinceton University Press.\n\n\nMichell, Joel. 1999. Measurement in Psychology: A\nCritical History of a Methodological Concept.\nCambridge University Press.\n\n\n———. 2008. “Is Psychometrics Pathological\nScience?” Measurement: Interdisciplinary Research and\nPerspectives 6 (January): 7–24. https://doi.org/10.1080/15366360802035489.\n\n\nMitchell, Melanie. 1998. An Introduction to\nGenetic Algorithms. MIT Press.\n\n\n———. 2009. Complexity: A Guided Tour. Oxford\nUniversity Press.\n\n\nMonroe, Brian M., and Stephen J. Read. 2008. “A General\nConnectionist Model of Attitude Structure and Change: The\nACS (Attitudes as Constraint\nSatisfaction) Model.” Psychological Review 115:\n733–59. https://doi.org/10.1037/0033-295X.115.3.733.\n\n\nMorel, Benoit, and Rangaraj Ramanujam. 1999. “Through the\nLooking Glass of Complexity: The\nDynamics of Organizations as Adaptive\nand Evolving Systems.” Organization Science\n10 (3): 278–93. https://doi.org/10.1287/orsc.10.3.278.\n\n\nO’Byrne, Jordan, and Karim Jerbi. 2022. “How Critical Is Brain\nCriticality?” Trends in Neurosciences 45 (11): 820–37.\nhttps://doi.org/10.1016/j.tins.2022.08.007.\n\n\nOliva, Terence A., Wayne S. Desarbo, Diana L. Day, and Kamel Jedidi.\n1987. “Gemcat: A General Multivariate Methodology for\nEstimating Catastrophe Models.” Behavioral Science 32\n(2): 121–37. https://doi.org/10.1002/bs.3830320205.\n\n\nOlthof, Merlijn, Fred Hasselman, Freek Oude Maatman, Anna M. T. Bosman,\nand Anna Lichtwarck-Aschoff. 2023. “Complexity Theory of\nPsychopathology.” Journal of Psychopathology and Clinical\nScience 132: 314–23. https://doi.org/10.1037/abn0000740.\n\n\nOlthof, Merlijn, Fred Hasselman, Guido Strunk, Marieke van Rooij,\nBenjamin Aas, Marieke A. Helmich, Günter Schiepek, and Anna\nLichtwarck-Aschoff. 2020. “Critical Fluctuations as\nan Early-Warning Signal for Sudden Gains and\nLosses in Patients Receiving Psychotherapy for\nMood Disorders.” Clinical Psychological\nScience 8 (1): 25–35. https://doi.org/10.1177/2167702619865969.\n\n\nOoyen, Arjen van, and Markus Butz-Ostendorf. 2017. The\nRewiring Brain: A Computational Approach to\nStructural Plasticity in the Adult Brain.\nAcademic Press.\n\n\nPaulos, John Allen. 2008. Mathematics and Humor.\nUniversity of Chicago Press.\n\n\nPavlus, John. 2016. “The Clumsy Quest to\nPerfect the Walking Robot.”\nScientific American.\nhttps://www.scientificamerican.com/article/the-clumsy-quest-to-perfect-the-walking-robot/.\nhttps://doi.org/10.1038/scientificamerican0716-60.\n\n\nPerc, Matjaž, Jillian J. Jordan, David G. Rand, Zhen Wang, Stefano\nBoccaletti, and Attila Szolnoki. 2017. “Statistical Physics of\nHuman Cooperation.” Physics Reports, Statistical physics\nof human cooperation, 687 (May): 1–51. https://doi.org/10.1016/j.physrep.2017.05.004.\n\n\nPiaget, Jean. 1952. The Origins of Intelligence in Children.\nEdited by Margaret Cook. The Origins of Intelligence in Children.\nNew York, NY, US: W W Norton & Co. https://doi.org/10.1037/11494-000.\n\n\nPlenz, Dietmar, Tiago L. Ribeiro, Stephanie R. Miller, Patrick A. Kells,\nAli Vakili, and Elliott L. Capek. 2021. “Self-Organized\nCriticality in the Brain.” Frontiers in\nPhysics 9. https://doi.org/10.3389/fphy.2021.639389.\n\n\nPloeger, Annemie, Han L. J. Van Der Maas, and Pascal A. I. Hartelman.\n2002. “Stochastic Catastrophe Analysis of Switches in the\nPerception of Apparent Motion.” Psychonomic Bulletin &\nReview 9 (1): 26–42. https://doi.org/10.3758/BF03196255.\n\n\nPool, Robert. 1989. “Is It Healthy to Be\nChaotic?” Science 243 (4891): 604–7. https://doi.org/10.1126/science.2916117.\n\n\nPort, Robert F., and Timothy Van Gelder. 1995. Mind as\nMotion: Explorations in the\nDynamics of Cognition. MIT\nPress.\n\n\nPoston, Tim, and Ian Stewart. 2014. Catastrophe Theory\nand Its Applications. Courier\nCorporation.\n\n\nPritchard, Walter s., and Dennis w. Duke. 1992. “Measuring\nChaos in the Brain: A Tutorial\nReview of Nonlinear Dynamical Eeg Analysis.”\nInternational Journal of Neuroscience 67 (1-4): 31–80. https://doi.org/10.3109/00207459208994774.\n\n\nReher, Jenna, and Aaron D. Ames. 2021. “Dynamic\nWalking: Toward Agile and Efficient\nBipedal Robots.” Annual Review of Control, Robotics,\nand Autonomous Systems 4 (1): 535–72. https://doi.org/10.1146/annurev-control-071020-045021.\n\n\nRendell, Paul. 2016. “Game of Life Universal Turing\nMachine.” In Turing Machine Universality\nof the Game of Life, edited by Paul\nRendell, 71–89. Emergence, Complexity and\nComputation. Cham: Springer\nInternational Publishing. https://doi.org/10.1007/978-3-319-19842-2_5.\n\n\nRepp, Bruno H., and Yi-Huang Su. 2013. “Sensorimotor\nSynchronization: A Review of Recent Research\n(2006).” Psychonomic Bulletin & Review 20 (3):\n403–52. https://doi.org/10.3758/s13423-012-0371-2.\n\n\nRoberts, James A., Leonardo L. Gollo, Romesh G. Abeysuriya, Gloria\nRoberts, Philip B. Mitchell, Mark W. Woolrich, and Michael Breakspear.\n2019. “Metastable Brain Waves.” Nature\nCommunications 10 (1): 1056. https://doi.org/10.1038/s41467-019-08999-0.\n\n\nRobertson, Robin, and Allan Combs, eds. 2014. Chaos Theory in\nPsychology and the Life Sciences.\nNew York: Psychology Press. https://doi.org/10.4324/9781315806280.\n\n\nRobinaugh, Donald J., Ria H. A. Hoekstra, Emma R. Toner, and Denny\nBorsboom. 2020. “The Network Approach to Psychopathology: A Review\nof the Literature 2008 and an Agenda for Future Research.”\nPsychological Medicine 50 (3): 353–66. https://doi.org/10.1017/S0033291719003404.\n\n\nRosser, J. Barkley. 2007. “The Rise and Fall of Catastrophe Theory\nApplications in Economics: Was the Baby Thrown Out with the\nBathwater?” Journal of Economic Dynamics and Control 31\n(10): 3255–80. https://doi.org/10.1016/j.jedc.2006.09.013.\n\n\nSandubete, Julio, E., and Lorenzo Escot. 2021.\n“DChaos: An R Package for Chaotic\nTime Series Analysis.” The R Journal 13 (1): 232.\nhttps://doi.org/10.32614/RJ-2021-036.\n\n\nSavi, Alexander O., Maarten Marsman, Han L. J. van der Maas, and Gunter\nK. J. Maris. 2019. “The Wiring of\nIntelligence.” Perspectives on Psychological\nScience 14 (6): 1034–61. https://doi.org/10.1177/1745691619866447.\n\n\nScheffer, Marten. 2004. Ecology of Shallow Lakes.\nDordrecht: Springer Netherlands. https://doi.org/10.1007/978-1-4020-3154-0.\n\n\nSchelling, Thomas C. 1971. “Dynamic Models of Segregation.”\nThe Journal of Mathematical Sociology 1 (2): 143–86. https://doi.org/10.1080/0022250X.1971.9989794.\n\n\nSchiepek, Günter K., Kathrin Viol, Wolfgang Aichhorn, Marc-Thorsten\nHütt, Katharina Sungler, David Pincus, and Helmut J. Schöller. 2017.\n“Psychotherapy Is Chaotic(not Only) in a\nComputational World.” Frontiers in Psychology 8. https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00379.\n\n\nSchiepek, Günter, and Volker Perlitz. 2009.\n“Self-Organization in Clinical\nPsychology.” In Synergetics, edited by Axel Hutt\nand Haken, 263–85. New York, NY: Springer US.\nhttps://doi.org/10.1007/978-1-0716-0421-2_472.\n\n\nSchmidhuber, Jürgen. 2015. “Deep Learning in Neural Networks:\nAn Overview.” Neural Networks 61 (January):\n85–117. https://doi.org/10.1016/j.neunet.2014.09.003.\n\n\nSchmidt, R. C., C. Carello, and M. T. Turvey. 1990. “Phase\nTransitions and Critical Fluctuations in the Visual Coordination of\nRhythmic Movements Between People.” Journal of Experimental\nPsychology. Human Perception and Performance 16 (2): 227–47. https://doi.org/10.1037//0096-1523.16.2.227.\n\n\nSchöner, Gregor. 2020. “The Dynamics of Neural\nPopulations Capture the Laws of the\nMind.” Topics in Cognitive Science 12 (4):\n1257–71. https://doi.org/10.1111/tops.12453.\n\n\nSchöner, Gregor, and John P. Spencer. 2016. Dynamic Thinking:\nA Primer on Dynamic Field Theory. Oxford\nUniversity Press.\n\n\nScott, John. 2011. “Social Network Analysis: Developments,\nAdvances, and Prospects.” Social Network Analysis and\nMining 1 (1): 21–26. https://doi.org/10.1007/s13278-010-0012-6.\n\n\nSerra, Roberto, and Gianni Zanarini. 1990. Complex\nSystems and Cognitive Processes.\nBerlin, Heidelberg: Springer. https://doi.org/10.1007/978-3-642-46678-6.\n\n\nSilver, David, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou,\nMatthew Lai, Arthur Guez, Marc Lanctot, et al. 2018. “A General\nReinforcement Learning Algorithm That Masters Chess, Shogi, and\nGo Through Self-Play.” Science 362 (6419):\n1140–44. https://doi.org/10.1126/science.aar6404.\n\n\nSimon, Herbert A. 1962. “The Architecture of\nComplexity.” Proceedings of the American\nPhilosophical Society 106 (6): 467–82. https://www.jstor.org/stable/985254.\n\n\nSkarda, Christine A., and Walter J. Freeman. 1987. “How Brains\nMake Chaos in Order to Make Sense of the World.” Behavioral\nand Brain Sciences 10 (2): 161–73. https://doi.org/10.1017/S0140525X00047336.\n\n\nSmolensky, Paul. 1986. “Information Processing in\nDynamical Systems: Foundations of\nHarmony Theory.”\n\n\nSnijders, Tom A. B. 2001. “The Statistical Evaluation\nof Social Network Dynamics.” Sociological\nMethodology 31 (1): 361–95. https://doi.org/10.1111/0081-1750.00099.\n\n\nStefan, Martin. 2020. “RPubs - Fractals\nwith R.” https://rpubs.com/mstefan-rpubs/fractals.\n\n\nStengers, Isabelle, and Ilya Prigogine. 1978. Order Out\nof Chaos: Man’s New Dialogue with\nNature. London.\n\n\nStewart, Ian. 1982. “Catastrophe Theory in Physics.”\nReports on Progress in Physics 45 (2): 185–221. https://doi.org/10.1088/0034-4885/45/2/002.\n\n\nStewart, Ian, and P. L. Peregoy. 1983. “Catastrophe Theory\nModeling in Psychology.” Psychological Bulletin 94:\n336–62. https://doi.org/10.1037/0033-2909.94.2.336.\n\n\nStouffer, Samuel A., Edward A. Suchman, Leland C. Devinney, Shirley A.\nStar, and Robin M. Williams Jr. 1949. The American\nSoldier: Adjustment During Army Life. (Studies\nin Social Psychology in World War II), Vol.\n1. The American Soldier: Adjustment\nDuring Army Life. (Studies in Social Psychology in\nWorld War II), Vol. 1. Oxford,\nEngland: Princeton Univ. Press.\n\n\nSurowiecki, James. 2005. The Wisdom of\nCrowds. Knopf Doubleday Publishing Group.\n\n\nSutton, Richard S., and Andrew G. Barto. 2018. Reinforcement\nLearning, Second Edition: An\nIntroduction. MIT Press.\n\n\nTesfatsion, Leigh. 2002. “Agent-Based Computational\nEconomics: Growing Economies From the Bottom\nUp.” Artificial Life 8 (1): 55–82. https://doi.org/10.1162/106454602753694765.\n\n\nThelen, Esther. 1995. “Motor Development: A New\nSynthesis.” American Psychologist 50: 79–95. https://doi.org/10.1037/0003-066X.50.2.79.\n\n\nThelen, Esther, and Linda B. Smith. 1994. A Dynamic Systems\nApproach to the Development of\nCognition and Action. MIT\nPress.\n\n\nThom, René. 1977. “Structural Stability,\nCatastrophe Theory, and Applied\nMathematics.” SIAM Review 19 (2): 189–201. https://doi.org/10.1137/1019036.\n\n\nToker, Daniel, Friedrich T. Sommer, and Mark D’Esposito. 2020. “A\nSimple Method for Detecting Chaos in Nature.” Communications\nBiology 3 (1): 1–13. https://doi.org/10.1038/s42003-019-0715-9.\n\n\nTreiber, Martin, Ansgar Hennecke, and Dirk Helbing. 2000.\n“Congested Traffic States in Empirical Observations and\nMicroscopic Simulations.” Physical Review E 62 (2):\n1805–24. https://doi.org/10.1103/PhysRevE.62.1805.\n\n\nVallacher, Robin R., and Andrzej Nowak, eds. 1994. Dynamical Systems\nin Social Psychology. Dynamical Systems in Social Psychology.\nSan Diego, CA, US: Academic Press.\n\n\nvan der Maas, H. L. J. 1995. “Beyond the Metaphor?”\nCognitive Development 10.\n\n\nVan Der Maas, Han L. J., Conor V. Dolan, Raoul P. P. P. Grasman, Jelte\nM. Wicherts, Hilde M. Huizenga, and Maartje E. J. Raijmakers. 2006.\n“A Dynamical Model of General Intelligence: The\nPositive Manifold of Intelligence by Mutualism.”\nPsychological Review 113 (4): 842–61. https://doi.org/c3jm44.\n\n\nvan der Maas, Han L. J., Rogier Kolstein, and Joop van der Pligt. 2003.\n“Sudden Transitions in\nAttitudes.” Sociological Methods &\nResearch 32 (2): 125–52. https://doi.org/10.1177/0049124103253773.\n\n\nvan der Maas, Han L. J., Lukas Snoek, and Claire E. Stevenson. 2021.\n“How Much Intelligence Is There in Artificial Intelligence?\nA 2020 Update.” Intelligence 87 (July):\n101548. https://doi.org/10.1016/j.intell.2021.101548.\n\n\nvan der Maas, Han L. J., Paul F. M. J. Verschure, and Peter C. M.\nMolenaar. 1990. “A Note on Chaotic Behavior in Simple Neural\nNetworks.” Neural Networks 3 (1): 119–22. https://doi.org/10.1016/0893-6080(90)90050-U.\n\n\nVan der Maas, Han L., and Peter C. Molenaar. 1992. “Stagewise\nCognitive Development: An Application of Catastrophe\nTheory.” Psychological Review 99 (3): 395–417. https://doi.org/10.1037/0033-295X.99.3.395.\n\n\nVisser, Ingmar, and Maarten Speekenbrink. 2022. Mixture and\nHidden Markov Models with R.\nSpringer International Publishing.\n\n\nVolberda, Henk W., and Arie Y. Lewin. 2003. “Co-Evolutionary\nDynamics Within and Between Firms: From\nEvolution to Co-evolution.”\nJournal of Management Studies 40 (8): 2111–36. https://doi.org/10.1046/j.1467-6486.2003.00414.x.\n\n\nWagemans, Johan, James H. Elder, Michael Kubovy, Stephen E. Palmer, Mary\nA. Peterson, Manish Singh, and Rüdiger von der Heydt. 2012. “A\nCentury of Gestalt Psychology in Visual Perception:\nI. Perceptual Grouping and Figureground\nOrganization.” Psychological Bulletin 138: 1172–1217. https://doi.org/10.1037/a0029333.\n\n\nWagenmakers, Eric-Jan, Peter C. M. Molenaar, Raoul P. P. P. Grasman,\nPascal A. I. Hartelman, and Han L. J. van der Maas. 2005.\n“Transformation Invariant Stochastic Catastrophe Theory.”\nPhysica D: Nonlinear Phenomena 211 (3): 263–76. https://doi.org/10.1016/j.physd.2005.08.014.\n\n\nWeaver, Warren. 1948. “Science and\nComplexity.” American Scientist 36 (4):\n536–44. https://www.jstor.org/stable/27826254.\n\n\nWichers, Marieke, Peter C. Groot, and ESM Group Psychosystems. 2016.\n“Critical Slowing Down as a Personalized Early\nWarning Signal for Depression.”\nPsychotherapy and Psychosomatics 85 (2): 114–16. https://doi.org/10.1159/000441458.\n\n\nWiener, Norbert. 2019. Cybernetics or Control and\nCommunication in the Animal and the\nMachine, Reissue of the 1961 Second\nEdition. MIT Press.\n\n\nWilensky, Uri, and William Rand. 2015. An Introduction to\nAgent-Based Modeling: Modeling Natural, Social, and Engineered Complex\nSystems with NetLogo. Cambridge,\nMassachusetts: The MIT Press.\n\n\nWitkiewitz, Katie, Han L. J. van der Maas, Michael R. Hufford, and G.\nAlan Marlatt. 2007. “Nonnormality and Divergence in Posttreatment\nAlcohol Use: Reexamining the Project MATCH\nData \"Another Way.\".” Journal of Abnormal Psychology\n116: 378–94. https://doi.org/10.1037/0021-843X.116.2.378.\n\n\nXue, Jiankai, and Bo Shen. 2020. “A Novel Swarm Intelligence\nOptimization Approach: Sparrow Search Algorithm.” Systems\nScience & Control Engineering 8 (1): 22–34. https://doi.org/10.1080/21642583.2019.1708830.\n\n\nZahler, Raphael S., and Hector J. Sussmann. 1977. “Claims and\nAccomplishments of Applied Catastrophe Theory.” Nature\n269 (October): 759–63. https://doi.org/10.1038/269759a0.\n\n\nZeeman, E. C. 1976. “Catastrophe Theory.”\nScientific American 234 (4): 65–83."
  },
  {
    "objectID": "ch5.html#basic-concepts",
    "href": "ch5.html#basic-concepts",
    "title": "5  Building dynamic system models",
    "section": "5.1 Basic concepts",
    "text": "5.1 Basic concepts\n\n5.1.1 Back to the logistic equation\nWe have seen the logistic equation in the form of the logistic map, where time progressed in discrete steps. The logistic map is a difference equation, \\(X_{t + 1} = f(X_{t})\\), but in this chapter we will focus on differential equations in continuous time. We will limit ourselves to ordinary differential equations (ODE’s). In such equations we take the derivatives with respect to only one variable. The ODE for logistic growth1 is:\n\\[\\begin{array}{r}\n\\frac{dX}{dt} = rX(1 - X)\n\\end{array} \\tag{5.1}\\]\nA solution to this equation expresses \\(X_{t}\\) as a function of the initial state \\(X_{0}\\). In simple cases we can do this using the math we learned in high school. For exponential growth \\(\\frac{dX}{dt} = rX\\), this is the derivation:\n\\[\\frac{dX}{dt} = rX\\]\n\\(\\frac{dX}{X} = rdt\\) by separation of variables\n\\(\\frac{\\int_{}^{}{dX}}{X} = \\int_{}^{}{rdt}\\) integrate\n\\(\\ln X = rt + C\\) assuming \\(X \\geq 0\\)\n\\(X = e^{rt + C} = e^{C}e^{rt}\\) by taking the exponent\n\\(X_{0} = e^{C}e^{r0} \\Longrightarrow X_{0} = e^{C}\\) compute the integration constant\n\\[\\begin{array}{r}\n\\Longrightarrow X_{t} = {X_{0}e}^{rt}\n\\end{array} \\tag{5.2}\\]\nBut for more complex models such an analytical solution is out of scope and numerical solutions (by simulation) are required. This is not the preferred choice. These simulations can be slow, may accumulate rounding errors, and it can be difficult to search the entire parameter space, especially when multiple parameters are involved.\nThe naive implementation of differential equations in R is risky. This would involve a for loop:\nx &lt;- x0 &lt;- .1  # initial value\nr &lt;- .5 # growth rate\ndt &lt;- .00001 # time step in simulation\nt &lt;- 10  # Nt, time we want to know the value of x\ntimesteps &lt;- t/dt # required time steps given t and dt\nfor(i in 2:timesteps) # note the 2 to use the starting value\n{\n  x[i] &lt;- x[i-1] + r*x[i-1]*dt\n}\nx0*exp(r*timesteps*dt) # analytical solution\nx[timesteps] # compare\ntimesteps # length of simulation\nwhere \\(dt\\) must be chosen by hand. If you test some values of \\(dt\\), you will see that a value too high (.5) leads to a solution (x[timesteps]) that is different from the analytical solution. But if we set \\(dt\\) very low (.00001), it takes unnecessarily long.\nThis is why we use ‘solvers’, numerical methods for ordinary differential equations. We will use the R-package Grind, although many other methods are available in R. One could also directly use the R packages deSolve and rootSolve by Soetaert, Petzoldt, and Setzer (2010a), on which the Grind package is based. Grind has to be installed from GitHub using:\ninstall.packages(\"remotes\")\nremotes::install_github(\"hansschepers/grindr\")\nThe packages required are:\nlibrary(deSolve)\nlibrary(rootSolve)\nlibrary(FME)\nlibrary(Grind)\nThe code consists of defining the model, the parameters \\(p\\) and the initial values \\(s\\). Main functions are run(), plane(), newton(), continue() and fit(). They will be introduced using examples. With run() we generate a time series for the model.\ninstall.packages(\"remotes\")\nremotes::install_github(\"hansschepers/grindr\")\nlibrary(deSolve)\nlibrary(rootSolve)\nlibrary(FME)\nlibrary(Grind)\nmodel &lt;- function(t, state, parms) {\n  with(as.list(c(state,parms)), {\n    dX &lt;- r*X            # the exponential model\n      return(list(c(dX)))\n  })\n}\np &lt;- c(r=.5) # parameter r\ns &lt;- c(X=.1) # initial value\nrun(tmax=5) # run until t = 5, numerical solution\ns['X']*exp(p['r']*5) # compare with analytical solution\nWe don’t have to worry about time steps anymore and the numerical and analytical solutions converge. This is of course a trivial use of an ODE solver, but much more can be done.\nIn analyzing the behavior of a dynamical system, the first thing we want to know about a dynamical system is what the equilibria \\(X^{*}\\)are. To do this, we need to set the time derivative equal to zero,\\(\\frac{dX}{dt} = 0.\\) For the exponential function this is simply \\(rX = \\ 0\\), i.e., when \\(X\\) is zero. Second, we want to determine whether these equilibria are stable or unstable. Whether \\(X^{*}=0\\) is stable can be determined by checking the second derivative in \\(X^{*}\\). If this derivative is less than zero, then the fixed point is stable. The second derivative is \\(r\\), so \\(X^{*} = 0\\) is an unstable fixed point whenever \\(r &gt; 0\\) and stable whenever \\(r &lt; 0\\). You can check this in Grind by using\\(\\ r\\) values of -.1 and .1, and start values equal to or just above or below 0.\nFor Equation 5.1, the logistic function, we also want to know the equilibria, the stable and unstable fixed points. To do so we follow the same steps as for the exponential function (see exercises).\nI note that the continuous-time implementation of the logistic function is somewhat boring compared to its discrete-time variant that we studied in chapter 2. The difference is that the overshooting and undershooting do not occur in continuous time. By changing the logistic model in Grind to:\ndX &lt;- r*X*(1-X) – X \nand use method='euler' in the run() function, you can simulate the discrete-time logistic map. Check if you get chaos for \\(r = 4\\). Use the Euler method only in special cases, as it is generally the least accurate approach.\n\n\n5.1.2 The Lotka-Volterra models\nPerhaps the best-known population models are the Lotka-Volterra equations (J. D. Murray 2002). These consist of coupled differential equations, one for the density of the prey and one for the density of the predator.\n\\[\\begin{array}{r}\n\\frac{dN}{dt} = aN - bPN\n\\end{array} \\tag{5.3}\\]\n\\[\\begin{array}{r}\n\\frac{dP}{dt} = cPN - dP\n\\end{array} \\tag{5.4}\\]\nWhere \\(N\\) and \\(P\\) refer to the sizes of the prey and predator populations, a and c determine the growth rates, and b and d control the mortality rates. Note that the mortality rate of prey depends on both \\(N\\) and \\(P\\), while the mortality rate of predators depends only on \\(P\\). Similarly, the growth terms are also asymmetric, predators increase as a function of both \\(N\\) and \\(P\\), they eat prey. We will follow the simple example provided by Wikipedia (on Lotka-Volterra equations).\nTo implement this model in Grind, we use:\nLV &lt;- function(t, state, parms) {\n  with(as.list(c(state,parms)), {\n    dN &lt;- a*N - b*P*N\n    dP &lt;- c*P*N - d*P\n    return(list(c(dN, dP)))\n  })\n}\np &lt;- c(a=1.1,b=.4,c=.1,d=0.4) # parameters\ns &lt;- c(N=10,P=10)             # 10 baboons and 10 cheetahs\nSome typical uses of Grind are:\nlayout(1:2)\ndata=run(odes=LV,tstep=.01,table=T) # set tstep to low value\n# phase plot for different starting values\nplane(odes=LV,portrait = TRUE, ymax=17, xmax=50, tstep=0.1,grid=4)\nThe plane function makes a phase plot with \\(N\\) and \\(P\\) as axes. The black points are initial states. What we learn from this is that the equilibrium of the Lotka-Volterra equations is a limit cycle that depends on the choice of the initial conditions. A well-known improvement to this model is to make the prey growth density dependent by using the logistic equation. This can be done by setting dN &lt;- a*N *(1-N) - b*P*N in the model. This is the case used as an example in the Grind tutorial, which I highly recommend reading (de Boer 2018). It also contains the appropriate parameter values for this model variant. In this density dependent model there are fixed points, in contrast to the original model. This shows that such model choices can have a large effect.\nA famous example of a system of three coupled differential equations is the SIR model used to model infectious diseases. The differential equations specify the change in susceptible, infected, and recovered members of the population. You can now easily implement this model yourself (see exercises).\n\n\n5.1.3 Fitting models: stochasticity versus noise\nGrind includes an option to fit dynamical systems models. With fit(), based on the modFit function from the FME package (Soetaert, Petzoldt, and Setzer 2010b), one can estimate the model parameters given a data set. These functions also provide confidence intervals, allow fixing parameters and bootstrap analysis. Fitting nonlinear dynamical systems models to data is an art in itself. For example, these methods can be very sensitive to the choice of initial values.\nI will illustrate the use of fit() on three data sets created with the original Lotka-Volterra model from the previous section. The first data set is the deterministic data set, the data that follows directly from the code above. The second one is created using a stochastic Lotka-Volterra model. How this works will be explained in the next section. The third is a deterministic data set with measurement error. We will see that the last two cases are very different.\nset.seed(1)\nlayout(matrix(1:4,2,2,byrow=T))\np &lt;- c(a=1.1,b=.4,c=.1,d=0.4) # p is a named vector of parameters\ns &lt;- c(N=10,P=10)             # s is the state\nn &lt;- 30\ndata_deterministic &lt;- run(odes=LV,n,table=T,timeplot =F) # deterministic data\ndata_stochastic &lt;- run(odes=LV,n,table=T,after=\"state&lt;-state+rnorm(2,0,.1)\",\n                       timeplot =F) # add stochasticity\ndata_error &lt;- run(odes=LV,n,table=T,timeplot =F)\ndata_error[,2:3] &lt;- data_error[,2:3]+\n  matrix(rnorm(2*n,0,2),,2) # measurement error \n#fit & plot\ns&lt;- s*abs(rnorm(2,1,0.1));s; p&lt;- p*abs(rnorm(4,1,0.1));p    # start values\nf_deter&lt;- fit(data_deterministic,main='deterministic')\nf_stoch&lt;- fit(data_stochastic,main='stochastic')\nf_error&lt;- fit(data_error,main='error')\npars &lt;- matrix(c(f_deter$par[3:6],f_stoch$par[3:6],f_error$par[3:6]),,3)\npars &lt;- rbind(pars,c(summary(f_deter)$sigma,summary(f_stoch)$sigma,summary(f_error)$sigma))\nbarplot(t(pars),beside=T,names=c('a','b','c','d','Residuals'),\n        legend.text=c('deterministic','stochastic','error'),\n        args.legend=c(x=13))\nThis results in:\n\n\n\nFigure 5.1: Fit of the Lotka-Volterra model on three types of data.\n\n\nNote that the error data set looks very similar to the deterministic data set because it contains only the measurement error (X is true score + error). The error does not affect the dynamics itself. In the stochastic case, the error (noise) is added to the states after each time step, which affects the dynamics. In Figure 5.1, you can see that the positions of the waves change. In this well-chosen case, the fit is quite good in all three cases, the parameter estimates are all quite close to the true values. Unfortunately, these results are quite unstable. You can do some testing yourself.\n\n\n5.1.4 Back to the cusp\nTo illustrate how Grind can be used to perform bifurcation analysis, we go back to the cusp. Recall that the differential equation for the cusp is:\n\\[\\begin{array}{r}\n\\frac{dX}{dt} = - V^{'}(X) = {a + bX - X}^{3}\n\\end{array} \\tag{5.5}\\]\nmodel &lt;- function(t, state, parms){\n  with(as.list(c(state,parms)),{\n    dX &lt;-  a + b*X - X^3        # cusp\n    return(list(dX))\n  })\n}\np &lt;- c(a=0,b=1); s &lt;- c(X=.1); run(ymin=-1)\ns[1] &lt;- -.1; run(add=T)\nThis shows two runs demonstrating bistability for \\(a = 0\\) and \\(b = 1\\).\nA better way to demonstrate bistability in the time series is to make the system stochastic. This was done in Chapter 2 by using a stochastic differential equation: \\(dX = - V^{'}(X)dt + \\sigma dW(t)\\). Grind has a great trick for this. With the ‘after’ parameter in the function call, we can add discrete events to the system. ‘After’ can also be used to change parameter or state values after a certain amount of time or after some condition (see the manual). We use it here to add a random number sampled from a normal distribution, with a mean of 0 and a standard deviation of .4, to \\(X\\). The best way to simulate this in Grind is using the Euler method with a small timestep. The noise term should be corrected with \\(\\sqrt{dt}\\), as shown in the code. The Wikipedia page on stochastic differential equations will tell you more about the underlying ideas.\nAs can be seen in Figure 5.2, the stochastic force causes spontaneous jumps between the two modes of the cusp. When noise or random fluctuations cause the entire equilibrium landscape of a dynamical system to become observable, it is often referred to as stochastic resonance. Stochastic resonance is a notable example of how noise, which is often considered undesirable or disruptive, can actually play a constructive role in certain systems, helping to reveal hidden patterns and structures that might otherwise remain obscured. You can see this by comparing the figure with one generated with a standard deviation of .1 or less.\nlayout(t(c(1,1,1,2)))\ndata &lt;- run(table=T,tmax=1000,method='euler',tstep=.1,after=\"state&lt;-state+\n            rnorm(1,mean=0,sd=0.4)*sqrt(tstep)\",ymax=2,ymin=-2,timeplot=F)\nplot(data,type='l',bty='n')\nbarplot(hist(data[,2],30,plot=F)$counts,xlab=\"X\",hor=T)\n\n\n\nFigure 5.2: Spontaneous jumps in the cusp due to stochastics (noise).\n\n\n\n\n5.1.5 Bifurcation analysis\nBy combining the Grind functions newton() and continue(), we can perform bifurcation analysis. The newton() function finds stable and unstable fixed points and the continue() function implements the parameter continuation of a steady state, providing a bifurcation diagram. It show the change in equilibria when we change parameter. This is what we did in Chapter 2 for the logistic map, when we varied r and plotted the equilibria (see Figure 2.8).\nIt is often necessary to run the combination of these two functions repeatedly, starting from different initial states.\np &lt;- c(a=0,b=1)\nlow &lt;- newton(s=c(X=-1)) # finds a minimum starting from X = -1\ncontinue(low,x=\"a\",y=\"X\",xmin=-2,xmax=2,ymax=2) # Continue this steady state varying a\nhigh &lt;- newton(s=c(X=1)) # again starting from X = 1\ncontinue(high,x=\"a\",y=\"X\",xmin=-2,xmax=2,ymax=2,add=T)\n\n\n\nFigure 5.3: Hysteresis plot made with newton() and continue(). The function newton() finds an equilibrium, which is used in continue() to vary the normal variable $a$ until a bifurcation point is found\n\n\nAnother great tool in R is the deBif package by Andre M. de Roos. This is a R Shiny application that uses the same model specification and allows for a more interactive investigation. Given our previous model and the definition of \\(s\\) and \\(p\\), we can run:\ninstall.packages(\"deBif\")\nlibrary(deBif)\nphaseplane(model,s,p)\nThe phaseplane() function returns a time plot and the steady states. You can change parameters and initial states on the left side, and plot parameters on the upper right side (click on the two gears). The Steady States option is very useful as it shows the stable and unstable fixed points. Be sure to set the minima and maxima of the plot correctly.\nWith\nbifurcation(model,s,p)\nYou can create one- and two-parameter bifurcation diagrams (using the LP curve option). The two-parameter bifurcation diagram (bottom left) cannot be created in Grind. See the deBif help pages (with ??deBif) for further instructions.\n\n\n\nFigure 5.4: Output from Shinyapp Debif. The last plot is a two-dimensional bifurcation diagram showing the bifurcation lines of the cusp in the a, b plane. This plot cannot be made with Grind.\n\n\n\n\n5.1.6 Spruce Budworm outbreak model\nIn chapter 3, I introduced the Spruce Budworm outbreak model. We will use this model later as a model of addiction. The bifurcation diagram can be made with:\nspruce &lt;- function(t, state, parms) {\n  with(as.list(c(state,parms)), {\n    du = r*u*(1 - u/q)-u^2/(1+u^2)\n    return(list(c(du)))\n  })\n}\nstate &lt;- c(u = 0.5)\nparms &lt;- c(r = 0.4, q = 10)\nbifurcation(spruce, state, parms)\nNote that this predator-prey model only consists of one equation. There is no separate dynamic equation for the birds. The reason is that these budworm outbreaks happen in a few weeks. Birds do not reproduce on this time scale. Note that the variables are reparametrized (see Section 3.3.1). The predation term, in the original parametrization \\(- \\frac{BN^{2}}{A^{2} + N^{2}}\\), also has a logistic form that starts to accelerate at \\(N = A\\) up to the maximum level \\(B\\). The slow start A is used because birds only switch their diet to budworms when this population reaches a certain level (Ludwig, Jones, and Holling 1978). The fixed number of birds can only eat B budworms. This specific predation term is called the Holling type III model. All Holling types and their formulas are shown in Figure 5.5.\n\n\n\nFigure 5.5: The Holling functional response models. Type III is used in the Spruce Budworm model.\n\n\n\n\n5.1.7 Evaluation of ecological modelling\nUnderstanding the technical basics of dynamical systems theory is one thing, but actually building useful dynamical systems models is quite another. Every term in every differential equation of a model needs some underpinning. These models make many assumptions, both implicit and explicit. The Lotka-Volterra model, for example, assumes that the prey population grows exponentially in the absence of the predator, that the predator population dies off with the prey population and does not switch to other prey species, that the response of the predator population to changes in the prey population is direct and not delayed, that there is no spatial component to the model, and that the rates of change of the populations are proportional to their sizes, to name just a few. These assumptions are widely debated in the biological literature (Abrams et al. 2000), and modifications of these assumptions may have significant consequences. In fact, hundreds of extensions and variants have been proposed and studied.\nFor example, the original Lotka-Volterra model has no stable points, only limit cycles. While these cycles have been observed in nature, they are not overwhelmingly common. As we have seen, the dynamics of the system are significantly altered when prey growth is made dependent on prey density. This model has fixed-point equilibria instead of limit cycles.\nAdding a spatial component can also make a big difference, as shown in the example of hypercycles (see Szostak, Wasik, and Blazewicz 2016 for a brief review). Adding more prey and predator species also makes a difference (Johnson, Mumma, and St-Laurent 2019). There are many interesting options for the predator term in the prey equation. Tyutyunov and Titova (2020) compare 12 trophic functions, alternatives to the Holling functional responses. The options are overwhelming. Biologists face a problem here that I discussed in Chapter 1. Models easily become too complex. Recall that the traffic simulation models were extremely simple, yet sufficient to explain key phenomena.\nAn additional problem is that empirically testing all these different models is difficult. Although the quality of biological data is often superior to that of psychological data, biologists must also rely on the qualitative predictions of their models. Models in chemistry and especially physics can often be tested quantitatively. Transitions occur precisely at the predicted values of the control variables. Ecological models, much like those in psychology, do not allow for this level of prediction. This is a problem because if we can only test our model qualitatively (are there limit cycles or not, what type of transitions can be detected, is there hysteresis or not), many model choices are not particularly relevant. One of the most significant challenges in complex systems research in the life sciences and psychology is constructing dynamical system models that effectively address these data-related issues.\nA case in which this is less of an issue is the traffic example that I presented in Chapter 1. I asked you to play around with the online simulation. We now know the basics to better understand this model. The Wikipedia page on this model (‘Intelligent Driver Model’) presents the equations, which are also coupled ordinary differential equations. The implementation in Grind of the simplest case looks like this:\nmodel &lt;- function(t, state, parms){\n  with(as.list(c(state,parms)),{\n    x &lt;- state[1:n]\n    v &lt;- state[(n+1):(2*n)]\n    dx &lt;-  v # change in distance = speed\n    delta_v &lt;- v- m %*% v # difference in speed to next car\n    s_alpha &lt;- m %*% x - x -l #  distance to next car\n    s_alpha[n] &lt;- 100 # front car has no car in front\n    s_star &lt;- s0 + v * T + v * delta_v / (2*sqrt(a*b))\n    dv &lt;- a * (1 - (v/v0)^delta - (s_star/s_alpha)^2) # change in speed\n    return(list(c(dx,dv)))\n  })\n}\n\nn=50\np &lt;- c(l=5,v0=30,T=1.5,a=.73,b=1.67,delta=4,s0=2)\nx_init &lt;- (0:(n-1))*(p['s0']+p['l'])\nv_init &lt;- rep(0,n)\ns &lt;- c(x_init,v_init)\n\nm &lt;- diag(1, n, n); m= rbind(m[-1,],0) # order cars\n# simulation with front car suddenly breaking at t = 150\ndata=run(tmax=300,timeplot = F,table=T,after = 'if (t==150) state[2*n] = 0')\nmatplot(data[,2:(n+1)],type='l',bty='n',xlab='time',ylab = 'x')\n\n\n\nFigure 5.6: The traffic jam simulation described at https://en.wikipedia.org/wiki/Intelligent_driver_model. The top line represents the front car, which moves off immediately. Other cars are waiting for their turn. At t=150, the first car suddenly breaks off, creating a traffic jam for the later cars. The effect of this disturbance is greater for the last car than for the first car itself.\n\n\nUnderstanding the reasoning behind the differential equation is not so easy, but I want to make another point. The Wikipedia page gives parameters values with units (s, m/s or m/s2). One can also have dimension free parameters (the acceleration exponent). This dimensional analysis is a crucial step in modeling in physics but a weak point in biological and especially psychological applications. They hamper the quantitative test of models."
  },
  {
    "objectID": "ch5.html#psychological-models",
    "href": "ch5.html#psychological-models",
    "title": "5  Building dynamic system models",
    "section": "5.2 Psychological models",
    "text": "5.2 Psychological models\nIn this section, I present an overview of dynamical systems models in psychology, primarily in the form of systems of differential equations. Although the list is extensive, it is not exhaustive. It is important to explore different models and applications before embarking on your own modeling efforts.\n\n5.2.1 Response time models\nMany dynamic models have been proposed in the study of speeded decision making (Bogacz et al. 2006). The best-studied case is the two-alternative forced-choice task, where a stimulus is presented, and a choice must be made between two alternatives as quickly as possible. The stimulus could be an arrow pointing left or right. Accumulator models assume that noisy information is accumulated over time until a decision bound is reached and a motor response is initiated.\n\n\n\nFigure 5.7: A stochastic accumulator model of speeded decision making. Evidence accumulates in stochastic steps biased by the drift rate I (stimulus related). When one of the bounds is reached, a response is generated that may be incorrect if the bounds are too low.\n\n\nOne way to model this process is with a single stochastic linear differential equation, called the drift-diffusion model, with $I$as the stimulus-driven input:\n\\[\\begin{array}{r}\ndX = Idt + \\sigma dW\n\\end{array} \\tag{5.6}\\]\nAs before \\(dt\\) is moved to the left-hand side of the equation. \\(dW\\) is white noise, normally distributed with zero mean and with standard deviation \\(\\sigma\\) (set to .1 by default). \\(X_{t = 0} = 0\\), assuming no bias for one of the choice alternatives.\nThe implementation of the model in Grind is quite simple. The trick is again in the run statement, which adds white noise after each step2. We stop the run when either the negative or positive bound is reached.\nmodel &lt;- function(t, state, parms) {\n  with(as.list(c(state,parms)), {\n    dX = I\n    return(list(c(dX)))\n  })\n}\np &lt;- c(I=.01); s &lt;- c(X=0)\nbound &lt;- 1\nrun(table=T,method='euler', tstep=.1,\n    tmax=500,after=\"state&lt;-state+rnorm(1,mean=0,sd=0.1)*sqrt(tstep);\n    if(abs(state)&gt;bound) break\",ymin=-bound,ymax=bound)\nThe model explains observed response times and accuracies in terms of the underlying process parameters, drift rate and confidence bound. By fitting the model to the data, we can determine whether slow responses are due to a low drift rate (low skill or difficult task) or a conservatively chosen bound. The DDMs also explain the speed-accuracy tradeoff. If we set our confidence bound higher, we are slower but more accurate.\nA well-known extension of the drift diffusion model is the Ornstein–Uhlenbeck (O-U) model:\n\\[\\begin{array}{r}\ndX = (\\lambda x + I)dt + \\sigma dW\n\\end{array} \\tag{5.7}\\]\nFor \\(\\lambda &lt; 0\\) this process converges to \\(I/\\lambda\\) (assuming \\(\\sigma = 0\\)), while for \\(\\lambda &gt; 0\\) it diverges \\(.\\) For the psychological interpretation, I refer to Bogacz et al. (2006). The simplest two-dimensional model is the race model:\n\\[\n\\begin{align*}\ndX_{1} = I_{1}dt + \\sigma W_{1} \\\\\ndX_{2} = I_{2}dt + \\sigma W_{2}\n\\end{align*}\n\\tag{5.8}\\]\nNow two independent processes run (race) to one positive bound. The first one to arrive wins. More biologically inspired models involve inhibition. The model of mutual inhibition model:\n\\[\n\\begin{align*}\ndX_{1} &= (-k_{1}X_{1} - w_{1}X_{2} + I_{1})dt + \\sigma W_{1} \\\\\ndX_{2} &= (-k_{2}X_{2} - w_{2}X_{1} + I_{2})dt + \\sigma W_{2}\n\\end{align*}\n\\tag{5.9}\\]\nNote that these are all linear dynamical system that do not exhibit complex behavior. Examples of nonlinear alternatives are presented in Roxin and Ledberg (2008) and Verdonck and Tuerlinckx (2014) and discussed in Ratcliff et al. (2016).\nThe relations between different accumulator models are summarized in this figure from Bogacz et al. (2006). It shows that convenient models such as the DDM can be derived by constraints on the parameters from more biologically realistic models, such as the pooled and mutual inhibition model.\n\n\n\nFigure 5.8: Relations between the main evidence accumulator models of decision making. DDM is the drift diffusion model which can be derived from the mutual inhibition model by setting w = k and w + k to a large value.\n\n\n\n\n5.2.2 Dyadic models\nThe study of dyadic interaction lends itself to dynamic modeling. Dyadic interactions have been studied extensively in the field of caregiver-child interactions (Ainsworth et al. 2015). Here, we focus on a dyadic interaction in romantic relationships.\n\n5.2.2.1 Romeo and Juliet\nOne type of model can be traced back to publications by Rapoport (1960) and Strogatz (1988). I follow the setup described by Sprott (2004). Note that it was intended as a toy model to demonstrate dynamical modeling.\nThe model is about the interactions between Romeo and Juliet, where \\(R\\) and \\(J\\) represent the feelings of Romeo and Juliet. The change in feelings is supposed to be a function of the feelings of both people:\n\\[\\begin{align*}\n\\frac{dR}{dt} = aR + bJ \\\\\n\\frac{dJ}{dt} = cR + dJ\n\\end{align*}\n\\tag{5.10}\\]\nFirst note that the case of \\(b = c = 0\\) resembles the exponential model with solutions \\(R = {R_{0}e}^{at}\\) and \\(J = {J_{0}e}^{dt}\\), which converge (to 0) or diverge (to infinity) depending on whether a and d are negative or positive. Divergence, unbounded exponential growth of positive feelings is an attractive concept, but impractical, I’m afraid. We will see a more realistic setup in the next model. Nevertheless, this system of coupled linear differential equations is surprisingly rich in behavior. With the signs of the parameters we define very different romantic styles. Strogatz (1988) distinguishes the following:\n\nEager beaver: \\(a\\  &gt; \\ 0,\\ b\\  &gt; \\ 0\\), Romeo is encouraged by his own feelings as well as Juliet’s.\nNarcissistic nerd: \\(a\\  &gt; \\ 0,\\ b\\  &lt; \\ 0,\\) Romeo wants more of what he feels, but retreats from Juliet’s feelings.\nCautious (secure) lover: \\(a\\  &lt; \\ 0,\\ b\\  &gt; \\ 0\\), Romeo retreats from his own feelings but is encouraged by Juliet’s.\nHermit: \\(a\\  &lt; \\ 0,\\ b\\  &lt; \\ 0,\\) Romeo retreats from his own feelings as well as Juliet’s.\n\nJuliet may have his/her own style, which leads to complicated interactions. (Sprott 2004) and other sources give an extended analytical treatment of this model. Systems of linear differential equations can be solved analytically and the behavior of the equilibria can be characterized by the eigenvalues. Some knowledge of matrix algebra is required to understand this. If you want to learn more about dynamical systems, you should study matrix algebra and its applications in linear dynamical systems. I have chosen to leave it out of this book because most psychological dynamical systems models are nonlinear. Here we just use Grind to test some cases. I give three examples with three different sets of parameter values. In the first case, the initial mutual interest diminishes, in the second case, after some ups and downs, the relationship comes to nothing, while in the third case, the couple ends up in a cycle of hate and love.\nmodel &lt;- function(t, state, parms) {\n  with(as.list(c(state,parms)), {\n    dR &lt;- a*R+b*J\n    dJ &lt;- c*R+d*J\n    return(list(c(dR, dJ)))\n  })\n}\nlayout(matrix(1:6,3,2,byrow=T))\np &lt;- c(a=-1,b=1,c=.5,d=-1) # parameters\ns &lt;- c(R=0.1,J=.1) \nrun()\nplane(portrait=T,ymin=-1,xmin=-1,grid=3,vector=T,legend=F)\np &lt;- c(a=-.2,b=-1,c=1,d=0) # parameters\nrun(ymin=-.2,legend=F)\nplane(portrait=T,ymin=-1,xmin=-1,grid=2,tstep=.001,legend=F)\np &lt;- c(a=-.1,b=-1,c=1,d=0.1) # parameters\nrun(ymin=-.2,legend=F)\nplane(portrait=T,ymin=-1,xmin=-1,grid=3,tstep=.001,legend=F)\n\n\n\nFigure 5.9: Three different love affairs between Romeo and Juliet\n\n\nThe lines in the phase plots are the nullclines. Nullclines are the curves (straight lines in case of linear systems) for which the time derivatives of the behavioral variables \\(R\\) and \\(J\\) are zero. Where they intersect, stable or unstable fixed points can occur. Depending on the angle between the nullclines we get a fixed point (cases 1 and 2), a limit cycle (case 3), or divergence (not shown).\nRinaldi (1998) proposed an extension and a constraint to the model that makes it a bit more realistic and easier to study. The basic equation is now \\(\\frac{dR}{dt} = - aR + bJ + A_{J}\\), where a is interpreted as a forgetting parameter (constrained to be positive) and \\(A_{J}\\) is the attractiveness of the Julia. In this case a necessary and sufficient condition for asymptotic stability (i.e., having a fixed point) is that \\(ad &gt; bc\\).\nRinaldi also considers the case of a population of heterosexual men and women with different levels of attractiveness. The idea is that a man and a woman will leave their partner and bond together when both reach a more optimal level of love. Rinaldi analyses when and when not the population reach a stable state. This marriage assignment problem, as it is called, is an example of an assignment problem. The goal is to find a stable assignment of men to women, such that no man and woman prefer each other to their current partners (Gale and Shapley 1962).\nSome other advanced variations of this model have been proposed. In these papers the analysis of the mathematical properties of the model gets much more attention than the psychological theory. What exactly the variables are and the reasoning behind certain model assumptions is often unclear. The work of Murray and Gottman is more interesting in this regard.\n\n\n5.2.2.2 The mathematics of marriage\nThe model of marriage developed by the psychologist John Gottman and the mathematical biologist James Murray (2002) is firmly grounded in psychological theory and data. The main phenomenon that inspired this modeling work is the finding by Gottman and Levenson (1992) finding that the patterns of interaction between couples, when discussing a major area of ongoing disagreement in their marriage, are predictive of divorce.\nThe model consists of two coupled difference equations, but I present the model in the form of differential equations3.\n\\[\n\\begin{align*}\n\\frac{dW}{dt} = I_{w}(H,a,b) - r_{w}W + W_{e}, \\\\\n\\frac{dH}{dt} = I_{h}(W,a,b) - r_{h}H + H_{e},\n\\end{align*}\n\\tag{5.11}\\]\nwhere influence functions \\(I_{w}\\) and \\(I_{h}\\) are defined conform\n\\[\\begin{array}{r}\nI(x,a,b) = \\frac{sign(x)}{1 + e^{a\\left( |x| - b \\right)}}.\n\\end{array} \\tag{5.12}\\]\nI made up this flexible function to allow for very different forms of influence (as we will see below). When both influences are zero (\\(a = - 8,b = - \\infty\\)), the state or mood of the wife (\\(W\\)) and the husband (\\(H\\)), converge to \\(W_{e}\\) and \\(H_{e}\\), with rates \\(r_{w}\\) and \\(r_{h}\\), respectively. \\(W_{e}\\) and \\(H_{e}\\) are the uninfluenced steady states of mood when the spouses de not interact.4\nHowever, if the influence function (\\(a = - 8, b = 0\\)) is such that a positive mood in one spouse provokes a positive mood in the other, while a negative mood provokes a negative mood, we expect a negative and a positive equilibrium depending on the initial states and uninfluenced steady state values.\nAnother more complex influence function (\\(a = - 8, b = 1\\)), assumes that only extreme mood states influence the other spouse.\nThis is implemented with:\nmodel &lt;- function(t, state, parms) {\n  with(as.list(c(state,parms)), {\n    dW &lt;- influence(H,a,b)-rw*W+We\n    dH &lt;- influence(W,a,b)-rh*H+He\n    return(list(c(dW,dH)))\n  })\n}\nlayout(matrix(1:9,3,3,byrow=T))\npar(mar=c(4,4,1,2))\ninfluence &lt;- function(x,a=-8,b=1) sign(x)/(1+exp(a*(abs(x)-b)))\np &lt;- c(rw=.6,rh=.6,We=.18,He=-.18,a=-8,b=Inf)\ns &lt;- c(W=0,H=0)\nfor(b in c(Inf,0,1)){\np['b']&lt;- b\ncurve(influence(x,-8,b),-3,3,xlab='W',ylab='H',lwd=2)\nplane(xmin=-2.5,xmax=2.5,ymin=-2,ymax=2,legend=F)\nfor(i in seq(-2,2,by=.25)) newton(s=c(W=i,H=i),plot=T)\nfor (i in 1:100)\n  run(state=c(W=rnorm(1,0,.5),H=rnorm(1,0,1)), tmax=50,ymin=-2,ymax=2,add=(i&gt;1),legend=F)\n}\nResulting in:\n\n\n\nFigure 5.10: Qualitative difference marriage equilibrium landscapes depending on the form of the influence function. In the first, they simply have no influence and both partners converge on their uninfluenced steady states of mood. In the second, the response to the partner’s mood is extreme, resulting in either a positive or negative mutual state. In the last case, the response to low positive or negative moods is close to zero, but extreme at higher levels. Now there are three stable states.\n\n\nThe three influence functions are shown in the first column, the null clines in the second, and a series of runs from random initial states in the third. The first case shows that the moods converge to \\(W_{e}\\) and \\(H_{e}\\), when there is no mutual influence. The second has two equilibria, with an unstable fixed point in the middle, while the last case has five fixed points, three of which are stable.\nI have kept the influence functions and most parameters the same for both spouses, but this is not necessarily the case (see the work of Gottman and Murray for discussion and alternative influence functions). It is possible to derive the equilibria analytically and to determine the stability of these equilibria (Gottman et al. 2002). They also propose a two-stage procedure for fitting of the model to data consisting of positive and negative speaker interactions using a bilinear influence function. A more advanced statistical approach is proposed in (hamakerUsingThresholdAutoregressive2009?).\n\n\n\n5.2.3 The van Geert models\nIn a series of papers, Paul van Geert proposed dynamical systems models for developmental processes (Den Hartigh et al. 2016; van Geert 1998, 1991). The idea is that cognitive and language abilities grow over time in an autocatalytic process constrained by a limited capacity, similar to the logistic growth of populations.\nVan Geert has proposed many different models, I will give just one example. van Geert (1991) introduced a system of two coupled differential equations to model where the growth rate of one cognitive ability depends on the level of another cognitive ability:\n\\[\n\\begin{align*}\nX_{t + 1} = (a - bY)X - \\frac{aX^{2}}{K} \\\\\nY_{t + 1} = (c - dX)Y - \\frac{cY^{2}}{K}\n\\end{align*}\n\\tag{5.13}\\]\nThis can be implemented as follows:\nmodel &lt;- function(t, state, parms) {\n  with(as.list(c(state,parms)), {\n    dX &lt;- (a + b * Y) * X - a * X^2 / K\n    dY &lt;- (c + d * X) * Y - c * Y^2 / K\n    return(list(c(dX, dY)))\n  }) }\n\nlayout(matrix(1:4,2,2))\n# Set parameter values and run the model:\np &lt;- c(K = 1, a = 0.4, b = -0.05, c=.4, d = -0.15)\ns &lt;- c(X = 0.01, Y = 0.01)\nrun(method = \"euler\", tstep = 1)\nplane(portrait = TRUE,grid=4)\np &lt;- c(K = 1, a = 0.05, b = -0.1,  c = 0.05, d = -0.09)\ns &lt;- c(X = 0.0126, Y = 0.01)\nrun(tmax = 1500, method = \"euler\", tstep = 1)\nplane(portrait = TRUE,grid=4)\n\n\n\nFigure 5.11: The development of two interrelated cognitive abilities in one of the van Geert models. In the left case they coexist, in the right case one ability suppresses the other.\n\n\nSo, there are basically two outcomes, either both grow, or one grows and suppresses the other. Note that the method is set to ‘Euler’ to simulate difference equations.\n\n\n5.2.4 The Polya Urn model of the third source\nAnother type of discrete dynamical systems model is the Polya-Urn model, which is relevant to understanding developmental processes in psychology. The Third Source Hypothesis (P. C. M. Molenaar, Boomsma, and Dolan 1993) proposes that the development of complex living systems is influenced by three sources of variation: genetic variation, environmental variation, and self-organizing processes. Based on a series of studies, (Gärtner 1990) concluded that 70-80% of the variation in body weight in inbred mice appears to be due to a third component that generates biological variability in addition to genetic and environmental influences.\nA simple and, in my opinion, insightful dynamical model for this effect is the Pólya-Eggenberger urn model (Mahmoud 2008). In this discrete dynamical model, we add marbles to an urn containing some red and blue marbles. We could start with 2 blue and 1 red marbles. we randomly take out a marble. If we draw a blue marble, we put it back with another blue marble. If we draw a red marble, we put it back and add a red marble. Initially, \\(p(blue) = 2/3\\), but what will happen to that over time when we have more and more marbles?\nMy intuition was simply wrong, and in my experience, this is true for the vast majority of people. But take your own guess. What happens is shown in Figure 5.12. Each time you run the process, \\(p(blue)\\) reaches a stable state, but the value of that state is random. What happens is that early (random) samples have a huge influence on the long-term dynamics. This creates a Matthew Effect (the rich get richer, and the poor get poorer).\n\n\n\nFigure 5.12: The Polya Urn model. A random marble is sampled and placed back with an extra marble of the same color. The evolution of the probability of picking a blue marble is unpredictable and converges to a random number. This mechanism may play a role in the Matthew Effect\n\n\nSavi et al. (2019) provide a developmental interpretation. Imagine a girl receiving a tennis racket for her birthday. First, she practices the backhand twice at home, but incorrectly. Then, during the first tennis lesson, her trainer demonstrates to her the correct backhand. She now has three experiences, two incorrect and one correct. Now, suppose her backhand development is based on a very simple learning schema. Whenever a backhand return is required, she samples from her earlier experiences, and the sampled backhand is then added to the set of earlier experiences. Then the cumulation of experiences follows the Polya urn scheme. While she has the potential to become a tennis master, her twin sister, who had less fortunate initial experiences, decides to quit tennis lessons within the first year. This model is consistent with many developmental theories (e.g., the Critical Period Hypothesis), but these theories lack a formal approach.\n\n\n5.2.5 The panic model\nIn recent years, we have been working on a model of panic disorder (Haslbeck et al. 2022; Robinaugh et al. 2019). In theories of panic disorder, there is a reinforcing feedback loop between arousal and perceived threat. When an increase in arousal is perceived as a threat (e.g., a heart attack), arousal increases further. This “vicious cycle” results in a panic attack (Clark 1986). Thus, these theories posit two causal effects: an effect of perceived threat on arousal and an effect of arousal on perceived threat.\nWe will further assume that the effect of perceived threat on changes in arousal is essentially linear while the causal effect of arousal on perceived threat is nonlinear (S-shaped). For the argument, see our paper. It could be argued that both are nonlinear, but this does not fundamentally change the qualitative behavior of the model. The central part of the model consists of two coupled differential equations:\n\\[\\frac{dT}{dt} = \\  - T + bA\\]\n\\[\\begin{array}{r}\n\\frac{dA}{dt} = \\frac{1}{1 + e^{- \\alpha(T + \\beta)}} - A\n\\end{array} \\tag{5.14}\\]\nThis looks a bit like the Romeo and Juliet model, but now the effect of perceived threat T on the change in arousal A is a logistic function that starts at one and grows to 1. The location is determined by \\(\\beta\\) and the acceleration or steepness is determined by \\(\\alpha\\).\nAn implementation and simple illustration is:\nmodel &lt;- function(t, state, parms) {\n  with(as.list(c(state,parms)), {\n    dA &lt;- -A + b*T  \n    dT &lt;- -T + 1/(1+exp(-alpha*(A+beta)))\n    return(list(c(dA, dT)))\n  })\n}\np &lt;- c(b=1, alpha=12, beta=-.7) \ns &lt;- c(A=0, T=0) \n# arousal increase for time t in 20:30, leads to panic, which after some time ('30 min') disappears\nlayout(1:2)\nplane(vector=T,xmin=0,ymin=0,xmax=1,ymax=1.1,legend=F) \nnewton(s=c(A=0,T=0),plot=T)\nnewton(s=c(A=0.8,T=.8),plot=T)\nnewton(s=c(A=1,T=1),plot=T);\nrun(after=\"if(t&gt;20&t&lt;30)state[1]&lt;-1;state&lt;-state+rnorm(2,mean=0,sd=0.1)\")\nThe \\(\\beta\\) parameter is set so that the non-panic mode dominates, but the panic mode is present (a metastable state) but can be easily disturbed (see plane). For \\(20 &lt; t &lt; 30\\), arousal is set to a high value, resulting in a high perceived threat. But because we also added some noise to both processes, after some time both arousal and perceived threat jump back to low values.\nThis dynamic of this model is the cusp, as can be checked with:\np &lt;- c(b=1,alpha=12,beta=-.5)\nstart &lt;- newton(s=c(A=.1,T=.1)) \ncontinue(start,x=\"beta\",y=\"T\",xmin=-1,xmax=1,ymax=1) \ncontinue(start,x=\"alpha\",y=\"T\",xmin=-1,xmax=20,ymax=1) \nstart &lt;- newton(s=c(A=1,T=1)) # finds a minimum starting from X = -1\ncontinue(start,x=\"alpha\",y=\"T\",xmin=-1,xmax=20,ymax=1,add=T) \nIn Robinaugh et al. (2019), this model is extended with other processes, such as arousal and escape schemes, that operate on the parameters of the basic model. These are slower processes that are modeled on different time scales.\n\n\n\nFigure 5.13: The panic model. Arousal is set high between time is 20 and 30, but panic persists due to the hysteresis effect. Eventually, due to noise, it escapes from the metastable attractor at A = T = 1.\n\n\n\n\n5.2.6 Neural models: van der Pol and different time scales\nImagine taking the cusp equation \\(\\frac{dX}{dt} = {a + bX - X}^{3}\\), with \\(b=1\\), such that we have hysteresis. But now we make \\(a\\), or actually \\(da/dt\\), a function of \\(X\\): \\(\\frac{da}{dt} = - \\varepsilon X\\), where \\(\\varepsilon\\) is small constant. If we set \\(\\varepsilon\\) to .05, \\(a\\) changes 20 times slower than \\(X\\). What happens now is that with \\(X = 1\\) and \\(a = 0\\), \\(a\\) decreases up to the point where \\(X\\) jumps to a negative value. Now \\(a\\) increases, resulting to a new jump to a positive value of\\(\\ X\\). And this loop will continue endlessly.\nmodel &lt;- function(t, state, parms){\n  with(as.list(c(state,parms)),{\n    dX &lt;-  a + b*X - X^3        # cusp\n    da &lt;- -e*X\n    return(list(c(dX,da)))\n  })\n}\n\ns &lt;- c(X=.1,a=0); # initial state and parameter values\nlayout(matrix(1:4,2,2,byrow=T))\np &lt;- c(e=.05,b=-.5)\nrun(ymin=-.1,main='b = -.5',legend=F)\nplane(xmax=2,ymin=-1,ymax=2,xmin=-2,portrait=T,grid=2,main='b = -.5')\np &lt;- c(e=.05,b=1)\nrun(ymin=-1.5,main='b = 1',legend=F)\nplane(xmax=2,ymin=-1,ymax=2,xmin=-2,portrait=T,grid=2,main='b = 1')\n\n\n\nFigure 5.14: Two runs of the van der Pol oscillator. For high b this system oscillates between the two stables states of the cusp. The black dots represent different initial states.\n\n\nThe plots illustrate this behavior. For \\(b &lt; 0\\), \\(X\\) converges to a fixed point, for \\(b &gt; 0\\) we see cyclic jumps up and down. This oscillator is basically the famous van der Pol oscillator, originally written in the form\n\\[\\begin{array}{r}\n\\frac{d^{2}X}{dt^{2}} = \\mu\\left( 1 - X^{2} \\right)\\frac{dX}{dt} - x\n\\end{array} \\tag{5.15}\\]\nSuch a second-order differential equation can be reduced to first-order systems with multiple equations, which is the form required for ‘Grind’. This model is of (neuro-)psychological interest because it is a special case of the FitzHugh-Nagumo model for neuronal excitability (Izhikevich and FitzHugh 2006):\n\\[\n\\begin{align*}\n\\frac{dV}{dt} = V - \\frac{V^{3}}{3} - W + I \\\\\n\\frac{dW}{dt} = .08(V + .7 - .8W)\n\\end{align*} \\tag{5.16}\\]\nThe equation for \\(V\\), the membrane potential, has a cubic nonlinearity that allows regenerative self-excitation via positive feedback, and \\(W\\), a recovery variable, provides linear negative feedback. \\(I\\) represents the input. The main phenomena in this model are shown in:\n\n\n\nFigure 5.15: The dynamics of the FitzHugh–Nagumo model.\n\n\nThe FitzHugh–Nagumo model itself is a simplified version of the famous Hodgkin–Huxley model, consisting of four differential equations, that models the activation and deactivation dynamics of a spiking neuron in more detail. This model is for a single neuron. Crucial is that second equation is a slow process. Time-scale effects also play an important role in learning in neural networks. In most neural networks, there is a fast equation for updating neuron activities and a much slower equation for updating the connection strengths.\nOther applications of the van der Pol model concern extensions of the HKB model (see Section 4.3.3), the sleep-wake cycle (Forger, Jewett, and Kronauer 1999), multistable perception (Fürstenau 2014), developmental processes (P. Molenaar and Oppenheimer 1985), and bipolar disorder (Daugherty et al. 2009). One case where it seems to be especially useful in in modeling the wake sleep cycle.\n\n\n5.2.7 Budworms and Beers\nBuilding nonlinear dynamical models of psychological processes from scratch is difficult. What you have learned so far in this book is probably not enough. The knowledge you now have will allow you to study existing models from different fields and to collaborate with experts in dynamical modeling. You now have the basic language for communicating about such models.\nBut even when you work with experts in dynamic modeling, building useful models is far from easy. I recommend following, at least roughly, the steps we proposed in our theory construction methodology (Borsboom et al. 2021). The key is to formulate phenomena, replicated recurring patterns in data, that need to be explained. This requires a good knowledge of existing verbal theories and, if they exist, alternative formal models. I find the process of formalizing a verbal theory or model fascinating. It tends to be very confusing. Suddenly it is unclear what the basic assumptions are, what mechanism is really being proposed in some psychological theory, and what actually the time scales are.\nAs an example, I mention the well-known investment theory of Cattell (1987), in which fluid intelligence is invested in crystallized intelligence. I knew this theory for a long time before I tried to translate it into dynamical equations. But it was not so easy. I began to wonder why it was called an investment theory in the first place. When you invest in something, it becomes less at first, but more in the future. Is that really what Cattell meant? The phenomena, the data patterns, suggest something else, because fluid intelligence grows rapidly and declines slowly after adolescence. Crystallized intelligence grows more slowly, but never really declines. Where the return on investment is, is unclear. I would not argue that Cattell’s theory is nonsense, and a possible model is proposed in the next chapter (Section 6.3.1.3), but this illustrates that the process of formalization is itself a test for verbal theories.\nAnother problem is that if we build our own dynamic model, there is a clear risk that we will not fully understand the model. We have seen that some very simple models already show amazingly complex behavior.\nMy favorite approach to cope with these issues is analogical modeling, or basically copying models. We used the Ising model to model attitudes and the mutualistic Lotka-Volterra model to model intelligence. Both are explained in the next chapter. Here, I will use addiction as an example, focusing on a selection of key phenomena (and for now ignoring many others).\nWe have reviewed existing formal models of addiction in van den Ende et al. (2022). Most of these models are quite complicated. I want the model of the individual addict to be as simple as possible. The reasons for this will become clear in the last chapter when we include social effects. The key phenomena are that initiation, cessation, and relapse are often discontinuous processes. The verbal theories we adapt are dual-process models in which an automatic process of using more and more is controlled by a non-automatic process, self-control.\nInstead of creating our own model, we look for well-studied models in other sciences, which led me to the spruce budworm model:\n\\[\\begin{array}{r}\n\\frac{dN}{dt} = r_{b}N\\left( 1 - \\frac{N}{K} \\right) - \\frac{BN^{2}}{A^{2} + N^{2}}\n\\end{array} \\tag{5.17}\\]\nBut now we interpret the variables and parameters as follows. Let’s say then \\(N\\) is the number of drinks you consume. The time scale is a day or an evening (depending on when you have your first beer). \\(K\\) is the upper limit of drinks you can take, either because of lack of availability or, worse, because you just collapse. \\(r_{b}\\) is the addiction sensitivity. If this is too low (\\(r_{b} &lt; 0\\)), the zero state is stable. The logistic function seems to be a reasonable choice. Drinking might start of a bit slow, then accelerates and levels off at \\(K\\). This happens when there is only an autonomous process. The second term, the predator term, is now interpreted as self-control. This is not something that changes on the time scale of a day, so as in the case of the birds, a second equation is not required. \\(A\\) (or actually \\(1/A\\)) is a responsiveness parameter, the number of drinks at which self-control is activated, which may not be at the first or second beer. \\(B\\) is the maximum level of self-control. As in the original model this term is a Holling type III form (see Figure 5.5). We could also insert a Holing type IV form, with the idea that self-control deteriorates after too many drinks. Depending on the values of the parameters one may not drink at all (\\(r_{b} &lt; 0\\) drink at a recreational level or have an ‘outbreak’ to heavy use.\nThe advantage of this type of analogical modelling is that we already know everything about the model. We know it is a cusp and we have already made the bifurcation diagram. There are also disadvantages or ambiguities.\nFirst, the definition of \\(N\\) is imprecise. Is it the blood alcohol concentration, the number of drinks, or some other quantity?\nSecond, the choice of a logistic function for the autonomous part seems reasonable but is not derived from first principles. One could also assume a linear function with a ceiling at \\(K\\).\nThird, and relatedly, the self-control function is also not derived from first principles. An additional problem is that we cannot measure this term directly (duckworthSelfControlGritRelated2014?).\nFourth, this model may not work for all addictions or should be adapted to specific cases. An example is smoking. First, for smoking, the intermediate recreational state is very unstable (Epskamp et al. 2022), and the autocatalytic effect described by the logistic equation seems less appropriate for smoking. For alcohol, the Holling type IV seems to be a good choice for the self-control term as alcohol directly impairs brain regions involved in self-control (Remmerswaal et al. 2019). For gambling, Holling Type III may be sufficient.\nFifth, processes at other timescales are missing. The model seems to work well for the time scale of a day or an evening. Other relevant timescales are minutes (direct effect of alcohol intake on the brain), weeks (abuse is often concentrated on weekends), and months. On timescales of months or even years, the parameters \\(r_{b}\\), \\(K\\) and \\(B\\), may change. For example, experienced drinkers can drink more, for instance. Also, the \\(r_{b}\\), addiction sensitivity, may slowly increase over time. This can be taken into account with additional equations. Furthermore, \\(K\\), \\(A\\) and \\(B\\) could change as an effect of the social network. Non-drinkers might increase \\(A\\), while other users in the social network might increase \\(K\\) (availability).\nThese modeling issues are serious but at the same time also very interesting. Ambiguities in our thinking about psychological systems come to light in the process of building concrete mathematical models (Borsboom et al. 2021).\n\n\n5.2.8 Cascading transitions in multifigure multistable perception\n\n5.2.8.1 Interacting cusps\nIn Section 5.2.6, we studied the van der Pol oscillator. In that model the normal variable of the cusp was itself a dynamic variable \\(\\frac{da}{dt}= - \\varepsilon X\\). Instead of a linear equation, we could also use a cusp. We then get:\n\\[\n\\begin{align*}\n\\frac{dX}{dt} = {aY + bX - X}^{3} \\\\\n\\frac{dY}{dt} = {cX + dY - Y}^{3}\n\\end{align*} \\tag{5.18}\\]\nThis model, first proposed by Kadyrov, was analyzed in detail by (abrahamComputationalUnfoldingDoublecusp1991?). We can study this model in Grind by specifying:\nmodel &lt;- function(t, state, parms) {   \n  with(as.list(c(state,parms)), {\n    dX &lt;- a*Y + b*X - X^3 \n    dY &lt;- c*X + d*Y - Y^3\n    return(list(c(dX, dY))) \n  })\n}\nDepending on the choice of the parameters and initial values many different things can happen. (abrahamComputationalUnfoldingDoublecusp1991?) created bifurcation diagrams to summarize the qualitatively different regimes. We will restrict ourselves to the case where \\(b = d = 1\\), and \\(a\\) and \\(c\\) are varied. The bifurcation diagrams and associated phase planes are shown in Figure 5.16.\n\n\n\nFigure 5.16: On the left the bifurcation diagram for the double cusp (b = d = 1) is shown. The figures on the right show the phase planes associated with the four different cases in the bifurcation diagram. Case a has 9 fixed points, 4 of which are stable. Case b has 5 fixed points, 2 of which are stable. Case c has 3 fixed points, 2 of which are stable. Case d is special because it has a limit cycle, the Kadyrov oscillator.\n\n\nThe phase planes of Figure 5.16 can be made with:\nlayout(matrix(1:4,2,2))\ns &lt;- c(X=0,Y=0) \nfor(i in c('a','b','c','d'))\n{\n  if (i == 'a') p &lt;- c(a=.3,b=1,c=.3,d=1)\n  if (i == 'b') p &lt;- c(a=.6,b=1,c=.6,d=1)\n  if (i == 'c') p &lt;- c(a=1,b=1,c=1,d=1)\n  if (i == 'd') p &lt;- c(a=1,b=1,c=-1,d=1)\n  plane(tstep=0.5,portrait=(i=='d'),xmin=-2,ymin=-2,xmax=2,ymax=2,\n        legend=F,grid=2,main = paste(\"Case \",i)) # make a phase portrait (Fig 1c)\n  if (i != 'd') for(i in 1:200) newton(c(X=runif(1,-2,2),Y=runif(1,-2,2)),plot=T) else\n    newton(c(X=0,Y=0),plot=T)\n}\ns &lt;- c(X=0.1,Y=.1) \np &lt;- c(a=1,b=1,c=-1,d=1)\nrun(tmax=20,tstep=0.1,ymin=-2,ymax=2) # Kadyrov oscillator\nThe last three lines of this code show the Kadyrov oscillator:\n\n\n\nFigure 5.17: The Kadyrov oscillator. Y attracts X to its state (as $d = 1$), but X pushes Y away (as $c = - 1$), resulting in oscillations.\n\n\nIf we simplify this analysis a bit to stable fixed points only, we see three regimes:\n\nCase a (weak interactions): Each cusp has two stable states, the combination of a negative and a positive state is possible because the interaction strength \\(a\\) and \\(c\\) are too weak.\nCase b and c (strong interactions): The combination of a negative and a positive state is now impossible because the interaction strengths \\(a\\) and \\(c\\) are too strong. The equilibria X* and Y* are both positive or both negative.\nCase d (opposite interactions): \\(a\\) and \\(c\\) have opposite signs, leading to oscillations.\n\n(abrahamComputationalUnfoldingDoublecusp1991?) generalize the model to:\n\\[\\frac{dX}{dt} = {a_{0} + a_{1}Y + (b_{0} + b_{1}Y)X - X}^{3}\\]\n\\[\\begin{array}{r}\n\\frac{dY}{dt} = {c_{0} + c_{1}X + \\left( d_{0} + d_{1}X \\right)Y - Y}^{3}\n\\end{array} \\tag{5.19}\\]\nsuch that now both the splitting and normal variable of the cusp are linear functions of the behavioral state of the other cusp. This can be further generalized to a system of \\(N\\) cusps by:\n\\[\\begin{array}{r}\n\\frac{dX_{i}}{dt} = a_{0i} + \\sum_{j \\neq i}^{}{a_{ij}X_{j}} + b_{0i}X_{i} + \\sum_{j \\neq i}^{}{b_{ij}X_{i}X_{j}} - {X_{i}}^{3}\n\\end{array} \\tag{5.20}\\]\nIn this model, \\(a_{0i}\\) is the intercept of the normal variable and the off-diagonal elements of matrix \\(a\\) are the slopes of the effect of the other cusps on the normal variable. The diagonal elements of \\(a\\) are set to 0. The \\(b_{0i}\\) values are the intercepts of the splitting variable. The \\(b_{ij}\\) values of matrix b (with diagonal = 0) are the slopes of the effect of other cusps on the splitting variable value of \\(X_{i}\\).\nThe cascading transition model has been proposed independently in various research areas. The idea of cuspoidal nets (\\(N&gt;3\\)) as a neural network has been mentioned in (abrahamCuspoidalNets1991?), analyzed in (hoffmannTeachableNeuralNetwork1986?) and (izhikevichMultipleCuspBifurcations1This1998?). (castroArtificialImmuneSystems2003?) discuss this model in the context of adaptive immune systems. The most recent application is in climate research (dekkerCascadingTransitionsClimate2018?; vonderheydtCascadingTransitionsClimate2019?; kloseEmergenceCascadingDynamics2020?). The idea of a cascade of collapsing subsystems in the climate is a frightening one. The applications involve special cases of Equation \\(40\\), such as the case where one cusp influence the other, but not vice versa. The case where \\(b_{ij} \\neq 0\\) has not been applied to my knowledge. A recent related approach using coupled van der Pol oscillators is described in Monsivais-Velazquez et al. (2020).\nI will give a psychological example of this multivariate model, concerning perception, in the next section.\n\n\n5.2.8.2 Application to perception\nNow take a look at Figure 5.18. This is a special case of multistable perception, which I call multifigure multistable perception.\n\n\n\nFigure 5.18: Multifigure multistable perception. Verify three phenomena: a) some attention or focus is required to see three-dimensional cubes, b) spontaneous transitions in the perception of cubes occur, c) such transitions affect the perception of neighboring cubes.\n\n\nWe can build a dynamical systems model of these perceptual phenomena by using the cascading transition model setup. We define \\(X\\) as the percept of the cube. \\(X = 0\\) means that no cubes are perceived, only lines and colored parallelograms. \\(X &gt; 0\\) represents for ‘front’ view, and \\(X &lt; 0\\) the ‘back’ view (cf. Figure 3.2). The cusp model for one cube is \\(\\frac{dX}{dt} = {a + bX - X}^{3}\\) , where \\(a\\) is the bias parameter and \\(b\\) is the attention parameter. If \\(a = 0\\) and \\(b &gt; 1\\) (no bias and some attention to the figure), we get bistable percepts and spontaneous switches in perception (assuming we add some noise, see Figure 5.2).\nNow we consider Figure 5.16 and apply Equation 5.20 . We have \\(N = 25\\) (a bit depending on how you count) The values of the parameters \\(a_{0i}\\) should be estimated from data, but for now we will assume no bias, so \\(a_{0i} = 0\\). We set \\(a_{ij} &gt; 0\\), meaning that we expect positive coupling between the cusps. The \\(b_{0}\\) is the attention vector. In the simulation we first assume that attention is low (\\(b_{0i} = - .3)\\). After an initial phase, we will set \\(b_{01} = 1\\), that is we suddenly attend to one cube. A biot later we set \\(b_{01}\\) back to -.3. However, we also set \\(b_{ij} &gt; 0\\), based on the idea that three-dimensional perception in one cube increases attention in the other cubes.\nTo make this model work we need to make one adjustment. We replace \\(\\sum_{j \\neq i}^{}{b_{ij}X_{i}X_{j}}\\) with \\(\\sum_{j \\neq i}^{}{b_{ij}X_{i}|X_{j}|}\\).5 This is because the increase in attention by the three-dimensional perception of neighbouring cubes does not depend on whether we perceive the ‘front’ or the ‘back’ view. Thus, the model for multifigure multistable perception is:\n\n\\[\\begin{array}{r}\n\\frac{dX_{i}}{dt} = a_{0i} + \\sum_{j \\neq i}^{}{a_{ij}X_{j}} + b_{0i}X_{i} + \\sum_{j \\neq i}^{}{b_{ij}X_{i}\\left| X_{j} \\right|} - {X_{i}}^{3}\n\\end{array} \\tag{5.21}\\]\nThe code to simulate this model is:\nset.seed(1)\nmodel &lt;- function(t, state, parms){\n  with(as.list(c(state,parms)),{\n    X &lt;- state[1:N]\n    b0_i &lt;- parms[1:N]\n    dX &lt;- -X^3 + a0_i + a_ij %*% X + b0_i*X + (X * b_ij %*%  abs(X))  # note abs(X)\n    return(list(dX))\n  })\n}\nN=10 # 10 necker cubes\nX &lt;- runif(N,-0.1,0.1) # initial state of X\na0_i &lt;- rep(0,N) # no  bias in percepts\na_ij &lt;- matrix(.02,N,N) # small couplings (normal)\ndiag(a_ij) &lt;-  0 # set diagonal of a to 0\nb0_i &lt;- rep(-.3,N) # attention initially low\nb_ij &lt;- matrix(.2,N,N) # some spread of attention (splitting)\ndiag(b_ij) &lt;- 0 # set diagonal of b to 0\n\ns &lt;- X;p &lt;- c(b0_i) # required for grind\nrun(after=\"if(t==33)parms&lt;-c(1,rep(-.3,N-1));\n           if(t==66)parms&lt;-rep(-.3,N);\n           state&lt;-state+rnorm(N,mean=0,sd=0.05)\",ymin=-1,ymax=2.5,\n            main='',ylab='X',legend=FALSE)\nb0_i &lt;- rep(-.3,100); b0_i[34:66]=1 # for plotting attention\nlines(b0_i,lwd=2,lty=3)\ntext(80,1.4,'Percepts')\ntext(80,-.5,'Attention')\nwhich gives:\n\n\n\nFigure 5.19: The multifigure Necker cube simulation. Initially attention is low and the percept is close to zero, representing the absence of three-dimensional perception. At t = 30, the attention intercept to one cube is increased to 1. At the t = 60 it is set back to its initial low value. However, this one cube is now perceived as a cube, and the perception spreads to other cubes. They also increase overall attention, so that the perception of cubes continues after t = 60.\n\n\nThere is much more to be said about this model and its empirical validation. One idea is to look at different stimuli like the one in Figure 5.20.\n\n\n\nFigure 5.20: Two embedded Necker cubes. The one on the left seems to have a positive coupling $a_{ij} &gt; 0$, while the one on the right seems to be switch independently ($a_{ij} &gt; 0)$. You can verify this introspectively. Adapted from https://royalsocietypublishing.org/doi/10.1098/rstb.2011.0365"
  },
  {
    "objectID": "ch5.html#causal-loop-diagrams",
    "href": "ch5.html#causal-loop-diagrams",
    "title": "5  Building dynamic system models",
    "section": "5.3 Causal loop diagrams",
    "text": "5.3 Causal loop diagrams\nIn this chapter I focused on the construction of dynamical system models and introduced R tools to study such models numerically. This introduction was necessarily somewhat superficial. At the beginning of this chapter, I referred to some texts that I recommend for further reading. There are some more psychological models that I could have included. For example, the setup of dynamical field theory is a bit too complicated to replicate in Grind but I recommend studying this model (Schöner and Spencer 2016). In the next chapter, I will present a dynamical model of developmental processes with mutualistic (positive) interactions. Dynamical systems models of social interactions are presented in the last chapter. I have also touched on some issues regarding dynamical systems modeling in psychology. Since we will see several more examples in the next two chapters, I will leave a full discussion to the Epilogue of this book.\nOne popular approach to dynamical systems modeling that I haven’t touched on is the use of causal loop diagrams, as developed in the field of systems dynamics (Forrester 1993; Meadows 2008). As argued in Crielaard et al. (2022), the step from verbal theory to formal model may require an intermediate step of setting up a diagram that specifies the causal relationships between variables. The diagram of the panic model can be seen as an example. Related to causal loop diagrams are several dedicated software packages for system dynamics analysis. A free online and simple sofwaretool is Insightmaker (Fortmann-Roe 2014).\nInsightmaker provides a graphical model construction interface for dynamical systems modeling and agent-based modeling. As such, it can be used to implement the models of this and the previous chapter. A Lotka- Volterra example is shown in Figure 5.21. Insightmaker is easy to use. Studying some examples, found with “Explore Insights” may suffice. I have added some models discussed in this chapter with the tag ‘vdmaas’.\n\n\n\nFigure 5.21: Some screenshots of the Lotka-Volterra model in Insightmaker.\n\n\nInsightmaker has many powerful built-in functions, allows sensitivity testing as well as some sort of optimization. Personally, I prefer the approach of writing the equations and implementing them in R. One reason is that this is how you communicate models in papers. Another is that the equations help you think about analytical results, which are always preferable to simulations. Finally, we can use Grind or deBif to go beyond simple simulations and classify equilibria and perform bifurcation analysis. But for building causal loop diagrams of larger models to concretize theorizing without the direct goal of running them, Insightmaker is a great tool."
  },
  {
    "objectID": "ch5.html#exercises",
    "href": "ch5.html#exercises",
    "title": "5  Building dynamic system models",
    "section": "5.4 Exercises",
    "text": "5.4 Exercises\n\nPut the logistic equation into Grind, find out what the equilibria are, and determine for which values of \\(r\\) these are stable or unstable fixed points. (*)\nCheck this analytically. Which are the two equilibria X*? For which values of \\(r\\) are these fixed points stable? Does your result agree with the results of the previous exercise? (**)\nCreate the logistic map in Grind. Plot the time series for \\(r = 4\\). (*)\nMake a plot of the pitchfork bifurcation, analogous to Figure 5.3 (*)\nUse the spruce model from Section 5.1.6 and the bifurcation() function of the deBif package to recreate the bifurcation diagram shown in Figure 3.15 . Describe what you did and present the resulting figure. (**)\nImplement the SIR model for infectious diseases in R using Grind. Reproduce the diagram of the SIR model with \\(\\beta = 0.4\\) and \\(\\gamma = 0.04\\) on the Wikipedia page on Compartmental models in epidemiology.\nReproduce the simulation of the Polya Urn model shown in Figure 5.12. (**)\nImplement the FitzHugh-Nagumo model in Grind and replicate the Figure 5.15. No exact replication is required but the phase diagram should look similar (**)\nUse Insightmaker to create a causal loop diagram of the Romeo and Juliet model. Reproduce the case where the couple ends up in a shrinking cycle of hate and love (damping oscillator, second case of Figure 5.9). Submit the simulation plot. (**)\n\n\n\n\n\nAbrams, Peter A., Lev R. Ginzburg, Peter A. Abrams, Lev R. Ginzburg, Peter A. Abrams, and Lev R. Ginzburg. 2000. “The Nature of Predation: Prey Dependent, Ratio Dependent or Neither?” Trends in Ecology & Evolution 15 (8): 337–41. https://doi.org/10.1016/S0169-5347(00)01908-X.\n\n\nAinsworth, Mary D. Salter, Mary C. Blehar, Everett Waters, and Sally N. Wall. 2015. Patterns of Attachment: A Psychological Study of the Strange Situation. New York: Psychology Press. https://doi.org/10.4324/9780203758045.\n\n\nBogacz, Rafal, Eric Brown, Jeff Moehlis, Philip Holmes, and Jonathan D. Cohen. 2006. “The Physics of Optimal Decision Making: A Formal Analysis of Models of Performance in Two-Alternative Forced-Choice Tasks.” Psychological Review 113: 700–765. https://doi.org/10.1037/0033-295X.113.4.700.\n\n\nBorsboom, Denny, Han L J van der Maas, Jonas Dalege, Rogier A Kievit, and Brian D Haig. 2021. “Theory Construction Methodology: A Practical Framework for Building Theories in Psychology.” Perspectives on Psychological Science 16 (4): 756–66. https://doi.org/10.1177/1745691620969647.\n\n\nCattell, R. B. 1987. Intelligence: Its Structure, Growth and Action. Elsevier.\n\n\nClark, David M. 1986. “A Cognitive Approach to Panic.” Behaviour Research and Therapy 24 (4): 461–70. https://doi.org/10.1016/0005-7967(86)90011-2.\n\n\nCrielaard, Loes, Jeroen F Uleman, Bas D L Châtel, Sacha Epskamp, Peter M A Sloot, and Rick Quax. 2022. “Refining the Causal Loop Diagram: A Tutorial for Maximizing the Contribution of Domain Expertise in Computational System Dynamics Modeling.” Psychological Methods, May. https://doi.org/10.1037/met0000484.\n\n\nDaugherty, Darryl, Tairi Roque-Urrea, John Urrea-Roque, Jessica Troyer, Stephen Wirkus, and Mason A. Porter. 2009. “Mathematical Models of Bipolar Disorder.” Communications in Nonlinear Science and Numerical Simulation 14 (7): 2897–2908. https://doi.org/10.1016/j.cnsns.2008.10.027.\n\n\nde Boer, Rob J. 2018. “Simple Phase Plane Analysis and Parameter Estimation in R,” no. 20.\n\n\nDen Hartigh, Ruud J. R., Marijn W. G. Van Dijk, Henderien W. Steenbeek, and Paul L. C. Van Geert. 2016. “A Dynamic Network Model to Explain the Development of Excellent Human Performance.” Frontiers in Psychology 7. https://doi.org/10.3389/fpsyg.2016.00532.\n\n\nEpskamp, Sacha, Han L. J. van der Maas, Roseann E. Peterson, Hanna M. van Loo, Steven H. Aggen, and Kenneth S. Kendler. 2022. “Intermediate Stable States in Substance Use.” Addictive Behaviors 129 (June): 107252. https://doi.org/10.1016/j.addbeh.2022.107252.\n\n\nForger, D B, M E Jewett, and R E Kronauer. 1999. “A Simpler Model of the Human Circadian Pacemaker.” Journal of Biological Rhythms 14 (6): 532–37. https://doi.org/10.1177/074873099129000867.\n\n\nForrester, Jay W. 1993. “System Dynamics and the Lessons of 35 Years.” In A Systems-Based Approach to Policymaking, edited by Kenyon B. De Greene, 199–240. Boston, MA: Springer US. https://doi.org/10.1007/978-1-4615-3226-2_7.\n\n\nFortmann-Roe, Scott. 2014. “Insight Maker: A General-Purpose Tool for Web-Based Modeling & Simulation.” Simulation Modelling Practice and Theory 47 (September): 28–45. https://doi.org/10.1016/j.simpat.2014.03.013.\n\n\nFürstenau, Norbert. 2014. “Simulating Bistable Perception with Interrupted Ambiguous Stimulus Using Self-Oscillator Dynamics with Percept Choice Bifurcation.” Cognitive Processing 15 (4): 467–90. https://doi.org/10.1007/s10339-014-0630-4.\n\n\nGale, D., and L. S. Shapley. 1962. “College Admissions and the Stability of Marriage.” The American Mathematical Monthly 69 (1): 9–15. https://doi.org/10.2307/2312726.\n\n\nGärtner, Klaus. 1990. “A Third Component Causing Random Variability Beside Environment and Genotype. A Reason for the Limited Success of a 30 Year Long Effort to Standardize Laboratory Animals?” Laboratory Animals 24 (1): 71–77. https://doi.org/10.1258/002367790780890347.\n\n\nGottman, John M., and Robert W. Levenson. 1992. “Marital Processes Predictive of Later Dissolution: Behavior, Physiology, and Health.” Journal of Personality and Social Psychology 63: 221–33. https://doi.org/10.1037/0022-3514.63.2.221.\n\n\nGottman, John M., James D. Murray, Catherine C. Swanson, Rebecca Tyson, and Kristin R. Swanson. 2002. The Mathematics of Marriage: Dynamic Nonlinear Models. The Mathematics of Marriage: Dynamic Nonlinear Models. Cambridge, MA, US: MIT Press.\n\n\nHaslbeck, Jonas M. B., Oisín Ryan, Donald J. Robinaugh, Lourens J. Waldorp, and Denny Borsboom. 2022. “Modeling Psychopathology: From Data Models to Formal Theories.” Psychological Methods 27: 930–57. https://doi.org/10.1037/met0000303.\n\n\nIzhikevich, Eugene M., and Richard FitzHugh. 2006. “FitzHugh-Nagumo Model.” Scholarpedia 1 (9): 1349. https://doi.org/10.4249/scholarpedia.1349.\n\n\nJohnson, Chris J., Matthew A. Mumma, and Martin-Hugues St-Laurent. 2019. “Modeling Multispecies Predatorprey Dynamics: Predicting the Outcomes of Conservation Actions for Woodland Caribou.” Ecosphere 10 (3): e02622. https://doi.org/10.1002/ecs2.2622.\n\n\nLudwig, D., D. D. Jones, and C. S. Holling. 1978. “Qualitative Analysis of Insect Outbreak Systems: The Spruce Budworm and Forest.” Journal of Animal Ecology 47 (1): 315–32. https://doi.org/10.2307/3939.\n\n\nMahmoud, Hosam. 2008. Polya Urn Models. CRC Press.\n\n\nMeadows, Donella H. 2008. Thinking in Systems: A Primer. Chelsea Green Publishing.\n\n\nMolenaar, Peter C. M., Dorret I. Boomsma, and Conor V. Dolan. 1993. “A Third Source of Developmental Differences.” Behavior Genetics 23 (6): 519–24. https://doi.org/10.1007/BF01068142.\n\n\nMolenaar, Peter, and Louis Oppenheimer. 1985. “Dynamic Models of Development and the Mechanistic-Organismic Controversy.” New Ideas in Psychology 3 (3): 233–42. https://doi.org/10.1016/0732-118X(85)90017-0.\n\n\nMonsivais-Velazquez, Daniel, Kunal Bhattacharya, Rafael A. Barrio, Philip K. Maini, and Kimmo K. Kaski. 2020. “Dynamics of Hierarchical Weighted Networks of van Der Pol Oscillators.” Chaos (Woodbury, N.Y.) 30 (12): 123146. https://doi.org/10.1063/5.0010638.\n\n\nMurray, J. D. 2002. Mathematical Biology. 3rd ed. Interdisciplinary Applied Mathematics. New York: Springer.\n\n\nMurray, James D. 1989. Mathematical Biology. Berlin, Heidelberg: Springer. https://doi.org/10.1007/978-3-662-08539-4.\n\n\nRapoport, Anatol. 1960. Fights, Games, and Debates. University of Michigan Press.\n\n\nRatcliff, Roger, Philip L. Smith, Scott D. Brown, and Gail McKoon. 2016. “Diffusion Decision Model: Current Issues and History.” Trends in Cognitive Sciences 20 (4): 260–81. https://doi.org/10.1016/j.tics.2016.01.007.\n\n\nRemmerswaal, Danielle, Joran Jongerling, Pauline J. Jansen, Charly Eielts, and Ingmar H. A. Franken. 2019. “Impaired Subjective Self-Control in Alcohol Use: An Ecological Momentary Assessment Study.” Drug and Alcohol Dependence 204 (November): 107479. https://doi.org/10.1016/j.drugalcdep.2019.04.043.\n\n\nRinaldi, Sergio. 1998. “Love Dynamics: The Case of Linear Couples.” Applied Mathematics and Computation 95 (2): 181–92. https://doi.org/10.1016/S0096-3003(97)10081-9.\n\n\nRobinaugh, Donald, Jonas Haslbeck, Lourens Waldorp, Jolanda Kossakowski, Eiko I. Fried, Alex Millner, Richard J. McNally, et al. 2019. “Advancing the Network Theory of Mental Disorders: A Computational Model of Panic Disorder.” PsyArXiv. https://doi.org/10.31234/osf.io/km37w.\n\n\nRoxin, Alex, and Anders Ledberg. 2008. “Neurobiological Models of Two-Choice Decision Making Can Be Reduced to a One-Dimensional Nonlinear Diffusion Equation.” PLOS Computational Biology 4 (3): e1000046. https://doi.org/10.1371/journal.pcbi.1000046.\n\n\nSavi, Alexander O., Maarten Marsman, Han L. J. van der Maas, and Gunter K. J. Maris. 2019. “The Wiring of Intelligence.” Perspectives on Psychological Science 14 (6): 1034–61. https://doi.org/10.1177/1745691619866447.\n\n\nSchöner, Gregor, and John P. Spencer. 2016. Dynamic Thinking: A Primer on Dynamic Field Theory. Oxford University Press.\n\n\nSoetaert, Karline, Thomas Petzoldt, and R. Woodrow Setzer. 2010a. “Solving Differential Equations in R : Package deSolve.” Journal of Statistical Software 33 (9). https://doi.org/10.18637/jss.v033.i09.\n\n\n———. 2010b. “Solving Differential Equations in R : Package deSolve.” Journal of Statistical Software 33 (9). https://doi.org/10.18637/jss.v033.i09.\n\n\nSprott, J. C. 2004. “Dynamical Models of Love.” Nonlinear Dynamics, Psychology, and Life Sciences 8 (3): 303–14.\n\n\nStrogatz, Steven H. 1988. “Love Affairs and Differential Equations.” Mathematics Magazine 61 (1): 35–35. https://doi.org/10.1080/0025570X.1988.11977342.\n\n\n———. 2018. Nonlinear Dynamics and Chaos with Student Solutions Manual: With Applications to Physics, Biology, Chemistry, and Engineering, Second Edition. CRC Press.\n\n\nSzostak, Natalia, Szymon Wasik, and Jacek Blazewicz. 2016. “Hypercycle.” Edited by Shoshana Wodak. PLOS Computational Biology 12 (4): e1004853. https://doi.org/10.1371/journal.pcbi.1004853.\n\n\nTyutyunov, Yu. V., and L. I. Titova. 2020. “From LotkaVolterra to ArditiGinzburg: 90 Years of Evolving Trophic Functions.” Biology Bulletin Reviews 10 (3): 167–85. https://doi.org/10.1134/S207908642003007X.\n\n\nvan den Ende, Maarten W. J., Sacha Epskamp, Michael H. Lees, Han L. J. van der Maas, Reinout W. Wiers, and Peter M. A. Sloot. 2022. “A Review of Mathematical Modeling of Addiction Regarding Both (Neuro-) Psychological Processes and the Social Contagion Perspectives.” Addictive Behaviors 127 (April): 107201. https://doi.org/10.1016/j.addbeh.2021.107201.\n\n\nvan Geert, Paul. 1991. “A Dynamic Systems Model of Cognitive and Language Growth.” Psychological Review 98: 3–53. https://doi.org/10.1037/0033-295X.98.1.3.\n\n\n———. 1998. “A Dynamic Systems Model of Basic Developmental Mechanisms: Piaget, Vygotsky, and Beyond.” Psychological Review 105: 634–77. https://doi.org/10.1037/0033-295X.105.4.634-677.\n\n\nVerdonck, Stijn, and Francis Tuerlinckx. 2014. “The Ising Decision Maker: A Binary Stochastic Network for Choice Response Time.” Psychological Review 121: 422–62. https://doi.org/10.1037/a0037012."
  },
  {
    "objectID": "ch5.html#footnotes",
    "href": "ch5.html#footnotes",
    "title": "5  Building dynamic system models",
    "section": "",
    "text": "I note that in many texts \\(\\frac{dX}{dt}\\) is written as \\(\\dot{X}\\).↩︎\nSimulating this model correctly is more difficult than one might expect. I refer to (tuerlinckxComparisonFourMethods2001?) for a discussion of methods.↩︎\nThe reason difference equations were used in the original model is that the data consist of turn takings in a conversation. This, however, does not lead to qualitative different results. With method='euler' and a change in \\(r_{w}\\) and \\(r_{h}\\) the difference model can be constructed.↩︎\nI follow the definition and notation of the original source, but this model is clearly not restricted to heterosexual relationships.↩︎\nWe could also use \\(X_j^2\\)↩︎"
  },
  {
    "objectID": "ch6.html#introduction",
    "href": "ch6.html#introduction",
    "title": "6  Psychological Network Models",
    "section": "6.1 Introduction",
    "text": "6.1 Introduction\nThe functioning (and dysfunctioning) of the human mind is best understood as a complex interplay of various psychological elements such as cognitive functions, mental states, symptoms, and behaviors. This interplay can be modeled using networks, psychological networks.\nPsychological networks are perhaps the most thriving area of complex systems research in psychology today. This chapter is about this new line of research. The paper on the mutualism model of general intelligence (Van Der Maas et al. 2006) can be seen as the root of this approach, but it really took off, as shown in Figure 6.1, when it was applied to clinical psychology (Borsboom 2017, 2008; Cramer et al. 2010), especially when the theoretical work was backed up with psychometric tools (Epskamp, Borsboom, and Fried 2018; Epskamp et al. 2012; Marsman and Rhemtulla 2022).\n\n\n\nFigure 6.1: The number of papers on the combination of symptoms and “network analysis” grows exponentially.\n\n\nIn this chapter I will present and discuss the theoretical and psychometric lines of research, accompanied by practical examples. However, I will begin with an introduction to network theory."
  },
  {
    "objectID": "ch6.html#network-theory",
    "href": "ch6.html#network-theory",
    "title": "6  Psychological Network Models",
    "section": "6.2 Network theory",
    "text": "6.2 Network theory\nIt is hard to imagine a discipline in which networks are not a central theme. Networks are the key to understanding systems ranging from particle physics to social networks, from ecosystems to the Internet, and from railways to the brain. The mathematics of network theory is not so easy to grasp, but fortunately the basic concepts and ideas are. I will give a brief introduction.\n\n6.2.1 Network concepts\nA network, a special type of graph, consists of nodes (often called vertices) and links (or connections or edges). I will explain some basic concepts here and illustrate each of them with R-code below.\nThe size of a network is equal to the number of nodes. Nodes can be anything, particles, neurons, words, people, train stations, etc. Nodes are connected by links. Links can be directed or undirected. For example, causal links are directed. Occasionally you see links from the node to itself. In causal networks this may represents self-excitation or if the weight is negative, self-inhibition. In some cases, links are simply present or absent, in other cases links are weighted, as in most neural networks. The list of all non-zero links is called the adjacency or edge list. The matrix of all weights, indicating the strengths of the connections between nodes, is called the adjacency or edge matrix. For an undirected network, the adjacency matrix is symmetric. For a network without self-loops, the diagonal of the adjacency matrix is zero.\nA connected network is a network in which every node is connected to every other node, possibly through intermediate nodes. In a fully connected network, or complete graph, every node is directly connected to every other node. Such a network has a density of one (i.e., the proportion of edges that is present).\nNodes can be in the center of a network or in the periphery. This should not be taken literally as psychological networks have no spatial dimension. Centrality measures quantifiy the relative influence, control, or connectivity of a node compared to other nodes in the network. There are many kinds of centrality measures, such as closeness centrality and degree centrality. The degree of a node is equivalent to the number of links it has. The average degree of a network is the average of this number over all nodes. The degree distribution can take several forms. A random graph, where nodes are connected randomly, has a binomial degree distribution. Most real-world networks have a skewed degree distribution. Sometimes nodes are organized into clusters or communities, where the density is higher than between clusters. The average shortest path length (ASPL) is the average number of edges that must be traversed to get from one node to another using the shortest paths (i.e., the fewest intermediate nodes).\nThere are many methods available in R for creating and visualizing networks and for computing properties of networks. The igraph and qgraph libraries are very useful. It is a good idea to do a bit of experimentation with this R code below by varying the parameter values.\nlibrary(igraph);library(qgraph)\ng1 &lt;- graph( edges=c(1,2, 2,3, 3,1), n=3, directed=F ) \nplot(g1) # an undirected network with 3 nodes\ng2 &lt;- graph( edges=c(1,2, 2,3, 3,1, 1,3, 3,3), n=3, directed=T ) \nplot(g2) # an directed network with self-excitation on node 3\nget.adjacency(g2) # weight matrix\nfcn &lt;- make_full_graph(10) # a fully connected network\nplot(fcn, vertex.size=10, vertex.label=NA)\nlayout(1)\nset.seed(1)\nadj &lt;- matrix(rnorm(100,0,.2),10,10) # a weighted adjacency matrix\nadj &lt;- adj*sample(0:1,100,replace=T,prob=c(.8,.2)) # set 80% to 0\nqgraph(adj) # plot in qgraph\nedge_density(fcn) # indeed 1\nedge_density(graph_from_adjacency_matrix(adj,weighted=TRUE)) # indeed .2\ncentralityPlot(qgraph(adj)) # note centrality() gives more indices\n\n\n\nFigure 6.2: A weighted directed network with self-loops. Red arrows indicate negative effects. OutStrength and InStrength represent two types of centrality measures in directed networks.\n\n\n\n\n6.2.2 Network types\nSimple networks do not have cycles. An example of an undirected acyclic graph is one with nodes on a line (but not a circle). Connected undirected acyclic graph are trees; if they are partially un-connected, they are forests. Directed acyclic graphs, such as family trees and citation networks, are called DAGs. Most current neutral networks are feedforward networks without cycles, but so-called recurrent networks have cycles.\nIgraph has an amazing number of functions for creating specific networks. Some examples are shown in Figure 6.3.\n\n\n\nFigure 6.3: Different network types generated with Igraph\n\n\nThe last case in the figure, preferential attachment, is of particular interest because it is created dynamically. It starts with a node and then new nodes are added that prefer links to nodes that already have many links. In the NetLogo model ‘Preferential Attachment simple’ you can see this growth process. This type of network is “scale-free”, meaning that the degree distribution looks the same no matter what scale you look at it (like fractals, see Section 2.7). Scale-free networks can be found in a wide range of real-world situations, from connections between websites to scientific collaborations. Scale-free networks have a degree distribution that follows a power law, with some nodes having many links, but most having only a few. Scale-free networks are useful for studying the robustness and vulnerability of networks to targeted attacks on highly connected nodes. Removing hubs with high degree potentially split the network into disconnected components and impede the network’s functionality. Because most nodes in the network have a small degree (few connections), randomly removing nodes tends not to disrupt the network’s overall structure. Preferential attachment networks are often called complex because it exhibits non-trivial structural patterns.\nAnother type of complex network is the small-world network. This type of network consists of clusters, but there are also links between the clusters. As a result, the distance between any two nodes in the network is always relatively short. A famous example is the six-handshake rule (also known as the six degrees of separation), which states that all people are six or fewer handshakes away from each other. For this reason, small-world networks are useful for studying the spread of information or disease through social networks.\nA prominent phase transition in graph theory is the emergence of a giant component. This happens when we start with a completely unconnected network of \\(n\\) nodes and randomly add links. We simply take a random node and connect it to another node to which it has no connection. This leads to many small unconnected clusters at first, but then a giant component suddenly appears. This happens when about \\(n/2\\) links have been added. You can verify this in the NetLogo model ‘Giant Component’. The implication is that randomly connected networks with a sufficient number of links are almost always connected networks.\nThis is just one example of network dynamics. We can distinguish between dynamics on node values (e.g., Lotka-Volterra models), on link values (connection strength in neural networks), and cases where the structure of the network is dynamic, as in the Giant Component example. These types of dynamics also coexist and interact. In neural networks, both node and link values are updated (on fast and slow time scales). We will see more examples in the next chapter.\nA relatively new topic in complex networks concerns higher order interactions. In most networks we only consider pairwise interactions, but third order and even higher order interactions may play a role (Battiston et al. 2021). Other work considers hierarchical complex networks (boccalettiStructureDynamicsMultilayer2014?). For more information on network concept and types, I first refer to Wikipedia. Another great (open) source is the book by Barabási and Pósfai (2016). A more concise overview is provided by (boccalettiStructureDynamicsMultilayer2014?)."
  },
  {
    "objectID": "ch6.html#psychological-network-models",
    "href": "ch6.html#psychological-network-models",
    "title": "6  Psychological Network Models",
    "section": "6.3 Psychological network models",
    "text": "6.3 Psychological network models\nThe idea of emergentism, discussed in Chapter 1, is that there are multiple, hierarchically ordered levels of description, and that one need not always refer to lower levels to explain phenomena. Psychology seems to have a problem with this: We are missing levels. The lowest relevant level seems to be the neural level. Neural activity can be aggregated into the activity of neural groups or even brain areas. At the highest level we have observed behavior, for example motor and speech actions. We have a similar gap between genes and psychological phenotypes (e.g., intelligence, personality, disorders). One attempt to bridge this gap is the watershed model (Penke, Denissen, and Miller 2007), in which many small genetic factors culminate, in a watershed-like process, into the phenotype.\nThe problem is that the biological and psychological levels are simply too far apart. What current deep learning neural networks can do is very impressive, but for reasoning, planning, and problem solving, some kind of symbolic processing seems to be necessary. A simple example is the computation of the outcome of 16 x 12, which requires active and systematic manipulation of mathematical symbols in working memory. This is an active area of research, but I’m not aware of any generally accepted solution (Garcez, Lamb, and Gabbay 2008). The current success of large language models in AI shows that a purely associative neural network approach to language is impressively powerful. Semantic networks also provide a fruitful intermediate level of analysis. I will not discuss semantic networks in this chapter, but they are one of the most successful applications of network science in psychology (Kumar 2021; Steyvers and Tenenbaum 2005).\nA final example of our struggle with a gap between levels is the use of latent variables in differential psychology. Latent variables are used in statistical modeling to represent unobservable or underlying factors that cannot be directly measured or observed. Differential psychology is concerned with individual differences, in contrast to experimental psychology that is concerned with mechanisms. This division comes from a renowned paper by Cronbach (1957) on the two disciplines of scientific psychology.\nExamples of extensively studied individual differences are personality and intelligence. Differential psychologists model relationships between observed behaviors, such as responses to test items and questionnaires, using latent variables. The statistical tools for analyzing latent variables come from modern test theory and structural equation modeling (SEM). These technically advanced tools are developed in a field called psychometrics.\nHowever, despite this technical sophistication, it is not always clear what latent variables are in psychometric models. Some researchers tend to think of them as purely statistical constructs that help summarize relationships between variables and make predictions. But more often, either implicitly or explicitly, latent variables are interpreted as real constructs, as common causes of observed measures (van Bork et al. 2017).\nThe latent variable or factor approach has long been dominant in differential psychology. When studying individual differences in a trait, psychologists generally follow the same approach. They construct tests, collect data, perform factor analysis, and propose one or more latent traits to explain observed individual differences. The justification for this approach, particularly in intelligence research, rests primarily on its predictive power.\nThe psychological network approach was developed in response to the factor approach. The main reason is that underlying common causes are unsatisfactory if they cannot be identified independently of the observed relationships they are supposed to explain (Van Der Maas et al. 2006). One consequence is that such an explanation does not provide guidance for possible interventions.\n\n6.3.1 Mutualism model: the case of general intelligence\n\n6.3.1.1 The g factor\nThe factor analytic tradition in psychology began with the study of general intelligence, and so does the psychological network approach.\nThe factor or g model of general intelligence was proposed by Spearman (1904) as an explanation of the positive manifold, i.e., the much replicated effect that subtests of intelligence test batteries are positively correlated. In the original simplest model, the observed test scores are statistically explained by a common factor, meaning that the correlations between test scores disappear when subjects have the same score on the common factor. In the Cattell-Horn-Carroll (CHC) model often referred to as the standard model, test scores load on subfactors such as visual processing (Gv) and fluid reasoning (Gf), which in turn are positively correlated. These latent correlations are explained by the general, higher order, factor g.\n\n\n\nFigure 6.4: The Cattell-Horn-Carroll (CHC) model of general intelligence. Blocks represent test scores (narrow), explained by the broad factors, which in turn are determined by the general factor g.\n\n\nThis model has been criticized extensively, including for its alleged implications for group differences in observed IQ and intervention strategies (Fraser 2008). In my view, some of the criticism is unwarranted. For example, the positive manifold is a very robust and widely replicated empirical phenomenon. It does not much matter what tests are included. That is, any reliable measure of creativity, emotional or social intelligence correlates positively with other IQ subtests. Nor is there much wrong with factor analysis as a statistical technique. To me, the most questionable aspect of g-theory is that it is not really a theory at all. The “elephant in the room” question is simply: What is g? What could this single factor be that explains everything? A century of research has not produced a generally accepted answer to this question. And this is a problem for many factor explanations in psychology (e.g., the big five of personality, the p-factor of psychopathology).\nIt is important to note that factor explanations are not always problematic. I like to use the example of heart disease, say a loose heart valve. This leads to symptoms such as shortness of breath, swelling of the ankles, dizziness, rapid weight gain, and chest discomfort. The relationship between these symptoms is explained by the underlying factor of heart disease. Treating a single symptom may provide some relief for that symptom, but not more. Only intervening on the cause will bring about real change. This is an example of a reflective interpretation of the factor model. When the factor is merely an index and not a common cause, we speak of a formative factor. Figure 6.5 explains the reflective and formative interpretations of the factor model.\n\n\n\nFigure 6.5: The reflective and formative interpretations of the factor model cannot be distinguished with correlational data, but they are very different. In the reflective model, the latent factor is a common cause (e.g., temperature) that causes the observations (e.g., different thermometers). Intervening on one thermometer (heating) will only change that particular thermometer because the X’s have no outgoing connections. In the formative interpretation, the factor is just an index (e.g., an economic index) that summarizes the state of many interacting components (companies). In this case, only interventions on the X’s can have an overall effect.\n\n\nSo, the fact that factor models fit intelligence data well does not tell us anything about the status of g. Is it a common cause or just an index?\n\n\n6.3.1.2 Mutualism model\nVan Der Maas et al. (2006) proposed an alternative model that is consistent with the formative interpretation of the factor model. The idea is that our cognitive system consists of many cognitive functions that develop over time in an autocatalytic process based on experience and training, but also due to weak positive reciprocal interactions between developing cognitive functions. Examples of such mutualistic interactions are those between short-term memory and cognitive strategies, language and cognition (syntactic and semantic bootstrapping), cognition and metacognition, action and perception, and performance and motivation (Van Der Maas et al. 2017). For example, babies learn to grasp objects by repeatedly reaching out, coordinating their hand and finger movements, and adjusting their grip. Through these actions, they gather sensory feedback, refining their perception and improving their grasping skills in a reciprocal learning process (Needham and Nelson 2023).\nTo model this we used the mutualistic Lotka-Volterra model, which is:\n\\[\\frac{dX_{i}}{dt} = a_{i}X_{i}\\left( 1 - \\frac{X_{i}}{K_{i}} \\right) + a_{i}\\sum_{\\begin{array}{r}\nj = 1 \\\\\nj \\neq i\n\\end{array}}^{W}\\frac{M_{ij}X_{i}X_{j}}{K_{i}}\\ \\ \\ for\\ i = 1..W\\]\n\\[\\begin{array}{r}\nK_{i} = c_{i}G_{i} + \\left( 1 - c_{i} \\right)E_{i} 42)\n\\end{array}\\]\nWhere $X_{i}X_{w}$denote the cognitive processes, \\(a\\) the growth rates, \\(K\\) the limited resources for each \\(X\\) (a weighted sum of a genetic (\\(G\\)) and an environmental (\\(E\\)) part), and \\(M\\) the interaction matrix. The second equation, assuming simple linear effects of genetics and environment, is sufficient to explain some typical phenomena in twin research, such as the increase in heritability with age (see the 2006 paper).\n\n\n\nFigure 6.6: The mutualism model. The self-loops, depicted in red, have an excitatory ($aX$) and an inhibitory part ($- aX^{2}/K$).\n\n\nWhen \\(M\\) contains mostly negative values, the model is known as a competitive Lotka-Volterra model. In this case, limit cycles and other nonlinear phenomena may occur (Hirsch 1985). For the mutualistic variant, with positive \\(M\\), we see either convergence to a positive state or exponential growth. This exponential growth is an unfortunate aspect of the Lotka-Volterra mutualism model. Robert May famously described this effect as an orgy of mutual benefaction (May, Oxford, and McLean 2007), which is not what we not see in nature, and all sorts of solutions have been proposed (Bascompte and Jordano 2013).\nThe mutualism model in Grind is specified as follows:\nmutualism &lt;- function(t, state, parms){\n  with(as.list(c(state,parms)),{\n    X &lt;- state[1:nr_var]\n    dX &lt;- a*X*(1-X/k) + a*(X * M %*% X)/k # using matrix multiplication\n    return(list(dX))\n  })\n}\nA simulation of the positive manifold requires us to run this model for multiple people and collect the \\(X\\)-values after some time points (tmax=60) for each person. We can then compute the correlations and check if they are positive. For each person, we resample \\(a\\), \\(K\\) and the initial values of \\(X\\), but \\(M\\) is the same across persons. Note that the M-values should not be set to high because we then end up in May’s orgy of mutual benefaction. In the second part of this chapter, we will generate more data with this model and fit network and factor models.\nlayout(matrix(1:2,1,2))\nnr_var &lt;- 12 # number of tests, abilities (W)\nnr_of_pp &lt;- 500\ndata &lt;- matrix(0,nr_of_pp,nr_var) # to collect the data in the simulation\nM &lt;- matrix(.05,nr_var,nr_var)\nM[diag(nr_var)==1] &lt;- 0 # set diagonal of M to 0\n\nfor(i in 1:nr_of_pp)\n{\n  # sample a,K, starting values X from normal distributions for each person separately\n  # note M is constant over persons.\n  a &lt;- rnorm(nr_var,.2,.05) \n  k &lt;- rnorm(nr_var,10,2)\n  x0 &lt;- rnorm(nr_var,2,0.1) # initial state of X\n  s  &lt;- x0;p &lt;- c() # required for grind\n  data[i,] &lt;- run(odes=mutualism ,tmax=60, timeplot = (i==1),legend=F) # collect data (end points)\n  #plot person 1 only\n}\nhist(cor(data)[cor(data)&lt;1],main='positive manifold',\n     xlab='between test correlations',col='lightgreen') # positive manifold\n\n\n\nFigure 6.7: A typical run of the mutualism model for one subject and the distribution of correlations between $X$ values across subjects.\n\n\n\n\n6.3.1.3 Abnormal development\nIn Van Der Maas et al. (2017), this model is applied in several ways, for example, by incorporating Cattell’s idea of investment of fluid skills in crystalized abilities. In a recent paper, de Ron et al. (2023) extends the mutualism model with resource competition to explain different patterns of abnormal development. One pattern of abnormal development is hyperspecialization, which is associated with rare variants of autism. In the process of modeling, we came to an interesting insight. Assuming that there is competition for scarce resources (time, money, educational support), hyperspecialization is the default outcome and it is ‘normal’ development that needs to be explained. The reason is the following insight from mathematical biology.\nIn basic resource competition models in population biology (Tilman, Kilham, and Kilham 1982), the growth of a species (\\(1...W\\)) is determined by its current size \\(X_{i}\\) and the sum over resources \\(R_{j}\\ (1...V)\\). The parameters \\(\\mu_{ij}\\) determines how much species \\(i\\) benefits from the resource \\(j\\). If no resources are available, \\(X_{i}\\) dies out with death rate \\(d_{i}\\).\nThe growth of the resource \\(r_{j}\\) consists of two parts. The first part models the growth by a concave function, which is determined by \\(r\\) (i.e., the steepness of the concave function) up to \\(r_{\\max}\\). The second part is the depletion by consumption of resources by \\(X_{i}\\) at rates \\(b_{ij}\\). Two differential equations specify these dynamics (see the appendix of de Ron et al. 2023) for the Grind code to study this model numerically):\n\\[\\frac{dX_{i}\\ }{dt} = X_{i}(\\sum_{j = 1}^{V}{\\mu_{ij}R_{j} - d_{i}})\\]\n\\[\\begin{array}{r}\n\\frac{dR_{j}\\ }{dt} = {r\\left( r_{\\max} - R_{j} \\right) - R}_{j}\\sum_{i = 1}^{W}{b_{ij}X_{i}} 43)\n\\end{array}\\]\nWhat has been shown for this and related models is that you will not get more species surviving than there are resources. Another famous quote from Robert May is “There is no comfortable theorem assuring that increased diversity and complexity beget enhanced community stability; rather, as a mathematical generality, the opposite is true. The task, then, is to elucidate the devious strategies which make for stability in enduring natural systems. There will be no one simple answer to these questions.” Thus, given a limited number of resources (time, money, educational support), we should expect early specialization in only a few skills.\nBiologists have proposed a number of mechanisms to deal with this problem (Meena et al. 2023). In de Ron et al. (2023) we added three mechanisms: a) density dependent growth (see Section 5.1.2) of the abilities \\(X\\) with a logistic term, b) mutualism between abilities as in the mutualism model, and c) growth-dependent depletion of resources. The idea of the latter is that especially the growth of abilities costs a lot of resources, the maintenance much less. Learning arithmetic or chess requires a lot of effort, but once a certain level of mastery is reached, it remains roughly at that level without further training (unfortunately, this is not the case with physical condition).\nIn this paper, we show that the combination of these mechanisms allows a balanced growth of several correlated abilities. Specially chosen parameter settings led to different patterns of abnormal development (such as hyperspecialization and delayed development). The final model is:\n\\[\\begin{array}{r}\n\\frac{dX_{i}}{dt} = X_{i}\\left( \\sum_{j = 1}^{V}{\\mu_{ij}R_{j}\\overset{\\text{Logistic growth}}{\\overbrace{\\left( 1 - \\frac{X_{i}}{K_{i}} \\right)}}} - d_{i} \\right) + \\overset{\\text{Mutualism}}{\\overbrace{\\sum_{j = 1}^{W}{M_{ij}X_{i}X_{j}\\text{/}}K_{i}}}\n\\end{array}\\]\n\\[\n\\begin{array}{r}\n\\frac{dR_{j}}{dt} = r\\left( r_{\\max} - R_{j} \\right) - R_{j}\\sum_{i = 1}^{W}{b_{ij}\\frac{dX_{i}}{dt}}\\ \\left\\{ \\begin{array}{r}\ngrowth - dependent\\  \\\\\nresource\\ depletion\n\\end{array} \\right\\}\\# 44) \\\\\n\\end{array}\n\\]\n\n\n6.3.1.4 The wiring of intelligence\nA limitation of mutualism models is that only the activation of nodes is updated. The weight and structure of the network are fixed. While this may be sufficient to explain some developmental phenomena, it is ultimately unsatisfactory. The links themselves should be adaptable, as in the learning of neural networks. An example of learning in the form of updating weights is presented in a later section on the Ising Attitude model.\nIn Savi et al. (2019) the case where both nodes and links are updated was considered. The idea is that cognitive growth is a process in which new nodes and links are added during development. For example, new facts (1+1=2) and procedures (addition) are developed in the process of learning arithmetic. Links between these nodes may prevent forgetting. In the paper we use the Fortuin-Kasteleyn model, a generalization of the Ising model, in which both nodes and links are random. An important property of the model is that whenever two abilities are connected, they are necessarily in the same state, i.e., they are either both present or both absent. It provides a parsimonious explanation of the positive manifold and hierarchical factor structure of intelligence. The dynamical variant suggests an explanation for the Matthew effect, i.e., the increase in individual differences in ability over the course of development.\nHowever, it is difficult to create a growing network with Fortuin-Kasteleyn properties. A simple example of this problem is the random network. In random networks, there is a uniform probability that two nodes are connected. But if we add new nodes to such a network and connect them to existing nodes with the same probability, the existing nodes will have more connections on average. Thus, adding new nodes destroys the randomness of the network, that is the probability that two nodes are connected is not uniform over nodes anymore. Such a network is a non-equilibrium network (Dorogovtsev and Mendes 2002). Rewiring algorithms to achieve equilibrium exist, but they are not trivial.\n\n\n\n6.3.2 Symptom networks\nIn the network perspective on psychopathology, a mental disorder can be viewed as a system of interacting symptoms. Network theory conceptualizes mental disorders as complex networks of symptoms that interact through feedback loops to create a self-sustaining syndromic constellation. Mental disorders can be understood as alternative stable states of highly interconnected networks of symptoms (Borsboom 2017).\nAs with the mutualism model, this is an alternative to the common cause view. Depression could be caused by some malfunction in the brain, a dysregulation of hormones, or even a genetic defect. But as with general intelligence, no such common cause has yet been found. Drugs work to some extent, but so do most interventions, even placebos and waiting lists (Posternak and Miller 2001). We explicitly offered the network approach as an alternative to the p-factor account of psychopathology (van Bork et al. 2017).1 It is called the p-factor because it is thought to be conceptually parallel to the g-factor of general intelligence (Caspi et al. 2014). And again, no one seems to have any idea what p might be.\n\n\n\nFigure 6.8: The small world of psychopathology. Symptoms are represented as nodes and connected by an edge whenever they figure in the same disorder. From: [@borsboomSmallWorldPsychopathology2011].\n\n\nThis lack of theoretical progress encouraged the development of network theory (Cramer et al. 2010; cramerMajorDepressionComplex2016?). As mentioned in the introduction of this chapter, this line of research has become very popular. Most of this work consists of data analytic studies. In the simplest case, a questionnaire asking about the severity of symptoms is administered to a group of people, sometimes patients, sometimes a mixture of people who do and do not suffer from a disorder. A variety of psychometric approaches, discussed later in this chapter, are used to fit networks to the data. In this way, one learns to understand the structure of psychopathological networks. For example, comorbidity is modeled by bridging symptoms between network clusters (Cramer et al. 2010; Jones, Ma, and McNally 2021). In the case of major depression and generalized anxiety disorder, sleep problems seem to be a typical bridge symptom (Blanken et al. 2018).\nThe most popular application is to detect which symptoms are central to a disorder (Eiko I. Fried et al. 2016). However, centrality analysis based on cross-sectional data has its limitations (Bringmann et al. 2019; Spiller et al. 2020). This is one reason to focus on individual networks using timeseries data, often obtained in experience sampling methods (ESMs). Again, these techniques are still under development and not without problems (Dablander and Hinne 2019; Haslbeck and Ryan 2022). For a recent review of the network approach to psychopathology, (see Robinaugh et al. 2020).\nIn terms of building actual models, not as much work has been done. In (cramerMajorDepressionComplex2016?), we proposed an Ising-type model, with node values of 0 and 1, representing symptoms being on or off. Nodes were turned on and off based on a probability computed with a logistic function \\(P = 1/(1 + e^{(b_{i} - A_{i}^{t})}\\). \\(A_{i}^{t}\\) equals the sum of the weighted input from other connected nodes and \\(b_{i}\\) is a node-specific threshold that normally keeps nodes in the zero state. A strong point of this model is that the connections and thresholds were estimated from data. This model is the origin of the connectivity hypothesis. The idea is that high connectivity within a network of symptoms could lead to a more persistent and severe disorder for a discussion, (see Elovainio et al. 2021).\nSince thresholds are generally negative (the zero state of nodes is the default state), sufficient connectivity is required to have a depression as an alternative stable state. A limitation of this model is that although it is similar to the Ising model, the exact dynamics are not well understood.\nA similar approach was used by Lunansky et al. (2022) in order to define resilience and evaluate intervention targets. The model can be found in the NetLogo User Community Models under the name of ‘Vulnerability to Depression’ by Claudia van Borkulo (see Figure 6.9). Another relevant network modeling approach, based on causal loop diagrams, is proposed in Wittenborn et al. (2016). The panic disorder model discussed in the previous chapter is also an example.\n\n\n\nFigure 6.9: The Vulnerability to Depression model in NetLogo.\n\n\nThe connection to resilience is interesting. In dynamic terms, resilience is not associated with the healthy or unhealthy state, but with the stability of these states (Figure 6.10). In Section 3.2.3 the less deep minimum is called the metastable state. These states have less resilience than the globally stable state.\nThis suggests a distinction between perturbations and interventions. With interventions, we change the equilibrium landscape to allow a sustainable change to a healthy state. Perturbations (a brief intervention or a positive or negative event) can have a permanent or temporary effect, depending on which state is more resilient. In the situation shown in the top panel of Figure 6.10, any intervention, whether it is a real treatment or an alternative (or even being on the waiting list), will work. In the situation on the bottom left, no intervention would have a lasting effect. This definition of resilience may help to understand the inconsistent results of studies of intervention effects. Monitoring the resilience of the unhealthy state (with catastrophe flags such as anomalous variance) may also be important for timing interventions (Hayes and Andrews 2020). Failed interventions, such as an attempt to quit smoking, are likely to reinforce the unhealthy state (Vangeli et al. 2011).\n\n\n\nFigure 6.10: Resilience from a complex systems perspective. If the system is in a less resilient, metastable state, any perturbation will be effective. A perturbation to a metastable state will not last. Lasting interventions change the dynamic landscape of the system.\n\n\n\n\n6.3.3 Ising attitude model\nThe network approach has been applied to many other domains outside of intelligence research and the study of psychopathology. Examples include emotion (Lange and Zickfeld 2021), personality (Costantini et al. 2015), interest (Sachisthal et al. 2019), and organizational behavior (Lowery, Clark, and Carter 2021). One area where it has been developed into a new theory is attitude research.\nPeople have many attitudes, about food, politics, other people, horror movies, the police, etc. They help us make decisions and guide our behavior. Attitudes can be very stable and multifaceted, but they can also be inconsistent and inconsequential. Social psychology has studied attitudes for a long time, and many insights and theories have been developed.\nAttitudes are complex constructs and typical phenomena, such as cognitive dissonance, imbalance, ambivalence, and political polarization, can be well described by a network model. The formalization of attitude theories has been dominated by the connectionist account (Monroe and Read 2008; Van Overwalle and Siebler 2005). In connectionist models, developed in the Parallel Distributed Processing (PDP) approach, attitude units (e.g., beliefs) form a connected network whose activations (between -1 and 1) are updated based on the weighted sum of internal inputs from other units and an external input. These weights or connections are updated according to either the delta rule (a supervised learning rule based on the difference between the produced and expected output of the network) or the Hebb rule (a simpler unsupervised rule). With this setup, these models can explain a number of phenomena in attitude research. Another network account has been put forward in sociology (DellaPosta 2020).\nIn this section, I will discuss our network approach to attitudes using the Ising model, which was developed in a series of recent papers. The advantages of this model over the connectionist PDP models are that it is derived from basic assumptions, is better understood mathematically, is easy to simulate, provides a psychological interpretation of the temperature parameter, and can be fitted to data (dalegeNetworkAnalysisAttitudes2017?).\nIt was developed as an alternative to the tripartite factor model of attitudes, in which the attitude, a latent factor, consists of lower-order cognitive, affective, and behavioral factors, that each explain observed responses, similar to the CHC model of general intelligence. The causal attitude model (Jonas Dalege et al. 2016), maintains this distinction in cognitive, affective, and behavioral components, but now conceptualizes them as clusters within a network. In Jonas Dalege et al. (2018), this network model is formalized in the form of an Ising model with attention as the equivalent of (the inverse of) temperature. That is high attention ‘freezes’ the network and leads to consistent and stable positive or negative states of the attitude (the ‘mere thought effect’, see below).\n\n6.3.3.1 Model setup\nThe basic assumptions of the Ising Attitude Model are that nodes are binary (e.g., one eats red meat or not), that nodes influence each other causally, and that they have specific thresholds (as in the model for depression). An external field (a campaign to eat less meat) could also affect the nodes. The orientation of nodes to other nodes and to the external field depends on one’s attention, \\(A\\), to the attitude object.\nGiven these simplifying assumptions, which can be relaxed in various ways, we arrive at the random field Ising model Fytas et al. (2018). This model is not too different from the Ising model described in Chapter 4, except that the first term now has two components, a general external effect (\\(\\tau\\)) and an effect of node-specific ($t_{i})\\ $thresholds (‘I just like the taste of chicken a lot’). The random field Ising attitude model can then be defined as:\n\\[\\begin{array}{r}\nH\\left( \\mathbf{x} \\right) = - \\sum_{i}^{n}{(\\tau + {t_{i})x}_{i}} - \\sum_{&lt; ij &gt;}^{}{{W_{ij}x}_{i}x_{j}} 45)\n\\end{array}\\]\n\\[\\begin{array}{r}\nP\\left( \\mathbf{X} = \\mathbf{x} \\right) = \\frac{\\exp\\left( - AH\\left( \\mathbf{x} \\right) \\right)}{Z} 46)\n\\end{array}\\]\nAnother difference from the original Ising model introduced in Chapter 4 is that the interactions are now weighted and can even be negative. The main problem is the same. To compute the probability of a state, one has to compute \\(Z\\), which is the \\(\\sum_{&lt; \\mathbf{x} &gt;}^{}{exp( - AH\\left( \\mathbf{x} \\right))}\\), i.e., a sum over all possible states (\\(2^{n}\\)). For large values of \\(n\\) this is not feasible. One solution is to take a random initial state and use Glauber dynamics to update the states until an equilibrium state is reached. The Glauber algorithm does not require \\(Z\\). There are faster but less intuitive algorithms, the most popular being the Metropolis-Hastings algorithm, which is a slight modification of the Glauber dynamics presented in Chapter 4.\nAnother approach to understanding the dynamics of Ising-type models is the mean-field approximation. This requires the assumption that the network is fully and uniformly connected with equal thresholds (known as the Curie-Weiss model). In this approximation \\(W_{ij}\\) and \\(x_{j}\\) are replaced by their mean values, which greatly simplifies the energy function. It can be shown that the dynamics of the simple fully connected Ising model is very well approximated by the cusp, with the external field as normal and the inverse temperature as the splitting variable.\n\n\n\nFigure 6.11: The mean field approximation of the Ising attitude model is the cusp. Attention is the psychological equivalent of inverse temperature.\n\n\nThis is an important result because it makes the use of the cusp in attitude research (see Chapter 3) less phenomenological. The cusp is now derived from more basic principles (Figure 6.11). Note that here we use attention as the splitting variable, whereas in Chapter 3 we used involvement. These are closely related concepts, the difference being the time scale. Attention can change in seconds or minutes, whereas involvement can change in weeks or months. I will use attention and involvement interchangeably.\nThis mean-field approximation is very robust. In (vandermaasPolarizationIndividualsHierarchical2020?) it is shown by simulation that networks with much fewer connections and a distribution of weights, some of which are negative, are still well described by the cusp. This can be easily checked with some R code or in NetLogo. We will make use of the IsingSampler package in R.\n\n\n6.3.3.2 Simulation\nThe IsingSampler function runs the Metropolis-Hastings algorithm \\(nIter\\) times and returns the last state. It can return multiple final states for \\(N\\) runs. As input it takes a matrix of links (\\(W\\)), which for the Curie Wiess model should be symmetric with zeroes on the diagonal. The \\(thresholds\\) for each node should be equal. \\(Beta\\) is the inverse of the temperature (\\(1/T\\)).\nlibrary(\"IsingSampler\")\nn &lt;- 10 # nodes\nW &lt;- matrix(.1,n,n); diag(W)=0\ntau &lt;- 0\nN &lt;- 1000 # replications\nthresholds &lt;- rep(tau, n)\nlayout(t(1:2))\ndata &lt;- IsingSampler(N, W, nIter=100, thresholds, beta = .1, responses = c(-1, 1))\nhist(apply(data,1,sum),main=\"beta = .1\",xlab='sum of x')\ndata &lt;- IsingSampler(N, W, nIter=100, thresholds, beta = 2, responses = c(-1, 1))\nhist(apply(data,1,sum), main=\"beta = 2\",xlab='sum of x')\n\n\n\nFigure 6.12: The distribution of the attitude values (sum of node values) at low and high attention, respectively. This simple simulation shows the mere thought effect (Tesser 1978).\n\n\nIn Jonas Dalege and van der Maas (2020), we simulated the difference between implicit and explicit measures of attitude. The idea is that the individual thresholds contain information about the attitude that can only be detected when attention is moderately low. When attention is too high, the alignment between the nodes dominates the thresholds. Indeed, in implicit (indirect) measures of attitude, attention is much lower than in explicit measures such as an interview. This can be simulated as follows:\nlayout(1)\nN &lt;- 400\nn &lt;- 10\nW &lt;- matrix(.1,n,n); diag(W) &lt;- 0\nthresholds &lt;- sample(c(-.2,.2),n,replace=T) # a random pattern of thresholds\ndat &lt;- numeric(0)\nbeta.range &lt;- seq(0,3,by=.05)\nfor(beta in beta.range)\n{\ndata &lt;- IsingSampler(N, W, nIter = 100, thresholds, beta = beta, responses = c(-1, 1))\ndat &lt;- c(dat,sum(thresholds*apply(data,2,sum))) # a simple measure of alignment\n}\nplot(beta.range,dat,xlab='beta',ylab='alignment with thresholds',bty='n')\n\n\n\nFigure 6.13: At low levels of attention (but not too low), the node values are determined by the thresholds. At higher levels of attention, they are overridden by the collective effect of other nodes. This may explain the difference between implicit and explicit attitude measures.\n\n\nWe see that for medium attention, the agreement with the thresholds is highest. When attention is zero or very low, nodes behave randomly and do not correlate with the thresholds. When attention is very high, the effects of node-specific thresholds are masked by the collective effects of other nodes. The principal problem of implicit measurement is that for low to medium attention, the network is quite noisy. This is why this paper is called “Accurate by being noisy”.\n\n\n6.3.3.3 Learning\nThese connectionist attitude models are capable of “learning”, i.e., adjusting the weights. This can also be done in the Ising attitude model by using Hebbian learning. Hebbian learning, ‘what fires together, wires together’, can be formulated as:\n\n\\[\\begin{array}{r}\n\\mathrm{\\Delta}W_{i,j} = \\epsilon\\left( 1 - \\left| W_{i,j} \\right| \\right)x_{i}x_{j} - \\lambda W_{i,j} 47)\n\\end{array}\\]\nWeights will grow to 1 if the nodes they connect are consistently either both 1 or both -1. If they consistently differ in value, the weight grows to -1. If the nodes behave inconsistently, the weight shrinks to 0.\nIn R, this can be implemented as follows:\nlibrary(qgraph)\nhamiltonian=function(x,n,t,w) -sum(t*x)-sum(w*x%*%t(x)/2)\nglauber_step = function(x,n,t,w,beta)\n{\n  i = sample(1:n,size=1) # take a random node\n  x_new=x;x_new[i]=x_new[i]*-1 # construct new state with flipped node\n  p=1/(1+exp(beta*(hamiltonian(x_new,n,t,w)-hamiltonian(x,n,t,w))))  # update probability\n  if(runif(1)&lt;p) x=x_new # update state\n  return(x)\n}\nlayout(t(1:2))\nepsilon &lt;- .002;lambda &lt;- .002 # low values = slow time scale\nn &lt;- 10\nW &lt;- matrix(rnorm(n^2,0,.1),n,n); W &lt;- pmax(W,t(W)) # to make W symmetric\ndiag(W) &lt;- 0\nqgraph(W); title('before learning')\nthresholds &lt;- rep(.2, n)\nx &lt;- sample(c(-1,1),n,replace=T)\nfor(i in 1:500)\n{\nx &lt;- glauber_step(x,n,thresholds,W,beta=2)\nW &lt;- W+epsilon*(1-abs(W))*outer(x,x,\"*\")-lambda*W # Hebbian learning\ndiag(W) &lt;- 0\n}\nround(W,2)\nqgraph(W);title('after learning')\n\n\n\nFigure 6.14: Through Hebbian learning, a random (unbalanced) network becomes balanced.\n\n\nIn this case we want to update the nodes values using the Glauber dynamics (Equation \\(19\\)), which uses the computation of the energy of a particular state. Both functions (glauber_step and hamiltonian) are added to the R-code.\nDue to Hebbian learning, the network evolves from an unbalanced network (random connections) to a consistently balanced network. Without learning, we need high attention to make the attitude network behave consistently. In the Learning Ising Attitude Model (LIMA), weights increase during periods of high attention. The advantage is that in later instances less attention is required for consistent network behavior (chapter 8 of J. Dalege 2020). In this way we can develop stable consistent attitudes.\n\n\n6.3.3.4 The stability of attitudes and entropy measures\nSo, adding Hebbion learning to the Ising attitude model leads to stable and consistent attitudes. Computing the Gibbs entropy is the best way to quantify this (proposition I.2 in Jonas Dalege et al. 2018). Earlier the Boltzmann entropy was defined in Section 4.1.1 as the log of the number of ways (W) a particular macrostate can be realized. It measures the inconsistency of a particular attitude state (proposition I.1 in Jonas Dalege et al. 2018).2 Gibbs entropy is more general in that it does not assume that each microstate is equally probable. Instead, it deals with a probability distribution over the different microstates X. It is defined as:\n\\[\\begin{array}{r}\n- \\sum_{&lt; \\mathbf{x} &gt;}^{}{P\\left( \\mathbf{x} \\right)\\ln{P\\left( \\mathbf{x} \\right)}} 48)\n\\end{array}\\]\nNote that we sum over all microstate (\\(2^{n})\\). For small networks we can compute this measure using the IsingEntrophy() function of the IsingSampler package. There is much more to say about the different entropy measures. For instance, Shannon entropy (a measure in information theory) and Gibbs entropy have the same mathematical definition but are derived from completely different lines of reasoning. An introduction to the discussion on entropy measures can be found at Entropy page of Wikipedia.\n\n\n6.3.3.5 Tricriticality\nA new direction of research concerns Ising type models with trichotomic node values (-1,0,1). In physics this case is known as the tricritical Ising model or the Blume Capel model (Saul, Wortis, and Stauffer 1974). In physics, the states +1 and -1 could represent the spin of a particle pointing up or down, while 0 could represent a non-magnetic or spinless state. In an attitude model, +1 and -1 may represent pro and con beliefs, while 0 represents a neutral belief. The Hamiltonian of the model includes a penalty for the -1 and +1 states:\n\\[\\begin{array}{r}\nH\\left( \\mathbf{x} \\right) = - \\sum_{i}^{n}{\\tau x_{i}} - \\sum_{&lt; i,j &gt;}^{}{x_{i}x_{j}} + D\\sum_{i}^{n}{x_{i}}^{2}\\#\n\\end{array}49)\\]\nYou can compare this to equation \\(17\\). The last term penalizes (increases the energy) of the -1 and +1 states relative to the 0 state.\nThe dynamics of this model are more complicated. It resembles the butterfly catastrophe (Dattagupta 1981), which has a tricritical point. The potential function has three stable fixed points for some sets of parameters (see Section 3.2.5 and the exercise about the butterfly catastrophe). This is relevant to the modeling of attitudes because it opens up the possibility to have involved stable inbetween attitude positions (see Figure 6.15). In the Ising attitude model highly involved persons always radicalize, but this more advanced model allows for involved non-partisan positions.\n\n\n\nFigure 6.15: The butterfly catastrophe, $V(X) = {- aX - \\frac{1}{2}bX^{2} - \\frac{1}{3}cX^{3} - \\frac{1}{4}dX^{4} + \\frac{1}{6}X}^{6}$, associated with the tricritical Ising model. The potential function can have three minima (a = c = 0, d = 5, b varies from 1 to -7)."
  },
  {
    "objectID": "ch6.html#psychometric-network-techniques",
    "href": "ch6.html#psychometric-network-techniques",
    "title": "6  Psychological Network Models",
    "section": "6.4 Psychometric network techniques",
    "text": "6.4 Psychometric network techniques\nSo far, we have seen examples of theoretical psychological network models in the fields of cognitive, clinical, and social psychology. However, much of the popularity of this approach is due to the psychometric approach that has been developed to analyze data using networks. In the last 15 years, a family of statistical approaches has been developed for all kinds of data and empirical settings. Our psychosystems group (psychosystems.org) has published a book “Network Psychometrics with R: A Guide for Behavioral and Social Scientists” (Isvoranu et al. 2022). This resource is highly recommended. I will limit myself to a brief overview and some practical examples related to the models presented in the first part of this chapter.\n\n6.4.1 Main techniques\nAn important aspect of Network Psychometrics is to visualize the network. This is the process of creating visual representations of the network structure. This helps in interpreting the data. The main R packages for visualization are igraph and qgraph. Both packages include many other useful functions.\nA more advanced application of network psychometrics is network estimation. This involves using statistical methods to estimate the structure of the network, including which nodes are connected to each other and the strength of those connections. The most used methods for network estimation are Gaussian graphical models (packages bgms, BDgraph, ggm, psychonetrics, qgraph, BGGM, huge), partial correlation networks (qgraph, qgraphicalmodels), and Ising models (IsingFit, IsingSampler, rbinnet). The mgm package can be used to fit mixed graphical models, with a mixture of categorical and continuous valued nodes. The bgms package applies Bayesian estimation and allows testing for missing links. The huge package is used to represent the conditional dependence structure among many variables and is particularly useful when the number of variables is much larger than the sample size.\nThe estimation is usually followed by a centrality analysis. The most important nodes in the network are identified based on their degree of centrality, which measures the extent to which a node is connected to other nodes in the network. Centrality measures include degree centrality, betweenness centrality, bridge centrality, and eigenvector centrality, among others (packages psych, networktools).\nAnother important step is network comparison. Network comparison is the process of comparing the structure of two or more networks to determine if they are significantly different from each other. This can be done using techniques such as the network permutation test, bootstrapping and moderation analysis (R packages bootnet and NetworkComparisonTest).\nWe can perform network inference, inferring causal relationships between nodes, if we have time series data or if we have intervened in the network. Depending on the type of time series (N=1 time series, N&gt;1 time series, panel data), different modeling options and packages are available (packages psychonetrics, mgm, graphicalVar, mlVar). GVAR returns a temporal network, which is a directed network of temporal relationships, and a contemporaneous network, which is an undirected network of associations between the variables within the same time frame after controlling for temporal relationships.\nFor a detailed discussion of the reasons for using certain techniques, I again refer you to our recent book. The brief overview I have provided here may soon be obsolete. The CRAN Task View: Psychometric Models and Methods will give you an up-to-date overview. Another option is to use JASP. JASP is a free, open source, statistical analysis program developed under the supervision of Eric Jan Wagenmakers (Huth et al. 2023; Love et al. 2019). It is a user-friendly interface for accessing R packages. All major statistical analyses, both frequentist and Bayesian, are available in JASP (https://jasp-stats.org/features). Many of the network R packages mentioned above are available. You may want to start by reading the blog post on doing network analysis in JASP (https://jasp-stats.org/2018/03/20/perform-network-analysis-jasp/).\nFinally, I mention semantic network analysis again. A recent review of statistical approaches (available in R) is provided by Christensen and Kenett (2021).\n\n\n6.4.2 Fitting the mutualism model\nIn the section on the mutualism model, I provided code to simulate data. These data can be fitted using JASP. By re-running the previous code and adding\nwrite.table(file='mutualism.txt',data,ro=F,sep='\\t') # write data for JASP\nWe have a data file ready to analyze in JASP. After opening this file, you will see the data. In the Network (Frequentist) tab, select all variables and the EBICglasso option. EBICglasso is an R function from the qgraph package. It calculates the Gaussian graphical model and applies the LASSO regularization to shrink the estimates of links to zero (Friedman, Hastie, and Tibshirani 2008). This prevents the presence of many irrelevant links without losing predictive value. Alternatively, one could use significant testing or a Bayesian procedure. In JASP one could use the partial correlation option. It is recommended to play around with some options and additional plots.\nMutualism is an alternative explanation for the positive manifold, which means that the fit of a factor model to such data does not prove that the factor ‘g’ theory is correct. It can be shown (Van Der Maas et al. 2006) that the simple mutualism factor model with \\(M_{ij} = c\\), is equivalent to the one-factor model. This can be tested in JASP by fitting a one-factor model to the simulated data. The exploratory one-factor model with one factor will fit the data. The factor loadings should all be very similar.\nAs discussed, cross-sectional networks do not provide information about the direction of effects. We can illustrate this as follows.\nM[,1] &lt;- .2 # strong influence of X1 on all others\nM[2,] &lt;- .2 # strong influence on X2 by all others\nM[diag(nr_var)==1] &lt;- 0 # set diagonal of m to 0\nIf we rerun the code and create a centrality plot in JASP, we will see the risks of centrality analysis in cross-sectional networks. Node 2 is the most central, but we know from the simulation that this is because it is influenced by all the others. The node with the most causal power (node 1) does not turn out to be an important central node. With time series data, we can estimate the direction of the effects. We do this in R:\nlibrary(\"graphicalVAR\")\n# make time series for one persons with some stochastic effects\ndata &lt;- run(odes=mutualism, tmax=1000,table=T,timeplot = (i==1),legend=F, after=\"state&lt;-state+rnorm(nr_var,mean=0,sd=1);state[state&lt;0]=.1\")\ndata &lt;- data[,-1]\ncolnames(data) &lt;- vars &lt;- paste('X',1:nr_var,sep='',col='')\nfit=graphicalVAR(data[50:1000,], vars = vars, gamma=0, nLambda = 5)\nplot(fit,\"PDC\")\ncentralityPlot(fit$PDC)\nThe results are shown in Figure 6.16. Only the time-series approach provides useful information about possible causal effects.\n\n\n\nFigure 6.16: The top figure is based on cross-sectional data and incorrectly suggests that node V2 is the most important mode. The bottom figure is based on the time series of one individual and correctly shows that V2 is central because it is influenced by other nodes, while V1 is central because it influences other nodes and is therefore more important.\n\n\nThe M-matrix can take different forms. The typical multifactor structure can be achieved with a block structure.\nset.seed(1)\nfactors &lt;- 3\nM &lt;- matrix(0,nr_var,nr_var)\nlow &lt;- .0;high &lt;- .1 # interaction between and within factors\n# loop to create M\ncat &lt;- cut(1:nr_var,factors)\nfor(i in 1:nr_var)\n  for(j in 1:nr_var)\n    if(cat[i]==cat[j]) M[i,j] &lt;- high else M[i,j] &lt;- low\nM[diag(nr_var)==1] &lt;- 0 # set diagonal of m to 0\nIn JASP, you can perform network and confirmatory factor analysis. In the latter case, select 3 factors in the first window and select ‘assume uncorrelated factors’ in the model options. The resulting plots should look like this.\n\n\n\nFigure 6.17: The block structure in the mutualism model can be represented as either a network or a factor model.\n\n\n\n\n6.4.3 Fitting Ising models\nWith IsingFit we can easily fit cross-sectional data generated with the Ising attitude model. Figure 6.18 shows a good fit of the model. The code for this analysis is:\nlibrary(\"IsingSampler\")\nlibrary(\"IsingFit\")\nset.seed(1)\nn &lt;- 8\nW &lt;- matrix(runif(n^2,0.5,2),n,n); # random positive matrix\nW &lt;- W * matrix(sample(0:1,n^2,prob=c(.8,.2),replace=T),n,n) # delete 90% of nodes\nW &lt;- pmax(W,t(W)) # make symmetric \ndiag(W) &lt;- 0\nn &lt;- 1000\nthresholds &lt;- rnorm(n,0,1) \ndata &lt;- IsingSampler(n, W, thresholds, beta = .5, responses = c(-1, 1))\nfit &lt;- IsingFit(data,family='binomial', plot=FALSE)\nlayout(t(1:3))\nqgraph(W,fade = FALSE);title(\"Original network\",cex.main=2)\nqgraph(fit$weiadj,fade = FALSE);title(\"Estimated network\",cex.main=2)\nplot(thresholds,type='p',bty='n',xlab='node',ylab='Threshold',cex=2,cex.lab=1.5);lines(fit[[2]],lwd=2)\n\n\n\nFigure 6.18: The true (original) and the estimated Ising model are in good agreement. The thresholds are also well estimated from the data.\n\n\nAn empirical example is provided in@dalegeNetworkAnalysisAttitudes2017. The open-access data (N = 5728) come from the American National Election Study (ANES) of 2012 on evaluative reactions toward Barack Obama. The items and abbreviations are:\n\nTable 3: The abbreviation of items used in Figure 6.19\n\n\nItems tapping beliefs\nAbbreviation\n\n\n\n\n “Is moral”\nMor\n\n\n “Would provide strong leadership”\nLed\n\n\n “Really cares about people like you”\nCar\n\n\n “Is knowledgeable”\nKno\n\n\n “Is intelligent”\nInt\n\n\n “Is honest”\nHns\n\n\nItems tapping feelings\n\n\n\n “Angry”\nAng\n\n\n “Hopeful”\nHop\n\n\n “Afraid of him”\nAfr\n\n\n “Proud”\nPrd\n\n\n\nWe can use Isingfit and add community detection:\nObama &lt;- read.table(\"data/Obama.txt\",header=T) # see book data folder\nObamaFit &lt;- IsingFit(Obama,plot=F)\nObamaiGraph&lt;- graph_from_adjacency_matrix(abs (ObamaFit$weiadj), 'undirected', weighted = TRUE,     add.colnames = FALSE)\nObamaCom &lt;- cluster_walktrap(ObamaiGraph)\nqgraph(ObamaFit$weiadj, layout = 'spring', cut = .8, groups = communities(ObamaCom), legend = FALSE)\nFigure 6.19 shows the network. The red nodes represent negative feelings toward Barack Obama; the green nodes represent positive feelings toward Obama; the light blue nodes represent judgments primarily related to interpersonal warmth; and the purple nodes represent judgments related to Obama’s competence. This community structure is consistent with the postulate of the CAN model that similar evaluative responses cluster Jonas Dalege et al. (2016) . (finnemannTheoreticalStatisticalIsing2021?) present additional examples and applications of other packages.\n\n\n\nFigure 6.19: The attitude towards Obama"
  },
  {
    "objectID": "ch6.html#challenges",
    "href": "ch6.html#challenges",
    "title": "6  Psychological Network Models",
    "section": "6.5 Challenges",
    "text": "6.5 Challenges\nSince the early work on network psychology, the mutualism model, and the paper on the network perspective on comorbidity, a tremendous amount of work has been done. In particular, network psychometrics has taken off in an unprecedented way. One could say that modern psychometrics is being reinvented from a network perspective. For every type of data and research question, a network approach seems to be available. For example, there are R packages for meta-analysis from a network perspective (salantiEvaluatingQualityEvidence2014?). I also note that much work has been done to understand the relationship between network psychometrics and more traditional techniques such as item response theory (marsmanIntroductionNetworkPsychometrics2018?), factor models (Waldorp and Marsman 2022) and structural equation modeling (Epskamp, Rhemtulla, and Borsboom 2017). Nevertheless, there are still many challenges for both psychological network modeling and network psychometrics.\n\n6.5.1 Psychological network modelling\nDespite all the hard work on this, I can only conclude that this theoretical line of research is still in its infancy. The strength of the application to intelligence is that it provides an alternative to the g-factor approach, which is also nothing more than a sketch of a theory. The extensions of the mutualism model (Ron et al. 2023; Savi et al. 2019) are new steps, but still rather limited models. One reason for this state of affairs is that it is really hard to pinpoint the elementary processes involved in intelligence, and indeed in any psychological system.\nThis is less of a problem in the factor account because the indicators are interchangeable in a reflective factor model. Once one has a sufficiently broad set of indicators, the common cause estimate will be robust. In a formative model, each indicator contributes a specific meaning to the index variable. However, this is not a reason to prefer the common cause model (van der Maas, Kan, and Borsboom 2014).\nThe other modeling examples suffer from the same problem. In the clinical psychology models, we define the nodes either as the symptoms specified in the DSM or as the questions asked in interviews or questionnaires, with the advantage that we then have data to fit the model. But again, we have no real way of knowing the elementary processes in clinical disorders and their interactions. If we miss important elementary nodes, this will seriously affect the validity of our models and psychometric network analyses (Eiko I. Fried and Cramer 2017).\nA way out has been mentioned in the context of the Ising Attitude Model, using the mean field approximation. If we are only interested in the global behavior of the attitude (hysteresis, divergence), we can ignore the specification of the nodes (another interchangeable argument). But if one wants to intervene on specific nodes or links of a clinically depressed person, this is not sufficient.\nAnother critical point is that these models increase our understanding of psychological phenomena, but seemingly not our ability to predict or intervene. For example, the Ising Attitude model helps us understand the role of attention or involvement in the dynamics of attitudes. If this factor is too high, persuasion will be extremely difficult due to hysteresis. Anyone who has ever tried to argue with a conspiracy theorist knows what I mean. But too little attention is also a problem. In the model, these are people who are sensitive to the external field, e.g., you tell them to clean their room, but as soon as you leave, the attitude falls back into random fluctuations. The message gets through but does not stick. I find this insightful, but I must admit that it does not provide us with interventions. We don’t know how to control attention or engagement, although more work can and will be done on this.\nFor intelligence, the model suggests that the active establishment of near and far transfer might be effective. A disappointing lesson from developmental psychology is that transfer does not always occur automatically (e.g., Sala et al. 2019). However, strategies for improving transfer do exist (Barnett and Ceci 2002) and according to the mutualism model, should have a general effect.\nIn Chapter 1, I mentioned the case of the shallow lake studied in ecology, where catching the fish was a very effective intervention, while addressing the cause, pollution, was ineffective due to hysteresis. Ecologists now know why this is so, and have developed models to explain this phenomenon. However, I did not mention that this intervention was not suggested by modeling work, but by owners of ponds who observed that ponds without fish sometimes spontaneously tipped to the clear state. This is not an uncommon path in science, and it may well occur in clinical psychology. The touted extraordinary successes of electroshock therapy for severe depression or new drugs (MDMA) for post-traumatic stress disorder could be our “fish”. But also these claims have been criticized (e.g., Borsboom, Cramer, and Kalis 2019/ed; Read and Moncrieff 2022).\nAlthough much more progress can be made in network modeling of psychological systems, it is advisable to be realistic. Progress in mathematical modeling of ecosystems has also been slow. Ecosystems and human systems are devilishly complex. The formalization of psychological models is of interest for many reasons (borsboomNetworkAnalysisMultivariate2021?), but will only be effective if we also make progress in other areas, such as measurement.\n\n\n6.5.2 Psychometric network analysis\nThis approach is also not without its problems, some of which are related to the problems of psychological network modeling. For example, the definition of nodes and the risk of missing nodes in the data is a serious threat. Again, this is not a unique problem; simple regression analysis suffers from the same risks. Another common threat to many applications of psychometric network analysis is the reliance on self-report in interviews or questionnaires. Generalizability, which may depend more on the choice of sample and measurement method than on the statistical analysis itself, is another example of a common problem in psychology in general and psychometric network analysis, in particular.\nPsychometric network analysis has been criticized because the result are difficult to replicate (Forbes et al. 2017). Replication of advanced statistical analyses, whether structural equation modelling, fMRI, or network psychometrics, is always an issue. For network analysis, a number of safeguards have been developed to increase replicability (Borsboom et al. 2017, 2018; Burger et al. 2022).\nA final important issue concerns causality. Network models estimated from cross-sectional data are descriptive rather than causal, that is, they do not provide information about the direction of causal relationships between variables. Developing methods for inferring causality from network models is an important challenge in the field.\nThe move to time series data (either N=1, N&gt;1, or panel data) partially solves this problem. With time series data, we can establish Granger causality, a weaker form of causality based on the predictive power of one time series over another in a time series analysis. However, the relationship may be spurious, influenced by other variables. Network analysis on time series often requires a lot of reliable and stationary data. An important issue is the sampling rate of the time series. In general, to accurately estimate a continuous time-varying signal, it is necessary to sample at twice the maximum frequency of the signal. This is called the Nyquist rate. Another issue is the assumption of equidistance between time points (Epskamp et al. 2018), which can be circumvented by using continuous time models (Voelkle et al. 2012).\nWhile these problems are not unique to network psychometrics, they are common problems in practice (see Hamaker et al. 2015; Ryan, Bringmann, and Schuurman 2022). Finally, causal testing always requires direct intervention. The combination of observational and experimental data can provide sufficient information to properly estimate causal relationships in directed acyclic graphs (Dablander and van Bork 2021; Kossakowski, Waldorp, and van der Maas 2021).\nBut we can also think of other ways. A simple, but not easy to implement, procedure is to ask subjects about the links in their networks. If one claims not to eat meat because of its effect on the climate, one might consider adding a directed link to this individual’s network (Rosencrans, Zoellner, and Feeny 2021). Deserno et al. (2020) used clinicians’ perceptions of causal relationships in autism. These relationships were consistent with those found in self-reported client data. The main problem is that there are many more possible links than nodes to report on, which makes the questionaries extremely long and tedious to fill out. Alternatively, one could try to estimate links from social media data, interviews or essays using automatic techniques (Peters, Zörgő, and van der Maas 2022)."
  },
  {
    "objectID": "ch6.html#exercises",
    "href": "ch6.html#exercises",
    "title": "6  Psychological Network Models",
    "section": "6.6 Exercises",
    "text": "6.6 Exercises\n\nReproduce the degree distribution of the Barabási-Albert model shown on the Wikipedia page on the scale-free network. Use sample_pa from the Igraph library. (*)\nOpen and run the ‘Preferential attachment’ model in NetLogo. Replace the line ‘report [one-of both-ends] of one-of links’ with ‘report one-of turtles’. New nodes will now connect to a random node. Does this result in a random network? (*)\nMake a hysteresis plot in the ‘Vulnerability to Depression’ model in NetLogo. (*)\nWith the ADMINISTER-SHOCK button, you can deactivate all symptoms at once. It is as if you give the network an electric shock that resets all the symptoms. Try to find a setting of the CONNECTION-STRENGTH and EXTERNAL-ACTIVATION that creates a disordered network (above the black line in the NETWORK STATUS plot) whereby administering a shock, makes the system healthy again. Is this healthy state long term stable? (*)\nCompute the Gibbs entropy for the learning Ising model during the learning process. Show in a plot that learning minimizes the Gibbs entropy. (**)\nInstall and open JASP (jasp-stats.org). Open the data library: 6. Factor. Read all the output and add a confirmatory factor analysis. What is the standardized factor loading of Residual Pitch in the confirmatory one-factor model?\nRead the blog ‘How to Perform a Network Analysis in JASP’ (https://jasp-stats.org/2018/03/20/perform-network-analysis-jasp/. Reproduce the top plots of Figure 6.16. Generate the data using the R-code in the chapter, import the data into JASP and perform the network analysis. (*)\nStudy the R-code for the case where the M-matrix consists of three blocks. Generate the data and import into JASP. Fit the confirmatory 3 factor model. Does it fit? Add V1 to the second instead of the first factor. How do you see the misfit? (*)\nHow can you generate data for a higher order factor model using the mutualism model? What should be changed in the code of the M matrix for the case of three blocks? Show that the three-factor solution (assuming uncorrelated factors) does not fit the resulting data. Fit a higher order factor model and report the p-value of the goodness of fit. How does the network plot change?\nGenerate data for a network in a cycle (v1 -&gt; v2 -&gt; v3…v12 -&gt; v1). Fit a network and an exploratory factor model. Does this work? What does this tell us about the relationship between the class of all network models and all factor models? (**)\nFit a Bayesian network in JASP to the data generated for ?fig-ch7-img1-old-89. Warning: The GM in JASP expects (0,1) data. Check that only the simulated links have high Bayes factors. (*)\n\n\n\n\n\nBarabási, Albert-László, and Márton Pósfai. 2016. Network Science. 1st edition. Cambridge, United Kingdom: Cambridge University Press.\n\n\nBarnett, Susan M., and Stephen J. Ceci. 2002. “When and Where Do We Apply What We Learn?: A Taxonomy for Far Transfer.” Psychological Bulletin 128: 612–37. https://doi.org/10.1037/0033-2909.128.4.612.\n\n\nBascompte, Jordi, and Pedro Jordano. 2013. Mutualistic Networks. Princeton University Press.\n\n\nBattiston, Federico, Enrico Amico, Alain Barrat, Ginestra Bianconi, Guilherme Ferraz de Arruda, Benedetta Franceschiello, Iacopo Iacopini, et al. 2021. “The Physics of Higher-Order Interactions in Complex Systems.” Nature Physics 17 (10): 1093–98. https://doi.org/10.1038/s41567-021-01371-4.\n\n\nBlanken, Tessa F., Marie K. Deserno, Jonas Dalege, Denny Borsboom, Peter Blanken, Gerard A. Kerkhof, and Angélique O. J. Cramer. 2018. “The Role of Stabilizing and Communicating Symptoms Given Overlapping Communities in Psychopathology Networks.” Scientific Reports 8 (1): 5854. https://doi.org/10.1038/s41598-018-24224-2.\n\n\nBorsboom, Denny. 2008. “Psychometric Perspectives on Diagnostic Systems.” Journal of Clinical Psychology 64 (9): 1089–1108. https://doi.org/10.1002/jclp.20503.\n\n\n———. 2017. “A Network Theory of Mental Disorders.” World Psychiatry 16 (1): 5–13. https://doi.org/10.1002/wps.20375.\n\n\nBorsboom, Denny, Angélique O. J. Cramer, and Annemarie Kalis. 2019/ed. “Brain Disorders? Not Really: Why Network Structures Block Reductionism in Psychopathology Research.” Behavioral and Brain Sciences 42 (2019/ed): e2. https://doi.org/10.1017/S0140525X17002266.\n\n\nBorsboom, Denny, Eiko I. Fried, Sacha Epskamp, Lourens J. Waldorp, Claudia D. van Borkulo, Han L. J. van der Maas, and Angélique O. J. Cramer. 2017. “False Alarm? A Comprehensive Reanalysis of ‘Evidence That Psychopathology Symptom Networks Have Limited Replicability’ by Forbes, Wright, Markon, and Krueger (2017).” Journal of Abnormal Psychology 126: 989–99. https://doi.org/10.1037/abn0000306.\n\n\nBorsboom, Denny, Donald J. Robinaugh, Mijke Rhemtulla, and Angélique O. J. Cramer. 2018. “Robustness and Replicability of Psychopathology Networks.” World Psychiatry 17 (2): 143–44. https://doi.org/10.1002/wps.20515.\n\n\nBringmann, Laura F., Timon Elmer, Sacha Epskamp, Robert W. Krause, David Schoch, Marieke Wichers, Johanna T. W. Wigman, and Evelien Snippe. 2019. “What Do Centrality Measures Measure in Psychological Networks?” Journal of Abnormal Psychology 128: 892–903. https://doi.org/10.1037/abn0000446.\n\n\nBurger, Julian, Adela-Maria Isvoranu, Gabriela Lunansky, Jonas M. B. Haslbeck, Sacha Epskamp, Ria H. A. Hoekstra, Eiko I. Fried, Denny Borsboom, and Tessa F. Blanken. 2022. “Reporting Standards for Psychological Network Analyses in Cross-Sectional Data.” Psychological Methods, No Pagination Specified–. https://doi.org/10.1037/met0000471.\n\n\nCaspi, Avshalom, Renate M. Houts, Daniel W. Belsky, Sidra J. Goldman-Mellor, HonaLee Harrington, Salomon Israel, Madeline H. Meier, et al. 2014. “The p Factor: One General Psychopathology Factor in the Structure of Psychiatric Disorders?” Clinical Psychological Science : A Journal of the Association for Psychological Science 2 (2): 119–37. https://doi.org/10.1177/2167702613497473.\n\n\nChristensen, Alexander P., and Yoed N. Kenett. 2021. “Semantic Network Analysis (SemNA): A Tutorial on Preprocessing, Estimating, and Analyzing Semantic Networks.” Psychological Methods, No Pagination Specified–. https://doi.org/10.1037/met0000463.\n\n\nCostantini, Giulio, Sacha Epskamp, Denny Borsboom, Marco Perugini, René Mõttus, Lourens J. Waldorp, and Angélique O. J. Cramer. 2015. “State of the aRt Personality Research: A Tutorial on Network Analysis of Personality Data in R.” Journal of Research in Personality, R Special Issue, 54 (February): 13–29. https://doi.org/10.1016/j.jrp.2014.07.003.\n\n\nCramer, Angélique O. J., Lourens J. Waldorp, Han L. J. van der Maas, and Denny Borsboom. 2010. “Comorbidity: A Network Perspective.” The Behavioral and Brain Sciences 33 (2-3): 137-150; discussion 150-193. https://doi.org/10.1017/S0140525X09991567.\n\n\nCronbach, Lee J. 1957. “The Two Disciplines of Scientific Psychology.” American Psychologist 12: 671–84. https://doi.org/10.1037/h0043943.\n\n\nDablander, Fabian, and Max Hinne. 2019. “Node Centrality Measures Are a Poor Substitute for Causal Inference.” Scientific Reports 9 (1): 6846. https://doi.org/10.1038/s41598-019-43033-9.\n\n\nDablander, Fabian, and Riet van Bork. 2021. “Causal Inference.” In Network Psychometrics with R, 213–32. N Isvoranu, A. M., Epskamp, S., Waldorp, L. J., & Borsboom, D. (Eds.). Network Psychometrics with R: A Guide for Behavioral and Social Scientists. Routledge, Taylor & Francis Group. Routledge.\n\n\nDalege, J. 2020. “A Formal Approach to Attitude.”\n\n\nDalege, Jonas, Denny Borsboom, Frenk van Harreveld, Helma van den Berg, Mark Conner, and Han L. J. van der Maas. 2016. “Toward a Formalized Account of Attitudes: The Causal Attitude Network (CAN) Model.” Psychological Review 123 (1): 2–22. https://doi.org/10.1037/a0039802.\n\n\nDalege, Jonas, Denny Borsboom, Frenk van Harreveld, and Han L. J. van der Maas. 2018. “The Attitudinal Entropy (AE) Framework as a General Theory of Individual Attitudes.” Psychological Inquiry 29 (4): 175–93. https://doi.org/10.1080/1047840X.2018.1537246.\n\n\nDalege, Jonas, and Han L. J. van der Maas. 2020. “Accurate by Being Noisy: A Formal Network Model of Implicit Measures of Attitudes.” Social Cognition 38 (Suppl): S26–41. https://doi.org/10.1521/soco.2020.38.supp.s26.\n\n\nDattagupta, S. 1981. “The Tricritical Point - - a Qualitative Review.” Bull Mat Sci 3 (2): 133–39. https://doi.org/10.1007/BF02908488.\n\n\nDellaPosta, Daniel. 2020. “Pluralistic Collapse: The ‘Oil Spill’ Model of Mass Opinion Polarization.” American Sociological Review 85 (3): 507–36. https://doi.org/10.1177/0003122420922989.\n\n\nDeserno, Marie K., Denny Borsboom, Sander Begeer, Riet van Bork, Max Hinne, and Hilde M. Geurts. 2020. “Highways to Happiness for Autistic Adults? Perceived Causal Relations Among Clinicians.” PLOS ONE 15 (12): e0243298. https://doi.org/10.1371/journal.pone.0243298.\n\n\nDorogovtsev, S. N., and J. F. F. Mendes. 2002. “Evolution of Networks.” Advances in Physics 51 (4): 1079–1187. https://doi.org/10.1080/00018730110112519.\n\n\nElovainio, Marko, Jari Lipsanen, Laura Pulkki-Råback, Jaana Suvisaari, and Christian Hakulinen. 2021. “Is Symptom Connectivity Really the Most Important Issue in Depression? Depression as a Dynamic System of Interconnected Symptoms Revisited.” Journal of Psychiatric Research 142 (October): 250–57. https://doi.org/10.1016/j.jpsychires.2021.08.004.\n\n\nEpskamp, Sacha, Denny Borsboom, and Eiko I. Fried. 2018. “Estimating Psychological Networks and Their Accuracy: A Tutorial Paper.” Behavior Research Methods 50 (1): 195–212. https://doi.org/10.3758/s13428-017-0862-1.\n\n\nEpskamp, Sacha, Angélique O. J. Cramer, Lourens J. Waldorp, Verena D. Schmittmann, and Denny Borsboom. 2012. “Qgraph: Network Visualizations of Relationships in Psychometric Data.” Journal of Statistical Software 48 (May): 1–18. https://doi.org/10.18637/jss.v048.i04.\n\n\nEpskamp, Sacha, Mijke Rhemtulla, and Denny Borsboom. 2017. “Generalized Network Psychometrics: Combining Network and Latent Variable Models.” Psychometrika 82 (4): 904–27. https://doi.org/10.1007/s11336-017-9557-x.\n\n\nEpskamp, Sacha, Lourens J. Waldorp, René Mõttus, and Denny Borsboom. 2018. “The Gaussian Graphical Model in Cross-Sectional and Time-Series Data.” Multivariate Behavioral Research 53 (4): 453–80. https://doi.org/10.1080/00273171.2018.1454823.\n\n\nForbes, Miriam K., Aidan G. C. Wright, Kristian E. Markon, and Robert F. Krueger. 2017. “Evidence That Psychopathology Symptom Networks Have Limited Replicability.” Journal of Abnormal Psychology 126: 969–88. https://doi.org/10.1037/abn0000276.\n\n\nFraser, Steven. 2008. The Bell Curve Wars: Race, Intelligence, and the Future of America. Basic Books.\n\n\nFried, Eiko I, and Angélique O J Cramer. 2017. “Moving Forward: Challenges and Directions for Psychopathological Network Theory and Methodology.” Perspectives on Psychological Science 12 (6): 999–1020. https://doi.org/10.1177/1745691617705892.\n\n\nFried, Eiko I., Sacha Epskamp, Randolph M. Nesse, Francis Tuerlinckx, and Denny Borsboom. 2016. “What Are ’Good’ Depression Symptoms? Comparing the Centrality of DSM and Non-DSM Symptoms of Depression in a Network Analysis.” Journal of Affective Disorders 189 (January): 314–20. https://doi.org/10.1016/j.jad.2015.09.005.\n\n\nFriedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2008. “Sparse Inverse Covariance Estimation with the Graphical Lasso.” Biostatistics 9 (3): 432–41. https://doi.org/10.1093/biostatistics/kxm045.\n\n\nFytas, Nikolaos G., Victor Martin-Mayor, Marco Picco, and Nicolas Sourlas. 2018. “Review of Recent Developments in the Random-Field Ising Model.” Journal of Statistical Physics 172 (2): 665–72. https://doi.org/10.1007/s10955-018-1955-7.\n\n\nGarcez, Artur S. D’Avila, Luís C. Lamb, and Dov M. Gabbay. 2008. Neural-Symbolic Cognitive Reasoning. Springer Science & Business Media.\n\n\nHamaker, E. L., E. Ceulemans, R. P. P. P. Grasman, and F. Tuerlinckx. 2015. “Modeling Affect Dynamics: State of the Art and Future Challenges.” Emotion Review 7 (4): 316–22. https://doi.org/10.1177/1754073915590619.\n\n\nHaslbeck, Jonas M. B., and Oisín Ryan. 2022. “Recovering Within-Person Dynamics from Psychological Time Series.” Multivariate Behavioral Research 57 (5): 735–66. https://doi.org/10.1080/00273171.2021.1896353.\n\n\nHayes, Adele M., and Leigh A. Andrews. 2020. “A Complex Systems Approach to the Study of Change in Psychotherapy.” BMC Medicine 18 (1): 197. https://doi.org/10.1186/s12916-020-01662-2.\n\n\nHirsch, Morris W. 1985. “Systems of Differential Equations That Are Competitive or Cooperative II: Convergence Almost Everywhere.” SIAM Journal on Mathematical Analysis 16 (3): 423–39. https://doi.org/10.1137/0516030.\n\n\nHuth, Karoline, Jill de Ron, Judy Luigjes, Anneke Goudriaan, Reza Mohammadi, Ruth van Holst, Eric-Jan Wagenmakers, and Maarten Marsman. 2023. “Bayesian Analysis of Cross-sectional Networks: A Tutorial in R and JASP.” PsyArXiv. https://doi.org/10.31234/osf.io/ub5tc.\n\n\nIsvoranu, Adela-Maria, Sacha Epskamp, Lourens J. Waldorp, and Denny Borsboom. 2022. Network Psychometrics with R: A Guide for Behavioral and Social Scientists. Taylor & Francis Limited.\n\n\nJones, Payton J., Ruofan Ma, and Richard J. McNally. 2021. “Bridge Centrality: A Network Approach to Understanding Comorbidity.” Multivariate Behavioral Research 56 (2): 353–67. https://doi.org/10.1080/00273171.2019.1614898.\n\n\nKossakowski, Jolanda J., Lourens J. Waldorp, and Han L. J. van der Maas. 2021. “The Search for Causality: A Comparison of Different Techniques for Causal Inference Graphs.” Psychological Methods 26: 719–42. https://doi.org/10.1037/met0000390.\n\n\nKumar, Abhilasha A. 2021. “Semantic Memory: A Review of Methods, Models, and Current Challenges.” Psychonomic Bulletin & Review 28 (1): 40–80. https://doi.org/10.3758/s13423-020-01792-x.\n\n\nLange, Jens, and Janis H. Zickfeld. 2021. “Emotions as Overlapping Causal Networks of Emotion Components: Implications and Methodological Approaches.” Emotion Review 13 (2): 157–67. https://doi.org/10.1177/1754073920988787.\n\n\nLove, Jonathon, Ravi Selker, Maarten Marsman, Tahira Jamil, Damian Dropmann, Josine Verhagen, Alexander Ly, et al. 2019. “JASP: Graphical Statistical Software for Common Statistical Designs.” Journal of Statistical Software 88 (January): 1–17. https://doi.org/10.18637/jss.v088.i02.\n\n\nLowery, Megan R., Malissa A. Clark, and Nathan T. Carter. 2021. “The Balancing Act of Performance: Psychometric Networks and the Causal Interplay of Organizational Citizenship and Counterproductive Work Behaviors.” Journal of Vocational Behavior 125 (March): 103527. https://doi.org/10.1016/j.jvb.2020.103527.\n\n\nLunansky, Gabriela, Jasper Naberman, Claudia D. van Borkulo, Chen Chen, Li Wang, and Denny Borsboom. 2022. “Intervening on Psychopathology Networks: Evaluating Intervention Targets Through Simulations.” Methods 204 (August): 29–37. https://doi.org/10.1016/j.ymeth.2021.11.006.\n\n\nMarsman, Maarten, and Mijke Rhemtulla. 2022. “Guest Editors’ Introduction to The Special Issue ‘Network Psychometrics in Action’: Methodological Innovations Inspired by Empirical Problems.” Psychometrika 87 (1): 1–11. https://doi.org/10.1007/s11336-022-09861-x.\n\n\nMay, Edited by Professor Lord Robert, of Oxford, and Angela McLean, eds. 2007. Theoretical Ecology: Principles and Applications. Third Edition, Third Edition. Oxford, New York: Oxford University Press.\n\n\nMeena, Chandrakala, Chittaranjan Hens, Suman Acharyya, Simcha Haber, Stefano Boccaletti, and Baruch Barzel. 2023. “Emergent Stability in Complex Network Dynamics.” Nature Physics, April, 1–10. https://doi.org/10.1038/s41567-023-02020-8.\n\n\nMonroe, Brian M., and Stephen J. Read. 2008. “A General Connectionist Model of Attitude Structure and Change: The ACS (Attitudes as Constraint Satisfaction) Model.” Psychological Review 115: 733–59. https://doi.org/10.1037/0033-295X.115.3.733.\n\n\nNeedham, Amy Work, and Eliza L. Nelson. 2023. “How Babies Use Their Hands to Learn about Objects: Exploration, Reach-to-Grasp, Manipulation, and Tool Use.” WIREs Cognitive Science n/a (n/a): e1661. https://doi.org/10.1002/wcs.1661.\n\n\nPenke, Lars, Jaap J. A. Denissen, and Geoffrey F. Miller. 2007. “The Evolutionary Genetics of Personality.” European Journal of Personality 21 (5): 549–87. https://doi.org/10.1002/per.629.\n\n\nPeters, Gjalt Jorn Ygram, Szilvia Zörgő, and Han van der Maas. 2022. “The Qualitative Network Approach (QNA.” https://doi.org/10.31234/osf.io/cvf52.\n\n\nPosternak, Michael A., and Ivan Miller. 2001. “Untreated Short-Term Course of Major Depression: A Meta-Analysis of Outcomes from Studies Using Wait-List Control Groups.” Journal of Affective Disorders 66 (2): 139–46. https://doi.org/10.1016/S0165-0327(00)00304-9.\n\n\nRead, John, and Joanna Moncrieff. 2022. “Depression: Why Drugs and Electricity Are Not the Answer.” Psychological Medicine 52 (8): 1401–10. https://doi.org/10.1017/S0033291721005031.\n\n\nRobinaugh, Donald J., Ria H. A. Hoekstra, Emma R. Toner, and Denny Borsboom. 2020. “The Network Approach to Psychopathology: A Review of the Literature 2008 and an Agenda for Future Research.” Psychological Medicine 50 (3): 353–66. https://doi.org/10.1017/S0033291719003404.\n\n\nRon, Jill de, Marie Deserno, Donald Robinaugh, Denny Borsboom, and Han van der Maas. 2023. “Towards a General Modelling Framework of Resource Competition in Cognitive Development.” OSF Preprints. https://doi.org/10.31219/osf.io/sh6w7.\n\n\nRosencrans, Peter L., Lori A. Zoellner, and Norah C. Feeny. 2021. “A Network Approach to Posttraumatic Stress Disorder: Comparing Interview and Self-Report Networks.” Psychological Trauma: Theory, Research, Practice, and Policy, No Pagination Specified–. https://doi.org/10.1037/tra0001151.\n\n\nRyan, Oisín, Laura F. Bringmann, and Noémi K. Schuurman. 2022. “The Challenge of Generating Causal Hypotheses Using Network Models.” Structural Equation Modeling: A Multidisciplinary Journal 29 (6): 953–70. https://doi.org/10.1080/10705511.2022.2056039.\n\n\nSachisthal, Maien S. M., Brenda R. J. Jansen, Thea T. D. Peetsma, Jonas Dalege, Han L. J. van der Maas, and Maartje E. J. Raijmakers. 2019. “Introducing a Science Interest Network Model to Reveal Country Differences.” Journal of Educational Psychology 111: 1063–80. https://doi.org/10.1037/edu0000327.\n\n\nSala, Giovanni, N. Deniz Aksayli, K. Semir Tatlidil, Tomoko Tatsumi, Yasuyuki Gondo, and Fernand Gobet. 2019. “Near and Far Transfer in Cognitive Training: A Second-Order Meta-Analysis.” Edited by Rolf Zwaan and Peter Verkoeijen. Collabra: Psychology 5 (1): 18. https://doi.org/10.1525/collabra.203.\n\n\nSaul, D. M., Michael Wortis, and D. Stauffer. 1974. “Tricritical Behavior of the Blume-Capel Model.” Physical Review B 9 (11): 4964–80. https://doi.org/10.1103/PhysRevB.9.4964.\n\n\nSavi, Alexander O., Maarten Marsman, Han L. J. van der Maas, and Gunter K. J. Maris. 2019. “The Wiring of Intelligence.” Perspectives on Psychological Science 14 (6): 1034–61. https://doi.org/10.1177/1745691619866447.\n\n\nSpearman, C. 1904. “’General Intelligence,’ Objectively Determined and Measured.” The American Journal of Psychology 15: 201–93. https://doi.org/10.2307/1412107.\n\n\nSpiller, Tobias R., Ofir Levi, Yuval Neria, Benjamin Suarez-Jimenez, Yair Bar-Haim, and Amit Lazarov. 2020. “On the Validity of the Centrality Hypothesis in Cross-Sectional Between-Subject Networks of Psychopathology.” BMC Medicine 18 (1): 297. https://doi.org/10.1186/s12916-020-01740-5.\n\n\nSteyvers, Mark, and Joshua B. Tenenbaum. 2005. “The Large-Scale Structure of Semantic Networks: Statistical Analyses and a Model of Semantic Growth.” Cognitive Science 29 (1): 41–78. https://doi.org/10.1207/s15516709cog2901_3.\n\n\nTesser, Abraham. 1978. “Self-Generated Attitude.” In Advances in Experimental Social Psychology, edited by Leonard Berkowitz, 11:289–338. Academic Press. https://doi.org/10.1016/S0065-2601(08)60010-6.\n\n\nTilman, D, S S Kilham, and P Kilham. 1982. “Phytoplankton Community Ecology: The Role of Limiting Nutrients.” Annual Review of Ecology and Systematics 13 (1): 349–72. https://doi.org/10.1146/annurev.es.13.110182.002025.\n\n\nvan Bork, Riet, Sacha Epskamp, Mijke Rhemtulla, Denny Borsboom, and Han L. J. van der Maas. 2017. “What Is the p-Factor of Psychopathology? Some Risks of General Factor Modeling.” Theory & Psychology 27 (6): 759–73. https://doi.org/10.1177/0959354317737185.\n\n\nVan Der Maas, Han L. J., Conor V. Dolan, Raoul P. P. P. Grasman, Jelte M. Wicherts, Hilde M. Huizenga, and Maartje E. J. Raijmakers. 2006. “A Dynamical Model of General Intelligence: The Positive Manifold of Intelligence by Mutualism.” Psychological Review 113 (4): 842–61. https://doi.org/c3jm44.\n\n\nvan der Maas, Han L. J., Kees-Jan Kan, and Denny Borsboom. 2014. “Intelligence Is What the Intelligence Test Measures. Seriously.” Journal of Intelligence 2 (1): 12–15. https://doi.org/10.3390/jintelligence2010012.\n\n\nVan Der Maas, Han L. J., Kees-Jan Kan, Maarten Marsman, and Claire E. Stevenson. 2017. “Network Models for Cognitive Development and Intelligence.” Journal of Intelligence 5 (2): 16. https://doi.org/10.3390/jintelligence5020016.\n\n\nVan Overwalle, Frank, and Frank Siebler. 2005. “A Connectionist Model of Attitude Formation and Change.” Personality and Social Psychology Review: An Official Journal of the Society for Personality and Social Psychology, Inc 9 (3): 231–74. https://doi.org/10.1207/s15327957pspr0903_3.\n\n\nVangeli, Eleni, John Stapleton, Eline Suzanne Smit, Ron Borland, and Robert West. 2011. “Predictors of Attempts to Stop Smoking and Their Success in Adult General Population Samples: A Systematic Review.” Addiction (Abingdon, England) 106 (12): 2110–21. https://doi.org/10.1111/j.1360-0443.2011.03565.x.\n\n\nVoelkle, Manuel C., Johan H. L. Oud, Eldad Davidov, and Peter Schmidt. 2012. “An SEM Approach to Continuous Time Modeling of Panel Data: Relating Authoritarianism and Anomia.” Psychological Methods 17: 176–92. https://doi.org/10.1037/a0027543.\n\n\nWaldorp, Lourens, and Maarten Marsman. 2022. “Relations Between Networks, Regression, Partial Correlation, and the Latent Variable Model.” Multivariate Behavioral Research 57 (6): 994–1006. https://doi.org/10.1080/00273171.2021.1938959.\n\n\nWittenborn, A. K., H. Rahmandad, J. Rick, and N. Hosseinichimeh. 2016. “Depression as a Systemic Syndrome: Mapping the Feedback Loops of Major Depressive Disorder.” Psychological Medicine 46 (3): 551–62. https://doi.org/10.1017/S0033291715002044."
  },
  {
    "objectID": "ch6.html#footnotes",
    "href": "ch6.html#footnotes",
    "title": "6  Psychological Network Models",
    "section": "",
    "text": "The original title of this paper was “No reason to p,” but the editor did not think it was funny.↩︎\nAssuming that all the attitude states (items) are reencoded as positive (or negative) valued items.↩︎"
  }
]