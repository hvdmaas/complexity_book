[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Complex Systems in Psychology",
    "section": "",
    "text": "Foreword\nThis book has three primary objectives. The first is to provide a comprehensive review of complex systems research, with a specific emphasis on its applications in psychology and the social sciences. The second is to provide skills for complex systems research. Lastly, it strives to foster critical thinking regarding the potential applications of complex systems in psychology.\nThis book is intended for psychologists and social scientists who have an interest in the modeling of psychological processes. This is not an easy book to read, it requires study. I have used the material in the book for a master’s course for research-oriented psychology students. I assume only pre-university knowledge of mathematics and refer to basic sources where there is quite a bit of mathematics.\nAn important prerequisite is a basic knowledge of the programming language R. There are many online resources for learning the basics of R. Many exercises in the book require R. As an alternative option, one can utilize an online Python markdown file containing all the code. I also assume some knowledge of statistics and data-analysis, at the level of a Master’s in psychology. A lot of theoretical ideas will be illustrated with real examples. This is a theory and a practice book at the same time.\nFor many decades, scientists have been studying all kinds of complex systems made up of many smaller subsystems interacting locally on fast time scales. Well-known examples include lasers, tornados, chemical oscillations, ant nests and flocks of birds. Scientists have built mathematical models of these complex systems and developed techniques to study them. The application of these techniques requires a great deal of mathematical and technical knowledge, but also a deep understanding of the nature of the system. You do not just build a mathematical model. Finally, testing such models requires extensive and reliable quantitative data. The application of complex systems theory to the behavioral and social sciences is therefore not straightforward. Theories are often verbal, and quantitative measurement in these sciences is a longstanding issue. While there has been some reasonable progress over the past 150 years, it is fair to say that the behavioral and social sciences are still in their infancy.\nThe application of complex systems theory to the behavioral and social sciences is challenging but, in my view, also essential. Whether we consider humans in isolation, the billions of interacting neurons in the brain, or the social networks in which we find ourselves, complexity is everywhere. Humans, with their complex brains embedded in various hierarchies of social systems, are the ultimate complex systems.\nIn fact, research on this system can only succeed if we understand complexity. We need to apply the tools of complexity science to our field of science, which is in desperate need of breakthroughs. After all, the modern world revolves around human beings who, through language and thought, have created an unimaginably complex world. The greatest danger now is man himself, and progress in the field of psychology is necessary and urgent.\nI have written this book based on 35 years of scientific work in collaboration with fantastic colleagues and co-authors of the many papers. I’m part of the ecosystem of the Psychology department, especially the wonderful methods section, of the University of Amsterdam. Also important is the Institute of Advanced Study in Amsterdam, which has complex systems research as a central theme. In recent years I’ve also been an external faculty member at the famous Santa Fe Institute in New Mexico. I am indebted to all of them and to many other colleagues around the world.\nHan van der Maas, Amsterdam 2023"
  },
  {
    "objectID": "ch1.html#what-are-complex-systems",
    "href": "ch1.html#what-are-complex-systems",
    "title": "1  Introduction",
    "section": "1.1 What are complex systems?",
    "text": "1.1 What are complex systems?\nMarkdown allows you to write using…\nSome things in life are simple. When you open the tap, water starts to flow. If you open it further, it flows faster, and if you close it, it stops. Cause-and-effect relationships like this are clear and roughly linear. Such relationships are rare in psychology. Let’s take fear as an example. A fear stimulus, for example a barking dog, can lead to fear and flight, but also to anger and attack. Whether the stimulus is perceived as fearful might depend on subtle differences in context. It has also been debated whether the flight response precedes the feeling of fear or vice versa. Fear could also suddenly change into a panic attack. In psychology, cause and effect relationships are rarely simple, and effects are often non-linear.\nThese difficulties are not unique to psychology (Weaver 1948). Many systems studied in physics, chemistry, and biology show such complex behavior. They are complex systems. Unfortunately, there is no full consensus on the definition of a complex system (Ladyman, Lambert, and Wiesner 2013; Mitchell 2009), but some criteria can be specified (Simon 1962). First, complex systems are made up of many smaller interacting subsystems. These interactions are typically local and fast, as between neurons in our brain. Second, complex systems are open systems, meaning that energy can be absorbed from the environment. Third, complex systems have three types of emergent phenomena. They are fundamentally unpredictable (chaos), they can change very suddenly (phase transitions), and they exhibit globally organized behavior on a slow time scale (self-organization). These remarkable behavioral properties will be discussed in depth in chapters 2, 3 and 4. In this introduction I will present some key examples of complex systems, introduce some general concepts, and discuss the applicability to psychology. I start with the brain.\nThe brain can be considered the ultimate complex system. Compared to computers, brains are extremely energy efficient, but they do consume energy (the equivalent of a light bulb according to (Attwell and Iadecola 2002). About a hundred billion neurons interact with thousands of other neurons in their neighborhood. Fast local interactions somehow form global waves of electrical activity that make up thought processes and even consciousness. The letters you are reading activate retinal neurons that initiate a cascade of electrical waves across billions of neurons that somehow create your understanding of this text (Roberts et al. 2019; Schöner 2020). How is this possible? For me, this is the most fascinating scientific question of all time. It’s the main reason why I’m a psychologist and not a physicist. It is also an extremely difficult question. But we can learn a lot by studying similar systems in physics, chemistry, and biology. Many physical, chemical, and biological systems fall into this category of complex systems.\nAnother fascinating example of a complex system is a flock of birds (Figure 1.1). Flocks of birds move in a beautiful choreography as they glide through the air, their formations shifting and morphing as they twist and turn across the sky. Flocks are well understood and easy to simulate, as we will see in Chapter 4. Flocks fulfill all the criteria of a complex system. They are open systems as birds use energy to fly. Next, each bird responds only to birds in its local neighborhood. They follow roughly three rules. They try to fly in the same direction as their neighbors, stay close to their neighbors and avoid collisions. These are fast and local interactions. I suggest you watch some videos of flocks of birds on the internet. What you see is globally organized behavior on a much slower time scale than the local interactions. This is a prime example of self-organization. There is evidently no one bird in control ordering other birds to change direction. The globally organized behavior of a flock is a form of spontaneous order. What you can also see in these movies is that stable patterns, say an oval shape, can suddenly change. The birds may change direction or split up. Such bifurcations or catastrophes (to be explained in chapter 3) are very typical of complex systems. You can also see that the behavior of these swarms is rather unpredictable. As said, swarms are well understood and can be easily simulated on a computer, but this does not mean that we can predict these systems, an issue that will be discussed further in the next chapter.\n\n\n\nFigure 1.1: A flock of birds\n\n\nThe units or subsystems of a complex system are not necessarily biological systems. Tornados, for example, are made up of air molecules that also interact locally. Tornadoes are unpredictable, self-organizing, global weather phenomena. A famous chemical example is the Belousov-Zhabotinsky reaction, a chemical oscillator (Kuramoto 1984). Again, watching a YouTube video is highly recommended.\nA very inspiring example for me comes from the study of shallow lakes (Scheffer 2004). Shallow lakes tend to be either in a ‘healthy’ state, with clear water and a diverse population of fish and plants, or in an ‘unhealthy’ turbid state. I like to compare these complex lake systems in the turbid state to a patient suffering from depression. This turbid state usually occurs suddenly. There is a critical phosphorus load at which the system “turns over” from being healthy to complete dominance by algae and bream. Typical of this type of transition is the hysteresis effect (Figure 1.2). This means that the turning point from clear to turbid and from turbid to clear does not occur at the same phosphorus load. The turning point to clear water only occurs at much lower phosphorus loads. These tipping points may be so far apart that reducing the cause, the phosphorus load, is not a viable option. Of course, all sorts of interventions have been studied, such as supplemental oxygen, chemicals, sunscreens and stocking predatory fish. Not all of these interventions were successful in every case. The fact that they had some level of success brings to mind the partial effectiveness of clinical interventions, such as those used in the treatment of major depressive disorder.\n\n\n\nFigure 1.2: The transitions between clear and turbid states of shallow lakes do not occur at the same phosphorus load. This delay in jumps is called hysteresis. Hysteresis explains why transitions are often difficult to reverse. This concept is discussed in detail in Chapter 3.\n\n\nA breakthrough occurred in the 1980s. Catching all the fish proved to be a very effective intervention. The ecologists caught almost all the fish with nets during the winter. In the spring, a new, healthy equilibrium emerged, characterized by aquatic plants, other fish species and clear water. This new state is often stable for long periods of time. Remarkably, the analysis of the cause, the phosphorus load, was not part of the solution: although the increasing phosphorus load is the primary cause of the transition towards a turbid state, decreasing the phosphorus lead does not cause the system to transition back into the clear state. The dogma of intervention, that the cause of the problem is the key to the solution, does not necessarily apply to complex systems. What this means for our thinking about depressed patients will be discussed later."
  },
  {
    "objectID": "ch1.html#psychology-and-the-social-sciences",
    "href": "ch1.html#psychology-and-the-social-sciences",
    "title": "1  Introduction",
    "section": "1.2 Psychology and the social sciences",
    "text": "1.2 Psychology and the social sciences\nThe study of complex systems in the natural sciences (Figure 1.3) is highly technical. I like to think of the field of complex systems as a toolbox of empirical paradigms and mathematical models and techniques (Grauwin et al. 2012). Models are often formulated in the form of difference or differential equations and subjected to, for example, bifurcation analysis. These are mathematical ways of describing the behavior of complex systems. In addition, advanced numerical analysis, computer simulation, is standard. However, educational programs in psychology do not usually include courses in algebra, calculus and programming. Psychologists, and social scientists in general, lack the basic knowledge and skills to apply the toolbox of complex systems theory, as these are not ordinarily part of the psychology curriculum. Complex systems research simply seems too complex for psychologists and social scientists.\nMoreover, there are additional complications in applying this toolbox to our field. First, our subjects are much more complex than flocks of birds or tornadoes and display astonishing behavior. They can do science! They can also walk out of the lab because they find the experiment boring. This does not happen with lasers.\nSecond, we have to deal with the ethical constraints of experimenting on our subjects. We cannot take them apart, a very successful approach in the natural sciences. Finally, there is the measurement issue (Lumsden 1976; Michell 1999). We tend to forget how incredibly precise the natural sciences, especially physics, are. In 1985, Richard Feynman famously claimed that the accuracy of calculating the size of the magnetic moment of the electron was equivalent to measuring the distance from Los Angeles to New York, a distance of over 3,000 miles, to the width of a human hair. I find that shocking. Less famously, I would argue that social scientists have not yet discovered America and have no idea where New York is. Our instruments generally fail to meet elementary requirements of reliability and validity, we are plagued by replication failures, and our theories are often imprecise (Eronen and Bringmann 2021). Navigating the behavioral and social sciences and knowing which data to trust and which empirical phenomena to model is an art in itself.\n\n\n\nFigure 1.3: An overview of the toolbox of complex system science (source: Wikipedia)\n\n\nThis is all unfortunate because not only our brains, but every subject in our field seems to have the characteristics of a complex system. Any social system is a complex system, made up of individuals interacting to produce emergent phenomena such as cultures and economics. The human brain, the most complex system we know, is embedded in different hierarchies of very complex social systems such as families, education, economies, and cultures. We need the toolbox!\nDespite all these problems, I’m not pessimistic. I would also argue that tangible progress in the behavioral and social sciences is possible. It is not that these sciences are completely unsuccessful. We know a lot about people’s attitudes, addictive behavior, cognition, and the social systems in which they interact. We study these, with some success, using advanced experimental designs, and we have developed verbal theories about almost everything.\nWe also have no choice; we must make progress. Personally, I feel a strong tension between our struggle to elevate the behavioral and social sciences as a science on the one hand, and the enormous expectations of society to deliver on the other. Our most pressing global problems - climate change, overpopulation, war and violence, poverty, inequality, infectious diseases, addiction, to name but a few - are unsolvable without breakthroughs in the behavioral and social sciences.\nThe realization that the human mind in its social context is an amazingly complex system also offers opportunities. Despite their obvious differences, complex systems show remarkable similarities. A predecessor of complex system theory, general systems theory (Bertalanffy 1969), explicitly assumed that all systems share important characteristics. Certain mechanisms and phenomena seem to operate in similar ways at all possible levels of description. In the following, I will discuss three reasons to be somewhat optimistic, based on three key observations about complex systems. The first key observation has to do with simplification, the second with the tendency of complex systems to be characterized by a limited number of stable states, and the third key observations is that all complex systems seem to be describable as some kind of network. Simplification is perhaps the most important one, which I first discuss under the heading of emergentism."
  },
  {
    "objectID": "ch1.html#emergentism",
    "href": "ch1.html#emergentism",
    "title": "1  Introduction",
    "section": "1.3 Emergentism",
    "text": "1.3 Emergentism\nA difficult question, which I will not discuss in depth, is the relationship between complexity and reductionism (the idea that complex phenomena can be explained by reducing them to the interactions of their individual parts or components). The first question is why it is possible to do science in any field other than physics, since ultimately chemistry, biology, and even psychology, are all about interacting elementary particles. Should we not first finish the study of physics before starting to think about complex molecules, cells, neurons, or higher-order human cognition?\nPhilip Anderson’s renowned paper on “More is Different” convincingly argues that the answer to this question is a resounding no (Anderson 1972). Science is possible at many different levels of description without fully understanding the lower levels. Why this is possible is not entirely clear. There is much to be said for reductionism, but somehow the laws of quantum mechanics are irrelevant when studying interactions between neurons or people. I don’t think that emergence in complex systems is inconsistent with a reductionist view of science (Bechtel and Abrahamsen 2005). One could say that complex systems theory explains why emergent phenomena such as swarms can be used as entities at a higher level of description to explain new higher order phenomena, without being a dualist.\nA fascinating and instructive example is the traffic jam, which is made up of many people, with their amazingly complex brains, in modern cars full of advanced technology. Where to start? The answer is astonishing. It seems that we can reduce people in cars to simple blocks in a lane, speeding up when there is space in front of the artificial car and braking when they get too close to the car in front. This is even simpler than a flock of birds.\nIt is not difficult to set up a computer simulation for this case. I recommend that you spend some time playing around with an example (https://www.traffic-simulation.de/). It does not take long to see that traffic jams can easily form and have an unexpected property: while cars move forward, traffic jams move backwards! Another interesting observation is that variance in speed causes congestion. But the variance is not in any of the cars. Variance and congestion are properties at a higher level of description. With this simulation, you can study different types of traffic situations and interventions. This type of simulation seems to be very useful for the design of motorways (Barceló 2010; Treiber, Hennecke, and Helbing 2000).\nThe traffic example shows that extreme simplification is sometimes possible and necessary. In complex systems, the qualitative properties of large-scale phenomena do not depend on microscopic details. Only higher-level properties are relevant to global behavior (Castellano, Muñoz, and Pastor-Satorras 2009). To me, the art of doing science is, for a large part, finding the right level of simplification. Suppose we are studying smoking. Do we model the effects of nicotine on blood vessels, how the hand with the cigarette moves from the mouth to the ashtray, or the number of cigarettes smoked per day? Do we include the effects of marketing and the smoker’s social network?\nWhat is relevant and what can be ignored? It can be challenging to provide a definitive answer for specific cases. Nevertheless, in general, it can be stated that there is a limit to the lower levels that must be considered. When examining traffic jams, it is necessary to incorporate certain characteristics of individuals and vehicles, but delving deeper into topics like neuronal firing, DNA replication, or the intricate workings of car batteries becomes irrelevant. At that level of modeling, there is no relevant information that would alter the explanation of a traffic jam. This fundamental principle of emergence is what allows disciplines like psychology to exist as distinct and independent fields of science (Fodor 1974).\nThe second, more controversial, question is whether emergent phenomena have an independent causal role (strong emergence) or mainly have descriptive value (weak emergence). Strong emergence is often associated with downward causation (Chalmers 2006; Flack 2017; Kim 2006). Downward or circular causation is the idea that higher-level entities or properties can influence the behavior of lower-level entities or properties. I like to link this to the flocking example. Flocks of birds are emergent phenomena that do not determine the behavior of the individual birds. The birds only follow the local rules. Flocking is an example of weak emergence. However, when predators enter the scene things change. Predators get confused by flocks of prey, not by the behavior of individual birds. So, the flock has some causal power. Moreover, the birds react to the movements of the predator. This could be seen as an example of downwards causation and thus strong emergence (Figure 1.4). Recent work attempts to quantify such causal emergence effects (Hoel, Albantakis, and Tononi 2013).\nIt is also argued that emergence is a consequence of symmetry breaking (Krakauer 2023). Symmetry breaking occurs when a system transitions from a symmetric state to an asymmetric state, resulting in the emergence of distinct properties or behaviors. An example of symmetry breaking can be observed in the formation of snowflakes. Initially, ice crystals have a symmetrical hexagonal shape due to the underlying molecular structure of water. However, as the crystal continues to grow, environmental factors such as temperature and humidity influence its growth pattern. Minute variations in these factors lead to the breaking of initial symmetry and the formation of diverse and beautiful snowflake structures.\n\n\n\nFigure 1.4: An illustration of downwards or circular causation in flocks due to a predator responding to the emerging patterns of the flock and subsequently influencing the flight of individual birds. (adapted from https://arxiv.org/abs/1108.1682).\n\n\nIn my view, the arguments against strong emergence and downward causation may be difficult to entirely dismiss, yet they seem rather futile. Our minds, encompassing conscious thought, self-awareness, reasoning abilities, natural language comprehension, emotions, and attitudes, are not mere artifacts and cannot be simply reduced to intricate patterns of neural activity. These mental constructs possess their own causal influence, and psychology stands as a scientific discipline in its own right."
  },
  {
    "objectID": "ch1.html#theory-construction-methodology",
    "href": "ch1.html#theory-construction-methodology",
    "title": "1  Introduction",
    "section": "1.4 Theory construction methodology",
    "text": "1.4 Theory construction methodology\nFinding the right level of simplification is key but not a simple task at all. In (Borsboom et al. 2021) we propose a theory construction methodology (TCM) consisting of five steps. The first step is to identify the empirical phenomena that become the target of explanation. The second step is to formulate a set of theoretical principles that putatively explain these phenomena. Third, this set or prototheory is used to construct a formal model, a set of model equations that encode the explanatory principles. Fourth, we analyze the explanatory adequacy of the model, i.e., whether it actually reproduces the phenomena identified in step one. Fifth, we determine whether the explanatory principles are sufficiently parsimonious and substantively plausible. The article explains these steps in detail and provides an example, the mutualism model of general intelligence, which is explained in chapter five of this book.\nI will add a few comments to this list of steps. First of all, step 1 is key. It is crucial to be precise about what the phenomena to be explained are. Phenomena are not the same as data. Data are particular empirical patterns (a concrete data set), whereas phenomena refer to general empirical patterns, stable and general features of the world (Haig 2014). As noted above, in the behavioral and social sciences it is not always clear which data patterns can be trusted. In the last 10 years, the replication crisis has led to a revolution in psychological methods, but many results are collected using potentially biased methods. One problem is publication bias. Negative results are still harder to publish than results that support hypotheses. In other cases, the results of different studies contradict each other, and meta-analyses show weak effects at best. Drawing up a list of the most important phenomena on a topic, such as depression, forgetting or discrimination, is often a challenge.\nThe second observation is that taking these steps is not a linear process. Often, when you are building a model, you realize that there is crucial information missing from the list of phenomena. For example, you might be modelling addiction, but suddenly you need information about the combination of addictive substances that people use. And such simple questions are often impossible to answer. I spent days searching the literature for information that I expected to be readily available, only to find that many basic things are simply unknown.\nA third observation is that formal modelling is mostly a matter of analogical reasoning. You have to study many examples of complex system models to understand how to build such a model. Indeed, in my own work I often use established models developed in physics and biology as a base model. We will see many examples of this later.\nFourth, good models do not build in phenomena, but explain them from basic principles. We will see examples of phenomenological models of complex systems, as well as explanatory models, where the latter are based on fundamental principles. Building real explanatory models in our fields is extremely difficult.\nFifth, it is my conviction that a metaphorical use of the complex systems approach should be avoided by using concrete formal models. It is crucial to strive for the highest level of scientific rigor. There are no special, more lenient, methodological rules for complex systems research (van der Maas 1995)."
  },
  {
    "objectID": "ch1.html#a-limited-number-of-equilibria",
    "href": "ch1.html#a-limited-number-of-equilibria",
    "title": "1  Introduction",
    "section": "1.5 A limited number of equilibria",
    "text": "1.5 A limited number of equilibria\nThat complex systems can be simplified was the first key observation. The second key observation is that complex systems tend to be characterized by a limited number of equilibria. An important example is water. Water normally exists in either a solid, liquid or gaseous state (leaving aside the plasma state). These are stable states over wide ranges of temperature and pressure.\nA biological example is the life stages of a butterfly (egg, caterpillar, chrysalis and butterfly). Most of the time these insects are in one of these four relatively stable states. Another example is the horse, which is either standing still, walking, trotting or galloping. I am convinced that we must always start by identifying the equilibria of a complex system. This also applies to psychological and social science applications. A bipolar disorder seems to be characterized by two stable states (depressive and manic). In case of addiction we may think of a state of non-use, recreational use, and heavy use (Epskamp et al. 2022). Similarly, we should identify the stages in falling in love, in understanding of calculus, in sleeping and in radicalization.\nThis turns out to be more difficult than it first appears. There is an ongoing discussion about the number of stages, even for something like sleep stages (de Mooij et al. 2020). It is often possible to come up with more substages. For instance, in the case of horse movement people tend to further subdivide trot into three forms (working, medium, and collected). Subdivisions are also made in the case of heavy alcohol consumption (Leggio et al. 2009). It is possible to use objective statistical methods to support such classifications using modern machine learning techniques (automatic clustering) as well as more traditional means (finite mixture models, latent class analysis). I will say more about this in Chapter 3.\nA further complication is that equilibria come in different forms. The simplest form consists of fixed points or point attractors, an example being a ball lying in a valley. Under undisturbed conditions, the ball could also be resting on top of a hill, which is an unstable equilibrium. An equilibrium could also be a limit cycle or oscillator. For example, two pendulums could swing in phase or out of phase. It gets even weirder when we get to strange attractors, which often take the form of fractals. This will be explained in more detail in the next chapter.\nAlthough complex systems tend to be in one attractor state most of the time, they occasionally change states. If certain control parameters slowly change their values, the current equilibrium can become unstable and a transition to another equilibrium can occur. This is what happens when we lower the temperature of water to below zero. Transitions can occur in many ways, also depending on the types of equilibria involved. The family of transition models is described by bifurcation theory. This is explained in more detail in Chapter 3, where we focus on a very important transition model, the cusp catastrophe, and in Chapter 5, which considers dynamical systems models."
  },
  {
    "objectID": "ch1.html#networks-are-everywhere",
    "href": "ch1.html#networks-are-everywhere",
    "title": "1  Introduction",
    "section": "1.6 Networks are everywhere",
    "text": "1.6 Networks are everywhere\nThe third key observation of great relevance to the attempt to use complex systems modelling in psychology is that complex systems are networks, as they consist of interacting sub-elements. For me, the network is the most interdisciplinary research topic in modern science. Magnets, ecosystems, the brain, the Internet, and social networks are prime examples. Network science is a huge area of research with many fundamental insights.\nIn psychology, two applications are well known: the first is the study of neural networks, which started 70 years ago and has become the main foundation of the AI revolution of the last 10 years. In Chapter 4 I will discuss neural networks. The second is social networks, the simplest example being dyadic interactions. Social media such as Facebook are large examples. Key ideas relate to concepts such as weak and strong ties, central hubs and homophily, which are discussed in Chapter 6 and 7. The analysis of social network data is an exciting area of research (Scott 2011). It focuses on understanding how social entities are connected and how these connections influence various outcomes and behaviors. Connections between nodes (e.g., individuals, organizations, communities) can be based on different dimensions, such as friendship, communication, collaboration, information flow, or any other form of social interaction. These interactions may also change over time, which is studied in social network dynamics (Snijders 2001). The statnet.org website provides an overview of R packages for social network analysis.\nChapter 6 focuses on another use of networks, which we call network psychology. This is a level of description between neural networks and social networks. It involves modelling intelligence, attitudes, and psychological disorders at the individual level. Intelligence, for example, is modelled as an ecosystem of cooperating cognitive functions. This differs from the standard view that general intelligence is due to g, a single underlying source. Similarly, depression can be seen as a network of mutually reinforcing symptoms. This new view of mental disorders originated in our research group and is now very popular (Robinaugh et al. 2020). One reason for this is that many statistical techniques have been developed to investigate this network approach.\nThe latest line of research is the integrated study of psychological and social networks. Chapter 7 deals with models in which psychological network models of attitudes are nested within social networks of opinion change."
  },
  {
    "objectID": "ch1.html#other-work-and-sources",
    "href": "ch1.html#other-work-and-sources",
    "title": "1  Introduction",
    "section": "1.7 Other work and sources",
    "text": "1.7 Other work and sources\nThe complex systems approach is often introduced as the next new thing, but those days are gone. Even in psychology it can no longer be considered a new approach. Many different research groups have used the toolbox of complex systems research in many areas of psychology. This book will give many examples. One could even argue that a lot of work has been done that could be considered complex systems research but has not been published under that heading. For example, most neural network models of psychological processes are complex systems models because they investigate emergent computational properties of the interaction of neural units. This is also true of much work in mathematical psychology, for example when differential equations are used to study dynamical systems. Older work in complex systems research has often been published with reference to nonlinear dynamical systems, which is a related concept. Other related approaches are computational social science and agent-based modeling.\nToday, there are many interdisciplinary centers or hubs for complexity research. The Santa Fe Institute in Santa Fe, New Mexico, is one of the pioneers of complexity science. Its summer schools are highly recommended. Other famous ones are the Institute for Advanced Study in Princeton, the Complexity Science Hub in Vienna, and the Centre for Complexity Science at the University of Warwick. In my own country, the Netherlands, we have at least four of these centers. I’m a principal investigator at the Institute for Advanced Study in Amsterdam and an external faculty member at the Santa Fe Institute.\nIt is impossible to give a balanced review of all past and ongoing work on complex systems. I’m naturally somewhat biased towards our own work and contributions, but I’ll do my best to point out relevant work. As a general resource to complex systems research with a bit less technical approach I recommend Mitchell’s book (Mitchell 2009), for a bit more mathematical approach (but still doable), I recommend the book of Serra and Zanarini (Serra and Zanarini 1990). Overviews of work in psychology are provided by (Guastello, Koopmans, and Pincus 2008) and (Port and Gelder 1995). Other great books are written by (Heath 2000) and (Kelso 1995)."
  },
  {
    "objectID": "ch1.html#exercises",
    "href": "ch1.html#exercises",
    "title": "1  Introduction",
    "section": "1.8 Exercises",
    "text": "1.8 Exercises\n\nVisit https://www.traffic-simulation.de/. In what direction do traffic jams move? For roundabouts: what is a bad priority rule? Do traffic jams appear and disappear for the same values of critical parameters? Take for instance the ‘ring’ road and vary Politeness. (*)\nGive your own example of a psychological process or theory where different stable stage or states are distinguished. (*)\nCould consciousness be seen as a process of downwards causation. Explain your answer. (**)\n\n\n\n\n\nAnderson, P. W. 1972. “More Is Different.” Science 177 (4047): 393–96. https://doi.org/10.1126/science.177.4047.393.\n\n\nAttwell, David, and Costantino Iadecola. 2002. “The Neural Basis of Functional Brain Imaging Signals.” Trends in Neurosciences 25 (12): 621–25. https://doi.org/10.1016/S0166-2236(02)02264-6.\n\n\nBarceló, Jaume, ed. 2010. Fundamentals of Traffic Simulation. Vol. 145. International Series in Operations Research & Management Science. New York, NY: Springer New York. https://doi.org/10.1007/978-1-4419-6142-6.\n\n\nBechtel, William, and Adele Abrahamsen. 2005. “Explanation: A Mechanist Alternative.” Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences, Mechanisms in biology, 36 (2): 421–41. https://doi.org/10.1016/j.shpsc.2005.03.010.\n\n\nBertalanffy, Ludwig Von. 1969. General System Theory: Foundations, Development, Applications. Revised edition. New York, NY: George Braziller Inc.\n\n\nBorsboom, Denny, Han L J van der Maas, Jonas Dalege, Rogier A Kievit, and Brian D Haig. 2021. “Theory Construction Methodology: A Practical Framework for Building Theories in Psychology.” Perspectives on Psychological Science 16 (4): 756–66. https://doi.org/10.1177/1745691620969647.\n\n\nCastellano, Claudio, Miguel A. Muñoz, and Romualdo Pastor-Satorras. 2009. “Nonlinear $q$-Voter Model.” Physical Review E 80 (4): 041129. https://doi.org/10.1103/PhysRevE.80.041129.\n\n\nChalmers, David J. 2006. “Strong and Weak Emergence.” https://philpapers.org/rec/chasaw.\n\n\nde Mooij, Susanne M. M., Tessa F. Blanken, Raoul P. P. P. Grasman, Jennifer R. Ramautar, Eus J. W. Van Someren, and Han L. J. van der Maas. 2020. “Dynamics of Sleep: Exploring Critical Transitions and Early Warning Signals.” Computer Methods and Programs in Biomedicine 193 (September): 105448. https://doi.org/10.1016/j.cmpb.2020.105448.\n\n\nEpskamp, Sacha, Han L. J. van der Maas, Roseann E. Peterson, Hanna M. van Loo, Steven H. Aggen, and Kenneth S. Kendler. 2022. “Intermediate Stable States in Substance Use.” Addictive Behaviors 129 (June): 107252. https://doi.org/10.1016/j.addbeh.2022.107252.\n\n\nEronen, Markus I., and Laura F. Bringmann. 2021. “The Theory Crisis in Psychology: How to Move Forward.” Perspectives on Psychological Science 16 (4): 779–88. https://doi.org/10.1177/1745691620970586.\n\n\nFlack, Jessica C. 2017. “Coarse-Graining as a Downward Causation Mechanism.” Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 375 (2109): 20160338. https://doi.org/10.1098/rsta.2016.0338.\n\n\nFodor, J. A. 1974. “Special Sciences (or: The Disunity of Science as a Working Hypothesis).” Synthese 28 (2): 97–115. https://doi.org/10.1007/BF00485230.\n\n\nGrauwin, Sebastian, Guillaume Beslon, Éric Fleury, Sara Franceschelli, Celine Robardet, Jean-Baptiste Rouquier, and Pablo Jensen. 2012. “Complex Systems Science: Dreams of Universality, Interdisciplinarity Reality.” Journal of the American Society for Information Science and Technology 63 (7): 1327–38. https://doi.org/10.1002/asi.22644.\n\n\nGuastello, Stephen J., Matthijs Koopmans, and David Pincus. 2008. Chaos and Complexity in Psychology: The Theory of Nonlinear Dynamical Systems. Cambridge University Press.\n\n\nHaig, Brian D. 2014. Investigating the Psychological World: Scientific Method in the Behavioral Sciences. MIT Press.\n\n\nHeath, Richard A. 2000. Nonlinear Dynamics: Techniques and Applications in Psychology. 1st edition. Mahwah, N.J: Psychology Press.\n\n\nHoel, Erik P., Larissa Albantakis, and Giulio Tononi. 2013. “Quantifying Causal Emergence Shows That Macro Can Beat Micro.” Proceedings of the National Academy of Sciences 110 (49): 19790–95. https://doi.org/10.1073/pnas.1314922110.\n\n\nKelso, J. A. Scott. 1995. Dynamic Patterns: The Self-Organization of Brain and Behavior. Dynamic Patterns: The Self-Organization of Brain and Behavior. Cambridge, MA, US: The MIT Press.\n\n\nKim, Jaegwon. 2006. “Emergence: Core Ideas and Issues.” Synthese 151 (3): 547–59. https://doi.org/10.1007/s11229-006-9025-0.\n\n\nKrakauer, David C. 2023. “Symmetrysimplicity, Broken Symmetrycomplexity.” Interface Focus 13 (3): 20220075. https://doi.org/10.1098/rsfs.2022.0075.\n\n\nKuramoto, Yoshiki. 1984. “Chemical Turbulence.” In Chemical Oscillations, Waves, and Turbulence, edited by Yoshiki Kuramoto, 111–40. Springer Series in Synergetics. Berlin, Heidelberg: Springer. https://doi.org/10.1007/978-3-642-69689-3_7.\n\n\nLadyman, James, James Lambert, and Karoline Wiesner. 2013. “What Is a Complex System?” European Journal for Philosophy of Science 3 (1): 33–67. https://doi.org/10.1007/s13194-012-0056-8.\n\n\nLeggio, Lorenzo, George A. Kenna, Miriam Fenton, Erica Bonenfant, and Robert M. Swift. 2009. “Typologies of Alcohol Dependence. From Jellinek to Genetics and Beyond.” Neuropsychology Review 19 (1): 115–29. https://doi.org/10.1007/s11065-008-9080-z.\n\n\nLumsden, James. 1976. “Test Theory.” Annual Review of Psychology 27: 251–80. https://doi.org/10.1146/annurev.ps.27.020176.001343.\n\n\nMichell, Joel. 1999. Measurement in Psychology: A Critical History of a Methodological Concept. Cambridge University Press.\n\n\nMitchell, Melanie. 2009. Complexity: A Guided Tour. Oxford University Press.\n\n\nPort, Robert F., and Timothy Van Gelder. 1995. Mind as Motion: Explorations in the Dynamics of Cognition. MIT Press.\n\n\nRoberts, James A., Leonardo L. Gollo, Romesh G. Abeysuriya, Gloria Roberts, Philip B. Mitchell, Mark W. Woolrich, and Michael Breakspear. 2019. “Metastable Brain Waves.” Nature Communications 10 (1): 1056. https://doi.org/10.1038/s41467-019-08999-0.\n\n\nRobinaugh, Donald J., Ria H. A. Hoekstra, Emma R. Toner, and Denny Borsboom. 2020. “The Network Approach to Psychopathology: A Review of the Literature 2008 and an Agenda for Future Research.” Psychological Medicine 50 (3): 353–66. https://doi.org/10.1017/S0033291719003404.\n\n\nScheffer, Marten. 2004. Ecology of Shallow Lakes. Dordrecht: Springer Netherlands. https://doi.org/10.1007/978-1-4020-3154-0.\n\n\nSchöner, Gregor. 2020. “The Dynamics of Neural Populations Capture the Laws of the Mind.” Topics in Cognitive Science 12 (4): 1257–71. https://doi.org/10.1111/tops.12453.\n\n\nScott, John. 2011. “Social Network Analysis: Developments, Advances, and Prospects.” Social Network Analysis and Mining 1 (1): 21–26. https://doi.org/10.1007/s13278-010-0012-6.\n\n\nSerra, Roberto, and Gianni Zanarini. 1990. Complex Systems and Cognitive Processes. Berlin, Heidelberg: Springer. https://doi.org/10.1007/978-3-642-46678-6.\n\n\nSimon, Herbert A. 1962. “The Architecture of Complexity.” Proceedings of the American Philosophical Society 106 (6): 467–82. https://www.jstor.org/stable/985254.\n\n\nSnijders, Tom A. B. 2001. “The Statistical Evaluation of Social Network Dynamics.” Sociological Methodology 31 (1): 361–95. https://doi.org/10.1111/0081-1750.00099.\n\n\nTreiber, Martin, Ansgar Hennecke, and Dirk Helbing. 2000. “Congested Traffic States in Empirical Observations and Microscopic Simulations.” Physical Review E 62 (2): 1805–24. https://doi.org/10.1103/PhysRevE.62.1805.\n\n\nvan der Maas, H. L. J. 1995. “Beyond the Metaphor?” Cognitive Development 10.\n\n\nWeaver, Warren. 1948. “Science and Complexity.” American Scientist 36 (4): 536–44. https://www.jstor.org/stable/27826254."
  },
  {
    "objectID": "ch2.html#introduction",
    "href": "ch2.html#introduction",
    "title": "2  Chaos and unpredictability",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nChaos is one of the three most spectacular phenomena in complex systems and as psychologists we should know the basic results of chaos theory. It is also great fun to learn about chaos and it allows me to introduce many key concepts that we need in later chapters.\nIn my opinion, the applicability of chaos theory to psychology and social science is somewhat limited. For a long time, researchers have tried to show chaos in time series of psychophysiological measures, but this seems to be difficult. I will briefly review this work at the end of the chapter. The relevance of chaos theory may lie not in its application, but in its implications for prediction. What chaos theory basically shows is that even in the best of circumstances, where we have very accurate models and data, long-term prediction is impossible. This is known as the butterfly effect: A butterfly flaps its wings in India and that tiny change in air pressure could eventually cause a tornado in Iowa.\nChaos theory consists of many deep mathematical results, but understanding the basics of chaos is not so hard. Below I will explain chaos in difference equations at a very basic level of mathematics and programming. The elementary example is the famous logistic map, usually introduced as a model of population growth, for instance, of rabbits. Suppose we have rabbits on an island, and they start to multiply, what would be a mathematical model for such a process?\nPopulation growth is a typical example of a dynamical system, it is a model of change. In general, in a dynamical system, the change or growth of a variable (say \\(X\\)) depends on the current state and some parameters. Time plays a very special role. We can use discrete or continuous time steps. In the first case, which is the focus of this chapter, we use difference equations; in the second, we use difference equations. In the logistic map, time is discrete (population growth takes place in generations). The simplest model for the population growth of rabbits is:\n\\[\nX_{t + 1} = rX_{t} \\tag{2.1}\\]\nIn this equation \\(r\\) is the growth rate. We can simulate this model by choosing a value for \\(r\\), \\(r=2\\), for instance. We also need an initial value, say \\(X_{0} = 1.\\) If this is completely new to you, enter some values repeatedly. You will see exponential growth (\\(X_{1} = 2,\\ X_{2} = 4,X_{3} = 8,X_{4} = 16,\\ etc.)\\). In R we can simulate this using a for loop.\n\nn &lt;- 15\nr &lt;- 2\nx &lt;- 2 # initial state X0 = 1 and thus X1 = 2\nfor (i in 1:(n - 1))\n  x[i + 1] &lt;- r * x[i]\nplot(x, type = 'b', xlab = 'time', bty = 'n')\n\n\n\n\n\n\n\nFigure 2.1: Exponential growth\n\n\nNote that we can find any \\(X_{t}\\) given \\(X_{0}\\) by iterating the model as we do in the for loop. \\(X_{t}\\) is called the solution. Simulation is a bit odd in this case. We can compute the solution analytically. It is \\(X_{t} = X_{0}r^{t}\\). Thus for \\(X_{15} = 1 \\times 2^{15} = 32768\\). However, for more complex models the analytical solution is often not available, and we have to use simulation (the numerical solution).\nNote that the exponential model ignores the fact that population growth is limited by resources. At some point food will become scarce. One way of making the model, introduced by Verhulst in 1838, more realistic is to add a growth-limiting term:\n\\[\nX_{t + 1} = f\\left( X_{t} \\right) = rX_{t}\\left( 1 - \\frac{X_{t}}{K} \\right) \\tag{2.2}\\]\nWhat is the effect of this addition to the equation? If \\(X\\) is much smaller than the resource \\(K\\) then the second term, \\(\\left( 1 - \\frac{X_{t}}{K} \\right),\\) is close to 1 and we will see exponential growth. But as \\(X\\) approaches \\(K\\), this term becomes very small, reducing the effect of exponential growth. \\(X\\) does not actually grow up to \\(K\\), but to a lower value, if it converges at all. We are going to see this in a moment. It also turns out that the actual value of K is not of interest. Changing K does not change the qualitative behavior. Therefore, \\(K\\) is usually set to 1, scaling the population \\(X\\) between 0 and 1. The only remaining parameter is \\(r\\). Changing \\(r\\), however, leads to a number of surprising behaviors.1"
  },
  {
    "objectID": "ch2.html#stable-and-unstable-fixed-points",
    "href": "ch2.html#stable-and-unstable-fixed-points",
    "title": "2  Chaos and unpredictability",
    "section": "2.2 Stable and unstable fixed points",
    "text": "2.2 Stable and unstable fixed points\nLet us first study a simple ‘boring’ case, \\(r = 2\\) (Figure 2.2).\n\nn &lt;- 15; r &lt;- 2; x &lt;- .01 # initial state\nfor (i in 1:(n - 1))\n  x[i + 1] = r * x[i] * (1 - x[i])\nplot(x, type = 'b', xlab = 'time', bty = 'n')\n\n\n\n\nFigure 2.2: The \\(r=2\\) case\n\n\nThis is the simple case. The population initially develops exponentially but then levels off and reached a stable state at \\(X = .5\\). We need to understand a bit more about it. What you see here is that we have gone from an unstable initial state to a stable state, a point attractor. The next code shows that this point attractor attracts from a wide range of initial values, but not all. If we start exactly at zero, \\(X\\) stays at zero. So, zero is an equilibrium too, but a special one. It is an unstable fixed point. A small perturbation will cause \\(X\\) to move to .5, the stable fixed point. All initial values in close proximity of 0 will move away from 0 (repellent), but if \\(X = 0\\) exactly, then it remains 0 for all time. So, \\(X = 0\\) is a fixed point but unstable.\n\nn &lt;- 30; r &lt;- 2\nfor (x in seq(0, .7, by = .01))\n  # start form different initials values\n{\n  for (i in 1:(n - 1))\n    x[i + 1] &lt;- r * x[i] * (1 - x[i])\n  if (x[i] == 0)\n    plot(x,type = 'l',xlab = 'time',bty = 'n',ylim = c(0, .8),col = 'red')\n  else\n    lines(x)\n}\n\n\n\n\nFigure 2.3: Illustration of stable and unstable fixed points. For many initial values, \\(X = .5\\) is an attractor. \\(X = 0\\) is an unstable fixed point. Only if we start exactly at 0 do we stay there.\n\n\nThis concept of equilibrium, stable or unstable, is crucial for later chapters. The essence of the next chapter is to change a control parameter, here \\(r\\), and study how the pattern of equilibria (the equilibrium landscape) changes. You can easily do this yourself by setting \\(r = .9\\). For \\(r &lt; 1\\), there is only stable attractor (zero).\nSimulating this is again not really necessary. One has to realize that a fixed point (\\(X^{*}\\)) is found when \\(X_{t + 1} = X_{t} = X^{*}\\). See for yourself that:\n\\[{X_{t + 1} = X_{t} = X^{*}\n}{X^{*} = rX^{*}\\left( 1 - X^{*} \\right)\n}{X^{*} = 0\\ or\\ 1 = r - rX^{*}\n}{X^{*} = 0\\ or\\ X^{*} = \\frac{r - 1}{r}}\\]\nSo 0 and \\((r - 1)/r\\) are fixed points. Indeed for \\(r = 2\\), we have seen that 0 and .5 are equilibria, one stable and one unstable. To determine whether fixed points are stable we look at the derivative of the function, \\(f^{'}(x)\\), which, as you can easily check, is \\(r - 2rX\\).\nI will not explain why, however, the rule is that the fixed point is stable if the absolute value of the derivative in the fixed-point value is less than 1.2 For \\(r = 2\\) the fixed points are 0 and .5. \\(\\left| f^{'}\\left( X^{*} = 0 \\right) \\right| = |2 - 0| = 2\\), which is greater than 1 and thus \\(X^{*} = 0\\) is unstable. \\(\\left| f^{'}\\left( X^{*} = .5 \\right) \\right| = |2 - 2 \\times 2 \\times .5| = 0\\), which is less than 1 and thus \\(X^{*} = .5\\) is stable. You can check for yourself that \\(X^{*}\\)=\\(\\frac{r - 1}{r}\\) is stable for \\(1 &lt; r &lt; 3\\), both with the r-code and with the absolute value of the derivative."
  },
  {
    "objectID": "ch2.html#limit-cycles",
    "href": "ch2.html#limit-cycles",
    "title": "2  Chaos and unpredictability",
    "section": "2.3 Limit cycles",
    "text": "2.3 Limit cycles\nSo at \\(r = 3\\) the fixed point or \\((r - 1)/r\\) becomes unstable. Let’s study some cases. Plot are made with the code of Figure 2.2.\n\n\n\nFigure 2.4: Qualitative different behavior of the logistic map for different values of \\(r\\).\n\n\nFor \\(r = 2.9\\) we see that the series converges to the fixed point \\(\\frac{1.9}{2.9} = .66,\\) but in a process of over- and undershooting. For \\(r = 3.1\\) and \\(r = 3.3\\) a limit cycle of period 2 arises. The population oscillates between two values. For \\(r = 3.5\\) this gets even stranger, we see a limit cycle of period 4. For slightly larger values we could get cycles with even higher periods.\nIt has been claimed that these limit cycles occur in real population dynamics. Intuitively, it can be understood as a process of over- and undershooting, which dampens out for \\(r\\) a little below 3, but not for \\(r &gt; 3\\)."
  },
  {
    "objectID": "ch2.html#chaos",
    "href": "ch2.html#chaos",
    "title": "2  Chaos and unpredictability",
    "section": "2.4 Chaos",
    "text": "2.4 Chaos\nThis doubling of periods when we increase$ r$at some point leads to even stranger behavior.\nThis is what the time series looks like for \\(r = 4\\).\n\n\n\nFigure 2.5: Chaos for \\(r = 4\\).\n\n\nThere seems to be no regularity. This is what we call deterministic chaos. This time series is unpredictable, even though we now have the equation, and the system is deterministic. What exactly do we mean by this? Let me illustrate.\n\nr &lt;- 4; x &lt;- .001; n &lt;- 50\nfor (i in 1:(n - 1))\n  x[i + 1] &lt;- r * x[i] * (1 - x[i])\nplot(x, type = 'l', xlab = 'time', bty = 'n')\nx &lt;- .0010001\n# restart with sightly different initial state\nfor (i in 1:(n - 1))\n  x[i + 1] &lt;- r * x[i] * (1 - x[i])\nlines(x, col = 'red')\n\n\n\n\nFigure 2.6: The butterfly effect: A small difference in initial state causes divergence in the long run.\n\n\nWe can see that a run with a slightly different initial value will at first follow the same path, but then it will diverge sharply. A tiny perturbation (the butterfly flapping its wings) propagates through the system and dramatically changes the long-term course of the system.\nNote that some uncertainty about the exact value of the initial state is always inevitable. Suppose we have an equation like the logistic map for temperature in the weather system, and this equation perfectly describes that system. To make a prediction, we need to feed the current temperature into the computer. But we cannot measure temperature with infinite precision. And even if we could, we do not have a computer that can handle numbers with an infinite number of digits. So, we make a small error in setting the initial state, and this will always mess up our long-term forecast. This is why long-term weather will never be possible, even if we develop much more precise mathematical models, take more intensive and more accurate measurements and use more powerful computers. The weather turns out to be a chaotic system. Sensitivity to initial conditions is actually one of three conditions for deterministic chaos. For a discussion on the definition of chaos I refer to (Banks et al. 1992).\nThe Lyapunov coefficient quantifies chaos. The idea is to take two very close initial conditions with a difference of \\(\\varepsilon\\). In the next iteration this difference might be smaller, the same, or bigger. In the last case the time series diverge, which is typical for chaos. The Lyapunov coefficient is defined as:\n\\[\n{\\lambda_{L} = \\lim_{n \\rightarrow \\infty}}{\\sum_{i}^{n}{\\ln\\left| f^{'}\\left( X_{i} \\right) \\right|}} \\tag{2.3}\\]\nwhere \\(f^{'}\\left( X_{i} \\right) = r - 2rX\\) for the logistic map and \\(\\lambda_{L} &gt; 0\\) indicates chaos. You may verify in a simulation that \\(\\lambda_{L} &gt; 0\\) for $r = 4,$indicating chaos."
  },
  {
    "objectID": "ch2.html#phase-plot-and-bifurcation-diagrams",
    "href": "ch2.html#phase-plot-and-bifurcation-diagrams",
    "title": "2  Chaos and unpredictability",
    "section": "2.5 Phase plot and bifurcation diagrams",
    "text": "2.5 Phase plot and bifurcation diagrams\nEquation 2.2 is very simple. It is just one equation, a deterministic difference equation specifying how \\(X_{t + 1}\\) depends on \\(X_{t}\\), but the variety of behavior is astonishing. One way to better understand its behavior is to use phase plots. A phase plot is a graphical representation of the relationship between two or more variables that change over time. In one-dimensional systems we plot \\(X_{t}\\) against \\(X_{t + 1}\\).\n\nlayout(matrix(1:6,2,3))\nr &lt;- 3.3; x &lt;- .001; n &lt;- 200\nfor(i in 1:(n-1)) x[i+1] = r*x[i]*(1-x[i])\nx &lt;- x[-1:-100]\nplot(x,type='l',xlab='time',bty='n', main=paste('r = ',r),ylim=0:1,cex.main=2) \nplot(x[-length(x)],x[-1],xlim=0:1,ylim=0:1,xlab='Xt',ylab='Xt+1',bty='n')\nr &lt;- 4; x &lt;- .001; n &lt;- 200\nfor(i in 1:(n-1)) x[i+1] &lt;- r*x[i]*(1-x[i])\nx &lt;- x[-1:-100]\nplot(x,type='l',xlab='time',bty='n',main=paste('r = ',r),cex.main=2) \nplot(x[-length(x)],x[-1],xlim=0:1,ylim=0:1,xlab='Xt',ylab='Xt+1',bty='n')\nx &lt;- runif(200,0,1)\nx &lt;- x[-1:-100]\nplot(x,type='l',xlab='time',bty='n',main='random noise',cex.main=2) \nplot(x[-length(x)],x[-1],xlim=0:1,ylim=0:1,xlab='Xt',ylab='Xt+1',bty='n')\n\n\n\n\nFigure 2.7: Time (top) and phase (bottom) plots for three cases. Chaos and random noise can be distinguished using the phase plots.\n\n\nThe top figures are time plots and lower figures are phase plots. The first column shows a limit cycle of period 2, the second deterministic chaos and the third noise generated from a uniform distribution. Although the time series of the second and third cases look similar, the phase diagram reveals hidden structure in the chaos time series. Phase plots can help us to distinguish chaos from noise.\nThe second useful graph is the bifurcation graph. It summarizes the behavior of the logistic map for different values of \\(r\\) in one figure. The idea is to plot the equilibria as y-values for a range of \\(r\\)-values on the \\(x\\)-axes. This means that if we take an\\(r\\) value \\((r &lt; 1)\\), we will only plot zero’s, as only \\(X^{*} = 0\\) is a stable fixed point. Between 1 and 3, we will also see one fixed point equal to \\((r - 1)/r\\). For \\(r = 3.3\\), we expect to see 2 points as the attractor is a limit cycle with period 2. For higher \\(r\\) we get chaos. How does this all look? It looks amazing!\nIt is actually a good challenge to program this yourself. The trick is to create time series for a range of values of \\(r\\), delete the first part of this series (we only want the equilibrium behavior) and plot these as y values. So, if the logistic map has period two (\\(r = 3.3\\)), we repeatedly plot only two points. For \\(r = 4\\) we get the whole chaos band.\nA clever way to do this is to use the sapply function in r.\n\nlayout(1)\nf &lt;- function(r, x, n, m){\n  x &lt;- rep(x,n)\n  for(i in 1:(n-1)) x[i+1] &lt;- r*x[i]*(1-x[i])\n  x[c((n-m):n)] # only return last m iterations\n}\nr.range &lt;- seq(0, 2.5, by=0.01) \nr.range &lt;- c(r.range,seq(2.5, 4, by=0.001)) \nn &lt;- 200; m &lt;-100 \nequilibria &lt;- as.vector(sapply(r.range, f,  x=0.1, n=n, m=m-1))\nr &lt;- sort(rep(r.range, m))\nplot(equilibria ~ r, pch=19,cex=.01,bty='n')\n\n\n\n\nFigure 2.8: The bifurcation diagram of the logistic map.\n\n\nHere we see indeed fixed stable points for \\(r &lt; 3\\), the period doubling of the limit cycles for \\(r &gt; 3\\), followed by chaos.\nA recurring phenomenon in many chaotic maps are fractals. Fractals are figures in which certain patterns reappear when we zoom in on the figure, and this happens again and again when we zoom in further. You can see this by zooming in on the interval of r between 3.83 and 3.86 (see exercise 2). The three equilibria in the limit cycle split again into period doubling cycles, as we saw in the overall plot between \\(r\\) in 3 and 3.5.\nOne famous result on this period doubling route to chaos is the Feigenbaum constant. The ratios of distances between consecutive period doubling points (e.g., the distance between first and second divided by the distance between the second and third point), converge to a value of approximately 4.6692. The amazing thing is that this happens for any unimodal map, not only the logistic map."
  },
  {
    "objectID": "ch2.html#what-did-we-learn",
    "href": "ch2.html#what-did-we-learn",
    "title": "2  Chaos and unpredictability",
    "section": "2.6 What did we learn",
    "text": "2.6 What did we learn\nI find these results stunning. I note again that the generating function is deceptively simple, but its behavior is utterly complex and beautiful to me. Mathematicians have studied every detail of these plots and most of it is beyond my comprehension. The Wikipedia on the logistic map will introduce you to some more advanced concepts, but for our purposes the present introduction will suffice.\nActually, it is good to realize which concepts we have already learned. The first is the concept of equilibrium. The states of dynamical systems tend to converge to certain values. The simplest of these is the fixed point. Fixed points can be stable or unstable (more on this in the next chapter). If we start a system exactly at its unstable fixed point (and there is no noise in the system), it will stay there. But any small perturbation will cause it to escape and move to the fixed stable point.\nThe bifurcation diagram summarizes this behavior and also shows how the equilibria change when a control parameter changes. For example, at \\(r = 1\\) we see a bifurcation in the logistic map. Initially 0 was the stable fixed point and \\((r\\  - 1)/r\\) was unstable. At \\(r = 1\\) this is reversed. At \\(r = 3\\) we see another bifurcation when limit cycles appear.\nWe have learnt that there are all sorts of equilibria. The strangest ones are called strange attractors, which are associated with deterministic chaos. You can see them by making a phase diagram. Phase diagrams for other famous maps are often stunning. The most famous is the Mandelbrot set (look on the internet). There is an R-blog about the Mandelbrot set. I recommend you check it out. Simulation helps understanding!\nThe last thing we learned is that even if our world were deterministic (it is not!), and we knew all the laws of motion (say, the logistic map), and knew initial states with enormous precision, the world is unpredictable.\nThis statement needs some nuance. I have already mentioned that the weather can be chaotic and unpredictable. But the weather is not always so unpredictable. Sometimes longer forecasts are possible. But forecasts beyond, say, 10 days seem out of reach. We also see in the logistic map that when \\(r\\) is close to 4, the forecast suffers from the butterfly effect, but for \\(r = 2\\) the time course is very predictable, even more predictable than in many linear systems. This is because there is only one stable fixed point (.5). The initial state does not matter, we always end up at .5! So the logistic map is extremely predictable or extremely unpredictable depending on \\(r\\)."
  },
  {
    "objectID": "ch2.html#other-maps-and-fractals",
    "href": "ch2.html#other-maps-and-fractals",
    "title": "2  Chaos and unpredictability",
    "section": "2.7 Other maps and fractals",
    "text": "2.7 Other maps and fractals\nThere are many accessible sources on chaos theory. As always, Wikipedia is a great resource. It helps me a lot by actually doing things, i.e., doing computer simulations. One example is the Henon map, which consists of two coupled differential equations:\n\\[\nX_{t + 1} = 1 - aX_{t}^{2} + Y_{t} \\\\\nY_{t + 1} = bX_{t} \\\\\n\\tag{2.4}\\]\nUsing the code example from the logistic map, you should be able to generate time series and a phase diagram for this model. Try to reproduce the first image on the Henon map wiki page. The amazing three-dimensional bifurcation diagram may be more challenging.\nFractals are another topic for further study. Another look at Wikipedia is recommended. Making your own fractals in R is made easy by the R blog by Martin (Stefan 2020)."
  },
  {
    "objectID": "ch2.html#detecting-chaos-in-psychophysiological-data",
    "href": "ch2.html#detecting-chaos-in-psychophysiological-data",
    "title": "2  Chaos and unpredictability",
    "section": "2.8 Detecting chaos in psychophysiological data",
    "text": "2.8 Detecting chaos in psychophysiological data\nChaos theory and the logistic map were popularized about 50 years ago, and since then researchers have been looking for chaos in all kinds of time series (Ayers 1997; Robertson and Combs 2014). One idea behind this work is the hypothesis that chaos might be healthy (Pool 1989) or be helpful. It would be helpful in learning algorithms, such as neutral networks, to prevent getting stuck in local minima (Bertschinger and Natschläger 2004). My very first publication was about chaos in neural networks (van der Maas, Verschure, and Molenaar 1990).\nMany publications appeared on the detection of chaos in psychophysiological data. Examples are EEG (Pritchard and Duke 1992) heart beat (Freitas et al. 2009) and EMG (Lei, Wang, and Feng 2001). This is all but easy because these signals are inevitably contaminated with noise. I’m not aware of any recent meta-analyses of these different lines of research but there are still appearing new papers on this topic.\nThere exist many techniques for chaos detection in times series. There are several packages available in R, including new methods based on machine learning techniques (Sandubete and Escot 2021; Toker, Sommer, and D’Esposito 2020). With the Lyapunov function in the package DChaos you can compute the Lyapunov coefficient for times series generated with the logistic map. You may verify that for \\(r = 4\\) you get the Lyapunov coefficient as computed with the derivative earlier."
  },
  {
    "objectID": "ch2.html#exercises",
    "href": "ch2.html#exercises",
    "title": "2  Chaos and unpredictability",
    "section": "2.9 Exercises",
    "text": "2.9 Exercises\n\nFor r=3.5, the logistic map iterates between four points. For which value(s) does it iterate between 8 points? (*)\nIn the bifurcation plot, you can zoom in by changing r.range to seq(3.4, 4, by=0.0001)), perhaps also changing cex=.01 to a lower value. Now zoom in on the interval of r between 3.83 and 3.86. In this interval the chaos suddenly disappears and limit cycles with period 3 appear. Check this with a time series plot for a particular value of r. (*)\nReproduce the first image from the Henon map wiki page (*).\nMake the bifurcation diagram of the Ricker model (see wiki). What is the advantage of this model over the logistic map?\nAlso reproduce the three-dimensional bifurcation diagram of the Henon map (**).\nVerify that for r=4 the DChaos package gives the Lyapunov coefficient equal to the one calculated with the derivative (Equation 2.3) (**).\nUse the Rmusic library (installed with devtools::install_github(“keithmcnulty/Rmusic”, build_vignettes = TRUE)) to create a chaos sound machine. Make one for white noise too. Can you hear the difference? (**)\n\n\n\n\n\nAyers, Susan. 1997. “The Application of Chaos Theory to Psychology.” Theory & Psychology 7 (June): 373. https://doi.org/10.1177/0959354397073005.\n\n\nBanks, J., J. Brooks, G. Cairns, G. Davis, and P. Stacey. 1992. “On Devaney’s Definition of Chaos.” The American Mathematical Monthly 99 (4): 332–34. https://doi.org/10.1080/00029890.1992.11995856.\n\n\nBertschinger, Nils, and Thomas Natschläger. 2004. “Real-Time Computation at the Edge of Chaos in Recurrent Neural Networks.” Neural Computation 16 (7): 1413–36. https://doi.org/10.1162/089976604323057443.\n\n\nFreitas, Ubiratan, Elise Roulin, Jean-François Muir, and Christophe Letellier. 2009. “Identifying Chaos from Heart Rate: The Right Task?” Chaos: An Interdisciplinary Journal of Nonlinear Science 19 (2): 028505. https://doi.org/10.1063/1.3139116.\n\n\nLei, Min, Zhizhong Wang, and Zhengjin Feng. 2001. “Detecting Nonlinearity of Action Surface EMG Signal.” Physics Letters A 290 (5): 297–303. https://doi.org/10.1016/S0375-9601(01)00668-5.\n\n\nPool, Robert. 1989. “Is It Healthy to Be Chaotic?” Science 243 (4891): 604–7. https://doi.org/10.1126/science.2916117.\n\n\nPritchard, Walter s., and Dennis w. Duke. 1992. “Measuring Chaos in the Brain: A Tutorial Review of Nonlinear Dynamical Eeg Analysis.” International Journal of Neuroscience 67 (1-4): 31–80. https://doi.org/10.3109/00207459208994774.\n\n\nRobertson, Robin, and Allan Combs, eds. 2014. Chaos Theory in Psychology and the Life Sciences. New York: Psychology Press. https://doi.org/10.4324/9781315806280.\n\n\nSandubete, Julio, E., and Lorenzo Escot. 2021. “DChaos: An R Package for Chaotic Time Series Analysis.” The R Journal 13 (1): 232. https://doi.org/10.32614/RJ-2021-036.\n\n\nStefan, Martin. 2020. “RPubs - Fractals with R.” https://rpubs.com/mstefan-rpubs/fractals.\n\n\nToker, Daniel, Friedrich T. Sommer, and Mark D’Esposito. 2020. “A Simple Method for Detecting Chaos in Nature.” Communications Biology 3 (1): 1–13. https://doi.org/10.1038/s42003-019-0715-9.\n\n\nvan der Maas, Han L. J., Paul F. M. J. Verschure, and Peter C. M. Molenaar. 1990. “A Note on Chaotic Behavior in Simple Neural Networks.” Neural Networks 3 (1): 119–22. https://doi.org/10.1016/0893-6080(90)90050-U."
  },
  {
    "objectID": "ch2.html#footnotes",
    "href": "ch2.html#footnotes",
    "title": "2  Chaos and unpredictability",
    "section": "",
    "text": "Verhulst proposed this model in the form of a differential equation in continuous time. We will discuss this type of model in Chapter 5. In continuous time, nothing particularly spectacular happens and we only see the kind of behavior displayed in Figure 2.2.↩︎\nWhy this is not too difficult to understand. If you google ‘fixed points of difference equations’, you will quickly arrive at stackexchange.com, where several insightful explanations are given.↩︎"
  },
  {
    "objectID": "ch3.html#introduction",
    "href": "ch3.html#introduction",
    "title": "3  Transitions in complex systems",
    "section": "3.1 Introduction",
    "text": "3.1 Introduction\nThe second key observation about complex systems was that complex systems tend to be characterized by a limited number of . As we have seen in the previous chapter these equilibria can take many different forms, but in this chapter, we consider only stable and unstable fixed points. We are particularly interested in the case where the configuration of stable and unstable points changes due to a smooth change in some external variable, a control variable. In such a case a discontinuous change or a (first order) phase transition can occur. A transition or tipping point is the second of the three intriguing properties of complex systems (chaos being the first).\nI call it an intriguing property because in the linear systems we are used to, smooth changes in control variables lead to similar (proportional) changes in behavior variables. We may see a big change in some behavior, but this requires a big change in the controls. An example would be the speed of your bike and the force you apply. But in the case of fear or panic, this process is often non-linear. If a smooth change in an independent or control variable, such as the smell of smoke, leads to a sudden jump in fear (e.g., panic), we are likely to be dealing with a phase transition.\nA key example is the change in state of water. Between, say, 10 and 80 degrees Celsius, a smooth change in temperature results in only a slight change in the liquid state of water. But if we change the temperature very slowly, close to the thresholds of 0 or 100 degrees Celsius, we see sudden phase transitions.\nWe saw something similar for the logistic map when \\(r\\) crossed the boundary \\(r = 1\\). However, this did not lead to a sudden change in \\(X^{*}\\). This is often called a second order phase transition, meaning that the configuration of stable and unstable points changes, but there is no discontinuous change in behavior.\n\n\n\nFigure 3.1: A first order (discontinuous) and second order (continuous) phase transition. (from: https://polymerdatabase.com/polymer%20physics/ThemalTransitions.html)\n\n\nDiscontinuous phase transitions such as melting and freezing occur in many systems. Famous examples from the natural sciences include collapsing bridges, turning over ships, cell division, and climate transitions such as the onset of ice ages. Examples from the social sciences include conflict, war, and revolution. Some examples from psychology are falling asleep, outbursts of aggression, radicalization, falling in love, sudden insights, relapses into depression or addiction, panic, and multistable perception.\n\n\n\nFigure 3.2: Transitions in the perception of the Necker cube. The perception of the middle cube is bistable, and sudden transitions occur between the left (‘front’) and right (‘back’) percepts.\n\n\nMy dissertation research was on the theory of Piaget, who proposed a stage theory of cognitive development. These stages were separated by transitions. One such transition should occur between the pre-operational and concrete-operational stages. In the latter stage, children learn logical, concrete physical rules about objects, such as weight, height, and volume. The most famous test to distinguish between the two stages is the conservation task.\nThere are many conservation tasks, but the setup is always the same. For example, you show a child two equal balls of clay, ask for confirmation that they weigh the same, roll one into a sausage shape, and then ask again for confirmation of equal weight. A non-conserving child will now claim that the longer sausage weighs more. One can do this with two rows of fiches (spreading one row out) or glasses of water (pouring the water from one glass into a smaller longer glass). It is actually a fascinating task, a real fun task to do with children between 5 and 8 years old.\nFrom the 1960’s to the 1980’s, this was a topic of major interest in developmental psychology, and hundreds of papers were published on the subject. A key question was whether there was actually a stage transition, and there was a lot of confusion about what a transition actually was. It was my task to clarify this and to prove Piaget’s hypothesis. I think I succeeded in clarifying the question, but whether I succeeded in proving the stage theory is debatable.1\nThe idea of Peter Molenaar, my supervisor, was to use catastrophe theory to define the concept of a transition in a precise way, to use the so-called catastrophe flags to test the hypothesis of a transition, and also to fit a cusp model to the conservation data. It took me, with the help of many people, more than 20 years to do all these steps.\nWhat is catastrophe theory, what are these flags, and what is the cusp? These are the first questions I will answer in this chapter. But this chapter is also about statistics. We will learn how to fit a cusp model to data. I will present a methodology for studying transitions in areas where we do not have a mathematical description of the underlying system. I will present examples from very different subfields of psychology. Finally, I will discuss the criticisms that were made in response to the hype around catastrophe theory about 50 years ago. This is a long chapter, but I have included only what is necessary to make intelligent use of this approach. This requires some basic understanding of the mathematics of catastrophe theory, a good overview of the possibilities for testing cusp models, and knowledge of the controversies from the early days of the popularization of this theory."
  },
  {
    "objectID": "ch3.html#bifurcation-and-catastrophe-theory",
    "href": "ch3.html#bifurcation-and-catastrophe-theory",
    "title": "3  Transitions in complex systems",
    "section": "3.2 Bifurcation and Catastrophe theory",
    "text": "3.2 Bifurcation and Catastrophe theory\nBifurcation theory is a branch of mathematics that studies changes in the qualitative or topological structure of a given family of dynamical systems as parameters are smoothly varied. Such changes are called bifurcations when, for example, equilibria disappear, appear, or split. Simply put, it studies how small changes in parameters or conditions can lead to large changes in outcomes in mathematical systems.\nCatastrophe theory can be viewed of as a branch of bifurcation theory, describing a subclass of bifurcations. It was developed by Rene (Thom 1977) and popularized by (Zeeman 1976). The reason I chose to focus on catastrophe theory in this chapter is fourfold: Firstly, it provides one of the few systematic treatments of bifurcations. A systematic treatment is more effective than simply listing all types of bifurcations. Secondly, once you have a grasp of the basics of catastrophe theory, it becomes easier to learn about other bifurcations not encompassed by this theory. Thirdly, it is most widely used approach in psychology and the social sciences. Finally, the field has developed an empirical program and statistical procedures for the practical application of catastrophe theory.\nCatastrophe theory is concerned with gradient systems, in which some quantity is minimized or maximized. These are dynamic systems that can be described by a potential function. Potential functions can be thought of as landscapes with minima and maxima in which we throw a ball and see where it ends up. The simplest case, discussed in the next section, is the quadratic minimum. We can also study what happens to the ball if the landscape changes shape smoothly and a minimum disappears. Then sudden jumps can occur.\nMinima and maxima are called critical points, points where the first derivative of the potential function is zero. Catastrophe theory analyzes so-called degenerate critical points of the potential function — points where not only the first derivative, but also the second derivative of the potential function is zero. Phase transitions can occur at these bifurcation points. Thom proved that there are only seven fundamental types of catastrophes (given a limited set of control parameters). I will start with a mathematical introduction and, after explaining the main concepts, give some psychological examples. An in depth discussion of the role of potential functions in catastrophe theory can be found in the introduction of Chapter 1 of (Gilmore 1993).\n\n3.2.1 The quadratic case\nThom’s theorems are known to be highly complicated, but the basic concepts are actually not that difficult to grasp. The simplest potential function is\n\\[\nV(X) = X^{2}\n\\tag{3.1}\\]\n\n\n\nFigure 3.3: The quadratic potential function\n\n\nYou can imagine a ball in a landscape. The ball will roll to the minimum of the potential function. We learned in school that this is the point where the first derivative is zero and the second derivative is positive. The first and second derivatives are \\(V^{'}(X) = 2X\\) and \\(V^{''}(X) = 2\\), respectively. At \\(X = 0\\) we find the minimum.\nThe potential function describes a dynamical system defined by\n\\[\n\\frac{dX}{dt} = - V^{'}(X).\n\\tag{3.2}\\]\nThis makes sense. When the ball is in \\((1,1)\\), \\(- V^{'}(X) = - 2\\) and the ball will move towards \\(X = 0\\). But if \\(X = 0\\), \\(- V^{'}(X) = 0\\), and the ball will not move anymore. In the case of the quadratic potential function, there is only one fixed point. By adding parameters and lower order terms to V, i.e., \\({aX + X}^{2}\\), we can move its location, but the qualitative form (one stable fixed point) will not change. Also note that the second derivative is positive, which tells us that we are dealing with a minimum and not a maximum (the so-called second derivative test).\nMany dynamical systems behave according to this potential function. Nothing spectacular happens: no bifurcations and no jumps. This is different when we consider potential functions with higher order terms.\n\n\n3.2.2 The fold catastrophe\nThe fold catastrophe is defined by the potential function\n\\[\nV(X) = {- aX + X}^{3}.\n\\tag{3.3}\\]\nThis function has a degenerate critical (bifurcation) point at \\(X = 0,\\ \\ a = 0\\), because at this point \\(V^{'}(X) = - a + 3X^{2} = 0\\) and \\(V^{''}(X) = 6X = 0\\), so both the first and second derivative are zero. What makes this point so special? This is illustrated in Figure 16.\n\n\n\nFigure 3.4: A bifurcation at \\(a = 0\\): the equilibria change in qualitative way.\n\n\n\nlayout(t(1:3))\nv &lt;- function(x,a) -a * x + x^3 \ncurve(v(x,a=-2),-3,3,bty='n')\ncurve(v(x,a=0),-3,3,bty='n')\ncurve(v(x,a=2),-3,3,bty='n')\n\nIn the left plot, \\(a &lt; 0\\) and there is no fixed point, the ball rolls away to minus infinity. This can be checked by setting the first derivative to zero, which gives \\(X = \\pm \\sqrt{\\frac{a}{3}}\\). For negative \\(a\\) there is no solution. A positive value of \\(a\\) gives two solutions, as shown on the right for \\(a = 2\\). The positive solution \\(X = \\sqrt{\\frac{2}{3}\\ }\\)is a stable fixed point because the second derivative in this point is positive. The negative solution \\(X = - \\sqrt{\\frac{2}{3}\\ }\\) is an unstable fixed point because the second derivative in this point is negative.\nThe middle figure depicts the case just in between these two cases. Here the equilibrium is an inflection point, a degenerate critical point. The bifurcation occurs at this point as we go from a landscape with no fixed points to one with two, one stable and one unstable.\nAnother way to visualize this is making a bifurcation diagram as we did for the logistic map. On the x-axis we put \\(a\\), from -1 to 2. On the y-axis we plot \\(X^{*}\\), the fixed points of equation \\(7\\). We use lines for stable fixed points and dashed lines for unstable points. The diagram is shown in Figure 17.\n\n\n\nFigure 3.5: The bifurcation diagram of the fold catastrophe\n\n\nThis bifurcation diagram may not look as spectacular as the logistic map, but its importance cannot be overstated. The fold is everywhere! In a fascinating book, The Seduction of Curves (McRobie 2017), McRobie shows that whenever we see an edge, we see a fold. Figure 18 is from the book where he demonstrates how different catastrophes appear in art. I also recommend his YouTube lecture.\n\n\n\nFigure 3.6: The fold in drawings (from McRobie, 2017).\n\n\nThe fold catastrophe has been studied in fields ranging from evolution theory (Dodson and Hallam 1977) to buoyancy in diving (Güémez, Fiolhais, and Fiolhais 2002). In addition, higher order catastrophes are composed of folds. The fold catastrophe is also known as a saddle node, tangential or blue-sky bifurcation. It is an example of a second order phase transition.\n\n\n3.2.3 The cusp catastrophe\nSudden jumps between stable states are associated with first order phase transitions. The cusp, the best-known catastrophe, is the simplest catastrophe with this behavior. The potential function of the cusp is\n\\[ V(X) = {- aX - \\frac{1}{2}bX^{2} + \\frac{1}{4}X}^{4}.  \\tag{3.4}\\]\nThe half and quarter are added to make later derivations a little easier. The highest power is now 4. The first two terms contain the control variables \\(a\\) and \\(b\\), known as the normal and splitting variables. You might ask why there is no third order term. The non-technical answer is that such a term would not change the qualitative behavior of the bifurcation. Catastrophe theory studies bifurcations that are structurally stable, meaning that perturbing the equations (and not just the parameters) does not fundamentally change the behavior (see Section 3.2.6 and (Stewart 1982) for further explication.\nIt is advisable to do some minimal research on this equation yourself, using a tool like WolframAlpha or GeoGebra (paste f(X)=a X-(1/2) b X^2+(1/4) X^4). For example, set \\(a = 1\\) and \\(b = 3\\) and look at the graph of the potential function. Think in terms of the ball moving to a stable fixed point. What you should see is that there are three fixed points, of which the middle one is unstable. This bistability is important. Again, there is a relationship to unpredictability. Although you know the potential function and the values of \\(a\\) and \\(b\\), you are still not sure where the ball is. It could be in either of the minima.\nOther typical behavior occurs when we slowly vary \\(a\\ (\\)up and down from -2 to 2), for a positive \\(b\\) value (\\(b = 2).\\) This is shown in Figure 19. At about \\(a = 1.5\\) we see the sudden jump. The left fixed point loses its stability and the ball rolls to the other minimum.\n\n\n\nFigure 3.7: The change in the potential function of the cusp by varying \\(a\\).\n\n\nNow consider what will happen if we decrease \\(a\\) from 2 to -2. In this case the ball will stay in the right minimum until \\(a = - 1.5\\). Where the jump takes place depends on the direction of the change in \\(a\\), the normal variable. This is called hysteresis. Hysteresis is of great importance in understanding change or lack of change in complex systems. The state in which the ball is the less deep minimum (for \\(a = 0.5\\) in Figure 19) is often called a metastable or locally stable state. Metastable states appear to be stable for some time but are not in their globally stable state.\n(Gilmore 1993) made an important point about noise in the system. If there is a lot of noise, the jumps occur earlier and we see less or no hysteresis effect. This is called the Maxwell convention as opposed to the ‘delay’ convention. Demonstrating hysteresis therefore requires precise experimental control.\nAnother very interesting pattern occurs when \\(a = 0\\) and \\(b\\) is increased.\n\n\n\nFigure 3.8: The change in the potential function of the cusp by varying \\(b\\).\n\n\nFor low \\(b\\) there is one stable fixed point that becomes unstable. It splits up in two new attractors. As we did for the fold, we can make bifurcation diagrams showing the equilibria of X as a function of \\(a\\) and \\(b\\). Along the \\(a\\)-axis we see hysteresis and along the \\(b\\)-axis we see divergence or what is often called a pitchfork bifurcation.\n\n\n\nFigure 3.9: Bifurcation diagrams along the \\(a\\) and \\(b\\) axes. The area in the dotted box is a fold.\n\n\nTo depict the combined effects of \\(a\\) and \\(b\\), we require a three-dimensional plot, which combines the hysteresis and pitchfork diagrams.\n\n\n\nFigure 3.10: The cusp catastrophe combines hysteresis along the normal axis (\\(a\\)), and the pitchfork along the splitting axis (\\(b\\)). At the back of the cusp, changes in \\(a\\) only lead to smooth changes in the equilibrium behavior \\(X^{*}\\). At the front, sudden jumps occur when we cross the bifurcation lines. These jumps are typical of first order phase transitions. The area between the bifurcation lines is called the bifurcation set. In this area there are two stable and one instable equilibrium (colored grey).\n\n\nThe cusp diagram can be expressed mathematically by setting the first derivative to zero:\n\\[\nV^{'}(X) = {- a - bX + X}^{3} = 0.\n\\tag{3.5}\\]\nThis type of equation is called a cubic equation.2 The degenerate critical points of the cusp can be found by setting the first and second derivative to zero. This is just within reach of your high school mathematics training and I leave this as an exercise. The result is:\n\\[\n27a^{2} = 4b^{3}.\n\\tag{3.6}\\]\nThis equation defines the bifurcation lines where the first and second derivatives are both zero and sudden jumps occur (see Figure 22). The region between the bifurcation lines is the bifurcation set. In this region, the bifurcation has three fixed points, the middle of which is unstable. These unstable states in the middle are called the inaccessible area, colored gray in the cusp diagram. The bifurcation lines meet at (0,0,0). At this point, the third derivative is also zero. This is the cusp point.\n\n\n3.2.4 Examples of cusp models\nTo illustrate the cusp, I always use the business card (Figure 23). I strongly recommend that you test this example (not with your credit card). You can play with two forces. \\(Fv\\) is the vertical force and the splitting control variable (\\(b\\)) in the cusp. \\(Fh\\) is the horizontal force and the normal variable (\\(a\\)) in the cusp. Note that you will only get smooth changes when \\(Fv = 0\\), but sudden jumps and hysteresis when you employ vertical force. One very important phenomenon is that the card has no ‘memory’ when the \\(Fv = 0\\). You can push the card to a position, but as soon as you release this force (\\(Fh\\) back to zero), the card moves back to the center position. This is not the case with vertical pressure. If we force the card to the left or right position it will stay there, even if we remove the horizontal force. The card has a ‘memory’.\n\n\n\nFigure 3.11: A simple business card can be used to illustrate all the properties of the cusp (see text).\n\n\nThis seems simple but the mathematical analysis of such elastic bending structures is a huge topic in itself (Poston and Stewart 2014). The freezing of water is also a cusp. As an approximation, we could say that the density of water is the behavioral variable, temperature is the normal variable, and pressure acts as a splitting variable (see chapter 14 of (Poston and Stewart 2014) ,for a more nuanced analysis. It is very instructive to study the full phase diagram of water. We do not have to know what a triple point is. What we do need to understand is that this can be viewed as a map of the equilibria. This type of mapping would be extremely useful in psychology and the social sciences.\n\nA psychological example of a cusp concerns sudden jumps in attitudes (Latané and Nowak 1994; van der Maas, Kolstein, and van der Pligt 2003). Attitudes will be discussed in much more detail in later chapters. In general, we have relatively stable attitudes toward many things in life (politics, snakes, hamburgers, and sports), but sometimes they change, and in rare cases they change radically. For example, you may suddenly become a conspiracy theorist, an atheist, or a vegetarian. One example is the attitude toward abortion.\n\n\n\nFigure 3.12: The cusp model of attitudes (toward abortion). Because of hysteresis, it is very difficult to persuade highly involved people with new information. But if they change it will be a sudden jump.\n\n\nCusp modeling begins by the definition of the states of the behavioral variable. In this case the two states of the bistable cusp are the two opposing positions, pro-life and pro-choice. The other state associated with \\(a = 0, b = 0\\) is the neutral state, an ‘I don’t know’ or ‘I don’t care’ position.\nThe normal (\\(a\\)) and splitting (\\(b\\)) variable are interpreted as information and involvement. Information is a collection of factors that influence whether people tend to be in the pro-life and pro-choice position. Political and religious orientation as well as personal experiences add to this overall factor. One way to construct this information variable is through a factor analysis or principal component analysis.\nThe splitting factor, involvement, also combines a number of effects (importance, attention). The main idea is that there are two types of independent variables. Some will work (mainly) along the normal axis and some will (mainly) impact the splitting axis.\nThe implications of this model are that for low involvement change is continuous (Figure 25). Presenting people with some new information supporting the pro-life and pro-choice position will have a moderate effect. One problem, as demonstrated with the business card, is that the uninvolved person has “no memory”. As soon as you stop influencing this person, he drifts to the neutral ‘I don’t care’ position. We have another problem when people are highly involved. Because of the hysteresis effect, it will be very difficult to persuade people with new information. When this hysteresis effect is high, persuasion just does not work. If you have been involved in political discussions, you probably have experienced that yourself.\nBut if the underlying change in information is large enough, attitudes can show a sudden jump. There is a lot of anectodical evidence for this, but it is very hard to capture such an effect in actual time series of attitude measures. Another effect that is consistent with the cusp model is ambivalence. In the cusp, ambivalence is not the same thing as being neutral. The neutral point is at the back of the cusp and is associated with low involvement. Ambivalence is associated with high involvement. Highly involved people with balanced information (\\(a = 0)\\), may oscillate between extreme positions (see Figure 50 in Chapter 5). Finally, the pitchfork bifurcation can explain issue or political polarization. When involvement increases in a group of neutral people, e.g., due to discussion, they may split into two extreme positions.\nAnother psychological example of the cusp is multistable perception. (Stewart and Peregoy 1983) proposed a model in which the perception of male phase or female figure is used as a behavioral variable, the splitting variable is the amount of detail, and the normal variable is a change in detail related to the male/female distinction. The results are shown in Figure 26.\n\n\n\nFigure 3.13: From (Stewart & Peregoy, 1983). The fitted bifurcation lines were calculated using Cobb’s method, which is explained in section 3.3.3.\n\n\n\n\n3.2.5 Higher order catastrophes\nNote that the cusp is made up of folds. This is best seen in the hysteresis diagram in Figure 21 (see the dotted rectangle). Higher order catastrophes yield elements of cusps and folds. The swallowtail catastrophe with potential function \\(V(X) = {- aX - \\frac{1}{2}bX^{2} - \\frac{1}{3}cX}^{3} + \\frac{1}{5}X^{5}\\) consists of three surfaces of fold bifurcations meeting in two lines of cusp bifurcations, which in turn meet in a single swallowtail bifurcation point. We need a four-dimensional space to visualize this, which is difficult. The Wikipedia page on Catastrophe theory has some rotating graphs that may help. The butterfly catastrophe has \\(X^{6}\\) as the highest term (and four control variables).\nThe butterfly catastrophe is of interest when we observe trimodal behavior. We will discuss this catastrophe in Chapter 6 in relation to the modeling of attitudes. I note that the butterfly catastrophe and the butterfly effect in chaos theory are two completely unrelated concepts. Other catastrophes have two instead of one behavioral variable. However, the vast majority of applications of catastrophe theory focus on the cusp, which will also be the focus of the remaining of this chapter. There are many good (but not easy) books that present the full scope of catastrophe theory (Gilmore 1993; Poston and Stewart 2014).\n\n\n3.2.6 Other bifurcations\nCatastrophe theory is limited to structurally stable, local bifurcations. Bifurcation theory also deals with non-structurally stable bifurcations and so-called global bifurcations.\nExamples of nonstructural stable local bifurcations are the transcritical bifurcation (\\(\\frac{dX}{dt} = aX - X^{2})\\) and pitchfork bifurcation (\\(\\frac{dX}{dt} = bX - X^{3})\\). The pitchfork is part of the cusp and is not structurally stable because it can be perturbed by an additional term \\(a\\), which, if unequal to 0, will distort the pitchfork (see Figure 27).\n\n\n\nFigure 3.14: Perturbed pitchfork bifurcation (\\(a = .1\\)). For \\(a = 0\\) we would get the pitchfork bifurcation as shown in Figure 21. Thus, a perturbation in a model parameter leads to qualitative change in this bifurcation, and this is the reason why it is not considered structurally stable.\n\n\nAnother one we have already seen is the period doubling bifurcation. This happened in the logistic map when the fixed point changed in a limit cycle of period 2. Finally, global bifurcations cannot be localized to a small neighborhood in the phase space, such as when a limit cycle diverges (Guckenheimer and Holmes 1983). However, I don’t know of any applications of global bifurcations in psychology or the social sciences."
  },
  {
    "objectID": "ch3.html#testing-catastrophe-models",
    "href": "ch3.html#testing-catastrophe-models",
    "title": "3  Transitions in complex systems",
    "section": "3.3 Testing catastrophe models",
    "text": "3.3 Testing catastrophe models\n\n3.3.1 Phenomenological versus mechanistic models\nThe model of the attitude towards abortion is called a phenomenological model, as opposed to a mechanistic model. In the former one, we assume the presence of a cusp, and make hypotheses about the involved variables. In the latter, the cusp is derived from basic assumptions or first principles. The mechanistic approach is much more common in the physical and life sciences. An example is the phase transition in water described by the van der Waals equation (see Wikipedia). (Poston and Stewart 2014) show how the van der Waal equation can be reparametrized to take the form of the cusp equation. The advantage is that we learn how exactly temperature and pressure are related to the control variables of the cusp. This gives us a full understanding of the dynamics of this phase transition.\nA case that we will analyze further in Chapter 5 is the model of the spruce budworm outbreak, which occurs every 30 to 40 years and results in the defoliation of tens of millions of hectares of trees. The model is\n\\[\n\\frac{dN}{dt} = r_{b}N\\left( 1 - \\frac{N}{K} \\right) - \\frac{BN^{2}}{A^{2} + N^{2}}.\n\\tag{3.7}\\]\nWhere \\(N\\) is the size of budworm population, \\(r_{b}\\) is the growth rate, \\(K\\) is the carrying capacity, \\(B\\) is the upper limit of predation, and \\(1/A\\) is the responsiveness of the predator.\nThe first part is the logistic growth equation. \\(N\\) will grow to \\(K\\) at a rate \\(r_{b}\\). Note that this is a differential equation, not a difference equation. There is no chaos in logistic growth in continuous time. The second part is the predation function and has a concave shape flattening out at \\(B\\). The curvature of this function is determined by \\(A\\). High \\(A\\) makes the concave shape less steep, meaning that predation rather slowly reacts to the increase in budworms (more about the construction of this model later).\nThe analytical approach to this model is to reparametrize the model so that it takes the form of a cusp. Such reparameterizations are not so easy to do yourself. The idea is to create a smaller set of new variables that are functions of the model parameters. For this model a convenient reparameterization is\n\\[\nr = \\frac{A\\ r_{b}}{B}\\ and\\ q = \\frac{K}{A}. \\tag{3.8}\\]\nUsing these two ‘constructed’ control variables, we can depict the bifurcation lines of the cusp as:\n\n\n\nFigure 3.15: The bifurcation diagram of the Spruce Budworm model (Copied from Modeling the Spruce Budworm, Jacai deNeveu, 2015).\n\n\nLater we will discuss a psychological example of a mechanistic approach, but these are rare. The phenomenological approach is much more common. Phenomenological models are less persuasive than mechanistic models. One disadvantage of phenomenological models is that they may not provide a deep understanding of the underlying mechanisms that drive the system. Phenomenological models are often used to describe the behavior of a system without providing an explanation of how the behavior arises. But in psychology and the social sciences we cannot be too picky. Compared to many other, verbally stated, attitude models, the cusp attitude model is quite precise. It implies a number of phenomena and is testable. This will be the subject of the next section.\nI suggest some guidelines for setting up a phenomenological cusp model. First, define the behavioral variable. It is important to think about the bistable modes. What are they? What is the inaccessible state in-between? Can you have jumps between these states? What is neutral state at the back of the cusp? If you cannot answer these questions, you should reconsider whether a cusp is an appropriate model.\nSecond, select the control variables. What could be a normal variable and what could be a splitting variable. These are not easy questions. Sometimes there are too many candidates. For the cusp model of attitudes, instead of involvement, we could suggest interest, importance, emotional value, etc. In this case, I think of the splitting axis as a common factor of all these slightly different variables. In other cases, we have no good candidates. In the example in Figure 26, it is not clear exactly what is being manipulated along the normal axis. If you made a choice, it is good to check whether, at high values of the splitting values, variation of the normal variable may lead to sudden jumps and hysteresis. Also check whether the pitchfork bifurcation makes sense.\nThere is another issue here. In some phenomenological models the control variables are rotated by 45 degrees. The most famous example is Zeeman’s (Zeeman 1976) model dog aggression.\n\n\n\nFigure 3.16: Zeeman (1976) dog aggression model with rage and fear as rotated control variables.\n\n\nThe control variables are fear and rage (see Figure 29). In such a rotation the normal variable is the difference between fear and rage, while the splitting variable is the sum of fear and rage. Another example can be found in our model of the speed-accuracy trade- off in reaction time tasks (Dutilh et al. 2011). When constructing a phenomenological model, these two options for setting the control variable should be considered.\nThere are many other examples of phenomenological cusp model in psychology. For example, cusp models have been proposed for addiction (S. J. Guastello 1984; Mazanov and Byrne 2006; Witkiewitz et al. 2007), for performance in work and sports (Cohen, Pargman, and Tenenbaum 2003; S. Guastello, Correro, and Marra 2019; Hardy 1996) and for humor (Paulos 2008). More examples can easily be found online.3\n\n\n3.3.2 The catastrophe flags\nA question I often get is: How sudden is sudden? It is claimed that climate changes are transitions between stages (e.g., ice ages), but these transitions can take hundreds of years. Even when the ball is rolling towards its new minimum, it takes time to roll. So sudden transitions are not instantaneous.\nBut then what is the difference with an acceleration, such as we see in a logistic growth pattern? The time course of an acceleration and a sudden jump will look something like this:\n\n\n\nFigure 3.17: Continuous and discontinuous growth curves my look very similar.\n\n\nThus, in terms of time series data, they may look exactly the same. The difference is that in the continuous case the intermediate values are stable. It can be understood as a quadratic minimum that changes its position quickly. If we stop the process by freezing the manipulated control variable in the process, the state will remain at an intermediate value. These intermediate values are all stable values. If we freeze the manipulated variable in a discontinuous process, it will continue to move to a stable state. In this case, the intermediate state is unstable. The ball keeps rolling.\nIn practice using data, this is a difficult distinction to make. It means that simple time series are not sufficient to distinguish accelerations from phase transitions. So how do we distinguish between the two processes? In the context of catastrophe theory, Gilmore (1993) proposed the catastrophe flags. These are cusp related phenomena that can be seen in the data. While no single one of these is enough to indicate the cusp, when considered together they provide compelling evidence for its existence.\nIn the upcoming subsections, I will provide definitions for the flags and illustrate their applications in psychology using examples. The first flag is the sudden jump.\n\n3.3.2.1 Sudden jump\nThe sudden jump is large fast change in equilibrium behavior. Although the sudden jump is not sufficient (it could be due to an acceleration), demonstrating a sudden jump in time series is useful (also in relation to other flags). Statistical detection of sudden jumps is possible using a number of techniques. Figure 31 presents raw weekly measurements of depressive symptoms using the SCL-90-R depression subscale of a patient who gradually quitted antidepressant medication during the study. The participant and researchers were blind to the dose reduction scheme (Wichers, Groot, and Psychosystems 2016). One question was whether this reduction led to a sudden jump to the depressed state. Using a change point detection method (James and Matteson 2014), we found a jump at 18 weeks with a bootstrapped p-value of .005 (with the null hypothesis of no change point).\n\nFigure 31: A sudden jump to depression (score at the SLC-90) in a patient who gradually quitted antidepressant medication during the study.\nMany methods for change point analysis have been developed and compared in (Burg and Williams 2022).\nThe code for this figure is:\n\nlayout(t(1)); par(mar=c(4,4,1,1))\nx &lt;- read.table('data/PNAS_patient_data.txt',header=T)\nlibrary(ecp) # if error: install.packages('ecp')\ne1 &lt;- e.divisive(matrix(x$dep,,1),sig=.01,min.size=10)\nplot(x$week,x$dep,type='b',pch=(e1$cluster-1)*16+1,xlab='Week',ylab='SLC-90',bty='n',main='Jump to depression')\n\n\n\n3.3.2.2 Multimodality\nMultimodality (in the case of the cusp bimodality) is an important and easy-to-use flag, as it can be tested with cross-sectional data. Finite mixture models have been developed to test for multimodality in frequency distributions (McLachlan, Lee, and Rathnayake 2019).\nAn example is shown in Figure 32. These data come from a conservation anticipation task, where children have to predict the level of water in the second glass when it is poured over. The resulting data and the fit of a mixture of two normal distributions are shown on the right. The data are clearly bimodal supporting the hypothesis of a transition in conservation learning (Van der Maas and Molenaar 1992). These data were used in (Dolan and van der Maas 1998) to fit multivariate normal mixture distributions subject to a structural equation model.\n\n\n\nFigure 3.18: Bimodality in the expected heights of water when it is poured into a wider glass. This variation of the Piagetian maintenance task is used with children ages 5-8.\n\n\nThe code is:\n\nx=unlist(read.table('data/conservation_anticipation_item3.txt'))\nlibrary(mixtools) # if error: install.packages('mixtools')\nresult=normalmixEM(x)\nplot(result,whichplot=2,breaks=30)\n\nThere is a whole field in statistics focused on multimodality, mixtures and clustering. There are some blogs that present overviews of the relevant R-packages (Arnaud 2021). Several detailed examples from psychology, using hidden Markov models, are presented in (Visser and Speekenbrink 2022).\nThe advantage of multimodality over the sudden jump is that we can use it with cross-sectional data. To capture a sudden jump in a development process, you need a lot of high-frequency data. Sudden shifts in opinion are also rare. But it is easy to collect data on large numbers of people who are asked to make judgments about statements on an issue such as abortion. If these judgments are bimodally distributed, this is consistent with a phase transition. Bimodal data may also be produced by a process of acceleration, with time series consisting mainly of data values before and after the acceleration. So, bimodality is not sufficient. It can be considered necessary, so I always suggest starting with cross-sectional multimodal studies. If they fail, you might reconsider your hypothesis. I have often looked for multimodality in measures of arithmetic learning and never found anything convincing, which made me rethink my hypothesis.\n\n\n3.3.2.3 Inaccessibility\nInaccessibility means that certain values of the behavioral variable are unstable. The business card is a good example. Given some vertical pressure, we can try what we want but we cannot force the card to stay in the middle position, it is unstable. Inaccessibility is relevant to reject the alternative hypothesis that the sudden jump and bimodality are due to an acceleration.\nIn Experiment 2 of (Dutilh et al. 2011) we focused on this flag. Our hypothesis was that in simple choice response tasks there is a phase transition between a fast-guessing state and a slower stimulus-driven response state. The idea is that if we force subjects to speed up, there will be a catastrophic jump in performance (from almost 100% correct to 50% correct).\nWe created a game in which subjects responded to a series of simple choice items (a lexical decision task). The length of the series was not known to the subject. At the end of a series, they were rewarded according to how close their percentage correct was to 75%. Speed was also rewarded, but much less. So, we asked the subject to be in the inaccessible state. The alternative hypothesis, based on information accumulation models, was that there was no phase transition and that responding with 75% accuracy required the correct setting of a boundary (see Section 5.2.1).\nIt appeared that subjects solved the task by switching between the fast-guessing mode and the slower stimulus-controlled mode, even when instructed according to the alternative model. Thus, the 75% intermedia/ch3te state appears to be unstable.\n\n\n3.3.2.4 Divergence\nDivergence or the pitchfork bifurcation requires the manipulation of the splitting variable. In the case of attitudes, we hypothesize this to be involvement or some related variable. In (van der Maas, Kolstein, and van der Pligt 2003) we re-analyzed a dataset from (Stouffer et al. 1949), which (Latané and Nowak 1994) presented as evidence for the cusp model. The attitude concerned demobilization (from 0, unfavorable, to 6, favorable) and respondents were asked to indicate how strongly they felt about their answer (from intensity 0 to intensity 5). For low intensities of feeling the data are normally distributed whereas for higher intensities data are bimodally distributed (see Figure 33).\n\n\n\nFigure 3.19: The pitchfork bifurcation in attitudes. The dotted lines represent the fit of the cusp model to these data. This technique will be discussed in the final section in this chapter.\n\n\n\n\n3.3.2.5 Hysteresis\nHysteresis requires sophisticated manipulation of the normal control variable. We need to slowly increase and decrease this variable and test whether sudden jumps occur with a delay. We have demonstrated hysteresis with some success for proportional reasoning (Jansen and Van der Maas 2001), for the speed-accuracy trade-off (Dutilh et al. 2011), and for multistable perception (Ploeger, Van Der Maas, and Hartelman 2002).\nIn the latter case we used the quartet motion paradigm, in which two lights are presented simultaneously, first a pair from two of the diagonally opposite corners of the rectangle, and then a second pair from the other two diagonally opposite corners of the rectangle. Usually, either vertical or horizontal apparent motion is perceived. By gradually increasing or decreasing the aspect ratio (i.e., the ratio of height to width of the quartet), hysteresis in the jumps between the two percepts was demonstrated (see Figure 34).\nIn (Ploeger, Van Der Maas, and Hartelman 2002) we used a special design, the method of modified limits, to rule out the alternative explanation that hysteresis is simply due to delayed responses. It could be that the switches always occur in the middle (at an aspect ratio of 1), but the self-report is delayed. In the modified limits method, subjects do not respond during a trial, but only after the entire trial. By varying the length of the trials, it is possible to determine at which parameter value the subject perceives a switch.\n\n\n\nFigure 3.20: Hysteresis in the perception of apparent motion. Switches between the perception in of vertical or horizontal apparent motion occur when the aspect ratio (horizontal axis) is varied. The aspect ratio is the ratio of height to width of the quartet.\n\n\n\n\n3.3.2.6 Anomalous variance, divergence of linear response and critical slowing down\nGilmore’s last three flags, anomalous variance, divergence of linear response and critical slowing down, are indicators that occur near the bifurcation lines. They are also known as early warning systems and are a popular line of research (Dakos et al. 2012).\nAnomalous variance occurs because near a bifurcation point the second derivative diminishes, meaning that the minimum becomes less deep. Assuming there is always some perturbation of the state, this will lead to larger fluctuations in the state.\nDivergence of linear response is the size of the effect of a small perturbation of the state, which will be greater near a bifurcation point. It will also take longer to return to equilibrium. The latter is known as critical slowing down and is also studied in other approaches to nonlinear dynamical systems (e.g., synergetics (Haken 1977). Examples of applications in psychology can be found in (Leemput et al. 2014) and (Olthof et al. 2020). A somewhat critical review is provided in (Dablander et al. 2020).\nIn my experience, the problem with early warning signals is that both type 1 and type 2 errors should be low for predicting transitions. This is challenging even in simulations, let alone in noisy psychological data. It would be fantastic if these early warnings really worked. For example, being able to predict a relapse into depression or addiction would be of great therapeutic value.\nThe catastrophe flags together provide a research methodology for phase transition research in psychology. A single flag may not be sufficient, but the combination is. For example, the combination of evidence for inaccessibility and hysteresis is convincing. I have given psychological examples of most of the flags. Which flags to use in a particular case depends on the knowledge and experimental control of the control variables. Another approach is to fit the cusp model directly to the data. This is the subject of the next section.\n\n\n\n3.3.3 Fitting the cusp to cross-sectional data\n\n3.3.3.1 Cobb’s maximum likelihood approach\nIn a series of papers Loren Cobb an colleagues (Cobb and Zacks 1985; Cobb 1978) developed a maximum likelihood approach to fit the cusp catastrophe to data consisting of cross-sectional measurements of \\(X\\), \\(a\\) and \\(b\\). We have implemented this approach in a cusp R package described in (Grasman, van der Maas, and Wagenmakers 2009).\nThe basic idea is to make catastrophe theory, a deterministic theory, stochastic by adding a stochastic term, called Wiener noise (with variance \\(\\sigma^{2})\\), to Equation \\(6\\)4:\n\\[\ndX = - V^{'}(X)dt + \\sigma dW(t). \\tag{3.9}\\]\nWe will discuss this type of stochasticity later, but it is important to note that it is not the same as measurement noise. Measurement noise, i.e., \\(\\varepsilon\\) in \\(Y = X + \\varepsilon\\), does not affect the dynamics of \\(X\\). Wiener noise does, it is part of the updating equation of \\(X\\) itself. This stochastic differential equation is associated with a probability distribution of the form\n\\[\nf(X) = \\frac{1}{{Z\\sigma}^{2}}e^{\\frac{- V(X)}{\\sigma^{2}}}, \\tag{3.10}\\]\nwhere Z is a normalizing constant5 necessary to ensure that the area under \\(f(X)\\) is 1. This may look complicated but for the quadratic case \\(V(X) = {\\frac{1}{2}X}^{2}\\), this results in the standard normal distribution, with \\(Z = \\frac{\\sqrt{2\\pi}}{\\sigma}\\).\nAs in the case of the normal distribution we want to allow for some transformations of the variables. To simplify the necessary statistical notation, we write the cusp as \\(V(y) = {- \\alpha y - \\frac{1}{2}\\beta y^{2} + \\frac{1}{4}y}^{4}\\). The probability distribution for the cusp is\n\\[\nf(y) = \\frac{1}{{Z\\sigma}^{2}}e^{\\frac{\\alpha y + \\frac{1}{2}\\beta y^{2} - \\frac{1}{4}y^{4}}{\\sigma^{2}}}. \\tag{3.11}\\]\nAs in regression models, the cusp variables are modelled as linear function of measured variables. That is, the dependent variables \\(Y_{i1},\\ Y_{i2},\\ldots,Y_{ip}\\) and the independent variables \\(X_{i1},\\ X_{i2},\\ldots,X_{iq}\\), for subjects \\(i = 1,\\ldots,n\\), are related to the cusp variables as follows:\n\nBy estimating these regression parameters, we fit the cusp model to empirical data. The cusp package in R makes this possible. I will first demonstrate this using simulated data. This is my number one rule when using statistical techniques: never use a statistical technique on real data before you have tested it on simulated data. First, it forces you to understand what the statistical technique actually does, and second, it gives you a way to test the power and investigate violations of the technique’s assumptions.\n\nlibrary(cusp) # if error: install.packages('cusp')\nset.seed(1)\nX1 &lt;- runif(1000) # independent variable 1\nX2 &lt;- runif(1000) # independent variable 2\n# to be estimated parameters\nw0 &lt;- 2; w1 &lt;- 4; a0 &lt;- -2; a1 &lt;- 3; b0 &lt;- -2; b1 &lt;- 4 \n# sample Y1 according to cusp using rcusp and the chosen parameter values\nY1 &lt;- -w0/w1 + (1/w1) * Vectorize(rcusp)(1, a0+a1*X1, b0+b1*X2) \ndata &lt;- data.frame(X1, X2, Y1) # collect ‘measured’ variables in data\n\nI recommend doing some descriptive analysis first. With hist(data$Y1) we can inspect whether there is some indication of bimodality. X2 is the splitting variable so perhaps we see stronger bimodality with hist(data$Y1[data$X2&gt;mean(data$X2)]). The function pairs in R, pairs(data), is also always recommended. In this perfect simulated case, you will already see strong indications of the cusp. Now we fit the full model with alpha and beta both as function of X1 and X2.\n\nfit &lt;- cusp(y ~ Y1, alpha ~ X1+X2, beta ~ X1+X2, data) \nsummary(fit) \n\nSummary provides the following table:\n\nTable 1: The parameter estimates including standard errors and p-values generated by the cusp package.\n\n\n\n\n\n\n\n\n\n\nCoefficients:\nEstimate\nStd.Error\nz-value\nPr(&gt;|z|)\n\n\n\n\n\na[(Intercept)]\n-2.13\n0.19\n-11.0\n&lt; 2e-16\n***\n\n\na[X1]\n3.11\n0.22\n14.2\n&lt; 2e-16\n***\n\n\na[X2]\n0.15\n0.17\n0.9\n0.39\n\n\n\nb[(Intercept)]\n-2.29\n0.34\n-6.7\n2.66e-11\n***\n\n\nb[X1]\n-0.09\n0.33\n-0.3\n0.79\n\n\n\nb[X2]\n4.40\n0.27\n16.5\n&lt; 2e-16\n***\n\n\nw[(Intercept)]\n1.98\n0.07\n27.6\n&lt; 2e-16\n***\n\n\nw[Y1]\n3.97\n0.10\n38.0\n&lt; 2e-16\n***\n\n\n\nNote that we fit a model with too many parameters. We also estimated \\(a_{2}\\) and \\(b_{1}\\) (because the model was specified as alpha ~ X1+X2, beta ~ X1+X2). These estimates are not significantly different from 0. The other parameters are estimated reasonably close to their true values. Reasonable because the true values fall within the confidence interval of the estimates (defined by twice the standard error on either sides). We expect a better fit in terms of AIC and BIC if we fit a reduced model without \\(a_{2}\\) and \\(b_{1}\\).\n\nfit_correct_model &lt;- cusp(y ~ Y1, alpha ~ X1, beta ~ X2, data) \nsummary(fit_correct_model)\n\n\nTable 2: The comparative fit measures, AIC, AICc, and BIC indicate that the reduced model should be the model of choice.\n\n\n\n\n\n\n\n\n\n\n\n\nR.Squared\nlogLik\nnpar\nAIC\nAICc\nBIC\n\n\n\n\nFull model\n0.428\n-1058.7\n8\n2133.3\n2133.5\n2172.6\n\n\nReduced model\n0.426\n-1059.0\n6\n2130.0\n2130.1\n2159.5\n\n\n\nThe next simulation demonstrates that we can detect hysteresis using this approach. We simulate data with \\(- 2 &lt; \\alpha &lt; 2,\\) and fixed \\(\\beta\\). If \\(\\beta &lt; 0\\) we have no hysteresis, if \\(\\beta &gt; 0\\) we have. With the code below we simulate datasets for different \\(\\beta\\), and compare the goodness of fit between the linear and cusp model. The figure summarizes the results. Note that a lower BIC indicated the better fitting model.\n\nset.seed(10)\nn &lt;- 500\nX1 &lt;- seq(-1,1,le=n) # rnorm(n) #runif(1000) # independent variable 1\na0 &lt;- 0; a1 &lt;- 2; b0 &lt;- 2 # to be estimated parameters\nb0s &lt;- seq(-1,2,by=.25)\ni &lt;- 0\ndat &lt;- matrix(0,length(b0s),7)\nfor (b0 in b0s)\n{\n  i &lt;- i + 1\n  Y1 &lt;- Vectorize(rcusp)(1, a1 * X1, b0)\n  data &lt;- data.frame(X1, Y1) # collect ‘measured’ variables in data\n  fit &lt;- cusp(y ~ Y1, alpha ~ X1, beta ~ 1, data)\n  sf &lt;- summary(fit)\n  dat[i, ] &lt;- c(b0, sf$r2lin.r.squared[1], sf$r2cusp.r.squared[1],sf$r2lin.bic[1], sf$r2cusp.bic[1],sf$r2lin.aic[1], sf$r2cusp.aic[1])\n}\npar(mar=c(4,5,1,1))\nmatplot(dat[,1],dat[,4:5],ylab='Bic',xlab='b0',bty='n',type='b',pch=1:2,cex.lab=1.5)\nlegend('right',legend=c('linear','cusp'),lty=1:2,pch=1:2,col=1:2,cex=1.5)\nabline(v=0,lty=3)\ntext(-.5,800, 'no hysteresis',cex=1.5)\ntext(.5,800, 'hysteresis',cex=1.5)\n\n\n\n\nFigure 3.21: At the back of the cusp (low \\(b0\\)), the cusp is approximately linear and cuspfit prefers this simpler model over the cusp model.\n\n\n\n\n3.3.3.2 Empirical examples\nIn (Grasman, van der Maas, and Wagenmakers 2009) we present several examples with real data. As another example, we use Stoufer’s data, which we used as an example of divergence before (see Figure 33).\n\nx &lt;- read.table('data/stoufer.txt')\ncolnames(x) &lt;- c('IntensityofFeeling','Attitude')\nfit &lt;- cusp(y ~ Attitude, alpha ~ IntensityofFeeling, beta ~ IntensityofFeeling, x)\nsummary(fit)\n\nInspection of the parameter estimates shows that, as expected, Intensity of Feeling only loads on the splitting axis and not on the normal axis. This is the location of the data in the bifurcation set (plot(fit)).\n\n\n\nFigure 3.22: Placement of the data of Figure 33 in the bifurcation set.\n\n\nAnother example is the conservation data set of (Bentler 1970), which contains the scores on a 12 item test from a conservation test of 560 children from 8 different age groups. These data are expected to be bimodal and to move along the normal axis (Van der Maas and Molenaar 1992).\n\nx &lt;- read.table('data/bentler.txt',header=T)\nlayout(t(1:8))\nage &lt;- c('age 4 to 4.5','age 4.5 to 5','age 5 to 5.5','age 5.5 to 6','age 6 to 6.5','age 6.5 to 7','age 7 to 7.5','age 7.5 to 8')\nfor(i in 1:8)\n{\n  if(i==1) {par(mar=c(4,3,2,1));names=0:12} else {names='';par(mar=c(4,1,2,1))}\n  barplot(table(factor(x[x[,1]==i,2],levels=0:12)),horiz=T,axes=F,main=age[i],xlab='',names=names,cex.main=1.5,cex.names=1.5)\n}\nfit &lt;- cusp(y ~ score, alpha ~ age_range, beta ~ age_range, x)\nsummary(fit)\nplot(fit)\n\nThis is supported by results of cuspfit. You can verify that a model with beta ~ 1, fits better according to the AIC and BIC.\n\n\n\nFigure 3.23: The fit of Bentler conservation data.\n\n\nA great exercise we have often used in the classroom is to build a Zeeman machine, collect data with the machine and fit the cusp model to the data (see Grasman et al., 2009, for details). This machine was invented by Zeeman to demonstrate the properties of the cusp. Our students were rewarded for the quality of the model and the artistic value of their Zeeman machine.\n\n\n\nFigure 3.24: Zeemans’s catastrophe machine. One end of the elastic (red dot) is moved by hand through the control plan. The strap point moves according to the cusp catastrophe. Data is gathered by collecting a set of X, Y and Z values. Typically, 50 to 100 data points are sufficient to run Cuspfit.\n\n\n\n\n3.3.3.3 Evaluation\nI like to make a few final remarks. First, Cobb’s method is not valid for time series. Data points should be independent. To test for hysteresis in time series other approaches are required. One option is to use hidden Markov models as in (Dutilh et al. 2011).\nThe second remark is that there are some issues with the approach of Cobb that are due to fundamental differences between probability distributions and potential functions. The latter can be transformed in many ways (so called local diffeomorphisms) without changing the qualitative properties of the cusp. With the added constraint on probability distributions (area = 1), the same transformations can lead to qualitative effects, such as a change in the number of modes. (Wagenmakers et al. 2005) suggest a solution to this problem for time series.\nThe third remark is that two alternative approaches have been proposed. Both Guastello’s (S. J. Guastello 1982) change score least square regression approach and the Gemcat approach (Oliva et al. 1987) use the first derivative of the cusp as point of departure. A problem with both approaches is that they do not distinguish between stable and unstable equilibrium states. Data points in the inaccessible region improve the fit of the model, whereas they should decrease the fit. (Alexander et al. 1992) provide a detailed critique."
  },
  {
    "objectID": "ch3.html#criticism-of-catastrophe-theory",
    "href": "ch3.html#criticism-of-catastrophe-theory",
    "title": "3  Transitions in complex systems",
    "section": "3.4 Criticism of catastrophe theory",
    "text": "3.4 Criticism of catastrophe theory\nOne often speaks of the rise and the fall of catastrophe theory (Rosser 2007). The hype following Zeeman’s famous Scientific American paper (Zeeman 1976) led to a strongly worded reply by (Zahler and Sussmann 1977) in Nature.\nBecause people still refer to this paper when we use catastrophe theory in our work, let us briefly respond to the main points of criticism made by Zahler and Sussmann. I note that in the introduction to their paper they state that there may be legitimate uses of catastrophe theory in physics and engineering. Moreover, they do not question the correctness or importance of catastrophe theory as a purely mathematical subject.\nThey raise ten points, some of which we have already addressed. For example, their first point is about how sudden a jump actually is, but they call this a less serious criticism. A number of points are about inferring a cusp from data, which was indeed done rather superficially in Zeeman’s earlier work. They pointed out that there are no testable predictions, that the location of the cusp can be shifted, and that there is no way to decide whether the data fit the cusp. We hope to have shown that these problems are largely solved. The catastrophe flags allow us to make new testable predictions, and with Cobb’s maximum likelihood approach we can fit the model as we would any statistical model in modern science. Of course, one can be critical of the use of statistics in psychology and the social sciences, but these criticisms are not specific to catastrophe theory.\nAnother somewhat inconsistent line of criticism is that many of catastrophe models in psychology and the social sciences are just wrong and inconsistent with the data (which could be true), while it is also claimed that Zeeman’s models are not falsifiable. Despite this inconsistency, they have a point. It is important to really think about falsifiability. Theories in psychology tend to be moving targets. As soon as someone finds an empirical result that contradicts the theory, the theory is quickly modified.\nThen they point out that catastrophe theory theorists often try to make a discrete variable into a continuous one. Their example is aggression, which they believe is inherently discrete. They call Zeeman’s interpretation of aggression as a continuous family of behaviors absurd and utterly meaningless. This may be a bit strong. We can think of situations in which aggression can vary from mild to severe. Aggression can be verbal, physical, directed at a person’s belongings, mild physical directed at the person, to severe physical. We are well aware that it is problematic to claim a quantitative dimension of aggression here, but a rich ordering of aggressive acts is very useful for describing domestic violence. A discrete description in aggressive/not aggressive is clearly insufficient. Whether such an ordering can be treated as a real continuum is the most difficult questions in our field (Borsboom et al. 2016; Michell 2008).\nThe last point of Zahler and Sussmann is that there are better alternatives, such as quantum mechanics, discrete mathematics, and bifurcation theory. There is work on quantum mechanics in psychology (especially in the context of consciousness), but whether this will lead to breakthroughs in this field remains to be seen. Discrete mathematics may be an alternative in some cases (e.g., to model symbolic thinking). I see catastrophe theory as a special branch of bifurcation theory, especially useful when the system under study is difficult to describe in terms of mathematical equations. This goes back to the distinction between phenomenological and mechanistic models. I think we should put more effort into developing mechanistic models based on first principles. More on this in the next chapters.\n(Loehle 1989) present an excellent discussion on the usefulness of catastrophe theory in the context of modelling ecosytems. He concluded that “an unresolved problem in applying catastrophe models is that of testing the goodness of fit of the model to data”. But this problem has now been largely solved.\nI also recommend the BBC documentary “Case Study Catastrophe Theory Maths Foundation Course”\n(https://www.youtube.com/watch?v=myDvcvox1V4&t=1435s) to see Zeeman at work."
  },
  {
    "objectID": "ch3.html#exercises",
    "href": "ch3.html#exercises",
    "title": "3  Transitions in complex systems",
    "section": "3.5 Exercises",
    "text": "3.5 Exercises\n\nThe equilibria of the fold are \\(X = \\pm \\sqrt{\\frac{a}{3}}\\). This can can be checked by setting the first derivative to zero. Show this. (*)\nIn Zeeman’s dog aggression model fear and rage are ‘rotated’ control variables. How can we translate this to a model with unrotated axes? What would be the definitions of the normal and splitting axis in terms of fear and rage? (*)\nDerive the equation for the bifurcation lines of the cusp (\\(27a^{2} = 4b^{3})\\), by setting the first and second derivatives to zero. (**)\nSome insight into the butterfly catastrophe \\(V(X) = {- aX - bX^{2} - cX}^{3} - dX^{4} + X^{6}\\) can be gained by entering the equation in the online graphing calculator GeoGebra. Set a, b, c, d to 0, -5, 0, 5. Then start varying a and c. What is the qualitative difference in the effect of these two parameters? (*)\nSet up a phenomenological cusp for falling in love. Follow my guidelines (see Section 3.3.1). (**)\nCheck whether indeed the Bentler data fit better with when age_range only loads on the normal axis (according to the AIC and BIC). What is the correct specification of beta in cusp() in this case? (*)\n\nn=500\nz = Vectorize(rcusp)(1, .7*rnorm(n), 2+2*rnorm(n)) # sample z \nx = rnorm(n) \ny = rnorm(n) \ndata &lt;- data.frame(z,x,y) # collect variables in data\n\n\nWhat is the best fitting cusp model (according to the BIC) for this tricky data set? (**)\n\nBuild a Zeeman machine, collect data and fit the cusp (see Example III of (Grasman, van der Maas, and Wagenmakers 2009). What is your best fitting model? Provide a plot of the data in the bifurcation set and a picture of your Zeeman machine. (**)\n\n\n\n\n\nAlexander, Ralph A., Glenn R. Herbert, Richard P. DeShon, and Paul J. Hanges. 1992. “An Examination of Least-Squares Regression Modeling of Catastrophe Theory.” Psychological Bulletin 111: 366–74. https://doi.org/10.1037/0033-2909.111.2.366.\n\n\nArnaud, M. 2021. “Mixture Modelling from Scratch, in R.” Medium. https://towardsdatascience.com/mixture-modelling-from-scratch-in-r-5ab7bfc83eef.\n\n\nBentler, P. M. 1970. “Evidence Regarding Stages in the Development of Conservation.” Perceptual and Motor Skills 31 (3): 855–59. https://doi.org/10.2466/pms.1970.31.3.855.\n\n\nBorsboom, D., M. Rhemtulla, A. O. J. Cramer, H. L. J. van der Maas, M. Scheffer, and C. V. Dolan. 2016. “Kinds Versus Continua: A Review of Psychometric Approaches to Uncover the Structure of Psychiatric Constructs.” Psychological Medicine 46 (8): 1567–79. https://doi.org/10.1017/S0033291715001944.\n\n\nBurg, Gerrit J. J. van den, and Christopher K. I. Williams. 2022. “An Evaluation of Change Point Detection Algorithms.” arXiv. https://doi.org/10.48550/arXiv.2003.06222.\n\n\nCobb, Loren. 1978. “Stochastic Catastrophe Models and Multimodal Distributions.” Behavioral Science 23 (4): 360–74. https://doi.org/10.1002/bs.3830230407.\n\n\nCobb, Loren, and Shelemyahu Zacks. 1985. “Applications of Catastrophe Theory for Statistical Modeling in the Biosciences.” Journal of the American Statistical Association 80 (392): 793–802. https://doi.org/10.1080/01621459.1985.10478184.\n\n\nCohen, Alexander, David Pargman, and Gershon Tenenbaum. 2003. “Critical Elaboration and Empirical Investigation of the Cusp Catastrophe Model: A Lesson for Practitioners.” Journal of Applied Sport Psychology 15 (2): 144–59. https://doi.org/10.1080/10413200305393.\n\n\nDablander, Fabian, Anton Pichler, Arta Cika, and Andrea Bacilieri. 2020. “Anticipating Critical Transitions in Psychological Systems Using Early Warning Signals: Theoretical and Practical Consideration.”\n\n\nDakos, Vasilis, Stephen R. Carpenter, William A. Brock, Aaron M. Ellison, Vishwesha Guttal, Anthony R. Ives, Sonia Kéfi, et al. 2012. “Methods for Detecting Early Warnings of Critical Transitions in Time Series Illustrated Using Simulated Ecological Data.” PloS One 7 (7): e41010. https://doi.org/10.1371/journal.pone.0041010.\n\n\nDodson, M. M., and A. Hallam. 1977. “Allopatric Speciation and the Fold Catastrophe.” The American Naturalist 111 (979): 415–33. https://doi.org/10.1086/283176.\n\n\nDolan, Conor V., and Han L. J. van der Maas. 1998. “Fitting Multivariage Normal Finite Mixtures Subject to Structural Equation Modeling.” Psychometrika 63 (3): 227–53. https://doi.org/10.1007/BF02294853.\n\n\nDutilh, Gilles, Eric-Jan Wagenmakers, Ingmar Visser, and van der Han L. J. Maas. 2011. “A Phase Transition Model for the Speed-Accuracy Trade-Off in Response Time Experiments.” Cognitive Science 35 (2): 211–50. https://doi.org/10.1111/j.1551-6709.2010.01147.x.\n\n\nGilmore, Robert. 1993. Catastrophe Theory for Scientists and Engineers. Courier Corporation.\n\n\nGrasman, Raoul, Han L. J. van der Maas, and Eric-Jan Wagenmakers. 2009. “Fitting the Cusp Catastrophe in R: A Cusp Package Primer.” Journal of Statistical Software 032 (i08).\n\n\nGuastello, Stephen J. 1982. “Moderator Regression and the Cusp Catastrophe: Application of Two-Stage Personnel Selection, Training, Therapy, and Policy Evaluation.” Behavioral Science 27 (3): 259–72. https://doi.org/10.1002/bs.3830270305.\n\n\n———. 1984. “Cusp and Butterfly Catastrophe Modeling of Two Opponent Process Models: Drug Addiction and Work Performance.” Behavioral Science 29 (4): 258–62. https://doi.org/10.1002/bs.3830290405.\n\n\nGuastello, Stephen, Anthony Correro, and David Marra. 2019. “Cusp Catastrophe Models for Cognitive Workload and Fatigue in Teams.” Applied Ergonomics, September.\n\n\nGuckenheimer, John, and Philip Holmes. 1983. “Global Bifurcations.” In Nonlinear Oscillations, Dynamical Systems, and Bifurcations of Vector Fields, edited by John Guckenheimer and Philip Holmes, 289–352. Applied Mathematical Sciences. New York, NY: Springer. https://doi.org/10.1007/978-1-4612-1140-2_6.\n\n\nGüémez, J., C. Fiolhais, and M. Fiolhais. 2002. “The Cartesian Diver and the Fold Catastrophe.” American Journal of Physics 70 (7): 710–14. https://doi.org/10.1119/1.1477433.\n\n\nHaken, Herman. 1977. “Synergetics.” Physics Bulletin 28 (9): 412. https://doi.org/10.1088/0031-9112/28/9/027.\n\n\nHardy, Lew. 1996. “Testing the Predictions of the Cusp Catastrophe Model of Anxiety and Performance.” The Sport Psychologist 10 (2): 140–56. https://doi.org/10.1123/tsp.10.2.140.\n\n\nJames, Nicholas A., and David S. Matteson. 2014. “Ecp : An R Package for Nonparametric Multiple Change Point Analysis of Multivariate Data.” Journal of Statistical Software 62 (7). https://doi.org/10.18637/jss.v062.i07.\n\n\nJansen, Brenda R. J., and Han L. J. Van der Maas. 2001. “Evidence for the Phase Transition from Rule I to Rule II on the Balance Scale Task.” Developmental Review 21 (4): 450–94. https://doi.org/10.1006/drev.2001.0530.\n\n\nLatané, Bibb, and Andrzej Nowak. 1994. “Attitudes as Catastrophes: From Dimensions to Categories with Increasing Involvement.” In Dynamical Systems in Social Psychology, 219–49. San Diego, CA, US: Academic Press.\n\n\nLeemput, van de Ingrid A., Marieke Wichers, Angélique O. J. Cramer, Denny Borsboom, Francis Tuerlinckx, Peter Kuppens, van Egbert H. Nes, et al. 2014. “Critical Slowing down as Early Warning for the Onset and Termination of Depression.” Proceedings of the National Academy of Sciences 111 (1): 87–92. https://doi.org/10.1073/pnas.1312114110.\n\n\nLoehle, Craig. 1989. “Catastrophe Theory in Ecology: A Critical Review and an Example of the Butterfly Catastrophe.” Ecological Modelling 49 (1): 125–52. https://doi.org/10.1016/0304-3800(89)90047-1.\n\n\nMazanov, Jason, and D. G. Byrne. 2006. “A Cusp Catastrophe Model Analysis of Changes in Adolescent Substance Use: Assessment of Behavioural Intention as a Bifurcation Variable.” Nonlinear Dynamics, Psychology, and Life Sciences 10: 445–70.\n\n\nMcLachlan, Geoffrey J., Sharon X. Lee, and Suren I. Rathnayake. 2019. “Finite Mixture Models.” Annual Review of Statistics and Its Application 6 (1): 355–78. https://doi.org/10.1146/annurev-statistics-031017-100325.\n\n\nMcRobie, Allan. 2017. The Seduction of Curves: The Lines of Beauty That Connect Mathematics, Art, and the Nude. Princeton University Press.\n\n\nMichell, Joel. 2008. “Is Psychometrics Pathological Science?” Measurement: Interdisciplinary Research and Perspectives 6 (January): 7–24. https://doi.org/10.1080/15366360802035489.\n\n\nOliva, Terence A., Wayne S. Desarbo, Diana L. Day, and Kamel Jedidi. 1987. “Gemcat: A General Multivariate Methodology for Estimating Catastrophe Models.” Behavioral Science 32 (2): 121–37. https://doi.org/10.1002/bs.3830320205.\n\n\nOlthof, Merlijn, Fred Hasselman, Guido Strunk, Marieke van Rooij, Benjamin Aas, Marieke A. Helmich, Günter Schiepek, and Anna Lichtwarck-Aschoff. 2020. “Critical Fluctuations as an Early-Warning Signal for Sudden Gains and Losses in Patients Receiving Psychotherapy for Mood Disorders.” Clinical Psychological Science 8 (1): 25–35. https://doi.org/10.1177/2167702619865969.\n\n\nPaulos, John Allen. 2008. Mathematics and Humor. University of Chicago Press.\n\n\nPloeger, Annemie, Han L. J. Van Der Maas, and Pascal A. I. Hartelman. 2002. “Stochastic Catastrophe Analysis of Switches in the Perception of Apparent Motion.” Psychonomic Bulletin & Review 9 (1): 26–42. https://doi.org/10.3758/BF03196255.\n\n\nPoston, Tim, and Ian Stewart. 2014. Catastrophe Theory and Its Applications. Courier Corporation.\n\n\nRosser, J. Barkley. 2007. “The Rise and Fall of Catastrophe Theory Applications in Economics: Was the Baby Thrown Out with the Bathwater?” Journal of Economic Dynamics and Control 31 (10): 3255–80. https://doi.org/10.1016/j.jedc.2006.09.013.\n\n\nStewart, Ian. 1982. “Catastrophe Theory in Physics.” Reports on Progress in Physics 45 (2): 185–221. https://doi.org/10.1088/0034-4885/45/2/002.\n\n\nStewart, Ian, and P. L. Peregoy. 1983. “Catastrophe Theory Modeling in Psychology.” Psychological Bulletin 94: 336–62. https://doi.org/10.1037/0033-2909.94.2.336.\n\n\nStouffer, Samuel A., Edward A. Suchman, Leland C. Devinney, Shirley A. Star, and Robin M. Williams Jr. 1949. The American Soldier: Adjustment During Army Life. (Studies in Social Psychology in World War II), Vol. 1. The American Soldier: Adjustment During Army Life. (Studies in Social Psychology in World War II), Vol. 1. Oxford, England: Princeton Univ. Press.\n\n\nThom, René. 1977. “Structural Stability, Catastrophe Theory, and Applied Mathematics.” SIAM Review 19 (2): 189–201. https://doi.org/10.1137/1019036.\n\n\nvan der Maas, Han L. J., Rogier Kolstein, and Joop van der Pligt. 2003. “Sudden Transitions in Attitudes.” Sociological Methods & Research 32 (2): 125–52. https://doi.org/10.1177/0049124103253773.\n\n\nVan der Maas, Han L., and Peter C. Molenaar. 1992. “Stagewise Cognitive Development: An Application of Catastrophe Theory.” Psychological Review 99 (3): 395–417. https://doi.org/10.1037/0033-295X.99.3.395.\n\n\nVisser, Ingmar, and Maarten Speekenbrink. 2022. Mixture and Hidden Markov Models with R. Springer International Publishing.\n\n\nWagenmakers, Eric-Jan, Peter C. M. Molenaar, Raoul P. P. P. Grasman, Pascal A. I. Hartelman, and Han L. J. van der Maas. 2005. “Transformation Invariant Stochastic Catastrophe Theory.” Physica D: Nonlinear Phenomena 211 (3): 263–76. https://doi.org/10.1016/j.physd.2005.08.014.\n\n\nWichers, Marieke, Peter C. Groot, and ESM Group Psychosystems. 2016. “Critical Slowing Down as a Personalized Early Warning Signal for Depression.” Psychotherapy and Psychosomatics 85 (2): 114–16. https://doi.org/10.1159/000441458.\n\n\nWitkiewitz, Katie, Han L. J. van der Maas, Michael R. Hufford, and G. Alan Marlatt. 2007. “Nonnormality and Divergence in Posttreatment Alcohol Use: Reexamining the Project MATCH Data \"Another Way.\".” Journal of Abnormal Psychology 116: 378–94. https://doi.org/10.1037/0021-843X.116.2.378.\n\n\nZahler, Raphael S., and Hector J. Sussmann. 1977. “Claims and Accomplishments of Applied Catastrophe Theory.” Nature 269 (October): 759–63. https://doi.org/10.1038/269759a0.\n\n\nZeeman, E. C. 1976. “Catastrophe Theory.” Scientific American 234 (4): 65–83."
  },
  {
    "objectID": "ch3.html#footnotes",
    "href": "ch3.html#footnotes",
    "title": "3  Transitions in complex systems",
    "section": "",
    "text": "Learning a particular conservation task does seem to be rather sudden, but there could easily be two years between learning conservation of number and conservation of volume [[CSL STYLE ERROR: reference with no printed form.]]. This is inconsistent with the stage theory.↩︎\nThe cubic equation that cannot solved easily. This is due to the fact that the cusp is not a function of the form \\(y = f(x)\\). Functions assign to each element of \\(x\\) exactly one element of \\(y\\). But in bistable systems we assign two values of \\(y\\) to one value of \\(x\\).↩︎\nGiven these guidelines and examples it is an interesting exercise to develop one’s own cusp model, for example, for falling in love. This is a tricky exercise.↩︎\nMany different t notations exist for his. Perhaps clearer is \\(dX(t) = - V^{'}\\left( X(t) \\right)dt + \\sigma dW(t)\\), as \\(dX\\) and $ dW\\ $ depend on time.↩︎\nFor consistency with later chapters, I define \\(Z\\) differently from the notation in (Grasman, van der Maas, and Wagenmakers 2009). It is the inverse of \\(Z\\) in that paper.↩︎"
  },
  {
    "objectID": "ch4.html#key-examples-from-the-natural-sciences",
    "href": "ch4.html#key-examples-from-the-natural-sciences",
    "title": "4  Self-organization",
    "section": "4.1 Key examples from the natural sciences",
    "text": "4.1 Key examples from the natural sciences\n\n4.1.1 Physics\nOne physical example of self-organization is the laser. An important founder of complex systems theory is Herman Haken (Herman Haken 1977). He developed synergetics, a specific approach to the study of self-organization and complexity in systems that is also popular in psychology. Synergetics originated in Haken’s work on lasers. We will not discuss lasers in detail here, but the phenomenon is fascinating. Light from an ordinary lamp is irregular (unsynchronized). By increasing the energy in a laser, a transition to powerful coherent light occurs. In the field of synergetics, the order parameter is the term used to describe the coherent laser light wave that emerges. It is a measure that signifies how ordered or structured a system is. The individual atoms within this system move in a manner that aligns with this emergent property, which is known as enslavement. Interestingly, the motion of these atoms contributes to the formation of the order parameter, i.e., the laser light wave. Conversely, the laser light wave dominates the movement of the individual atoms. This interaction exhibits a cyclical cause-and-effect relationship or strong emergence (cf. Figure 1.4). Synergetics has been applied, as we will see later, to perception (Hermann Haken 1992) and coordinated human movement (Fuchs and Kelso 2018).\nAnother famous example, which will be very important for psychological modeling later, is the Ising model of magnetism. This very simple model (replaced by more advanced models of magnetism in modern physics) has found applications in many sciences. In the standard 2d version of the model, atoms are locations on a two-dimensional grid. Atoms have up or down spins. Only when the spins are aligned (all up or all down), we have an effective magnet. If they are not aligned, the effect of the individual spins is canceled out. Two variables control the behavior of the magnet. These are the temperature of the magnet and the external magnetic field. The lower the temperature the more the spins align. At high temperatures, all the atoms behave randomly, and the magnet loses its magnetic effect. The temperature at which the magnet loses its magnetic force is called the Curie point (see YouTube for some fun demonstrations). With an external field we can force the spins to be all up or all down. This external field could be caused another magnet.\n\n\n\nFigure 4.1: Schematic picture of the magnet\n\n\nThe main model equations of the Ising model are:\n\\[\nH\\left( \\mathbf{x} \\right) = - \\sum_{i}^{n}{\\tau x_{i}} - \\sum_{&lt; i,j &gt;}^{}{x_{i}x_{j}} \\tag{4.1}\\] 17\n\\[\nP\\left( \\mathbf{X} = \\mathbf{x} \\right) = \\frac{\\exp\\left( - \\beta H\\left( \\mathbf{x} \\right) \\right)}{Z}. \\tag{4.2}\\] 18\nThe first equation defines the energy of a given state vector \\(\\mathbf{x}\\) (for \\(n\\) spins with states -1 and 1). The notation \\(&lt; i,j &gt;\\) in the summation means that we sum over all neighboring, or linked, pairs.\nThe external field and temperature are \\(\\tau\\) and \\(\\frac{1}{\\beta}\\), respectively. The first equation simply states that nodes congruent with the external field lower the energy. Also, neighboring nodes$$with equal spins lower the energy. Suppose we have only four connected positive spins (top row of Figure 4.1) and no external field, then we have \\(\\mathbf{x} = (1,1,1,1)\\) and \\(H = - 6\\). This is also the case for \\(\\mathbf{x} = ( - 1, - 1, - 1, - 1)\\), but any other state has a higher energy.\nThe second equation defines the probability of a certain state (e.g., all spins up). This probability requires a normalization,\\(Z\\), to ensure that the probabilities over all possible states sum up to 1. For large systems (\\(N &gt; 20\\)), the computation of \\(Z\\) is a substantive issue as the number of possible states grows exponentially. If the temperature is very high, that is, \\(\\beta\\) is close to zero, \\(\\exp\\left( - \\beta H\\left( \\mathbf{x} \\right) \\right)\\) will be 1 for all possible states, and the spins will behave randomly. The differences in energy between states do not matter anymore.\nThe randomness of the behavior is captured by the concept of entropy. Entropy is a measure of the degree of disorder or randomness in a system. To explain this a bit better we need to distinguish the micro- and macrostate of an Ising system. The microstate is defined by the configuration \\(\\mathbf{x}\\) of spins, while the macrostate is determined by the sum of spins (similar to how magnetization is defined). The Boltzmann entropy is a function of the number of ways (\\(W\\)) a particular macrostate can be realized. For \\(\\sum_{}^{}x = 4\\) there is only one way (\\(\\mathbf{x} = 1,1,1,1)\\). But for \\(\\sum_{}^{}x = 0\\), there are 6 ways (\\(W = 6\\)). The Boltzmann entropies (\\(\\ln W)\\) for these two cases are 0 and 1.79, respectively. The concept of entropy will be important in later discussions.\nIn the simulation of this model, we take a random spin, calculate the energy of the current \\(\\mathbf{x}\\) and the \\(\\mathbf{x}\\) with that particular spin flipped. The difference in energy determines the probability of a flip:\n\\[\nP\\left( x_{i} \\rightarrow - x_{i} \\right) = \\frac{1}{\\left( 1 + e^{- \\beta\\left( H\\left( x_{i} \\right) - H\\left( - x_{i} \\right) \\right)} \\right)}. \\tag{4.3}\\] 19\nIf we do these flips repeatedly, we find equilibria of the model. This is called the Glauber dynamics (more efficient algorithms do exist). The beauty of these algorithms is that the normalization constant Z falls out of the equation. In this way we can simulate Ising systems with \\(N\\) much larger than 20.\nIn the case of a fully connected Ising network (also called the Curie-Weiss model), the emergent behavior, what is called the mean field behavior, can be described by the cusp (Section 3.2.3; (Abe et al. 2017; Poston and Stewart 2014). The external field is the normal variable and temperature acts as a splitting variable. The relationship to self-organization is that when we cool a hot magnet, at some threshold the spins begin to align and soon are all up or down. This is the pitchfork bifurcation, creating order out of disorder.1\nIn the 2D Ising model (see Figure 4.1), the connections are sparse (only local) and more complicated (self-organizing) behavior occurs. We will simulate this in NetLogo later in this chapter and as a model of attitudes in chapter 6.\n\n\n4.1.2 Chemistry\nAnother founder of self-organizing systems research is Ilya Prigogine. Prigogine won the 1977 Nobel Prize in Chemistry for his work on self-organization in dissipative systems. These are systems far from thermodynamic equilibrium (due to high energy input) in which complex, sometimes chaotic, structures form due to long-range correlations between interacting particles. One notable example of such behavior is the Belousov-Zhabotinsky reaction, an intriguing nonlinear chemical oscillator, which I mentioned earlier.\nCollaborating with Stengers, he authored the influential book “Order out of Chaos” in 1978. This work significantly influenced the scientific community, particularly through their formulation of the second law of thermodynamics. This law states that the total entropy of an isolated system always increases over time and never decreases, meaning that spontaneous processes in nature tend to move towards a state of increasing disorder or randomness. Another way of stating the second law is that heat flows spontaneously from hot objects to cold objects, and not the other way around, unless external work is applied to the system. A more appealing example might be the student room that never naturally becomes clean and tidy, but rather the opposite.\n(Stengers and Prigogine 1978) argued that while entropy may indeed decrease in a closed system, the process of self-organization in such systems can create ordered structures that compensate for the entropy increase, resulting in a net increase in what they called “local entropy”. Prigogine and his colleagues placed particular emphasis on irreversible transitions, highlighting their importance in understanding complex systems. While the catastrophe models we previously discussed exhibited symmetrical transitions (sudden jumps in the business card are symmetric), Prigogine’s research revealed that this symmetry does not always hold true.\nTo illustrate this point, consider the analogy of frying an egg. The process of transforming raw eggs into a fried form represents a transition, but it is impossible to reverse this change and “unfry” the egg. Prigogine linked these irreversible transitions to a profound question regarding the direction of time, commonly known as the arrow of time. Although a fascinating topic in itself, we will not explore it further here.\n\n\n4.1.3 Biology\nThere is no shortage of founders of complex systems science. Another fantastic book is Kaufmann’s Origin of Order (Kauffman 1993), which introduces the concept of self-organization into evolutionary theory. He argues that the small incremental steps in neo-Darwinistic processes cannot fully explain natural evolution. If you want to know about adaptive walks and niche hopping in rugged fitness landscapes, you need to read his book. Another influential theory is that of punctuated equilibria, which proposes that species undergo long periods of stability interrupted by relatively short bursts of rapid evolutionary change (Eldredge and Gould 1972).\nA neat example of the role of self-organization in evolution is the work on spiral wave structures in prebiotic evolution by (Boerlijst and Hogeweg 1991). This work builds on the classic work of (Eigen and Schuster 1979) on the information threshold. Evolution requires the copying of long molecules. But in a system of self-replicating molecules, the length of the molecules is limited by the accuracy of replication, which is related to the mutation rate. Eigen and Schuster showed that this threshold can be overcome if such molecules are organized in a cycle in which each molecule catalyzes its nearest neighbor (a hypercycle). However, the hypercycle was shown to be vulnerable to parasites. These are molecules that benefit from one neighbor but do not help another. This molecule will outcompete the others and we are back to the limited one-molecule system.\nWhat Boerlijst and Hogeweg did was to implement the hypercycle in a cellular automaton (CA). A CA is basically a two-dimensional grid of cells, where cells interact with their neighbors, as in the Ising model. In the hypercycle simulation, cells could be empty (dead) or filled with one out of several colors. Colors die with some probability but are also copied to empty cells with a probability that depends on whether there is a catalyzing color in the local neighborhood. One of the colors is a parasite, catalyzed by one color, but not catalyzing any other colors. The amazing effect, and you will see this later using NetLogo, is that moving global spirals emerge that isolate the parasites so that a stable hypercycle prevails.\nMany examples of self-organization come from ecosystem biology. We will see simulations of flocking below, but I would also like to mention ants. \nAnts exhibit amazing forms of globally organized behavior. They build bridges, nests, and rafts, and they fight off predators. I once saw a documentary on an ant nest that somehow decided to move to another location 50 meters away. Ant colonies utilize pheromones and swarm intelligence to relocate to a new location. Scouts search for potential sites, leaving pheromone trails. If a promising location is found, more ants follow the trail, reinforcing the signal. Unsuitable sites result in fading trails. Once a decision is made, the colony collectively moves to the chosen site, transporting their brood and establishing a new nest.\nIt is not a strange idea to think of an ant society as a living organism. Note that all this behavior is self-organized. In other words, there is clearly no super ant or management team that has a blueprint for building bridges and telling the rest of the ants to do certain things. The same is true of flocks of birds. There is no bird that chirps commands to move collectively to the left, to the right, or to split up. It is also clear that this is true of our brain. Each neuron is not intelligent at all. Our intelligence is based on the collective behavior of billions of neurons.\n\n\n4.1.4 Computer science\nAnother crucially important area of research on self-organisation has been computer science. A simple but utterly amazing example is the work on Conways’ game of life (Berlekamp, Conway, and Guy 2004). The rules are depicted in Figure 4.2.\n\n\n\nFigure 4.2: The rules of the Game of Life\n\n\nFor each cell, given the current neighbors, the next state for all cells is computed. This is called synchronous updating.2 It is hard to predict what will happen if we start from a random initial state. But you may already realize that a block of 4 squares is stable, and a line of three blocks will oscillate between a horizontal and a vertical line.\nA great tool for playing around with the Game of Life is Golly, which is freely available for computers and mobile phones. I ask you to download and open Golly, draw some random lines, press Enter and see what happens. Often you will see it converging to a stable state (with oscillating sub-patterns). Occasionally you will see walkers or gliders (zoom out). These are patterns that move around the field.\nRandom initial patterns rarely lead to anything remarkable, but by choosing special initial states, surprising results can be achieved. First, take a look at the Life within Patterns folder. Take, for example, the line-puffer superstable or the spaceship types. One of my favorites is the metapixel-galaxy in the HashLife folder. Note that with + and - you can speed up and slow down the simulation. What this does is simulate the game of life in the game of life! Zoom in and zoom out to see what really happens. I’ve seen this many times and I’m still amazed. A small childish experiment is to disturb the metapixel galaxy in a few cells. This leads to a big disturbance and a collapse of the pattern.\nIt is even possible to create the (universal) Turing machine in the Game of Life (Rendell 2016). The Turing machine is a theoretical machine, developed by Alan Turing in 1936, that despite its simplicity can implement any computer algorithm. This raises the question of whether we can build self-organizing intelligent systems in this way. Actually, we can to some extent, but by using a different setup, based on brain-like mechanisms (see the next section).\n\n\n\nFigure 4.3: The Turing Machine built in the Game of Life\n\n\nAnother root of complex systems theory and the role of self-organization in computational systems is cybernetics (Ashby 1956; Wiener 2019). To give you an idea of this highly original work, I will only mention the titles of a few chapters of Norman Wiener’s book, originally published in 1948: Gestalt and Universals, Cybernetics and Psychopathology, On Learning and Self-reproducing Machines, and finally, Brainwaves and Self-organization. And this was written in 1948.\nThe interest in self-organization is not only theoretical. In optimization, the search for the best parameters of a model describing some data, techniques inspired by cellular automata and self-organization have been applied (Langton 1990; Xue and Shen 2020). I have always been fascinated with genetic algorithms (Holland 1992a; Mitchell 1998), where the solution to a problem (sets of parameter values) are individuals in an evolving population. Through mutation and crossover, better individuals evolve. This is a slow but very robust way of optimizing, preventing convergence to local minima. John Henry Holland is considered one of the founding fathers of the complex systems approach in the United States. He has written a number of influential books on complex systems. His most famous book, Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control theory, and artificial intelligence (Holland 1992b), has been cited over 75,000 times.\nA self-organizing algorithm that has played a large role in my work is the Elo rating system developed for chess competitions (Elo 1978). Based on the outcomes of games, ratings of chess players are estimated, which in turn are used to match players in future games. The ratings converge over time, but adjusted when players suddenly improve their skills. We have adapted this system for use in online learning systems where children play against math and language exercises (Maris and van der Maas 2012). The ratings of children and exercises are estimated on the fly in a large-scale educational system (Brinkhuis et al. 2018; Klinkenberg, Straatemeier, and van der Maas 2011).\n\n\n4.1.5 Neural networks\nThe current revolution in AI, which is having a huge impact on our daily lives, is due to a number of ‘self-organizing’ computational techniques. Undoubtedly, deep learning neural networks have played the largest role. A serious overview of the field of neural networks is clearly beyond the scope of this book, but one cannot understand the role of complex systems in psychology without knowing at least the basics of artificial neural networks (ANN), i.e., networks of artificial neurons.\nArtificial neurons are characterized by their response to input from other neurons in the network, which is typically weighted and summed before being passed through an activation function. This activation function may produce either a binary output or a continuous value that reflects the level of activation of the neuron. The input could be images, for example, and the output could be a classification of these images. The important thing is that neural networks learn from examples.\nUnsupervised learning is based on the structure of the input. A famous unsupervised learning rule is the Hebb rule (Hebb 1949), which states that what fires together, wires together. Thus, neurons that correlate in activity strengthen their connection (and otherwise connections decay). In supervised learning connections are updated based on the mismatch between model output and intended output (the supervised output). Backpropagation is a mechanism to update specific connections such that this mismatch or error is minimized over time. These are just two of the learning mechanisms used in modern ANNs.\nModern large language models large language models, like GPT, differ from traditional backpropagation networks in terms of their architecture, training objective, pre-training process, scale, and application. Large language models use transformer architectures, undergo unsupervised pre-training followed by supervised fine-tuning, are trained on massive amounts of unlabeled data, are much larger in size, and are primarily used for natural language processing tasks.\nAn interesting unsupervised model is the Boltzmann machine. It is basically an Ising model (see section 4.1.1) where the connections between nodes have continuous values. These weights can be updated according to the Hebbian rule. A simple setup of the Boltzmann machine is to take a network of connected artificial neurons, present the inputs to be learned in some sequence by setting the states of these neurons equal to the input. The Hebb rule should change the weights between neurons so that the Boltzmann machine builds a memory for these input states. This is the training phase. In the test phase, we present partial states by setting some, but not all, nodes to the values of a particular learned input pattern. By the Glauber’s dynamics, we update the remaining states that should take on the values belonging to the pattern. This pattern completion task is typical for ANN’s.\nThis setup is called the general or unrestricted Boltzmann machine, where any node can be connected to any other node and each node is an input node. The restricted Boltzmann machine (RBM) is much more popular because of its computational efficiency. In an RBM, nodes are organized in layers, with connections between layers but not within layers. In a deep RBM we stack many of these layers, which can be trained in pairs. I recommend Timo Matzen’s R package for a hands-on explanation (https://github.com/TimoMatzen/RBM). Other famous approaches are the Kohonen self-organizing maps and the Hopfield neural network.\n\n\n\nFigure 4.4: The deep learning restricted Boltzmann machine\n\n\nIn supervised learning, connections between artificial neurons are updated based on the difference between the output and the desired or expected output of the output neurons. The first supervised ANN, the perceptron, consisted of multiple input nodes and one output node and was able to classify input patterns from linearly separable classes. This included the OR and AND relation but excluded the XOR relation. In the XOR pattern, the combinations of 00 and 11 are false, 01 and 10 are true. In this case the sum of the two bits is not useful for classification. By adding a hidden layer to the perceptron, the XOR can be solved, but it took many years to develop a backpropagating rule for multi-layer networks, such that they can learn this non-linear classification from examples. We will do a simple simulation in NetLogo later. Although extremely powerful, it is debatable whether backprop networks are self-organizing systems. Self-organizing systems are characterized by their ability to adapt to their environment without explicit instructions. Unsupervised neural networks are more interesting in this respect.\nAll these models were known at the end of the 20th century, but their usefulness was limited. This has changed due to some improvements in algorithms but especially in hardware. Current deep-learning ANNs consist of tens of layers within billions of nodes, trained on billions of inputs using dedicated parallel processors (e.g., (Schmidhuber 2015).\nNeural networks are at the heart of the AI revolution, but other developments have also played a key role. Reinforcement learning is essential in AI systems that need to behave or act on the environment. Examples are game engines, robots, and self-driving cars. Note that the study of reinforcement learning also has its roots in psychology (see Chapter 1 of (Sutton and Barto 2018).\nI was most amazed by the construction and performance of AlphaZero chess. AlphaZero chess (Silver et al. 2018) combines a deep learning neural network that evaluates positions and predicts next moves with a variant of reinforcement learning (Monte Carlo tree search). Amazingly, AlphaZero learns chess over millions of self-played games. This approach is a radical departure from classic chess programs, where brute force search and built-in indexes of openings and endgames were the key to success. AlphaZero Chess is a self-organizing chess program with a phase transition in learning after 64000 training steps (see fig.7 in (McGrath et al. 2022). For an analysis of the interrelations between psychology and modern AI, I refer to (Han L. J. van der Maas, Snoek, and Stevenson 2021).\n\n\n4.1.6 The concept of self-organization\nI trust that you now possess some understanding of self-organization and its applications across various scientific fields. Self-organization is a generally applicable concept that transcends various disciplines, yet it maintains strong connections with specific examples within each discipline.\nAs previously mentioned, the precise definition of self-organization remains under discussion, and a range of criteria continue to be debated. Key questions, such as the degree of order necessary for a system to be deemed self-organized, whether any external influences are permissible, whether a degree of randomness within the system is acceptable, and whether the emergent state must be irreversible, are among the issues that lack definitive resolutions.\nThis ambiguity in the definition isn’t unusual for psychologists, as many non-formal concepts lack strict definitions. The value of the self-organization concept is primarily found in its concrete examples, its broad applicability, such as in the field of artificial intelligence, and our capability to create simulations of it. The focus of the next section will be on such simulations."
  },
  {
    "objectID": "ch4.html#netlogo",
    "href": "ch4.html#netlogo",
    "title": "4  Self-organization",
    "section": "4.2 NetLogo",
    "text": "4.2 NetLogo\n\n4.2.1 Examples\nNetLogo (Wilensky and Rand 2015) is based on Logo, a revolutionary educational programming language from the early days of computer languages, in which an on-screen turtle, a cursor, could be moved around to create graphics. The turtle is still there, but there is much more that you can do with NetLogo.\nI strongly recommend that you download and install NetLogo for the next part of this chapter.\nThe Ising model:\nWhen you start NetLogo, you see an interface with a black area (the world), a 33 by 33 matrix of patches (cells). You can change the world using the settings (see top right). Interface and Code are the most important tabs.\nFirst, we open the Model library (menu ‘File: Model Library’) and find and open ‘Ising’. Click on ‘setup’ and ‘go’. That is all. Verify that high temperature indeed causes random spin behavior. Also verify that lowering the temperature causes a pitchfork bifurcation. The random state becomes unstable and all spins become either positive or negative (light or dark blue). Now go to settings and set max-pxcor and max-pycor to 200 and patch size to 1. With these settings you will see self-organized global patterns, constantly moving clusters of positive and negative spins.\nHypercycles:\nSome models are available in NetLogo, others can be found on the website of NetLogo (see Community). Download Hypercycle by Maarten Boerlijst and read the information. You have to run the model with 8 species for 20000 iterations or ticks (to speed up, deselect view updates) and then add parasites. The spirals keep the growth of the parasites under control. If you do this earlier, the parasites will quickly take over. I think this is a beautiful example of functional self-organization. The implementation in the form of a cellular automata is essential for the success of this model. If we implement this model in the form of coupled differential equations, the parasite will simply win.\nFlocking:\nNetLogo 3D allows us to create three-dimensional plots of self-organizing patterns. Start NetLogo 3D and load the flocking model 3D Alternate. I recommend editing the Population slider by ‘right-clicking’ it and setting the max to 1000. This will result in more realistic swarms. Play around with the controls and don’t kill all the birds.\nTraffic:\nIn the models library of NetLogo (not 3D) you will find ‘Traffic 2 Lanes’. Run the model with 20 cars and notice that the congestion actually moves backwards. Play around with the number of cars as well. Is there a clear threshold where you get congestion as you slowly increase the number of cars? And what happens when you decrease the number of cars? Is there a threshold where congestion dissipates? I hope you see that finding hysteresis in this way is quite difficult. There are clearly sudden changes, but finding hysteresis requires very precise and patient experimentation.\nNeural networks:\nIn the Model Library you will find a perceptron and a multilayer network. Start with the perceptron. Set the target function to ‘and’, train the model for a few seconds, and test the perceptron. You will see that it correctly classifies 11 as 1 and the other patterns as -1. The graph on the bottom right is particularly instructive. It shows how the patterns are separated. The perceptron can do linear separation. This is sufficient for most of the logical rules that can be learned, but not for the XOR. You will see that the linear separation just jumps around and the XOR cannot be learned. Also train the multilayer model on the XOR. Another nice tool to play around with can be found on the internet by searching for ‘A Neural Network Playground’.\nOf course, these are just illustrative tools. But building serious deep learning ANNs is not that hard either. Many resources and books are available (e.g., (Ghatak 2019).\nThe sandpile model:\n(Bak, Tang, and Wiesenfeld 1988) introduced the concept of self-organized criticality. In systems such as the Ising model, there are parameters (e.g., temperature) that must be precisely tuned for the system to reach criticality. The Bak-Tang-Wiesenfeld sandpile model exhibits critical phenomena without any parameters. In the sandpile model, grains of sand are added to the center of the pile. When the difference in height between the center column and its neighbors exceeds a critical value, a grain of sand rolls to that neighboring location. This occasionally results in avalanches. The point is that no matter how we start, we get to a critical state where these avalanches occur. Thus, the sandpile model spontaneously evolves toward its critical point, which is why this phenomenon has been called self-organized criticality.\nThe NetLogo model ‘Sandpile’ in the Models library demonstrates this behavior (use ‘setup uniform’, ‘center’ drop location and ‘animate avalanches’). We now drop grains of sand onto the center of a table, one at a time, creating avalanches. The plots on the right show an important characteristic of self-organized criticality. The frequencies of avalanche sizes and durations follow a power law. This means that the log-log plot should be linear, which can be verified by running the model for some time. One of the key features of power law distributions is that they exhibit a high degree of variability or heterogeneity. This means that there are many small events or phenomena, and a few very large ones, with a smooth distribution of sizes in between. Power law systems are scale invariant, meaning that we see the same behavior at any scale of the sand pile. For this reason, they are sometimes called ‘scale-free distributions’.\nOther models:\nI recommend running a few other models (e.g., sunflowers, beatbox, and the B-Z reaction). One thing we haven’t done yet is click on the Code tab. Read the code for the B-Z reaction and notice one thing: it is surprisingly short!\n\n\n4.2.2 A bit of NetLogo programming\nI find NetLogo programming very easy and very hard at the same time. Hard because it requires a different way of thinking. Uri Wilensky’s examples are often extremely elegant and much shorter than my clumsy code. NetLogo resembles object-oriented programming languages, quite different from (base) R. There are three types of objects, the patches, which refer to cells in a world grid (CA), turtles, which are agents that move around, and links, which connect turtles. Note that turtles are not necessarily turtles. We have already seen turtles in the form of neural nodes and cars.\nIn NetLogo, you “ask” objects to do something. A typical line would be:\nask turtles with [pcolor = red] set pcolor green\nThis would make red turtles green. To get started, I highly recommend watching the videos on the NetLogo page ‘The Beginner’s Guide to NetLogo Programming’ and following these examples. Here we make our own Game of Life.\n\n4.2.2.1 Game of Life\nThe first thing to do is to create two buttons in the interface, a setup and a go button. In Command, name them setup and go. In the settings of the go button, select ‘forever’. Now we go to the Code tab and define these two functions as:\nto setup\n  clear-all\n  reset-ticks\nend\n\nto go\n  tick\nend\nTicks count the iterations in NetLogo, and with this code we are really just resetting things. Now add this last line to setup (with “;” we add comments to code):\nask patches\n    [set pcolor one-of [white blue]] ; white is dead, blue is alive\nTo do a synchronous update, we need to store the update state in a temporary variable called new-state. Put this line at the top of your code\npatches-own [new-state]\nIn the ‘go’ function, we add the life rules.\nask patches[\n  if(count(neighbors with [pcolor = blue]) &gt; 3) [set new-state white]\n  if(count(neighbors with [pcolor = blue]) &lt; 2) [set new-state white]\n  if(count(neighbors with [pcolor = blue]) = 3) [set new-state blue]\n]\n\nask patches [set pcolor new-state]\nThe last line updates the state to the new state. That is all! We build a Game of Life simulation. Use Setting to create a larger world. You can take a look at the code of the Game of Life program in the Model Library to see some extensions to this code.\nIn the help menu, you will find the very useful NetLogo dictionary. Just reading through this dictionary will teach you a lot of useful tricks. NetLogo is similar to R in the sense that you should use the built-in functions as much as possible.\n\n\n4.2.2.2 The Ising model\nBuilding a NetLogo from scratch requires quite some experience, adapting a program is much easier. The Ising model in NetLogo was not complete, as there is no slider for the external field. Try to add this yourself. Add a slider for the external field ‘tau’. The code only needs to be changed in this line (study Equation 4.1):\nlet Ediff 2 * spin * sum [ spin ] of neighbors4\nIf successful, you can test for hysteresis and divergence. For tau = 0, decreasing the temperature should give the pitchfork bifurcation. For a positive temperature (say 1.5), moving tau up and down should give hysteresis.\nActually, this should work better if all spins are connected to all spins. To do this, ‘neighbors4’ should be replaced by ‘patches’. To normalize the effect of so many spins, it is recommended to use:\nlet 0.001 * Ediff 2 * spin * sum [ spin ] of patches\nNow you should see hysteresis and the pitchfork better. However, in this case the typical self-organized patterning that occurred in the Ising model with only local interactions is not present."
  },
  {
    "objectID": "ch4.html#self-organization-in-psychology-and-social-systems.",
    "href": "ch4.html#self-organization-in-psychology-and-social-systems.",
    "title": "4  Self-organization",
    "section": "4.3 Self-organization in psychology and social systems.",
    "text": "4.3 Self-organization in psychology and social systems.\nIn the final section of this chapter, I provide illustrations of research on self-organization within various psychological systems, spanning several subfields of psychology. The discussion begins with an exploration of self-organization in the context of the brain and concludes with an examination of its implications within human organizations. In the final part of the chapter, I offer specific case studies to illustrate self-organization, while also referencing relevant literature to guide further exploration in other areas.\n\n4.3.1 The brain\nMany different psychological and social processes involve self-organization. As discussed above, at the lowest level it plays a role in neural systems. Self-organization in the brain is an active area of research (Breakspear 2017; Chialvo 2010; Cocchi et al. 2017; Ooyen and Butz-Ostendorf 2017; Plenz et al. 2021). (Dresp-Langley 2020) distinguished seven key properties of self-organization clearly identified in brain systems: 1) modular connectivity, 2) unsupervised learning, 3) adaptive ability, 4) functional resiliency, 5) functional plasticity, 6) from-local-to-global functional organization, and 7) dynamic system growth.\nA key example is Walter Freeman’s work on the representation of odors in the brain (Skarda and Freeman 1987). He used EEG measurements to support his nonlinear system model of the brain. Freeman’s theory proposes that the brain operates through the generation of dynamic patterns of electrical activity, which he called “attractors”. These attractors represent stable states of neural activity that arise spontaneously from the interactions between large populations of neurons.\nAnother influential theory was proposed by neuroscientist Gerald Edelman. His theory of Neural Darwinism suggests that the development of the brain’s neural connections is based on a process of competition and selection, rather than being pre-wired in the genes (Edelman 1987). According to Edelman’s theory, the brain is a complex, dynamic system made up of many interconnected neurons that constantly interact with each other and the outside world. The process of competition and selection occurs through the formation of ensembles of neurons that respond to specific stimuli or experiences. Over time, the connections between neurons in successful ensembles become stronger, while those in unsuccessful ensembles weaken or disappear.\nIt has also been claimed that self-organized criticality (SOC, see the Sandpile model in Section 4.2.1) plays a role in the brain (Bak, Tang, and Wiesenfeld 1988). It is hypothesized that when a system is close to criticality, small perturbations can have large, cascading effects, which can allow the system to rapidly switch between different states of activity in response to changes in the environment. One of the key pieces of evidence for SOC in the brain comes from studies of the distribution of sizes of neural activity events, which has been found to follow a power law distribution, but alternative explanations have been provided (Bédard, Kröger, and Destexhe 2006). This is a technical area of research with many methodological challenges (Lurie et al. 2020; O’Byrne and Jerbi 2022).\nA promising general approach to understanding the so called “predictive” brain functions is the free energy account (Clark 2013), which implements a form of self-organization (Friston 2009). The idea is that the brain is constantly making predictions about the sensory inputs it receives from the environment. The brain is not simply reacting to the world around us but is actively generating predictions about what we will see, hear, feel, and experience, based on our past experiences and knowledge. The predictive brain theory suggests that the brain’s predictions are generated through a process of hierarchical inference, in which information from lower-level sensory areas is combined and integrated in higher-level areas to generate more complex predictions about the world. These predictions are then compared to the incoming sensory inputs, and any discrepancies between the predictions and the actual inputs are used to update the predictions and improve the brain’s accuracy over time.\n\n\n4.3.2 Visual illusions\nFrom the earliest days of psychology as a scientific discipline, researchers were interested in the organizational properties of perception. Gestalt psychologists such as Wertheimer and Koffka claimed that we perceive whole patterns or configurations, not just individual components. One might say that visual perception was one of the first applications of self-organization, even before anything like complexity science existed. The Gestalt psychologist formulated a number of Gestalt principles such as grouping, proximity, similarity, and continuity. A review of a century of research and an analysis of their current role in vision research is provided by (Wagemans et al. 2012). Much of the modeling of the self-organizing processes in perception has been done in the tradition of synergetics. Excellent sources include (J. A. Scott Kelso 1995; Kruse and Stadler 2012). (Grossberg and Pinna 2012) discuss neural implementations of the Gestalt principles.\nAnother related approach is the ecological approach to visual perception by (Gibson 2014). In Gibson’s approach, perception is not just a process of analyzing sensory input, but an active process that involves the perceiver’s relationship to the environment, including the perception of affordances (i.e., opportunities for action) in the environment that guide and shape perception.\nA combination of Gestalt principles, when acting in opposite directions, can lead to all kinds of perceptual illusions. The Optical Illusion model in NetLogo’s model library illustrates some of them. Check out the codes for each illusion, they are extremely short and elegant.\n\n\n\nFigure 4.5: The ‘Kindergarten’ Illusion from The Optical Illusion model in NetLogo\n\n\nIn Chapter 3, I provided examples of sudden jumps and hysteresis in multistable perception. NetLogo is also a great tool for experimenting with these effects. Download ‘Motion Quartet’ from the NetLogo community website and explore hysteresis in your own perception.\n\n\n4.3.3 Motor action\nMany body motions are periodic in nature, think of walking, swimming, dancing, and galloping. Key to these motions is the synchronization of the movements of body parts. A famous paradigm for studying coordinative movement patterns is the finger movement task, in which one has to move both index fingers up and down (or right and left), either in phase or out of phase. Figure 4.6 explains the setup and data showing the transition between two in-phase or out-of-phase oscillations.\n\n\n\nFigure 4.6: The finger movement task. Two fingers move up and down (x1 and x2). They can move in phase or out of phase with a phase difference of 0 and \\(\\pi\\) (bottom left figures). The model is shown on the right side. The potential function either has two stable states (a phase difference\\(\\ \\varphi\\) of 0 or \\(\\pi\\) (\\(- \\pi\\) is the same state) or only one stable state (a phase difference of 0). Coupling strength (\\(b/a\\)) and heterogeneity (\\(\\Delta w)\\) are control variables. Adapted from Haken et al. (1985) and Kelso (2021)\n\n\nThe Haken–Kelso–Bunz (HKB) model, developed in the tradition of synergetics, explains the phase transition between in phase and anti-phase motions in a way we have seen in the previous chapter (the phenomenological cusp model). They set-up a potential function in the form of\n\\[\nV(\\varphi) = - \\Delta w\\varphi - b\\cos\\varphi - a\\cos{2\\varphi} \\tag{4.4}\\] 20\nWhere \\(\\varphi\\) is the order or behavioral variable, the phase difference between the two fingers. The main control parameter is \\(b/a\\). According to (J. A. Scott Kelso 2021) coupling strength (\\(b/a\\)) corresponds to the velocity or frequency of the oscillations in the experiments. \\(\\Delta w\\) is the difference (heterogeneity, diversity) between the natural frequencies of the individual oscillatory elements. In the finger movement task this parameter is expected to be 0. The behavior of this protentional function is cusp like. It has two stable states 0 and \\(\\pm \\pi\\), and increasing and decreasing the frequency leads to hysteresis. The effects of \\(\\Delta w\\) is similar to the fold catastrophe (see Chapter 3).\nThis potential function is proposed as the simplest form that explains the experimental results. This is why I would call this a phenomenological model. However, (H. Haken, Kelso, and Bunz 1985) also present a more mechanistic model, a combination of Van der Pol and Rayleigh oscillators (Alderisio, Bardy, and di Bernardo 2016). The stochastic variant of the HKB model also predicts early warnings such as critical slowing down (see the catastrophe flags, Section 3.3.2). The presence of critical slowing down and other flags has been confirmed experimentally (J. A. S. Kelso, Scholz, and Schöner 1986).\nOne difference with the catastrophe approach is that the synergetic models that incorporate hysteresis typically do not have a splitting control variable. The concept of structural stability, which is fundamental to catastrophe theory, is not used in synergetics. What the splitting factor might be in this model is not so clear. I have never understood why coupling strength \\(b/a\\) (see Figure 4.6) and the frequency of the oscillations are equated in the basic version of the HKB model (see also (P. J. Beek, Peper, and Daffertshofer 2002). Clearly, uncoupled oscillators would have a rather random phase difference. Strengthening the coupling would lead to a kind of pitchfork bifurcation.\nThis coupling/uncoupling is a also a phenomenon in the visual coordination of rhythmic movements between people. (Schmidt, Carello, and Turvey 1990) used an experimental paradigm in which two people swing a leg up and down, while sitting side by side. A metronome was used to manipulate the frequency of the swing. Clear jumps from out-of-phase to in-phase movement were demonstrated.\n(J. A. Scott Kelso 2021) provide an overview of the impressive amount of work on the HKB model. (Repp and Su 2013) review empirical work in many different motor domains. Interestingly, learning motor tasks sometimes involves learning to couple movements (walking), and sometimes the uncoupling of movements (to drum more complex rhythms). Juggling is a fascinating case that has been studied in great detail (Peter J. Beek and Lewbel 1995). Another popular mathematical approach to synchronization phenomena is the Kuramoto model (Acebrón et al. 2005) with the synchronous flashing of fireflies as a basic example. A second-order multi-adaptive neural agent to interpersonal synchrony can be found in (Hendrikse, Treur, and Koole 2023).\n\n\n4.3.4 Robotics\nA major challenge in robotics is to build walking robots. Bipedal robots have evolved from clumsy mechanical walkers to flexible dynamic walkers and runners. Current legged robots can walk on slippery, uneven natural terrain, jump, do backflips, recover from rear shocks, and dance (see some videos on humanoid robots such as Atlas, Asimo). These successes are based on a combination of new technologies, but the principles of self-organization play a key role. An important concept is dynamic stability. In old-school robots, the path and momentum of each step had to be precisely calculated in advance to keep the robot’s center of mass continuously balanced at every point. A dynamically stable robot maintains balance the same way a human does: by catching itself mid-fall with each step (Pavlus 2016).\nAn intriguing application is called passive dynamics, which refers to robotic walking without external energy supply (McGeer 1990; Reher and Ames 2021). The idea is that truly dynamic locomotion should be based on the nonlinear dynamics in natural walking systems. An amazing demonstration is the artwork, Strandbeest, by Theo Jansen. His YouTube videos are strongly recommended.  ### Developmental processes\nThe early roots of interest in nonlinear dynamics and self-organization can be found in the seminal work of the French psychologist Jean Piaget. In order to understand the origin of knowledge, he studied the origin of intelligence in the child (Piaget 1952). His theorizing was inspired by both biological models and observations of children solving puzzles. He saw cognitive development as the building of structures on earlier knowledge structures in a process of equilibration. The idea was that the child would assimilate or accommodate to potentially conflicting external information.\nIn the case of assimilation, the child modifies the information to fit the current cognitive structure, while in the case of accommodation, the structure is modified. Such a modification could be the addition of an exception to the rule (‘Longer sausages of clay normally weigh more, but not when this professor rolls the clay ball into a sausage’). In the long run, this does not work, the cognitive conflicts intensify, and the cognitive structure is destabilized. In this state of disequilibrium, a new structure can be formed on top of the earlier structure. An example of this is the conservation task I introduced in the introduction of Chapter 3. The pre-operational structure, in which form and quantity are equated, leads to incorrect predictions in the conservation anticipation task. The child may ignore this (assimilation), create an ad hoc rule for this exception (accommodation), but the cognitive conflict is not resolved, and the pre-operational structure becomes unstable. This instability allows the formation of the more advanced concrete operational structure in which form and quantity are independent constructs. Piaget argued that cognitive development is a spontaneous, natural process that occurs as children interact with the world around them.\nI would say that this is self-organization theory avant la letter, as was the case for the Gestalt psychologists. I see my own work in developmental psychology (e.g., (Savi et al. 2019; Van Der Maas et al. 2006; Van der Maas and Molenaar 1992) as a formalization of these classical ideas of Piaget. The idea of stages and equilibrium lived on in neo-Piagetian theories.\nIn the late twentieth century developmental theories inspired by work in embodied cognition, nonlinear dynamics, synergetics and neural networks (e.g., Edelman’s neural Darwinism) became popular. A key example is Esther Thelen’s work on the development of walking and reaching (Thelen 1995). Another famous Piagetian task, the A not B error plays a central role in this. The A-not-B error typically occurs in a simple game where an adult hides an object in a known location (A) in front of the infant several times. After a few trials, the adult hides the object in a new location (B) while the infant is watching. Despite watching the object being hidden in the new location, infants tend to continue searching for the object in the old location (A).\nThe book by Thelen and Smith (Thelen and Smith 1994) had a strong influence on developmental psychology, although I was rather critical in my youthful enthusiasm (H. L. J. van der Maas 1995). Concrete mathematical dynamical models for A not B error have been developed in Dynamic Field theory (Schöner and Spencer 2016). Dynamic field theory posits that cognitive processes are represented as dynamic fields, which are patterns of neural activity that evolve over time. These fields can be thought of as distributed representations that encode information about specific aspects of a task or behavior. For example, there may be a dynamic field representing the position of an object in space or the intended movement trajectory of a limb. In this theory, complex behaviors arise from the coordination and integration of multiple dynamic fields. Dynamic Field theory is a very active area of research (more information on https://dynamicfieldtheory.org/).\nFinally, I note that some recent work considers the educational system itself as a complex system (Jacobson, Levin, and Kapur 2019; Lemke and Sabelli 2008).\n\n\n4.3.5 Psychological disorders\nSomewhat dated but interesting reviews of the application of the self-organization concept in clinical psychology are provided by (Barton 1994) and (Ayers 1997). A recent review is provided by (Olthof et al. 2023). Barton’s review begins: “There is perhaps no other area in which chaos theory, nonlinear dynamics, and self-organizing systems are so intuitively appealing yet so analytically difficult as in clinical psychology.” Ayers also concludes that most applications in this field have been rather metaphorical.\nIn recent work, both the modelling and the empirical work have become more concrete (Schiepek and Perlitz 2009). In later chapters I will discuss the mathematical model of marriage (Gottman et al. 2002) and the network approach to psychopathology (Borsboom 2017; Cramer et al. 2010).\nThe network approach to psychological disorders suggests that psychological disorders arise from complex interactions among symptoms, rather than being caused by a single underlying factor. It views disorders as interconnected networks of symptoms, where each symptom influences and is influenced by other symptoms. This approach emphasizes the dynamic nature of psychological disorders and highlights the importance of understanding the relationships between symptoms in order to effectively diagnose and treat them. Network modeling is accompanied by a new family of statistical techniques (Epskamp, Borsboom, and Fried 2018). An introduction to these techniques is given in chapter 6.\n\n\n4.3.6 Social relations\nA key publication in this area is the book on Dynamical Systems in Social Psychology, edited by (Vallacher and Nowak 1994). Concepts such as dissonance (Festinger 1962), balance (Heider 1946), and harmony (Smolensky 1986) reflect the idea that we optimize internal consistency when forming attitudes and knowledge. A formal implementation of these ideas was proposed using PDP-type connectionist models (e.g., (Monroe and Read 2008). Our own model (Dalege and van der Maas 2020; Dalege et al. 2018, 2016) is based on the Ising model and the Boltzmann machine, as in Smolensky’s proposal, which can be fitted to data. I will explain this work in more detail in Chapter 6.\nA simple but famous example of social self-organization concerns pedestrian dynamics as studied by (Helbing and Molnár 1995). They proposed a simple physics-based model for panic evacuation. For an excellent overview of crowd simulation, I again, refer to Wikipedia. Some of this work is rooted in the social sciences. An example in NetLogo is the model “Path”.\nFamous is the work of the sociologist Mark Granovetter (M. Granovetter 1973) on strong and weak ties in social networks (belonging to the best cited paper in the history of the social sciences). The idea is that weak ties in social networks are often more valuable than strong ties, as they provide access to new information and opportunities that may not be available within one’s close circle of friends and acquaintances.\nAnother of his contributions is the threshold model of collective behavior (Mark Granovetter 1978). I like to explain this work using the “Guy starts dance party” video on YouTube. The idea is that people have some threshold, between 0 and 1, to join the dancers. These thresholds have some distribution, a flexible one is the beta distribution. With this R-code we can simulate this effect:\n\nlayout(1:2)\nn &lt;- 1000 # number of persons\ninterations &lt;- 50\nthreshold &lt;- rbeta(n,1,2) # sample individual thresholds for dancing\nhist(threshold,col='grey')\ndancers &lt;- rep(0,n) # nobody dances\ndancers[1] &lt;- 1 # but one guy\nnumber_of_dancers &lt;- rep(0,interations) # keep track of number of dancers\nfor(i in 1:interations)\n{\n  number_of_dancers[i] &lt;- sum(dancers) # keep track of number of dancers\n  dancers[threshold&lt;(number_of_dancers[i]/n)] &lt;- 1 \n# if my threshold &lt; proportion of dancers, I dance\n}\nplot(number_of_dancers,xlab='time',ylab='#dancers',ylim=c(0,1000),type='b',bty='n')\n\nDepending on the parameters of the beta distribution you will see a phase transition to collective dancing. This basic setup can be extended in many ways.\nAnother classic contribution, explained in more detail in Chapter 7, is Schelling’s agent-based model of segregation (Schelling 1971). The idea is that even if individuals have only a small preference for in-group neighbors, segregated societies will form. For a broad overview of complex systems research on human cooperation, I refer to (Perc et al. 2017).\n\n\n4.3.7 Collective Intelligence\nCollective intelligence research examines how groups can collectively outperform individual members in problem solving, decision making, and idea generation. One famous concept is the idea of the wisdom of crowds (Surowiecki 2005). A key example, often cited to illustrate the wisdom of the crowds, is the “Guess the Weight of the Ox” contest that took place at the West of England Fat Stock and Poultry Exhibition in 1906. While individual guesses varied widely, the average guess was remarkably close to the actual weight of the ox. The average guess was only one pound off the actual weight, which was 1,198 pounds.\nHowever, there is a fine line between the wisdom of the crowd and the stupidity of the crowd (Galesic et al. 2023). It is extremely useful to know when that line is crossed. The wisdom of crowds tends to work when there is a diverse group of independent individuals, each making their own judgments or estimates about a particular question or problem. It is more likely to be effective when the group is large, has a wide range of knowledge and perspectives, and the judgments are made independently, without undue influence from others (Brush, Krakauer, and Flack 2018; Centola 2022). There is an extensive and up-to-date Wikipedia on collective intelligence, discussing findings from various disciplines, the idea of a collective intelligence factor c, biological examples (swarm intelligence), and an overview of applications (such as open source software, crowdsourcing, the Delphi technique and Wikipedia itself).\n\n\n4.3.8 Game theory\nOf particular importance is game theory, which consists of mathematical models of strategic interactions among rational agents. A great historical overview can be found at Wikipedia. One of the most famous paradigms is the prisoner’s dilemma. You and your buddy are arrested, and you both independently talk to the police. The options are to remain silent or to tell. The dilemma is that remaining silent is the best option if you both choose it, but the worst option if your friend betrays you (see the payoff matrix). In this game, loyalty to one’s friend is irrational, an outcome related to the tragedy of the commons (Hardin 1968). The tragedy of the commons can be studied in the hubnet extension of NetLogo, where multiple users can participate in NetLogo simulations.\n\n\n\nFigure 4.7: The prisoner’s dilemma\n\n\nA major topic in game theory is altruism. In many cases, individualistic choices lead to an unsatisfactory (Nash) equilibrium. A Nash equilibrium is a set of strategies in which no player can improve their payoff by unilaterally changing their strategy, given the strategies of the other players. The public goods game is a good example. In this game, everyone invests some money, which is then multiplied by an external party (the government). Then everyone gets an equal share of the multiplied total. The problem is that free riders, who do not invest, win the most, which in iterated public good games leads to a situation where no one invests and no one wins. Punishment (shaming and blaming) is known to help combat free riding. But punishment also requires investment. I like to tell my students when they are working in groups on an assignment that the problem of this one student doing nothing happens because nice, hard-working students refuse to betray their fellow students to me. These nice, hard-working students are what are called second-order free riders (Fowler 2005).\n\n\n4.3.9 Self-organization in organizations\nTranslating this basic research into real-world applications is far from straightforward (Anderson 1999; Morel and Ramanujam 1999). Human organizations can be placed on a scale from extreme hierarchy to radical forms of self-organization (Volberda and Lewin 2003). Note also that our economic system is a mixture of self-organization (pure capitalism) and top-down regulation (through laws, taxes and other regulations). Black markets are critical cases of unregulated self-organized systems (Tesfatsion 2002).\nA concrete modeling example is the team assembly model by (Guimerà et al. 2005). They study how the way creative teams self-assemble determine the structure of collaboration networks. The idea is that effective teams find a balance between being large enough to allow for specialization and efficient division of labor among members, while also being small enough to avoid excessive costs associated with coordinating group efforts. Agents in the model have only a few basic characteristics that influence their behavior: whether they are a newcomer or incumbent and what previous connections they have with other agents if they are incumbents.\nThree parameters that can be adjusted to influence behavior in the baseline assembly model: the team size, the probability of choosing an incumbent (\\(p\\)), and the probability of choosing a previous collaborator (\\(q\\)). The two probability parameters signify assumptions about agent motivations for team member selection. Low incumbent probability leads to preference for newcomers and new ideas, while high incumbent probability means a focus on experience. Low collaborator probability prioritizes experienced strangers, and high collaborator probability prioritizes previous collaborators. The model is part of the build in NetLogo models (“team assembly”). By simulating the model, it can be shown that the emergence of a large, connected community of practitioners can be described as a phase transition.\n(Guimerà et al. 2005) estimated the parameters \\(p\\) and \\(q\\) for the community formation in four scientific disciplines (social psychology, economics, ecology, and astronomy). Only the field of astronomy had a very dense collaboration structure. In the other fields the estimates of \\(p\\) and \\(q\\) of teams publishing in certain journals correlated well with impact factor. Interestingly, \\(p\\) correlates positively and \\(q\\) negatively with impact.\n\n\n\nFigure 4.8: Team assembly model. Newcomers and incumbents are added to growing networks based on probabilities p and q. If p is sufficiently high, a dense network emerges."
  },
  {
    "objectID": "ch4.html#zooming-out",
    "href": "ch4.html#zooming-out",
    "title": "4  Self-organization",
    "section": "4.4 Zooming out",
    "text": "4.4 Zooming out\nI hope I have succeeded in giving an organized and practical overview of a very disorganized and interdisciplinary field of research. For each subfield, I have provided key references that should help you find recent and specialized contributions. I find the examples of self-organization in the natural sciences fascinating and inspiring. I hope I have also shown that applications of this concept in psychology and the social sciences hold great promise. In the next chapters, I will present more concrete examples.\nI believe that understanding models requires working with models, for example through simulation. NetLogo is a great tool for this, although there are many alternatives available (Abar et al. 2017). I haven’t mentioned all the uses of NetLogo, but it’s good to know about the BehaviorSpace option. BehaviorSpace runs models repeatedly and in parallel (without visualization), systematically varying model settings and parameters, and recording the results of each model run. These results can then be further analyzed in R. An example will be provided in chapter 7."
  },
  {
    "objectID": "ch4.html#exercises",
    "href": "ch4.html#exercises",
    "title": "4  Self-organization",
    "section": "4.5 Exercises",
    "text": "4.5 Exercises\n\nWhat does the rice cooker have to do with the Ising model?\nWhat is the Boltzmann entropy for the state \\(\\sum_{}^{}x = 0\\) in an Ising model (with nodes states -1 and 1) with 10 nodes and no external field? (*).\nGo to the webpage ‘A Neural Network Playground’. What is the minimal network to solve the XOR with 100% success? Use only the x1 and x2 feature. (*)\nIn the Granovetter model (Section 4.3.7), people may also stop dancing (with probability .1). Add this to the model. What changes? (*)\nAdd the external field to the Ising model in NetLogo (neighbors4 case). Report the changed line in the NetLogo code. What did you change in the interface?\nSet the temperature to 1.5. Change tau slowly. At which values of tau do the hysteresis jumps occur? (*)\nTest whether the Ising model is indeed a cusp. Run the Ising model in NetLogo using the BehaviorSpace tool. Use the model in which all spins are connected to all spins (see Section 4.2.2.2). Vary tau (-.3 to .3 in .05 increments) and temperature (0 to 3, in .5 increments). One iteration per combination of parameter values is sufficient. Stop after 10000 ticks and collect only the final magnetization. Import the data into R and fit the cusp. Which cusp model best describes the data? (**)\nOpen the Sandpile 3D model in NetLogo3D. Grains of sand fall at random place. Change one line of code such that they all fall in the middle. What did you change? (*)\nDownload ‘Motion Quartet’ from the NetLogo community website and explore hysteresis in your own perception. What could be a splitting variable? (*)\nImplement the Granovetter model in NetLogo (max 40 lines of code) (**)\n\n\n\n\n\nAbar, Sameera, Georgios K. Theodoropoulos, Pierre Lemarinier, and Gregory M. P. O’Hare. 2017. “Agent Based Modelling and Simulation Tools: A Review of the State-of-Art Software.” Computer Science Review 24 (May): 13–33. https://doi.org/10.1016/j.cosrev.2017.03.001.\n\n\nAbe, Yayoi, Muneyuki Ishida, Erika Nozawa, Takayoshi Ootsuka, and Ryoko Yahagi. 2017. “Cusp Singularity in Mean Field Ising Model.” European Journal of Physics 38 (6): 065102. https://doi.org/10.1088/1361-6404/aa82fc.\n\n\nAcebrón, Juan A., L. L. Bonilla, Conrad J. Pérez Vicente, Félix Ritort, and Renato Spigler. 2005. “The Kuramoto Model: A Simple Paradigm for Synchronization Phenomena.” Reviews of Modern Physics 77 (1): 137–85. https://doi.org/10.1103/RevModPhys.77.137.\n\n\nAlderisio, Francesco, Benoît G. Bardy, and Mario di Bernardo. 2016. “Entrainment and Synchronization in Networks of Rayleighvan Der Pol Oscillators with Diffusive and Haken Couplings.” Biological Cybernetics 110 (2): 151–69. https://doi.org/10.1007/s00422-016-0685-7.\n\n\nAnderson, Philip. 1999. “Perspective: Complexity Theory and Organization Science.” Organization Science 10 (3): 216–32. https://doi.org/10.1287/orsc.10.3.216.\n\n\nAshby, W. R. 1956. “An Introduction to Cybernetics.” An Introduction to Cybernetics.\n\n\nAyers, Susan. 1997. “The Application of Chaos Theory to Psychology.” Theory & Psychology 7 (June): 373. https://doi.org/10.1177/0959354397073005.\n\n\nBak, Per, Chao Tang, and Kurt Wiesenfeld. 1988. “Self-Organized Criticality.” Physical Review A 38 (1): 364–74. https://doi.org/10.1103/PhysRevA.38.364.\n\n\nBarton, Scott. 1994. “Chaos, Self-Organization, and Psychology.” American Psychologist. https://doi.org/10.1037/0003-066X.49.1.5.\n\n\nBédard, C., H. Kröger, and A. Destexhe. 2006. “Does the $1/f$ Frequency Scaling of Brain Signals Reflect Self-Organized Critical States?” Physical Review Letters 97 (11): 118102. https://doi.org/10.1103/PhysRevLett.97.118102.\n\n\nBeek, P. J, C. E Peper, and A Daffertshofer. 2002. “Modeling Rhythmic Interlimb Coordination: Beyond the Haken.” Brain and Cognition 48 (1): 149–65. https://doi.org/10.1006/brcg.2001.1310.\n\n\nBeek, Peter J., and Arthur Lewbel. 1995. “The Science of Juggling.” Scientific American 273 (5): 92–97. https://doi.org/10.1038/scientificamerican1195-92.\n\n\nBerlekamp, Elwyn R., John H. Conway, and Richard K. Guy. 2004. Winning Ways for Your Mathematical Plays, Volume 4. 2nd ed. New York: A K Peters/CRC Press. https://doi.org/10.1201/9780429487309.\n\n\nBoerlijst, M. C., and P. Hogeweg. 1991. “Spiral Wave Structure in Pre-Biotic Evolution: Hypercycles Stable Against Parasites.” Physica D: Nonlinear Phenomena 48 (1): 17–28. https://doi.org/10.1016/0167-2789(91)90049-F.\n\n\nBorsboom, Denny. 2017. “A Network Theory of Mental Disorders.” World Psychiatry 16 (1): 5–13. https://doi.org/10.1002/wps.20375.\n\n\nBreakspear, Michael. 2017. “Dynamic Models of Large-Scale Brain Activity.” Nature Neuroscience 20 (3): 340–52. https://doi.org/10.1038/nn.4497.\n\n\nBrinkhuis, Matthieu J. S., Alexander O. Savi, Abe D. Hofman, Frederik Coomans, Han L. J. van der Maas, and Gunter Maris. 2018. “Learning As It Happens: A Decade of Analyzing and Shaping a Large-Scale Online Learning System.” Journal of Learning Analytics 5 (2): 29–46. https://doi.org/10.18608/jla.2018.52.3.\n\n\nBrush, Eleanor R., David C. Krakauer, and Jessica C. Flack. 2018. “Conflicts of Interest Improve Collective Computation of Adaptive Social Structures.” Science Advances 4 (1): e1603311. https://doi.org/10.1126/sciadv.1603311.\n\n\nCentola, Damon. 2022. “The Network Science of Collective Intelligence.” Trends in Cognitive Sciences 26 (11): 923–41. https://doi.org/10.1016/j.tics.2022.08.009.\n\n\nChialvo, Dante R. 2010. “Emergent Complex Neural Dynamics.” Nature Physics 6 (10): 744–50. https://doi.org/10.1038/nphys1803.\n\n\nClark, Andy. 2013. “Whatever Next? Predictive Brains, Situated Agents, and the Future of Cognitive Science.” Behavioral and Brain Sciences 36 (3): 181–204. https://doi.org/10.1017/S0140525X12000477.\n\n\nCocchi, Luca, Leonardo L. Gollo, Andrew Zalesky, and Michael Breakspear. 2017. “Criticality in the Brain: A Synthesis of Neurobiology, Models and Cognition.” Progress in Neurobiology 158 (November): 132–52. https://doi.org/10.1016/j.pneurobio.2017.07.002.\n\n\nCramer, Angélique O. J., Lourens J. Waldorp, Han L. J. van der Maas, and Denny Borsboom. 2010. “Comorbidity: A Network Perspective.” The Behavioral and Brain Sciences 33 (2-3): 137-150; discussion 150-193. https://doi.org/10.1017/S0140525X09991567.\n\n\nDalege, Jonas, Denny Borsboom, Frenk van Harreveld, Helma van den Berg, Mark Conner, and Han L. J. van der Maas. 2016. “Toward a Formalized Account of Attitudes: The Causal Attitude Network (CAN) Model.” Psychological Review 123 (1): 2–22. https://doi.org/10.1037/a0039802.\n\n\nDalege, Jonas, Denny Borsboom, Frenk van Harreveld, and Han L. J. van der Maas. 2018. “The Attitudinal Entropy (AE) Framework as a General Theory of Individual Attitudes.” Psychological Inquiry 29 (4): 175–93. https://doi.org/10.1080/1047840X.2018.1537246.\n\n\nDalege, Jonas, and Han L. J. van der Maas. 2020. “Accurate by Being Noisy: A Formal Network Model of Implicit Measures of Attitudes.” Social Cognition 38 (Suppl): S26–41. https://doi.org/10.1521/soco.2020.38.supp.s26.\n\n\nDresp-Langley, Birgitta. 2020. “Seven Properties of Self-Organization in the Human Brain.” Big Data and Cognitive Computing 2 (4): 10.\n\n\nEdelman, Gerald M. 1987. Neural Darwinism: The Theory of Neuronal Group Selection. Neural Darwinism: The Theory of Neuronal Group Selection. New York, NY, US: Basic Books.\n\n\nEigen, Manfred, and Peter Schuster. 1979. The Hypercycle. Berlin, Heidelberg: Springer. https://doi.org/10.1007/978-3-642-67247-7.\n\n\nEldredge, Niles, and Stephen Jay Gould. 1972. “Punctuated Equilibria: An Alternative to Phyletic Gradualism.” In Models in Paleobiology, edited by Thomas J. M. Schopf, 82–115. Freeman Cooper.\n\n\nElo, Arpad E. 1978. The Rating of Chessplayers, Past and Present. New York: Arco Pub.\n\n\nEpskamp, Sacha, Denny Borsboom, and Eiko I. Fried. 2018. “Estimating Psychological Networks and Their Accuracy: A Tutorial Paper.” Behavior Research Methods 50 (1): 195–212. https://doi.org/10.3758/s13428-017-0862-1.\n\n\nFestinger, Leon. 1962. A Theory of Cognitive Dissonance. A Theory of Cognitive Dissonance. Palo Alto, CA, US: Stanford Univer. Press.\n\n\nFowler, James H. 2005. “Second-Order Free-Riding Problem Solved?” Nature 437 (7058): E8–8. https://doi.org/10.1038/nature04201.\n\n\nFriston, Karl. 2009. “The Free-Energy Principle: A Rough Guide to the Brain?” Trends in Cognitive Sciences 13 (7): 293–301. https://doi.org/10.1016/j.tics.2009.04.005.\n\n\nFuchs, Armin, and Scott Kelso. 2018. “Coordination Dynamics and Synergetics: From Finger Movements to Brain Patterns and Ballet Dancing.” In Complexity and Synergetics, 301–16. https://doi.org/10.1007/978-3-319-64334-2_23.\n\n\nGalesic, Mirta, Daniel Barkoczi, Andrew M. Berdahl, Dora Biro, Giuseppe Carbone, Ilaria Giannoccaro, Robert L. Goldstone, et al. 2023. “Beyond Collective Intelligence: Collective Adaptation.” Journal of The Royal Society Interface 20 (200): 20220736. https://doi.org/10.1098/rsif.2022.0736.\n\n\nGhatak, Abhijit. 2019. Deep Learning with R. Singapore: Springer. https://doi.org/10.1007/978-981-13-5850-0.\n\n\nGibson, James J. 2014. The Ecological Approach to Visual Perception: Classic Edition. New York: Psychology Press. https://doi.org/10.4324/9781315740218.\n\n\nGottman, John M., James D. Murray, Catherine C. Swanson, Rebecca Tyson, and Kristin R. Swanson. 2002. The Mathematics of Marriage: Dynamic Nonlinear Models. The Mathematics of Marriage: Dynamic Nonlinear Models. Cambridge, MA, US: MIT Press.\n\n\nGranovetter, M. 1973. “The Strength of Weak Ties.” American Journal of Sociology 78 (6): 1360–80. https://doi.org/10.1086/225469.\n\n\nGranovetter, Mark. 1978. “Threshold Models of Collective Behavior.” The American Journal of Sociology 83 (6): 1420–43. https://doi.org/10.1086/226707.\n\n\nGrossberg, Stephen, and Baingio Pinna. 2012. “Neural Dynamics of Gestalt Principles of Perceptual Organization: From Grouping to Shape and Meaning.” GESTALT THEORY 34.\n\n\nGuimerà, Roger, Brian Uzzi, Jarrett Spiro, and Luís A. Nunes Amaral. 2005. “Team Assembly Mechanisms Determine Collaboration Network Structure and Team Performance.” Science 308 (5722): 697–702. https://doi.org/10.1126/science.1106340.\n\n\nHaken, Herman. 1977. “Synergetics.” Physics Bulletin 28 (9): 412. https://doi.org/10.1088/0031-9112/28/9/027.\n\n\nHaken, Hermann. 1992. “Synergetics in Psychology.” In Self-Organization and Clinical Psychology: Empirical Approaches to Synergetics in Psychology, edited by Wolfgang Tschacher, Günter Schiepek, and Ewald Johannes Brunner, 32–54. Springer Series in Synergetics. Berlin, Heidelberg: Springer. https://doi.org/10.1007/978-3-642-77534-5_2.\n\n\nHaken, H., J. A. S. Kelso, and H. Bunz. 1985. “A Theoretical Model of Phase Transitions in Human Hand Movements.” Biological Cybernetics 51 (5): 347–56. https://doi.org/10.1007/BF00336922.\n\n\nHardin, Garrett. 1968. “The Tragedy of the Commons” 162.\n\n\nHebb, D. O. 1949. The Organization of Behavior; a Neuropsychological Theory. The Organization of Behavior; a Neuropsychological Theory. Oxford, England: Wiley.\n\n\nHeider, Fritz. 1946. “Attitudes and Cognitive Organization.” The Journal of Psychology 21 (1): 107–12. https://doi.org/10.1080/00223980.1946.9917275.\n\n\nHelbing, Dirk, and Péter Molnár. 1995. “Social Force Model for Pedestrian Dynamics.” Physical Review E 51 (5): 4282–86. https://doi.org/10.1103/PhysRevE.51.4282.\n\n\nHendrikse, Sophie, Jan Treur, and Sander Koole. 2023. “Modeling Emerging Interpersonal Synchrony and Its Related Adaptive Short-Term Affiliation and Long-Term Bonding: A Second-Order Multi-Adaptive Neural Agent Model.” International Journal of Neural Systems, April. https://doi.org/10.1142/S0129065723500387.\n\n\nHolland, John H. 1992a. “Genetic Algorithms.” Scientific American 267 (1): 66–73. https://doi.org/10.1038/scientificamerican0792-66.\n\n\n———. 1992b. Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence. MIT Press.\n\n\nJacobson, Michael J., James A. Levin, and Manu Kapur. 2019. “Education as a Complex System: Conceptual and Methodological Implications.” Educational Researcher 48 (2): 112–19. https://doi.org/10.3102/0013189X19826958.\n\n\nKalantari, Somayeh, Eslam Nazemi, and Behrooz Masoumi. 2020. “Emergence Phenomena in Self-Organizing Systems: A Systematic Literature Review of Concepts, Researches, and Future Prospects.” Journal of Organizational Computing and Electronic Commerce 30 (3): 224–65. https://doi.org/10.1080/10919392.2020.1748977.\n\n\nKauffman, Stuart A. 1993. The Origins of Order: Self-Organization and Selection in Evolution. 1st edition. New York: Oxford University Press.\n\n\nKelso, J. A. Scott. 1995. Dynamic Patterns: The Self-Organization of Brain and Behavior. Dynamic Patterns: The Self-Organization of Brain and Behavior. Cambridge, MA, US: The MIT Press.\n\n\n———. 2021. “The Haken (HKB) Model: From Matter to Movement to Mind.” Biological Cybernetics 115 (4): 305–22. https://doi.org/10.1007/s00422-021-00890-w.\n\n\nKelso, J. A. S., J. P. Scholz, and G. Schöner. 1986. “Nonequilibrium Phase Transitions in Coordinated Biological Motion: Critical Fluctuations.” Physics Letters A 118 (6): 279–84. https://doi.org/10.1016/0375-9601(86)90359-2.\n\n\nKlinkenberg, S., M Straatemeier, and H. van der Maas. 2011. “Computer Adaptive Practice of Maths Ability Using a New Item Response Model for on the Fly Ability and Difficulty Estimation.” Computers & Education 57: 1813–24.\n\n\nKruse, Peter, and Michael Stadler. 2012. Ambiguity in Mind and Nature: Multistable Cognitive Phenomena. Springer Science & Business Media.\n\n\nLangton, Chris G. 1990. “Computation at the Edge of Chaos: Phase Transitions and Emergent Computation.” Physica D: Nonlinear Phenomena 42 (1): 12–37. https://doi.org/10.1016/0167-2789(90)90064-V.\n\n\nLemke, Jay L., and Nora H. Sabelli. 2008. “Complex Systems and Educational Change: Towards a New Research Agenda.” In Complexity Theory and the Philosophy of Education, 112–23. John Wiley & Sons, Ltd. https://doi.org/10.1002/9781444307351.ch8.\n\n\nLurie, Daniel J., Daniel Kessler, Danielle S. Bassett, Richard F. Betzel, Michael Breakspear, Shella Kheilholz, Aaron Kucyi, et al. 2020. “Questions and Controversies in the Study of Time-Varying Functional Connectivity in Resting fMRI.” Network Neuroscience 4 (1): 30–69. https://doi.org/10.1162/netn_a_00116.\n\n\nMaris, Gunter, and Han van der Maas. 2012. “Speed-Accuracy Response Models: Scoring Rules Based on Response Time and Accuracy.” Psychometrika 77 (4): 615–33. https://doi.org/10.1007/s11336-012-9288-y.\n\n\nMcGeer, T. 1990. “Passive Walking with Knees.” In, IEEE International Conference on Robotics and Automation Proceedings, 1640–1645 vol.3. https://doi.org/10.1109/ROBOT.1990.126245.\n\n\nMcGrath, Thomas, Andrei Kapishnikov, Nenad Tomašev, Adam Pearce, Martin Wattenberg, Demis Hassabis, Been Kim, Ulrich Paquet, and Vladimir Kramnik. 2022. “Acquisition of Chess Knowledge in AlphaZero.” Proceedings of the National Academy of Sciences 119 (47): e2206625119. https://doi.org/10.1073/pnas.2206625119.\n\n\nMitchell, Melanie. 1998. An Introduction to Genetic Algorithms. MIT Press.\n\n\nMonroe, Brian M., and Stephen J. Read. 2008. “A General Connectionist Model of Attitude Structure and Change: The ACS (Attitudes as Constraint Satisfaction) Model.” Psychological Review 115: 733–59. https://doi.org/10.1037/0033-295X.115.3.733.\n\n\nMorel, Benoit, and Rangaraj Ramanujam. 1999. “Through the Looking Glass of Complexity: The Dynamics of Organizations as Adaptive and Evolving Systems.” Organization Science 10 (3): 278–93. https://doi.org/10.1287/orsc.10.3.278.\n\n\nO’Byrne, Jordan, and Karim Jerbi. 2022. “How Critical Is Brain Criticality?” Trends in Neurosciences 45 (11): 820–37. https://doi.org/10.1016/j.tins.2022.08.007.\n\n\nOlthof, Merlijn, Fred Hasselman, Freek Oude Maatman, Anna M. T. Bosman, and Anna Lichtwarck-Aschoff. 2023. “Complexity Theory of Psychopathology.” Journal of Psychopathology and Clinical Science 132: 314–23. https://doi.org/10.1037/abn0000740.\n\n\nOoyen, Arjen van, and Markus Butz-Ostendorf. 2017. The Rewiring Brain: A Computational Approach to Structural Plasticity in the Adult Brain. Academic Press.\n\n\nPavlus, John. 2016. “The Clumsy Quest to Perfect the Walking Robot.” Scientific American. https://www.scientificamerican.com/article/the-clumsy-quest-to-perfect-the-walking-robot/. https://doi.org/10.1038/scientificamerican0716-60.\n\n\nPerc, Matjaž, Jillian J. Jordan, David G. Rand, Zhen Wang, Stefano Boccaletti, and Attila Szolnoki. 2017. “Statistical Physics of Human Cooperation.” Physics Reports, Statistical physics of human cooperation, 687 (May): 1–51. https://doi.org/10.1016/j.physrep.2017.05.004.\n\n\nPiaget, Jean. 1952. The Origins of Intelligence in Children. Edited by Margaret Cook. The Origins of Intelligence in Children. New York, NY, US: W W Norton & Co. https://doi.org/10.1037/11494-000.\n\n\nPlenz, Dietmar, Tiago L. Ribeiro, Stephanie R. Miller, Patrick A. Kells, Ali Vakili, and Elliott L. Capek. 2021. “Self-Organized Criticality in the Brain.” Frontiers in Physics 9. https://doi.org/10.3389/fphy.2021.639389.\n\n\nPoston, Tim, and Ian Stewart. 2014. Catastrophe Theory and Its Applications. Courier Corporation.\n\n\nReher, Jenna, and Aaron D. Ames. 2021. “Dynamic Walking: Toward Agile and Efficient Bipedal Robots.” Annual Review of Control, Robotics, and Autonomous Systems 4 (1): 535–72. https://doi.org/10.1146/annurev-control-071020-045021.\n\n\nRendell, Paul. 2016. “Game of Life Universal Turing Machine.” In Turing Machine Universality of the Game of Life, edited by Paul Rendell, 71–89. Emergence, Complexity and Computation. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-19842-2_5.\n\n\nRepp, Bruno H., and Yi-Huang Su. 2013. “Sensorimotor Synchronization: A Review of Recent Research (2006).” Psychonomic Bulletin & Review 20 (3): 403–52. https://doi.org/10.3758/s13423-012-0371-2.\n\n\nSavi, Alexander O., Maarten Marsman, Han L. J. van der Maas, and Gunter K. J. Maris. 2019. “The Wiring of Intelligence.” Perspectives on Psychological Science 14 (6): 1034–61. https://doi.org/10.1177/1745691619866447.\n\n\nSchelling, Thomas C. 1971. “Dynamic Models of Segregation.” The Journal of Mathematical Sociology 1 (2): 143–86. https://doi.org/10.1080/0022250X.1971.9989794.\n\n\nSchiepek, Günter, and Volker Perlitz. 2009. “Self-Organization in Clinical Psychology.” In Synergetics, edited by Axel Hutt and Hermann Haken, 263–85. New York, NY: Springer US. https://doi.org/10.1007/978-1-0716-0421-2_472.\n\n\nSchmidhuber, Jürgen. 2015. “Deep Learning in Neural Networks: An Overview.” Neural Networks 61 (January): 85–117. https://doi.org/10.1016/j.neunet.2014.09.003.\n\n\nSchmidt, R. C., C. Carello, and M. T. Turvey. 1990. “Phase Transitions and Critical Fluctuations in the Visual Coordination of Rhythmic Movements Between People.” Journal of Experimental Psychology. Human Perception and Performance 16 (2): 227–47. https://doi.org/10.1037//0096-1523.16.2.227.\n\n\nSchöner, Gregor, and John P. Spencer. 2016. Dynamic Thinking: A Primer on Dynamic Field Theory. Oxford University Press.\n\n\nSilver, David, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, et al. 2018. “A General Reinforcement Learning Algorithm That Masters Chess, Shogi, and Go Through Self-Play.” Science 362 (6419): 1140–44. https://doi.org/10.1126/science.aar6404.\n\n\nSkarda, Christine A., and Walter J. Freeman. 1987. “How Brains Make Chaos in Order to Make Sense of the World.” Behavioral and Brain Sciences 10 (2): 161–73. https://doi.org/10.1017/S0140525X00047336.\n\n\nSmolensky, Paul. 1986. “Information Processing in Dynamical Systems: Foundations of Harmony Theory.”\n\n\nStengers, Isabelle, and Ilya Prigogine. 1978. Order Out of Chaos: Man’s New Dialogue with Nature. London.\n\n\nSurowiecki, James. 2005. The Wisdom of Crowds. Knopf Doubleday Publishing Group.\n\n\nSutton, Richard S., and Andrew G. Barto. 2018. Reinforcement Learning, Second Edition: An Introduction. MIT Press.\n\n\nTesfatsion, Leigh. 2002. “Agent-Based Computational Economics: Growing Economies From the Bottom Up.” Artificial Life 8 (1): 55–82. https://doi.org/10.1162/106454602753694765.\n\n\nThelen, Esther. 1995. “Motor Development: A New Synthesis.” American Psychologist 50: 79–95. https://doi.org/10.1037/0003-066X.50.2.79.\n\n\nThelen, Esther, and Linda B. Smith. 1994. A Dynamic Systems Approach to the Development of Cognition and Action. MIT Press.\n\n\nVallacher, Robin R., and Andrzej Nowak, eds. 1994. Dynamical Systems in Social Psychology. Dynamical Systems in Social Psychology. San Diego, CA, US: Academic Press.\n\n\nvan der Maas, H. L. J. 1995. “Beyond the Metaphor?” Cognitive Development 10.\n\n\nVan Der Maas, Han L. J., Conor V. Dolan, Raoul P. P. P. Grasman, Jelte M. Wicherts, Hilde M. Huizenga, and Maartje E. J. Raijmakers. 2006. “A Dynamical Model of General Intelligence: The Positive Manifold of Intelligence by Mutualism.” Psychological Review 113 (4): 842–61. https://doi.org/c3jm44.\n\n\nvan der Maas, Han L. J., Lukas Snoek, and Claire E. Stevenson. 2021. “How Much Intelligence Is There in Artificial Intelligence? A 2020 Update.” Intelligence 87 (July): 101548. https://doi.org/10.1016/j.intell.2021.101548.\n\n\nVan der Maas, Han L., and Peter C. Molenaar. 1992. “Stagewise Cognitive Development: An Application of Catastrophe Theory.” Psychological Review 99 (3): 395–417. https://doi.org/10.1037/0033-295X.99.3.395.\n\n\nVolberda, Henk W., and Arie Y. Lewin. 2003. “Co-Evolutionary Dynamics Within and Between Firms: From Evolution to Co-evolution.” Journal of Management Studies 40 (8): 2111–36. https://doi.org/10.1046/j.1467-6486.2003.00414.x.\n\n\nWagemans, Johan, James H. Elder, Michael Kubovy, Stephen E. Palmer, Mary A. Peterson, Manish Singh, and Rüdiger von der Heydt. 2012. “A Century of Gestalt Psychology in Visual Perception: I. Perceptual Grouping and Figureground Organization.” Psychological Bulletin 138: 1172–1217. https://doi.org/10.1037/a0029333.\n\n\nWiener, Norbert. 2019. Cybernetics or Control and Communication in the Animal and the Machine, Reissue of the 1961 Second Edition. MIT Press.\n\n\nWilensky, Uri, and William Rand. 2015. An Introduction to Agent-Based Modeling: Modeling Natural, Social, and Engineered Complex Systems with NetLogo. Cambridge, Massachusetts: The MIT Press.\n\n\nXue, Jiankai, and Bo Shen. 2020. “A Novel Swarm Intelligence Optimization Approach: Sparrow Search Algorithm.” Systems Science & Control Engineering 8 (1): 22–34. https://doi.org/10.1080/21642583.2019.1708830."
  },
  {
    "objectID": "ch4.html#footnotes",
    "href": "ch4.html#footnotes",
    "title": "4  Self-organization",
    "section": "",
    "text": "An extremely useful application of this principle is the rice cooker!↩︎\nIn a synchronous update, all cells of the cellular automata update their state simultaneously. This implies that the new state of each cell at a given time step depends only on the states of its neighbors at the previous time step. In asynchronous update, cells update their state one at a time, rather than all at once. The order in which cells update can be deterministic (in a sequence), or it can be stochastic (random). These two different update schemes can lead to very different behaviors in cellular automata.↩︎"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Abar, Sameera, Georgios K. Theodoropoulos, Pierre Lemarinier, and\nGregory M. P. O’Hare. 2017. “Agent Based Modelling\nand Simulation Tools: A Review of the\nState-of-Art Software.” Computer Science Review 24\n(May): 13–33. https://doi.org/10.1016/j.cosrev.2017.03.001.\n\n\nAbe, Yayoi, Muneyuki Ishida, Erika Nozawa, Takayoshi Ootsuka, and Ryoko\nYahagi. 2017. “Cusp Singularity in Mean Field Ising\nModel.” European Journal of Physics 38 (6): 065102. https://doi.org/10.1088/1361-6404/aa82fc.\n\n\nAcebrón, Juan A., L. L. Bonilla, Conrad J. Pérez Vicente, Félix Ritort,\nand Renato Spigler. 2005. “The Kuramoto Model:\nA Simple Paradigm for Synchronization Phenomena.”\nReviews of Modern Physics 77 (1): 137–85. https://doi.org/10.1103/RevModPhys.77.137.\n\n\nAlderisio, Francesco, Benoît G. Bardy, and Mario di Bernardo. 2016.\n“Entrainment and Synchronization in Networks of\nRayleighvan Der Pol Oscillators with Diffusive\nand Haken Couplings.” Biological\nCybernetics 110 (2): 151–69. https://doi.org/10.1007/s00422-016-0685-7.\n\n\nAlexander, Ralph A., Glenn R. Herbert, Richard P. DeShon, and Paul J.\nHanges. 1992. “An Examination of Least-Squares Regression Modeling\nof Catastrophe Theory.” Psychological Bulletin 111:\n366–74. https://doi.org/10.1037/0033-2909.111.2.366.\n\n\nAnderson, P. W. 1972. “More Is Different.”\nScience 177 (4047): 393–96. https://doi.org/10.1126/science.177.4047.393.\n\n\nAnderson, Philip. 1999. “Perspective: Complexity\nTheory and Organization Science.”\nOrganization Science 10 (3): 216–32. https://doi.org/10.1287/orsc.10.3.216.\n\n\nArnaud, M. 2021. “Mixture Modelling from Scratch, in\nR.” Medium.\nhttps://towardsdatascience.com/mixture-modelling-from-scratch-in-r-5ab7bfc83eef.\n\n\nAshby, W. R. 1956. “An Introduction to Cybernetics.” An\nIntroduction to Cybernetics.\n\n\nAttwell, David, and Costantino Iadecola. 2002. “The Neural Basis\nof Functional Brain Imaging Signals.” Trends in\nNeurosciences 25 (12): 621–25. https://doi.org/10.1016/S0166-2236(02)02264-6.\n\n\nAyers, Susan. 1997. “The Application of Chaos\nTheory to Psychology.” Theory &\nPsychology 7 (June): 373. https://doi.org/10.1177/0959354397073005.\n\n\nBak, Per, Chao Tang, and Kurt Wiesenfeld. 1988. “Self-Organized\nCriticality.” Physical Review A 38 (1): 364–74. https://doi.org/10.1103/PhysRevA.38.364.\n\n\nBanks, J., J. Brooks, G. Cairns, G. Davis, and P. Stacey. 1992.\n“On Devaney’s Definition of\nChaos.” The American Mathematical Monthly\n99 (4): 332–34. https://doi.org/10.1080/00029890.1992.11995856.\n\n\nBarceló, Jaume, ed. 2010. Fundamentals of Traffic\nSimulation. Vol. 145. International Series in\nOperations Research & Management Science.\nNew York, NY: Springer New York. https://doi.org/10.1007/978-1-4419-6142-6.\n\n\nBarton, Scott. 1994. “Chaos, Self-Organization, and\nPsychology.” American Psychologist. https://doi.org/10.1037/0003-066X.49.1.5.\n\n\nBechtel, William, and Adele Abrahamsen. 2005. “Explanation: A\nMechanist Alternative.” Studies in History and Philosophy of\nScience Part C: Studies in History and Philosophy of Biological and\nBiomedical Sciences, Mechanisms in biology, 36 (2): 421–41. https://doi.org/10.1016/j.shpsc.2005.03.010.\n\n\nBédard, C., H. Kröger, and A. Destexhe. 2006. “Does the $1/f$\nFrequency Scaling of Brain Signals Reflect\nSelf-Organized Critical States?” Physical Review\nLetters 97 (11): 118102. https://doi.org/10.1103/PhysRevLett.97.118102.\n\n\nBeek, P. J, C. E Peper, and A Daffertshofer. 2002. “Modeling\nRhythmic Interlimb Coordination: Beyond the\nHaken.” Brain and Cognition 48 (1): 149–65.\nhttps://doi.org/10.1006/brcg.2001.1310.\n\n\nBeek, Peter J., and Arthur Lewbel. 1995. “The Science\nof Juggling.” Scientific American 273 (5):\n92–97. https://doi.org/10.1038/scientificamerican1195-92.\n\n\nBentler, P. M. 1970. “Evidence Regarding Stages in\nthe Development of Conservation.”\nPerceptual and Motor Skills 31 (3): 855–59. https://doi.org/10.2466/pms.1970.31.3.855.\n\n\nBerlekamp, Elwyn R., John H. Conway, and Richard K. Guy. 2004.\nWinning Ways for Your Mathematical Plays,\nVolume 4. 2nd ed. New York: A K\nPeters/CRC Press. https://doi.org/10.1201/9780429487309.\n\n\nBertalanffy, Ludwig Von. 1969. General System Theory:\nFoundations, Development,\nApplications. Revised edition. New York,\nNY: George Braziller Inc.\n\n\nBertschinger, Nils, and Thomas Natschläger. 2004. “Real-Time\nComputation at the Edge of Chaos in\nRecurrent Neural Networks.” Neural\nComputation 16 (7): 1413–36. https://doi.org/10.1162/089976604323057443.\n\n\nBoerlijst, M. C., and P. Hogeweg. 1991. “Spiral Wave Structure in\nPre-Biotic Evolution: Hypercycles Stable Against\nParasites.” Physica D: Nonlinear Phenomena 48 (1):\n17–28. https://doi.org/10.1016/0167-2789(91)90049-F.\n\n\nBorsboom, Denny. 2017. “A Network Theory of Mental\nDisorders.” World Psychiatry 16 (1): 5–13. https://doi.org/10.1002/wps.20375.\n\n\nBorsboom, Denny, Han L J van der Maas, Jonas Dalege, Rogier A Kievit,\nand Brian D Haig. 2021. “Theory Construction\nMethodology: A Practical Framework for\nBuilding Theories in Psychology.”\nPerspectives on Psychological Science 16 (4): 756–66. https://doi.org/10.1177/1745691620969647.\n\n\nBorsboom, D., M. Rhemtulla, A. O. J. Cramer, H. L. J. van der Maas, M.\nScheffer, and C. V. Dolan. 2016. “Kinds\nVersus Continua: A Review of Psychometric\nApproaches to Uncover the Structure of Psychiatric Constructs.”\nPsychological Medicine 46 (8): 1567–79. https://doi.org/10.1017/S0033291715001944.\n\n\nBreakspear, Michael. 2017. “Dynamic Models of Large-Scale Brain\nActivity.” Nature Neuroscience 20 (3): 340–52. https://doi.org/10.1038/nn.4497.\n\n\nBrinkhuis, Matthieu J. S., Alexander O. Savi, Abe D. Hofman, Frederik\nCoomans, Han L. J. van der Maas, and Gunter Maris. 2018. “Learning\nAs It Happens: A Decade of\nAnalyzing and Shaping a Large-Scale\nOnline Learning System.” Journal of Learning\nAnalytics 5 (2): 29–46. https://doi.org/10.18608/jla.2018.52.3.\n\n\nBrush, Eleanor R., David C. Krakauer, and Jessica C. Flack. 2018.\n“Conflicts of Interest Improve Collective Computation of Adaptive\nSocial Structures.” Science Advances 4 (1): e1603311. https://doi.org/10.1126/sciadv.1603311.\n\n\nBurg, Gerrit J. J. van den, and Christopher K. I. Williams. 2022.\n“An Evaluation of Change Point Detection\nAlgorithms.” arXiv. https://doi.org/10.48550/arXiv.2003.06222.\n\n\nCastellano, Claudio, Miguel A. Muñoz, and Romualdo Pastor-Satorras.\n2009. “Nonlinear $q$-Voter Model.” Physical Review\nE 80 (4): 041129. https://doi.org/10.1103/PhysRevE.80.041129.\n\n\nCentola, Damon. 2022. “The Network Science of Collective\nIntelligence.” Trends in Cognitive Sciences 26 (11):\n923–41. https://doi.org/10.1016/j.tics.2022.08.009.\n\n\nChalmers, David J. 2006. “Strong and Weak Emergence.”\nhttps://philpapers.org/rec/chasaw.\n\n\nChialvo, Dante R. 2010. “Emergent Complex Neural Dynamics.”\nNature Physics 6 (10): 744–50. https://doi.org/10.1038/nphys1803.\n\n\nClark, Andy. 2013. “Whatever Next? Predictive Brains,\nSituated Agents, and the Future of Cognitive Science.”\nBehavioral and Brain Sciences 36 (3): 181–204. https://doi.org/10.1017/S0140525X12000477.\n\n\nCobb, Loren. 1978. “Stochastic Catastrophe Models and Multimodal\nDistributions.” Behavioral Science 23 (4): 360–74. https://doi.org/10.1002/bs.3830230407.\n\n\nCobb, Loren, and Shelemyahu Zacks. 1985. “Applications of\nCatastrophe Theory for Statistical Modeling in\nthe Biosciences.” Journal of the American\nStatistical Association 80 (392): 793–802. https://doi.org/10.1080/01621459.1985.10478184.\n\n\nCocchi, Luca, Leonardo L. Gollo, Andrew Zalesky, and Michael Breakspear.\n2017. “Criticality in the Brain: A Synthesis of\nNeurobiology, Models and Cognition.” Progress in\nNeurobiology 158 (November): 132–52. https://doi.org/10.1016/j.pneurobio.2017.07.002.\n\n\nCohen, Alexander, David Pargman, and Gershon Tenenbaum. 2003.\n“Critical Elaboration and Empirical\nInvestigation of the Cusp Catastrophe Model: A\nLesson for Practitioners.” Journal of\nApplied Sport Psychology 15 (2): 144–59. https://doi.org/10.1080/10413200305393.\n\n\nCramer, Angélique O. J., Lourens J. Waldorp, Han L. J. van der Maas, and\nDenny Borsboom. 2010. “Comorbidity: A Network Perspective.”\nThe Behavioral and Brain Sciences 33 (2-3): 137-150; discussion\n150-193. https://doi.org/10.1017/S0140525X09991567.\n\n\nDablander, Fabian, Anton Pichler, Arta Cika, and Andrea Bacilieri. 2020.\n“Anticipating Critical Transitions in\nPsychological Systems Using Early Warning\nSignals: Theoretical and Practical\nConsideration.”\n\n\nDakos, Vasilis, Stephen R. Carpenter, William A. Brock, Aaron M.\nEllison, Vishwesha Guttal, Anthony R. Ives, Sonia Kéfi, et al. 2012.\n“Methods for Detecting Early Warnings of Critical Transitions in\nTime Series Illustrated Using Simulated Ecological Data.”\nPloS One 7 (7): e41010. https://doi.org/10.1371/journal.pone.0041010.\n\n\nDalege, Jonas, Denny Borsboom, Frenk van Harreveld, Helma van den Berg,\nMark Conner, and Han L. J. van der Maas. 2016. “Toward a\nFormalized Account of Attitudes: The Causal Attitude\nNetwork (CAN) Model.” Psychological\nReview 123 (1): 2–22. https://doi.org/10.1037/a0039802.\n\n\nDalege, Jonas, Denny Borsboom, Frenk van Harreveld, and Han L. J. van\nder Maas. 2018. “The Attitudinal Entropy\n(AE) Framework as a General Theory of Individual\nAttitudes.” Psychological Inquiry 29 (4): 175–93. https://doi.org/10.1080/1047840X.2018.1537246.\n\n\nDalege, Jonas, and Han L. J. van der Maas. 2020. “Accurate by\nBeing Noisy: A Formal Network Model of Implicit Measures of\nAttitudes.” Social Cognition 38 (Suppl): S26–41. https://doi.org/10.1521/soco.2020.38.supp.s26.\n\n\nde Mooij, Susanne M. M., Tessa F. Blanken, Raoul P. P. P. Grasman,\nJennifer R. Ramautar, Eus J. W. Van Someren, and Han L. J. van der Maas.\n2020. “Dynamics of Sleep: Exploring Critical\nTransitions and Early Warning Signals.” Computer Methods and\nPrograms in Biomedicine 193 (September): 105448. https://doi.org/10.1016/j.cmpb.2020.105448.\n\n\nDodson, M. M., and A. Hallam. 1977. “Allopatric\nSpeciation and the Fold Catastrophe.”\nThe American Naturalist 111 (979): 415–33. https://doi.org/10.1086/283176.\n\n\nDolan, Conor V., and Han L. J. van der Maas. 1998. “Fitting\nMultivariage Normal Finite Mixtures Subject to Structural Equation\nModeling.” Psychometrika 63 (3): 227–53. https://doi.org/10.1007/BF02294853.\n\n\nDresp-Langley, Birgitta. 2020. “Seven Properties of\nSelf-Organization in the Human Brain.”\nBig Data and Cognitive Computing 2 (4): 10.\n\n\nDutilh, Gilles, Eric-Jan Wagenmakers, Ingmar Visser, and van der Han L.\nJ. Maas. 2011. “A Phase Transition Model for the\nSpeed-Accuracy Trade-Off in Response Time\nExperiments.” Cognitive Science 35 (2): 211–50.\nhttps://doi.org/10.1111/j.1551-6709.2010.01147.x.\n\n\nEdelman, Gerald M. 1987. Neural Darwinism:\nThe Theory of Neuronal Group Selection. Neural\nDarwinism: The Theory of Neuronal Group\nSelection. New York, NY, US: Basic Books.\n\n\nEigen, Manfred, and Peter Schuster. 1979. The\nHypercycle. Berlin, Heidelberg:\nSpringer. https://doi.org/10.1007/978-3-642-67247-7.\n\n\nEldredge, Niles, and Stephen Jay Gould. 1972. “Punctuated\nEquilibria: An Alternative to Phyletic\nGradualism.” In Models in\nPaleobiology, edited by Thomas J. M. Schopf, 82–115.\nFreeman Cooper.\n\n\nElo, Arpad E. 1978. The Rating of Chessplayers, Past and\nPresent. New York: Arco Pub.\n\n\nEpskamp, Sacha, Denny Borsboom, and Eiko I. Fried. 2018.\n“Estimating Psychological Networks and Their Accuracy:\nA Tutorial Paper.” Behavior Research\nMethods 50 (1): 195–212. https://doi.org/10.3758/s13428-017-0862-1.\n\n\nEpskamp, Sacha, Han L. J. van der Maas, Roseann E. Peterson, Hanna M.\nvan Loo, Steven H. Aggen, and Kenneth S. Kendler. 2022.\n“Intermediate Stable States in Substance Use.”\nAddictive Behaviors 129 (June): 107252. https://doi.org/10.1016/j.addbeh.2022.107252.\n\n\nEronen, Markus I., and Laura F. Bringmann. 2021. “The Theory\nCrisis in Psychology: How to Move\nForward.” Perspectives on Psychological Science\n16 (4): 779–88. https://doi.org/10.1177/1745691620970586.\n\n\nFestinger, Leon. 1962. A Theory of Cognitive Dissonance. A\nTheory of Cognitive Dissonance. Palo Alto, CA, US:\nStanford Univer. Press.\n\n\nFlack, Jessica C. 2017. “Coarse-Graining as a Downward Causation\nMechanism.” Philosophical Transactions of the Royal Society\nA: Mathematical, Physical and Engineering Sciences 375 (2109):\n20160338. https://doi.org/10.1098/rsta.2016.0338.\n\n\nFodor, J. A. 1974. “Special Sciences (or: The\nDisunity of Science as a Working Hypothesis).” Synthese\n28 (2): 97–115. https://doi.org/10.1007/BF00485230.\n\n\nFowler, James H. 2005. “Second-Order Free-Riding Problem\nSolved?” Nature 437 (7058): E8–8. https://doi.org/10.1038/nature04201.\n\n\nFreitas, Ubiratan, Elise Roulin, Jean-François Muir, and Christophe\nLetellier. 2009. “Identifying Chaos from Heart Rate:\nThe Right Task?” Chaos: An Interdisciplinary\nJournal of Nonlinear Science 19 (2): 028505. https://doi.org/10.1063/1.3139116.\n\n\nFriston, Karl. 2009. “The Free-Energy Principle: A Rough Guide to\nthe Brain?” Trends in Cognitive Sciences 13 (7):\n293–301. https://doi.org/10.1016/j.tics.2009.04.005.\n\n\nFuchs, Armin, and Scott Kelso. 2018. “Coordination\nDynamics and Synergetics: From Finger\nMovements to Brain Patterns and Ballet\nDancing.” In Complexity and\nSynergetics, 301–16. https://doi.org/10.1007/978-3-319-64334-2_23.\n\n\nGalesic, Mirta, Daniel Barkoczi, Andrew M. Berdahl, Dora Biro, Giuseppe\nCarbone, Ilaria Giannoccaro, Robert L. Goldstone, et al. 2023.\n“Beyond Collective Intelligence: Collective\nAdaptation.” Journal of The Royal Society Interface 20\n(200): 20220736. https://doi.org/10.1098/rsif.2022.0736.\n\n\nGhatak, Abhijit. 2019. Deep Learning with\nR. Singapore: Springer. https://doi.org/10.1007/978-981-13-5850-0.\n\n\nGibson, James J. 2014. The Ecological Approach to\nVisual Perception: Classic Edition.\nNew York: Psychology Press. https://doi.org/10.4324/9781315740218.\n\n\nGilmore, Robert. 1993. Catastrophe Theory for\nScientists and Engineers. Courier\nCorporation.\n\n\nGottman, John M., James D. Murray, Catherine C. Swanson, Rebecca Tyson,\nand Kristin R. Swanson. 2002. The Mathematics of Marriage:\nDynamic Nonlinear Models. The Mathematics of Marriage:\nDynamic Nonlinear Models. Cambridge, MA, US:\nMIT Press.\n\n\nGranovetter, M. 1973. “The Strength of Weak Ties.”\nAmerican Journal of Sociology 78 (6): 1360–80. https://doi.org/10.1086/225469.\n\n\nGranovetter, Mark. 1978. “Threshold Models of\nCollective Behavior.” The American Journal of\nSociology 83 (6): 1420–43. https://doi.org/10.1086/226707.\n\n\nGrasman, Raoul, Han L. J. van der Maas, and Eric-Jan Wagenmakers. 2009.\n“Fitting the Cusp Catastrophe in R:\nA Cusp Package Primer.” Journal of\nStatistical Software 032 (i08).\n\n\nGrauwin, Sebastian, Guillaume Beslon, Éric Fleury, Sara Franceschelli,\nCeline Robardet, Jean-Baptiste Rouquier, and Pablo Jensen. 2012.\n“Complex Systems Science: Dreams of Universality,\nInterdisciplinarity Reality.” Journal of the American Society\nfor Information Science and Technology 63 (7): 1327–38. https://doi.org/10.1002/asi.22644.\n\n\nGrossberg, Stephen, and Baingio Pinna. 2012. “Neural\nDynamics of Gestalt Principles of\nPerceptual Organization: From Grouping to\nShape and Meaning.” GESTALT\nTHEORY 34.\n\n\nGuastello, Stephen J. 1982. “Moderator Regression and the Cusp\nCatastrophe: Application of Two-Stage Personnel Selection,\nTraining, Therapy, and Policy Evaluation.” Behavioral\nScience 27 (3): 259–72. https://doi.org/10.1002/bs.3830270305.\n\n\n———. 1984. “Cusp and Butterfly Catastrophe Modeling of Two\nOpponent Process Models: Drug Addiction and Work\nPerformance.” Behavioral Science 29 (4): 258–62. https://doi.org/10.1002/bs.3830290405.\n\n\nGuastello, Stephen J., Matthijs Koopmans, and David Pincus. 2008.\nChaos and Complexity in Psychology:\nThe Theory of Nonlinear Dynamical\nSystems. Cambridge University Press.\n\n\nGuastello, Stephen, Anthony Correro, and David Marra. 2019. “Cusp\nCatastrophe Models for Cognitive Workload and\nFatigue in Teams.” Applied\nErgonomics, September.\n\n\nGuckenheimer, John, and Philip Holmes. 1983. “Global\nBifurcations.” In Nonlinear\nOscillations, Dynamical Systems, and\nBifurcations of Vector Fields, edited by\nJohn Guckenheimer and Philip Holmes, 289–352. Applied Mathematical\nSciences. New York, NY: Springer. https://doi.org/10.1007/978-1-4612-1140-2_6.\n\n\nGüémez, J., C. Fiolhais, and M. Fiolhais. 2002. “The\nCartesian Diver and the Fold Catastrophe.”\nAmerican Journal of Physics 70 (7): 710–14. https://doi.org/10.1119/1.1477433.\n\n\nGuimerà, Roger, Brian Uzzi, Jarrett Spiro, and Luís A. Nunes Amaral.\n2005. “Team Assembly Mechanisms Determine Collaboration\nNetwork Structure and Team Performance.”\nScience 308 (5722): 697–702. https://doi.org/10.1126/science.1106340.\n\n\nHaig, Brian D. 2014. Investigating the Psychological\nWorld: Scientific Method in the Behavioral\nSciences. MIT Press.\n\n\nHaken, Herman. 1977. “Synergetics.” Physics\nBulletin 28 (9): 412. https://doi.org/10.1088/0031-9112/28/9/027.\n\n\nHaken, Hermann. 1992. “Synergetics in\nPsychology.” In Self-Organization\nand Clinical Psychology: Empirical Approaches\nto Synergetics in Psychology, edited by\nWolfgang Tschacher, Günter Schiepek, and Ewald Johannes Brunner, 32–54.\nSpringer Series in Synergetics. Berlin,\nHeidelberg: Springer. https://doi.org/10.1007/978-3-642-77534-5_2.\n\n\nHaken, H., J. A. S. Kelso, and H. Bunz. 1985. “A Theoretical Model\nof Phase Transitions in Human Hand Movements.” Biological\nCybernetics 51 (5): 347–56. https://doi.org/10.1007/BF00336922.\n\n\nHardin, Garrett. 1968. “The Tragedy of the\nCommons” 162.\n\n\nHardy, Lew. 1996. “Testing the Predictions of the\nCusp Catastrophe Model of Anxiety and\nPerformance.” The Sport Psychologist 10\n(2): 140–56. https://doi.org/10.1123/tsp.10.2.140.\n\n\nHeath, Richard A. 2000. Nonlinear Dynamics:\nTechniques and Applications in\nPsychology. 1st edition. Mahwah, N.J:\nPsychology Press.\n\n\nHebb, D. O. 1949. The Organization of Behavior; a Neuropsychological\nTheory. The Organization of Behavior; a Neuropsychological Theory.\nOxford, England: Wiley.\n\n\nHeider, Fritz. 1946. “Attitudes and Cognitive\nOrganization.” The Journal of Psychology 21 (1):\n107–12. https://doi.org/10.1080/00223980.1946.9917275.\n\n\nHelbing, Dirk, and Péter Molnár. 1995. “Social Force Model for\nPedestrian Dynamics.” Physical Review E 51 (5): 4282–86.\nhttps://doi.org/10.1103/PhysRevE.51.4282.\n\n\nHendrikse, Sophie, Jan Treur, and Sander Koole. 2023. “Modeling\nEmerging Interpersonal Synchrony and Its Related\nAdaptive Short-Term Affiliation and Long-Term\nBonding: A Second-Order Multi-Adaptive Neural Agent\nModel.” International Journal of Neural Systems,\nApril. https://doi.org/10.1142/S0129065723500387.\n\n\nHoel, Erik P., Larissa Albantakis, and Giulio Tononi. 2013.\n“Quantifying Causal Emergence Shows That Macro Can Beat\nMicro.” Proceedings of the National Academy of Sciences\n110 (49): 19790–95. https://doi.org/10.1073/pnas.1314922110.\n\n\nHolland, John H. 1992a. “Genetic Algorithms.”\nScientific American 267 (1): 66–73. https://doi.org/10.1038/scientificamerican0792-66.\n\n\n———. 1992b. Adaptation in Natural and Artificial\nSystems: An Introductory Analysis with\nApplications to Biology, Control,\nand Artificial Intelligence. MIT Press.\n\n\nJacobson, Michael J., James A. Levin, and Manu Kapur. 2019.\n“Education as a Complex System:\nConceptual and Methodological\nImplications.” Educational Researcher 48 (2):\n112–19. https://doi.org/10.3102/0013189X19826958.\n\n\nJames, Nicholas A., and David S. Matteson. 2014.\n“Ecp : An\nR Package for Nonparametric\nMultiple Change Point Analysis of Multivariate\nData.” Journal of Statistical Software 62 (7). https://doi.org/10.18637/jss.v062.i07.\n\n\nJansen, Brenda R. J., and Han L. J. Van der Maas. 2001. “Evidence\nfor the Phase Transition from Rule I to\nRule II on the Balance Scale Task.”\nDevelopmental Review 21 (4): 450–94. https://doi.org/10.1006/drev.2001.0530.\n\n\nKalantari, Somayeh, Eslam Nazemi, and Behrooz Masoumi. 2020.\n“Emergence Phenomena in Self-Organizing Systems: A Systematic\nLiterature Review of Concepts, Researches, and Future Prospects.”\nJournal of Organizational Computing and Electronic Commerce 30\n(3): 224–65. https://doi.org/10.1080/10919392.2020.1748977.\n\n\nKauffman, Stuart A. 1993. The Origins of\nOrder: Self-Organization and\nSelection in Evolution. 1st edition.\nNew York: Oxford University Press.\n\n\nKelso, J. A. Scott. 1995. Dynamic Patterns: The\nSelf-Organization of Brain and Behavior. Dynamic Patterns:\nThe Self-Organization of Brain and Behavior.\nCambridge, MA, US: The MIT Press.\n\n\n———. 2021. “The Haken (HKB) Model: From\nMatter to Movement to Mind.” Biological Cybernetics 115\n(4): 305–22. https://doi.org/10.1007/s00422-021-00890-w.\n\n\nKelso, J. A. S., J. P. Scholz, and G. Schöner. 1986.\n“Nonequilibrium Phase Transitions in Coordinated Biological\nMotion: Critical Fluctuations.” Physics Letters A 118\n(6): 279–84. https://doi.org/10.1016/0375-9601(86)90359-2.\n\n\nKim, Jaegwon. 2006. “Emergence: Core Ideas and\nIssues.” Synthese 151 (3): 547–59. https://doi.org/10.1007/s11229-006-9025-0.\n\n\nKlinkenberg, S., M Straatemeier, and H. van der Maas. 2011.\n“Computer Adaptive Practice of Maths Ability Using a\nNew Item Response Model for on the Fly Ability and Difficulty\nEstimation.” Computers & Education 57: 1813–24.\n\n\nKrakauer, David C. 2023. “Symmetrysimplicity, Broken\nSymmetrycomplexity.” Interface Focus 13 (3): 20220075.\nhttps://doi.org/10.1098/rsfs.2022.0075.\n\n\nKruse, Peter, and Michael Stadler. 2012. Ambiguity in\nMind and Nature: Multistable Cognitive\nPhenomena. Springer Science & Business\nMedia.\n\n\nKuramoto, Yoshiki. 1984. “Chemical\nTurbulence.” In Chemical\nOscillations, Waves, and\nTurbulence, edited by Yoshiki Kuramoto, 111–40.\nSpringer Series in Synergetics. Berlin,\nHeidelberg: Springer. https://doi.org/10.1007/978-3-642-69689-3_7.\n\n\nLadyman, James, James Lambert, and Karoline Wiesner. 2013. “What\nIs a Complex System?” European Journal for Philosophy of\nScience 3 (1): 33–67. https://doi.org/10.1007/s13194-012-0056-8.\n\n\nLangton, Chris G. 1990. “Computation at the Edge of Chaos:\nPhase Transitions and Emergent Computation.”\nPhysica D: Nonlinear Phenomena 42 (1): 12–37. https://doi.org/10.1016/0167-2789(90)90064-V.\n\n\nLatané, Bibb, and Andrzej Nowak. 1994. “Attitudes as Catastrophes:\nFrom Dimensions to Categories with Increasing\nInvolvement.” In Dynamical Systems in Social Psychology,\n219–49. San Diego, CA, US: Academic Press.\n\n\nLeemput, van de Ingrid A., Marieke Wichers, Angélique O. J. Cramer,\nDenny Borsboom, Francis Tuerlinckx, Peter Kuppens, van Egbert H. Nes, et\nal. 2014. “Critical Slowing down as Early Warning for the Onset\nand Termination of Depression.” Proceedings of the National\nAcademy of Sciences 111 (1): 87–92. https://doi.org/10.1073/pnas.1312114110.\n\n\nLeggio, Lorenzo, George A. Kenna, Miriam Fenton, Erica Bonenfant, and\nRobert M. Swift. 2009. “Typologies of Alcohol\nDependence. From Jellinek to Genetics\nand Beyond.” Neuropsychology Review 19 (1):\n115–29. https://doi.org/10.1007/s11065-008-9080-z.\n\n\nLei, Min, Zhizhong Wang, and Zhengjin Feng. 2001. “Detecting\nNonlinearity of Action Surface EMG Signal.”\nPhysics Letters A 290 (5): 297–303. https://doi.org/10.1016/S0375-9601(01)00668-5.\n\n\nLemke, Jay L., and Nora H. Sabelli. 2008. “Complex\nSystems and Educational Change:\nTowards a New Research Agenda.” In\nComplexity Theory and the Philosophy of\nEducation, 112–23. John Wiley & Sons,\nLtd. https://doi.org/10.1002/9781444307351.ch8.\n\n\nLoehle, Craig. 1989. “Catastrophe Theory in Ecology: A Critical\nReview and an Example of the Butterfly Catastrophe.”\nEcological Modelling 49 (1): 125–52. https://doi.org/10.1016/0304-3800(89)90047-1.\n\n\nLumsden, James. 1976. “Test Theory.” Annual Review of\nPsychology 27: 251–80. https://doi.org/10.1146/annurev.ps.27.020176.001343.\n\n\nLurie, Daniel J., Daniel Kessler, Danielle S. Bassett, Richard F.\nBetzel, Michael Breakspear, Shella Kheilholz, Aaron Kucyi, et al. 2020.\n“Questions and Controversies in the Study of Time-Varying\nFunctional Connectivity in Resting fMRI.” Network Neuroscience 4 (1):\n30–69. https://doi.org/10.1162/netn_a_00116.\n\n\nMaris, Gunter, and Han van der Maas. 2012. “Speed-Accuracy\nResponse Models: Scoring Rules Based on Response Time and\nAccuracy.” Psychometrika 77 (4): 615–33. https://doi.org/10.1007/s11336-012-9288-y.\n\n\nMazanov, Jason, and D. G. Byrne. 2006. “A Cusp Catastrophe\nModel Analysis of Changes in Adolescent\nSubstance Use: Assessment of Behavioural\nIntention as a Bifurcation Variable.”\nNonlinear Dynamics, Psychology, and Life Sciences 10: 445–70.\n\n\nMcGeer, T. 1990. “Passive Walking with Knees.” In,\nIEEE International Conference on Robotics and\nAutomation Proceedings, 1640–1645 vol.3. https://doi.org/10.1109/ROBOT.1990.126245.\n\n\nMcGrath, Thomas, Andrei Kapishnikov, Nenad Tomašev, Adam Pearce, Martin\nWattenberg, Demis Hassabis, Been Kim, Ulrich Paquet, and Vladimir\nKramnik. 2022. “Acquisition of Chess Knowledge in\nAlphaZero.” Proceedings of the National Academy\nof Sciences 119 (47): e2206625119. https://doi.org/10.1073/pnas.2206625119.\n\n\nMcLachlan, Geoffrey J., Sharon X. Lee, and Suren I. Rathnayake. 2019.\n“Finite Mixture Models.” Annual Review of\nStatistics and Its Application 6 (1): 355–78. https://doi.org/10.1146/annurev-statistics-031017-100325.\n\n\nMcRobie, Allan. 2017. The Seduction of\nCurves: The Lines of Beauty That Connect\nMathematics, Art, and the Nude.\nPrinceton University Press.\n\n\nMichell, Joel. 1999. Measurement in Psychology: A\nCritical History of a Methodological Concept.\nCambridge University Press.\n\n\n———. 2008. “Is Psychometrics Pathological\nScience?” Measurement: Interdisciplinary Research and\nPerspectives 6 (January): 7–24. https://doi.org/10.1080/15366360802035489.\n\n\nMitchell, Melanie. 1998. An Introduction to\nGenetic Algorithms. MIT Press.\n\n\n———. 2009. Complexity: A Guided Tour. Oxford\nUniversity Press.\n\n\nMonroe, Brian M., and Stephen J. Read. 2008. “A General\nConnectionist Model of Attitude Structure and Change: The\nACS (Attitudes as Constraint\nSatisfaction) Model.” Psychological Review 115:\n733–59. https://doi.org/10.1037/0033-295X.115.3.733.\n\n\nMorel, Benoit, and Rangaraj Ramanujam. 1999. “Through the\nLooking Glass of Complexity: The\nDynamics of Organizations as Adaptive\nand Evolving Systems.” Organization Science\n10 (3): 278–93. https://doi.org/10.1287/orsc.10.3.278.\n\n\nO’Byrne, Jordan, and Karim Jerbi. 2022. “How Critical Is Brain\nCriticality?” Trends in Neurosciences 45 (11): 820–37.\nhttps://doi.org/10.1016/j.tins.2022.08.007.\n\n\nOliva, Terence A., Wayne S. Desarbo, Diana L. Day, and Kamel Jedidi.\n1987. “Gemcat: A General Multivariate Methodology for\nEstimating Catastrophe Models.” Behavioral Science 32\n(2): 121–37. https://doi.org/10.1002/bs.3830320205.\n\n\nOlthof, Merlijn, Fred Hasselman, Freek Oude Maatman, Anna M. T. Bosman,\nand Anna Lichtwarck-Aschoff. 2023. “Complexity Theory of\nPsychopathology.” Journal of Psychopathology and Clinical\nScience 132: 314–23. https://doi.org/10.1037/abn0000740.\n\n\nOlthof, Merlijn, Fred Hasselman, Guido Strunk, Marieke van Rooij,\nBenjamin Aas, Marieke A. Helmich, Günter Schiepek, and Anna\nLichtwarck-Aschoff. 2020. “Critical Fluctuations as\nan Early-Warning Signal for Sudden Gains and\nLosses in Patients Receiving Psychotherapy for\nMood Disorders.” Clinical Psychological\nScience 8 (1): 25–35. https://doi.org/10.1177/2167702619865969.\n\n\nOoyen, Arjen van, and Markus Butz-Ostendorf. 2017. The\nRewiring Brain: A Computational Approach to\nStructural Plasticity in the Adult Brain.\nAcademic Press.\n\n\nPaulos, John Allen. 2008. Mathematics and Humor.\nUniversity of Chicago Press.\n\n\nPavlus, John. 2016. “The Clumsy Quest to\nPerfect the Walking Robot.”\nScientific American.\nhttps://www.scientificamerican.com/article/the-clumsy-quest-to-perfect-the-walking-robot/.\nhttps://doi.org/10.1038/scientificamerican0716-60.\n\n\nPerc, Matjaž, Jillian J. Jordan, David G. Rand, Zhen Wang, Stefano\nBoccaletti, and Attila Szolnoki. 2017. “Statistical Physics of\nHuman Cooperation.” Physics Reports, Statistical physics\nof human cooperation, 687 (May): 1–51. https://doi.org/10.1016/j.physrep.2017.05.004.\n\n\nPiaget, Jean. 1952. The Origins of Intelligence in Children.\nEdited by Margaret Cook. The Origins of Intelligence in Children.\nNew York, NY, US: W W Norton & Co. https://doi.org/10.1037/11494-000.\n\n\nPlenz, Dietmar, Tiago L. Ribeiro, Stephanie R. Miller, Patrick A. Kells,\nAli Vakili, and Elliott L. Capek. 2021. “Self-Organized\nCriticality in the Brain.” Frontiers in\nPhysics 9. https://doi.org/10.3389/fphy.2021.639389.\n\n\nPloeger, Annemie, Han L. J. Van Der Maas, and Pascal A. I. Hartelman.\n2002. “Stochastic Catastrophe Analysis of Switches in the\nPerception of Apparent Motion.” Psychonomic Bulletin &\nReview 9 (1): 26–42. https://doi.org/10.3758/BF03196255.\n\n\nPool, Robert. 1989. “Is It Healthy to Be\nChaotic?” Science 243 (4891): 604–7. https://doi.org/10.1126/science.2916117.\n\n\nPort, Robert F., and Timothy Van Gelder. 1995. Mind as\nMotion: Explorations in the\nDynamics of Cognition. MIT\nPress.\n\n\nPoston, Tim, and Ian Stewart. 2014. Catastrophe Theory\nand Its Applications. Courier\nCorporation.\n\n\nPritchard, Walter s., and Dennis w. Duke. 1992. “Measuring\nChaos in the Brain: A Tutorial\nReview of Nonlinear Dynamical Eeg Analysis.”\nInternational Journal of Neuroscience 67 (1-4): 31–80. https://doi.org/10.3109/00207459208994774.\n\n\nReher, Jenna, and Aaron D. Ames. 2021. “Dynamic\nWalking: Toward Agile and Efficient\nBipedal Robots.” Annual Review of Control, Robotics,\nand Autonomous Systems 4 (1): 535–72. https://doi.org/10.1146/annurev-control-071020-045021.\n\n\nRendell, Paul. 2016. “Game of Life Universal Turing\nMachine.” In Turing Machine Universality\nof the Game of Life, edited by Paul\nRendell, 71–89. Emergence, Complexity and\nComputation. Cham: Springer\nInternational Publishing. https://doi.org/10.1007/978-3-319-19842-2_5.\n\n\nRepp, Bruno H., and Yi-Huang Su. 2013. “Sensorimotor\nSynchronization: A Review of Recent Research\n(2006).” Psychonomic Bulletin & Review 20 (3):\n403–52. https://doi.org/10.3758/s13423-012-0371-2.\n\n\nRoberts, James A., Leonardo L. Gollo, Romesh G. Abeysuriya, Gloria\nRoberts, Philip B. Mitchell, Mark W. Woolrich, and Michael Breakspear.\n2019. “Metastable Brain Waves.” Nature\nCommunications 10 (1): 1056. https://doi.org/10.1038/s41467-019-08999-0.\n\n\nRobertson, Robin, and Allan Combs, eds. 2014. Chaos Theory in\nPsychology and the Life Sciences.\nNew York: Psychology Press. https://doi.org/10.4324/9781315806280.\n\n\nRobinaugh, Donald J., Ria H. A. Hoekstra, Emma R. Toner, and Denny\nBorsboom. 2020. “The Network Approach to Psychopathology: A Review\nof the Literature 2008 and an Agenda for Future Research.”\nPsychological Medicine 50 (3): 353–66. https://doi.org/10.1017/S0033291719003404.\n\n\nRosser, J. Barkley. 2007. “The Rise and Fall of Catastrophe Theory\nApplications in Economics: Was the Baby Thrown Out with the\nBathwater?” Journal of Economic Dynamics and Control 31\n(10): 3255–80. https://doi.org/10.1016/j.jedc.2006.09.013.\n\n\nSandubete, Julio, E., and Lorenzo Escot. 2021.\n“DChaos: An R Package for Chaotic\nTime Series Analysis.” The R Journal 13 (1): 232.\nhttps://doi.org/10.32614/RJ-2021-036.\n\n\nSavi, Alexander O., Maarten Marsman, Han L. J. van der Maas, and Gunter\nK. J. Maris. 2019. “The Wiring of\nIntelligence.” Perspectives on Psychological\nScience 14 (6): 1034–61. https://doi.org/10.1177/1745691619866447.\n\n\nScheffer, Marten. 2004. Ecology of Shallow Lakes.\nDordrecht: Springer Netherlands. https://doi.org/10.1007/978-1-4020-3154-0.\n\n\nSchelling, Thomas C. 1971. “Dynamic Models of Segregation.”\nThe Journal of Mathematical Sociology 1 (2): 143–86. https://doi.org/10.1080/0022250X.1971.9989794.\n\n\nSchiepek, Günter, and Volker Perlitz. 2009.\n“Self-Organization in Clinical\nPsychology.” In Synergetics, edited by Axel Hutt\nand Hermann Haken, 263–85. New York, NY: Springer\nUS. https://doi.org/10.1007/978-1-0716-0421-2_472.\n\n\nSchmidhuber, Jürgen. 2015. “Deep Learning in Neural Networks:\nAn Overview.” Neural Networks 61 (January):\n85–117. https://doi.org/10.1016/j.neunet.2014.09.003.\n\n\nSchmidt, R. C., C. Carello, and M. T. Turvey. 1990. “Phase\nTransitions and Critical Fluctuations in the Visual Coordination of\nRhythmic Movements Between People.” Journal of Experimental\nPsychology. Human Perception and Performance 16 (2): 227–47. https://doi.org/10.1037//0096-1523.16.2.227.\n\n\nSchöner, Gregor. 2020. “The Dynamics of Neural\nPopulations Capture the Laws of the\nMind.” Topics in Cognitive Science 12 (4):\n1257–71. https://doi.org/10.1111/tops.12453.\n\n\nSchöner, Gregor, and John P. Spencer. 2016. Dynamic Thinking:\nA Primer on Dynamic Field Theory. Oxford\nUniversity Press.\n\n\nScott, John. 2011. “Social Network Analysis: Developments,\nAdvances, and Prospects.” Social Network Analysis and\nMining 1 (1): 21–26. https://doi.org/10.1007/s13278-010-0012-6.\n\n\nSerra, Roberto, and Gianni Zanarini. 1990. Complex\nSystems and Cognitive Processes.\nBerlin, Heidelberg: Springer. https://doi.org/10.1007/978-3-642-46678-6.\n\n\nSilver, David, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou,\nMatthew Lai, Arthur Guez, Marc Lanctot, et al. 2018. “A General\nReinforcement Learning Algorithm That Masters Chess, Shogi, and\nGo Through Self-Play.” Science 362 (6419):\n1140–44. https://doi.org/10.1126/science.aar6404.\n\n\nSimon, Herbert A. 1962. “The Architecture of\nComplexity.” Proceedings of the American\nPhilosophical Society 106 (6): 467–82. https://www.jstor.org/stable/985254.\n\n\nSkarda, Christine A., and Walter J. Freeman. 1987. “How Brains\nMake Chaos in Order to Make Sense of the World.” Behavioral\nand Brain Sciences 10 (2): 161–73. https://doi.org/10.1017/S0140525X00047336.\n\n\nSmolensky, Paul. 1986. “Information Processing in\nDynamical Systems: Foundations of\nHarmony Theory.”\n\n\nSnijders, Tom A. B. 2001. “The Statistical Evaluation\nof Social Network Dynamics.” Sociological\nMethodology 31 (1): 361–95. https://doi.org/10.1111/0081-1750.00099.\n\n\nStefan, Martin. 2020. “RPubs - Fractals\nwith R.” https://rpubs.com/mstefan-rpubs/fractals.\n\n\nStengers, Isabelle, and Ilya Prigogine. 1978. Order Out\nof Chaos: Man’s New Dialogue with\nNature. London.\n\n\nStewart, Ian. 1982. “Catastrophe Theory in Physics.”\nReports on Progress in Physics 45 (2): 185–221. https://doi.org/10.1088/0034-4885/45/2/002.\n\n\nStewart, Ian, and P. L. Peregoy. 1983. “Catastrophe Theory\nModeling in Psychology.” Psychological Bulletin 94:\n336–62. https://doi.org/10.1037/0033-2909.94.2.336.\n\n\nStouffer, Samuel A., Edward A. Suchman, Leland C. Devinney, Shirley A.\nStar, and Robin M. Williams Jr. 1949. The American\nSoldier: Adjustment During Army Life. (Studies\nin Social Psychology in World War II), Vol.\n1. The American Soldier: Adjustment\nDuring Army Life. (Studies in Social Psychology in\nWorld War II), Vol. 1. Oxford,\nEngland: Princeton Univ. Press.\n\n\nSurowiecki, James. 2005. The Wisdom of\nCrowds. Knopf Doubleday Publishing Group.\n\n\nSutton, Richard S., and Andrew G. Barto. 2018. Reinforcement\nLearning, Second Edition: An\nIntroduction. MIT Press.\n\n\nTesfatsion, Leigh. 2002. “Agent-Based Computational\nEconomics: Growing Economies From the Bottom\nUp.” Artificial Life 8 (1): 55–82. https://doi.org/10.1162/106454602753694765.\n\n\nThelen, Esther. 1995. “Motor Development: A New\nSynthesis.” American Psychologist 50: 79–95. https://doi.org/10.1037/0003-066X.50.2.79.\n\n\nThelen, Esther, and Linda B. Smith. 1994. A Dynamic Systems\nApproach to the Development of\nCognition and Action. MIT\nPress.\n\n\nThom, René. 1977. “Structural Stability,\nCatastrophe Theory, and Applied\nMathematics.” SIAM Review 19 (2): 189–201. https://doi.org/10.1137/1019036.\n\n\nToker, Daniel, Friedrich T. Sommer, and Mark D’Esposito. 2020. “A\nSimple Method for Detecting Chaos in Nature.” Communications\nBiology 3 (1): 1–13. https://doi.org/10.1038/s42003-019-0715-9.\n\n\nTreiber, Martin, Ansgar Hennecke, and Dirk Helbing. 2000.\n“Congested Traffic States in Empirical Observations and\nMicroscopic Simulations.” Physical Review E 62 (2):\n1805–24. https://doi.org/10.1103/PhysRevE.62.1805.\n\n\nVallacher, Robin R., and Andrzej Nowak, eds. 1994. Dynamical Systems\nin Social Psychology. Dynamical Systems in Social Psychology.\nSan Diego, CA, US: Academic Press.\n\n\nvan der Maas, H. L. J. 1995. “Beyond the Metaphor?”\nCognitive Development 10.\n\n\nVan Der Maas, Han L. J., Conor V. Dolan, Raoul P. P. P. Grasman, Jelte\nM. Wicherts, Hilde M. Huizenga, and Maartje E. J. Raijmakers. 2006.\n“A Dynamical Model of General Intelligence: The\nPositive Manifold of Intelligence by Mutualism.”\nPsychological Review 113 (4): 842–61. https://doi.org/c3jm44.\n\n\nvan der Maas, Han L. J., Rogier Kolstein, and Joop van der Pligt. 2003.\n“Sudden Transitions in\nAttitudes.” Sociological Methods &\nResearch 32 (2): 125–52. https://doi.org/10.1177/0049124103253773.\n\n\nvan der Maas, Han L. J., Lukas Snoek, and Claire E. Stevenson. 2021.\n“How Much Intelligence Is There in Artificial Intelligence?\nA 2020 Update.” Intelligence 87 (July):\n101548. https://doi.org/10.1016/j.intell.2021.101548.\n\n\nvan der Maas, Han L. J., Paul F. M. J. Verschure, and Peter C. M.\nMolenaar. 1990. “A Note on Chaotic Behavior in Simple Neural\nNetworks.” Neural Networks 3 (1): 119–22. https://doi.org/10.1016/0893-6080(90)90050-U.\n\n\nVan der Maas, Han L., and Peter C. Molenaar. 1992. “Stagewise\nCognitive Development: An Application of Catastrophe\nTheory.” Psychological Review 99 (3): 395–417. https://doi.org/10.1037/0033-295X.99.3.395.\n\n\nVisser, Ingmar, and Maarten Speekenbrink. 2022. Mixture and\nHidden Markov Models with R.\nSpringer International Publishing.\n\n\nVolberda, Henk W., and Arie Y. Lewin. 2003. “Co-Evolutionary\nDynamics Within and Between Firms: From\nEvolution to Co-evolution.”\nJournal of Management Studies 40 (8): 2111–36. https://doi.org/10.1046/j.1467-6486.2003.00414.x.\n\n\nWagemans, Johan, James H. Elder, Michael Kubovy, Stephen E. Palmer, Mary\nA. Peterson, Manish Singh, and Rüdiger von der Heydt. 2012. “A\nCentury of Gestalt Psychology in Visual Perception:\nI. Perceptual Grouping and Figureground\nOrganization.” Psychological Bulletin 138: 1172–1217. https://doi.org/10.1037/a0029333.\n\n\nWagenmakers, Eric-Jan, Peter C. M. Molenaar, Raoul P. P. P. Grasman,\nPascal A. I. Hartelman, and Han L. J. van der Maas. 2005.\n“Transformation Invariant Stochastic Catastrophe Theory.”\nPhysica D: Nonlinear Phenomena 211 (3): 263–76. https://doi.org/10.1016/j.physd.2005.08.014.\n\n\nWeaver, Warren. 1948. “Science and\nComplexity.” American Scientist 36 (4):\n536–44. https://www.jstor.org/stable/27826254.\n\n\nWichers, Marieke, Peter C. Groot, and ESM Group Psychosystems. 2016.\n“Critical Slowing Down as a Personalized Early\nWarning Signal for Depression.”\nPsychotherapy and Psychosomatics 85 (2): 114–16. https://doi.org/10.1159/000441458.\n\n\nWiener, Norbert. 2019. Cybernetics or Control and\nCommunication in the Animal and the\nMachine, Reissue of the 1961 Second\nEdition. MIT Press.\n\n\nWilensky, Uri, and William Rand. 2015. An Introduction to\nAgent-Based Modeling: Modeling Natural, Social, and Engineered Complex\nSystems with NetLogo. Cambridge,\nMassachusetts: The MIT Press.\n\n\nWitkiewitz, Katie, Han L. J. van der Maas, Michael R. Hufford, and G.\nAlan Marlatt. 2007. “Nonnormality and Divergence in Posttreatment\nAlcohol Use: Reexamining the Project MATCH\nData \"Another Way.\".” Journal of Abnormal Psychology\n116: 378–94. https://doi.org/10.1037/0021-843X.116.2.378.\n\n\nXue, Jiankai, and Bo Shen. 2020. “A Novel Swarm Intelligence\nOptimization Approach: Sparrow Search Algorithm.” Systems\nScience & Control Engineering 8 (1): 22–34. https://doi.org/10.1080/21642583.2019.1708830.\n\n\nZahler, Raphael S., and Hector J. Sussmann. 1977. “Claims and\nAccomplishments of Applied Catastrophe Theory.” Nature\n269 (October): 759–63. https://doi.org/10.1038/269759a0.\n\n\nZeeman, E. C. 1976. “Catastrophe Theory.”\nScientific American 234 (4): 65–83."
  }
]